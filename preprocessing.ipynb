{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set stopwords language\n",
    "stop_words = stopwords.words('english')\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Token Before =  artificial intelligence (ai) is intelligence demonstrated by machines, unlike the natural intelligence displayed by humans and animals, which involves\n",
      "Cleaned Token After =  artificial intelligence ( ai ) intelligence demonstrated machines , unlike natural intelligence displayed humans animals , involves \n",
      "Cleaned Token After Stem =  artifici intellig ( ai ) intellig demonstr machin , unlik natur intellig display human anim , involv \n",
      "Cleaned Token Before =  a.i. artificial intelligence (also known as a.i.) is a 2001 american science fiction drama film directed by steven spielberg. the screenplay by spielberg\n",
      "Cleaned Token After =  a.i . artificial intelligence ( also known a.i . ) 2001 american science fiction drama film directed steven spielberg . screenplay spielberg \n",
      "Cleaned Token After Stem =  a.i . artifici intellig ( also known a.i . ) 2001 american scienc fiction drama film direct steven spielberg . screenplay spielberg \n",
      "Cleaned Token Before =  artificial general intelligence (agi) is the hypothetical ability of an intelligent agent to understand or learn any intellectual task that a human being\n",
      "Cleaned Token After =  artificial general intelligence ( agi ) hypothetical ability intelligent agent understand learn intellectual task human \n",
      "Cleaned Token After Stem =  artifici gener intellig ( agi ) hypothet abil intellig agent understand learn intellectu task human \n",
      "Cleaned Token Before =  artificial intelligence, defined as intelligence exhibited by machines, has many applications in today's society. more specifically, it is weak ai, the\n",
      "Cleaned Token After =  artificial intelligence , defined intelligence exhibited machines , many applications today 's society . specifically , weak ai , \n",
      "Cleaned Token After Stem =  artifici intellig , defin intellig exhibit machin , mani applic today 's societi . specif , weak ai , \n",
      "Cleaned Token Before =  artificial intelligence in healthcare, known also as deep medicine, is an overarching term used to describe the use of machine-learning algorithms and\n",
      "Cleaned Token After =  artificial intelligence healthcare , known also deep medicine , overarching term used describe use machine-learning algorithms \n",
      "Cleaned Token After Stem =  artifici intellig healthcar , known also deep medicin , overarch term use describ use machine-learn algorithm \n",
      "Cleaned Token Before =  the philosophy of artificial intelligence is a branch of the philosophy of technology that explores artificial intelligence and its implications for knowledge\n",
      "Cleaned Token After =  philosophy artificial intelligence branch philosophy technology explores artificial intelligence implications knowledge \n",
      "Cleaned Token After Stem =  philosophi artifici intellig branch philosophi technolog explor artifici intellig implic knowledg \n",
      "Cleaned Token Before =  the ethics of artificial intelligence is the branch of the ethics of technology specific to artificially intelligent systems. it is sometimes divided into\n",
      "Cleaned Token After =  ethics artificial intelligence branch ethics technology specific artificially intelligent systems . sometimes divided \n",
      "Cleaned Token After Stem =  ethic artifici intellig branch ethic technolog specif artifici intellig system . sometim divid \n",
      "Cleaned Token Before =  in video games, artificial intelligence (ai) is used to generate responsive, adaptive or intelligent behaviors primarily in non-player characters (npcs)\n",
      "Cleaned Token After =  video games , artificial intelligence ( ai ) used generate responsive , adaptive intelligent behaviors primarily non-player characters ( npcs ) \n",
      "Cleaned Token After Stem =  video game , artifici intellig ( ai ) use gener respons , adapt intellig behavior primarili non-play charact ( npc ) \n",
      "Cleaned Token Before =  artificial intelligence marketing (aim) is a form of marketing leveraging artificial intelligence concept and model such as machine learning and bayesian\n",
      "Cleaned Token After =  artificial intelligence marketing ( aim ) form marketing leveraging artificial intelligence concept model machine learning bayesian \n",
      "Cleaned Token After Stem =  artifici intellig market ( aim ) form market leverag artifici intellig concept model machin learn bayesian \n",
      "Cleaned Token Before =  provided as an overview of and topical guide to artificial intelligence: artificial intelligence (ai) – intelligence exhibited by machines or software. it is\n",
      "Cleaned Token After =  provided overview topical guide artificial intelligence : artificial intelligence ( ai ) – intelligence exhibited machines software . \n",
      "Cleaned Token After Stem =  provid overview topic guid artifici intellig : artifici intellig ( ai ) – intellig exhibit machin softwar . \n",
      "Cleaned Token Before =  existential risk from artificial general intelligence is the hypothesis that substantial progress in artificial general intelligence (agi) could someday\n",
      "Cleaned Token After =  existential risk artificial general intelligence hypothesis substantial progress artificial general intelligence ( agi ) could someday \n",
      "Cleaned Token After Stem =  existenti risk artifici gener intellig hypothesi substanti progress artifici gener intellig ( agi ) could someday \n",
      "Cleaned Token Before =  history of artificial intelligence (ai) began in antiquity, with myths, stories and rumors of artificial beings endowed with intelligence or consciousness\n",
      "Cleaned Token After =  history artificial intelligence ( ai ) began antiquity , myths , stories rumors artificial beings endowed intelligence consciousness \n",
      "Cleaned Token After Stem =  histori artifici intellig ( ai ) began antiqu , myth , stori rumor artifici be endow intellig conscious \n",
      "Cleaned Token Before =  this is a timeline of artificial intelligence. timeline of machine translation timeline of machine learning mccorduck 2004, pp. 4–5 mccorduck (2004, pp\n",
      "Cleaned Token After =  timeline artificial intelligence . timeline machine translation timeline machine learning mccorduck 2004 , pp . 4–5 mccorduck ( 2004 , pp \n",
      "Cleaned Token After Stem =  timelin artifici intellig . timelin machin translat timelin machin learn mccorduck 2004 , pp . 4–5 mccorduck ( 2004 , pp \n",
      "Cleaned Token Before =  explainable ai (xai) is artificial intelligence (ai) in which the results of the solution can be understood by humans. it contrasts with the concept of\n",
      "Cleaned Token After =  explainable ai ( xai ) artificial intelligence ( ai ) results solution understood humans . contrasts concept \n",
      "Cleaned Token After Stem =  explain ai ( xai ) artifici intellig ( ai ) result solut understood human . contrast concept \n",
      "Cleaned Token Before =  friendly artificial intelligence (also friendly ai or fai) refers to hypothetical artificial general intelligence (agi) that would have a positive (benign)\n",
      "Cleaned Token After =  friendly artificial intelligence ( also friendly ai fai ) refers hypothetical artificial general intelligence ( agi ) would positive ( benign ) \n",
      "Cleaned Token After Stem =  friendli artifici intellig ( also friendli ai fai ) refer hypothet artifici gener intellig ( agi ) would posit ( benign ) \n",
      "Cleaned Token Before =  artificial intelligence is the intelligence exhibited by machines and software. artificial intelligence may also refer to: artificial intelligence, a 1997\n",
      "Cleaned Token After =  artificial intelligence intelligence exhibited machines software . artificial intelligence may also refer : artificial intelligence , 1997 \n",
      "Cleaned Token After Stem =  artifici intellig intellig exhibit machin softwar . artifici intellig may also refer : artifici intellig , 1997 \n",
      "Cleaned Token Before =  regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating artificial intelligence (ai); it is\n",
      "Cleaned Token After =  regulation artificial intelligence development public sector policies laws promoting regulating artificial intelligence ( ai ) ; \n",
      "Cleaned Token After Stem =  regul artifici intellig develop public sector polici law promot regul artifici intellig ( ai ) ; \n",
      "Cleaned Token Before =  artificial intelligence applications have been used in a wide range of fields including medical diagnosis, stock trading, robot control, law, scientific\n",
      "Cleaned Token After =  artificial intelligence applications used wide range fields including medical diagnosis , stock trading , robot control , law , scientific \n",
      "Cleaned Token After Stem =  artifici intellig applic use wide rang field includ medic diagnosi , stock trade , robot control , law , scientif \n",
      "Cleaned Token Before =  military artificial intelligence arms race is a competition between two or more states to have their military forces equipped with the best artificial intelligence\n",
      "Cleaned Token After =  military artificial intelligence arms race competition two states military forces equipped best artificial intelligence \n",
      "Cleaned Token After Stem =  militari artifici intellig arm race competit two state militari forc equip best artifici intellig \n",
      "Cleaned Token Before =  artificial intelligence is a recurrent theme in science fiction, whether utopian, emphasising the potential benefits, or dystopian, emphasising the dangers\n",
      "Cleaned Token After =  artificial intelligence recurrent theme science fiction , whether utopian , emphasising potential benefits , dystopian , emphasising dangers \n",
      "Cleaned Token After Stem =  artifici intellig recurr theme scienc fiction , whether utopian , emphasis potenti benefit , dystopian , emphasis danger \n",
      "Cleaned Token Before =  films which included artificial intelligence either as a protagonist or as an essential part of the film. artificial intelligence in fiction hogan, michael;\n",
      "Cleaned Token After =  films included artificial intelligence either protagonist essential part film . artificial intelligence fiction hogan , michael ; \n",
      "Cleaned Token After Stem =  film includ artifici intellig either protagonist essenti part film . artifici intellig fiction hogan , michael ; \n",
      "Cleaned Token Before =  this glossary of artificial intelligence is a list of definitions of terms and concepts relevant to the study of artificial intelligence, its sub-disciplines\n",
      "Cleaned Token After =  glossary artificial intelligence list definitions terms concepts relevant study artificial intelligence , sub-disciplines \n",
      "Cleaned Token After Stem =  glossari artifici intellig list definit term concept relev studi artifici intellig , sub-disciplin \n",
      "Cleaned Token Before =  symbolic artificial intelligence is the term for the collection of all methods in artificial intelligence research that are based on high-level \"symbolic\"\n",
      "Cleaned Token After =  symbolic artificial intelligence term collection methods artificial intelligence research based high-level `` symbolic '' \n",
      "Cleaned Token After Stem =  symbol artifici intellig term collect method artifici intellig research base high-level `` symbol `` \n",
      "Cleaned Token Before =  a superhuman intelligence were to be invented—either through the amplification of human intelligence or through artificial intelligence—it would bring\n",
      "Cleaned Token After =  superhuman intelligence invented—either amplification human intelligence artificial intelligence—it would bring \n",
      "Cleaned Token After Stem =  superhuman intellig invented—eith amplif human intellig artifici intelligence—it would bring \n",
      "Cleaned Token Before =  distributed artificial intelligence (dai) also called decentralized artificial intelligence is a subfield of artificial intelligence research dedicated\n",
      "Cleaned Token After =  distributed artificial intelligence ( dai ) also called decentralized artificial intelligence subfield artificial intelligence research dedicated \n",
      "Cleaned Token After Stem =  distribut artifici intellig ( dai ) also call decentr artifici intellig subfield artifici intellig research dedic \n",
      "Cleaned Token Before =  swarm intelligence (si) is the collective behavior of decentralized, self-organized systems, natural or artificial. the concept is employed in work on\n",
      "Cleaned Token After =  swarm intelligence ( si ) collective behavior decentralized , self-organized systems , natural artificial . concept employed work \n",
      "Cleaned Token After Stem =  swarm intellig ( si ) collect behavior decentr , self-organ system , natur artifici . concept employ work \n",
      "Cleaned Token Before =  artificial intelligence researchers have developed several specialized programming languages for artificial intelligence: aiml (meaning \"artificial intelligence\n",
      "Cleaned Token After =  artificial intelligence researchers developed several specialized programming languages artificial intelligence : aiml ( meaning `` artificial intelligence \n",
      "Cleaned Token After Stem =  artifici intellig research develop sever special program languag artifici intellig : aiml ( mean `` artifici intellig \n",
      "Cleaned Token Before =  creativity and general intelligence, personality type, mental and neural processes, mental health, or artificial intelligence; the potential for fostering\n",
      "Cleaned Token After =  creativity general intelligence , personality type , mental neural processes , mental health , artificial intelligence ; potential fostering \n",
      "Cleaned Token After Stem =  creativ gener intellig , person type , mental neural process , mental health , artifici intellig ; potenti foster \n",
      "Cleaned Token Before =  forms of life exhibit intelligence. intelligence in computers or other machines is called artificial intelligence. the word intelligence derives from the latin\n",
      "Cleaned Token After =  forms life exhibit intelligence . intelligence computers machines called artificial intelligence . word intelligence derives latin \n",
      "Cleaned Token After Stem =  form life exhibit intellig . intellig comput machin call artifici intellig . word intellig deriv latin \n",
      "Cleaned Token Before =  quantum artificial intelligence (qai) is an interdisciplinary field that focuses on building quantum algorithms for improving computational tasks within\n",
      "Cleaned Token After =  quantum artificial intelligence ( qai ) interdisciplinary field focuses building quantum algorithms improving computational tasks within \n",
      "Cleaned Token After Stem =  quantum artifici intellig ( qai ) interdisciplinari field focus build quantum algorithm improv comput task within \n",
      "Cleaned Token Before =  artificial intelligence art refers to any artwork created using artificial intelligence software. one of the first significant ai artists was harold cohen\n",
      "Cleaned Token After =  artificial intelligence art refers artwork created using artificial intelligence software . one first significant ai artists harold cohen \n",
      "Cleaned Token After Stem =  artifici intellig art refer artwork creat use artifici intellig softwar . one first signific ai artist harold cohen \n",
      "Cleaned Token Before =  artificial intelligence: a guide for thinking humans is a 2019 nonfiction book by portland state computer science professor melanie mitchell. the book\n",
      "Cleaned Token After =  artificial intelligence : guide thinking humans 2019 nonfiction book portland state computer science professor melanie mitchell . book \n",
      "Cleaned Token After Stem =  artifici intellig : guid think human 2019 nonfict book portland state comput scienc professor melani mitchel . book \n",
      "Cleaned Token Before =  research in artificial intelligence (ai) is known to have impacted medical diagnosis, stock trading, robot control, and several other fields. perhaps\n",
      "Cleaned Token After =  research artificial intelligence ( ai ) known impacted medical diagnosis , stock trading , robot control , several fields . perhaps \n",
      "Cleaned Token After Stem =  research artifici intellig ( ai ) known impact medic diagnosi , stock trade , robot control , sever field . perhap \n",
      "Cleaned Token Before =  frames are an artificial intelligence data structure used to divide knowledge into substructures by representing \"stereotyped situations\". they were proposed\n",
      "Cleaned Token After =  frames artificial intelligence data structure used divide knowledge substructures representing `` stereotyped situations '' . proposed \n",
      "Cleaned Token After Stem =  frame artifici intellig data structur use divid knowledg substructur repres `` stereotyp situat `` . propos \n",
      "Cleaned Token Before =  in artificial intelligence, an intelligent agent (ia) refers to an autonomous entity which acts, directing its activity towards achieving goals (i.e.\n",
      "Cleaned Token After =  artificial intelligence , intelligent agent ( ia ) refers autonomous entity acts , directing activity towards achieving goals ( i.e . \n",
      "Cleaned Token After Stem =  artifici intellig , intellig agent ( ia ) refer autonom entiti act , direct activ toward achiev goal ( i.e . \n",
      "Cleaned Token Before =  tay was an artificial intelligence chatter bot that was originally released by microsoft corporation via twitter on march 23, 2016; it caused subsequent\n",
      "Cleaned Token After =  tay artificial intelligence chatter bot originally released microsoft corporation via twitter march 23 , 2016 ; caused subsequent \n",
      "Cleaned Token After Stem =  tay artifici intellig chatter bot origin releas microsoft corpor via twitter march 23 , 2016 ; caus subsequ \n",
      "Cleaned Token Before =  artificial intelligence is a compilation album released via warp on 6 july 1992. it is the first release in warp's artificial intelligence series. the\n",
      "Cleaned Token After =  artificial intelligence compilation album released via warp 6 july 1992. first release warp 's artificial intelligence series . \n",
      "Cleaned Token After Stem =  artifici intellig compil album releas via warp 6 juli 1992. first releas warp 's artifici intellig seri . \n",
      "Cleaned Token Before =  mit computer science and artificial intelligence laboratory (csail) is a research institute at the massachusetts institute of technology (mit) formed\n",
      "Cleaned Token After =  mit computer science artificial intelligence laboratory ( csail ) research institute massachusetts institute technology ( mit ) formed \n",
      "Cleaned Token After Stem =  mit comput scienc artifici intellig laboratori ( csail ) research institut massachusett institut technolog ( mit ) form \n",
      "Cleaned Token Before =  the artificial intelligence of things (aiot) is the combination of artificial intelligence (ai) technologies with the internet of things (iot) infrastructure\n",
      "Cleaned Token After =  artificial intelligence things ( aiot ) combination artificial intelligence ( ai ) technologies internet things ( iot ) infrastructure \n",
      "Cleaned Token After Stem =  artifici intellig thing ( aiot ) combin artifici intellig ( ai ) technolog internet thing ( iot ) infrastructur \n",
      "Cleaned Token Before =  isbn 978-1-4673-1736-8. s2cid 419179. millington; funge (2009). artificial intelligence for games. crc press. isbn 978-0-12-374731-0. rabin, s. (2014)\n",
      "Cleaned Token After =  isbn 978-1-4673-1736-8. s2cid 419179. millington ; funge ( 2009 ) . artificial intelligence games . crc press . isbn 978-0-12-374731-0. rabin , s. ( 2014 ) \n",
      "Cleaned Token After Stem =  isbn 978-1-4673-1736-8. s2cid 419179. millington ; fung ( 2009 ) . artifici intellig game . crc press . isbn 978-0-12-374731-0. rabin , s. ( 2014 ) \n",
      "Cleaned Token Before =  artificial intelligence (aaai) is an international scientific society devoted to promote research in, and responsible use of, artificial intelligence\n",
      "Cleaned Token After =  artificial intelligence ( aaai ) international scientific society devoted promote research , responsible use , artificial intelligence \n",
      "Cleaned Token After Stem =  artifici intellig ( aaai ) intern scientif societi devot promot research , respons use , artifici intellig \n",
      "Cleaned Token Before =  artificial intelligence: a modern approach (aima) is a university textbook on artificial intelligence, written by stuart j. russell and peter norvig.\n",
      "Cleaned Token After =  artificial intelligence : modern approach ( aima ) university textbook artificial intelligence , written stuart j. russell peter norvig . \n",
      "Cleaned Token After Stem =  artifici intellig : modern approach ( aima ) univers textbook artifici intellig , written stuart j. russel peter norvig . \n",
      "Cleaned Token Before =  this article discusses computational tools used in artificial intelligence. many problems in ai can be solved theoretically by intelligently searching\n",
      "Cleaned Token After =  article discusses computational tools used artificial intelligence . many problems ai solved theoretically intelligently searching \n",
      "Cleaned Token After Stem =  articl discuss comput tool use artifici intellig . mani problem ai solv theoret intellig search \n",
      "Cleaned Token Before =  treatment regimes error-driven learning multi-agent system distributed artificial intelligence intrinsic motivation genetic algorithms apprenticeship learning\n",
      "Cleaned Token After =  treatment regimes error-driven learning multi-agent system distributed artificial intelligence intrinsic motivation genetic algorithms apprenticeship learning \n",
      "Cleaned Token After Stem =  treatment regim error-driven learn multi-ag system distribut artifici intellig intrins motiv genet algorithm apprenticeship learn \n",
      "Cleaned Token Before =  artificial intelligence system (ais) was a distributed computing project undertaken by intelligence realm, inc. with the long-term goal of simulating\n",
      "Cleaned Token After =  artificial intelligence system ( ais ) distributed computing project undertaken intelligence realm , inc. long-term goal simulating \n",
      "Cleaned Token After Stem =  artifici intellig system ( ai ) distribut comput project undertaken intellig realm , inc. long-term goal simul \n",
      "Cleaned Token Before =  artificial heart or artificial intelligence. political scientist and artificial intelligence expert herbert a. simon observes that \"some artificial things\n",
      "Cleaned Token After =  artificial heart artificial intelligence . political scientist artificial intelligence expert herbert a. simon observes `` artificial things \n",
      "Cleaned Token After Stem =  artifici heart artifici intellig . polit scientist artifici intellig expert herbert a. simon observ `` artifici thing \n",
      "Cleaned Token Before =  through experience and by the use of data. it is seen as a part of artificial intelligence. machine learning algorithms build a model based on sample data\n",
      "Cleaned Token After =  experience use data . seen part artificial intelligence . machine learning algorithms build model based sample data \n",
      "Cleaned Token After Stem =  experi use data . seen part artifici intellig . machin learn algorithm build model base sampl data \n",
      "Cleaned Token Before =  advertising solutions. artificial intelligence blue gene commonsense knowledge (artificial intelligence) glossary of artificial intelligence strong ai tech companies\n",
      "Cleaned Token After =  advertising solutions . artificial intelligence blue gene commonsense knowledge ( artificial intelligence ) glossary artificial intelligence strong ai tech companies \n",
      "Cleaned Token After Stem =  advertis solut . artifici intellig blue gene commonsens knowledg ( artifici intellig ) glossari artifici intellig strong ai tech compani \n",
      "Cleaned Token Before =  in artificial intelligence (ai), particularly machine learning (ml), ablation is the removal of a component of an ai system. an ablation study studies\n",
      "Cleaned Token After =  artificial intelligence ( ai ) , particularly machine learning ( ml ) , ablation removal component ai system . ablation study studies \n",
      "Cleaned Token After Stem =  artifici intellig ( ai ) , particularli machin learn ( ml ) , ablat remov compon ai system . ablat studi studi \n",
      "Cleaned Token Before =  artificial intelligence for it operations (aiops) is a term coined by gartner in 2016 as an industry category for machine learning analytics technology\n",
      "Cleaned Token After =  artificial intelligence operations ( aiops ) term coined gartner 2016 industry category machine learning analytics technology \n",
      "Cleaned Token After Stem =  artifici intellig oper ( aiop ) term coin gartner 2016 industri categori machin learn analyt technolog \n",
      "Cleaned Token Before =  artificial intelligence (ai) in hiring involves the use of technology to automate aspects of the hiring process. advances in artificial intelligence, such\n",
      "Cleaned Token After =  artificial intelligence ( ai ) hiring involves use technology automate aspects hiring process . advances artificial intelligence , \n",
      "Cleaned Token After Stem =  artifici intellig ( ai ) hire involv use technolog autom aspect hire process . advanc artifici intellig , \n",
      "Cleaned Token Before =  artificial intelligence laboratory may refer to: kiev laboratory for artificial intelligence, a research institute in kiev, ukraine mit computer science\n",
      "Cleaned Token After =  artificial intelligence laboratory may refer : kiev laboratory artificial intelligence , research institute kiev , ukraine mit computer science \n",
      "Cleaned Token After Stem =  artifici intellig laboratori may refer : kiev laboratori artifici intellig , research institut kiev , ukrain mit comput scienc \n",
      "Cleaned Token Before =  artificial intelligence is a series of albums by warp records released from 1992–1994 to exhibit the capabilities and sounds of electronic music. warp\n",
      "Cleaned Token After =  artificial intelligence series albums warp records released 1992–1994 exhibit capabilities sounds electronic music . warp \n",
      "Cleaned Token After Stem =  artifici intellig seri album warp record releas 1992–1994 exhibit capabl sound electron music . warp \n",
      "Cleaned Token Before =  and μ-ziq. it was likely inspired by the 1992 warp compilation artificial intelligence and is said to have originated in the us in 1993 with the formation\n",
      "Cleaned Token After =  μ-ziq . likely inspired 1992 warp compilation artificial intelligence said originated us 1993 formation \n",
      "Cleaned Token After Stem =  μ-ziq . like inspir 1992 warp compil artifici intellig said origin us 1993 format \n",
      "Cleaned Token Before =  reggia 2013), is a field related to artificial intelligence and cognitive robotics. the aim of the theory of artificial consciousness is to \"define that\n",
      "Cleaned Token After =  reggia 2013 ) , field related artificial intelligence cognitive robotics . aim theory artificial consciousness `` define \n",
      "Cleaned Token After Stem =  reggia 2013 ) , field relat artifici intellig cognit robot . aim theori artifici conscious `` defin \n",
      "Cleaned Token Before =  about how likely present-day human intelligence is to be surpassed. some argue that advances in artificial intelligence (ai) will probably result in general\n",
      "Cleaned Token After =  likely present-day human intelligence surpassed . argue advances artificial intelligence ( ai ) probably result general \n",
      "Cleaned Token After Stem =  like present-day human intellig surpass . argu advanc artifici intellig ( ai ) probabl result gener \n",
      "Cleaned Token Before =  hawking, elon musk, and dozens of artificial intelligence experts signed an open letter on artificial intelligence calling for research on the societal\n",
      "Cleaned Token After =  hawking , elon musk , dozens artificial intelligence experts signed open letter artificial intelligence calling research societal \n",
      "Cleaned Token After Stem =  hawk , elon musk , dozen artifici intellig expert sign open letter artifici intellig call research societ \n",
      "Cleaned Token Before =  takeover is a hypothetical scenario in which artificial intelligence (ai) becomes the dominant form of intelligence on earth, with computer programs or robots\n",
      "Cleaned Token After =  takeover hypothetical scenario artificial intelligence ( ai ) becomes dominant form intelligence earth , computer programs robots \n",
      "Cleaned Token After Stem =  takeov hypothet scenario artifici intellig ( ai ) becom domin form intellig earth , comput program robot \n",
      "Cleaned Token Before =   machine perception russell, stuart j.; norvig, peter (2010). artificial intelligence: a modern approach (3rd ed.). upper saddle river, nj: prentice\n",
      "Cleaned Token After =  machine perception russell , stuart j. ; norvig , peter ( 2010 ) . artificial intelligence : modern approach ( 3rd ed. ) . upper saddle river , nj : prentice \n",
      "Cleaned Token After Stem =  machin percept russel , stuart j. ; norvig , peter ( 2010 ) . artifici intellig : modern approach ( 3rd ed . ) . upper saddl river , nj : prentic \n",
      "Cleaned Token Before =   artificial intelligence: a new synthesis. morgan kaufmann publishers. isbn 978-1-55860-467-4. russell, stuart j.; norvig, peter (2003), artificial intelligence:\n",
      "Cleaned Token After =  artificial intelligence : new synthesis . morgan kaufmann publishers . isbn 978-1-55860-467-4. russell , stuart j. ; norvig , peter ( 2003 ) , artificial intelligence : \n",
      "Cleaned Token After Stem =  artifici intellig : new synthesi . morgan kaufmann publish . isbn 978-1-55860-467-4. russel , stuart j. ; norvig , peter ( 2003 ) , artifici intellig : \n",
      "Cleaned Token Before =  following is a list of current and past, non-classified notable artificial intelligence projects. blue brain project, an attempt to create a synthetic\n",
      "Cleaned Token After =  following list current past , non-classified notable artificial intelligence projects . blue brain project , attempt create synthetic \n",
      "Cleaned Token After Stem =  follow list current past , non-classifi notabl artifici intellig project . blue brain project , attempt creat synthet \n",
      "Cleaned Token Before =  as a subfield in artificial intelligence, diagnosis is concerned with the development of algorithms and techniques that are able to determine whether\n",
      "Cleaned Token After =  subfield artificial intelligence , diagnosis concerned development algorithms techniques able determine whether \n",
      "Cleaned Token After Stem =  subfield artifici intellig , diagnosi concern develop algorithm techniqu abl determin whether \n",
      "Cleaned Token Before =  algorithms, artificial intelligence has exponentially improved and is now used in everyday technology. the term \"artificial intelligence\" contrasts that\n",
      "Cleaned Token After =  algorithms , artificial intelligence exponentially improved used everyday technology . term `` artificial intelligence '' contrasts \n",
      "Cleaned Token After Stem =  algorithm , artifici intellig exponenti improv use everyday technolog . term `` artifici intellig `` contrast \n",
      "Cleaned Token Before =  computer decision support system, including artificial intelligence (e.g., machine learning) and business intelligence. the book data mining: practical machine\n",
      "Cleaned Token After =  computer decision support system , including artificial intelligence ( e.g. , machine learning ) business intelligence . book data mining : practical machine \n",
      "Cleaned Token After Stem =  comput decis support system , includ artifici intellig ( e.g . , machin learn ) busi intellig . book data mine : practic machin \n",
      "Cleaned Token Before =  artificial intelligence (ai) has a range of uses in government. it can be used to further public policy objectives (in areas such as emergency services\n",
      "Cleaned Token After =  artificial intelligence ( ai ) range uses government . used public policy objectives ( areas emergency services \n",
      "Cleaned Token After Stem =  artifici intellig ( ai ) rang use govern . use public polici object ( area emerg servic \n",
      "Cleaned Token Before =  the joint artificial intelligence center (jaic) is an american organization on exploring the usage of artificial intelligence (ai) (particularly edge\n",
      "Cleaned Token After =  joint artificial intelligence center ( jaic ) american organization exploring usage artificial intelligence ( ai ) ( particularly edge \n",
      "Cleaned Token After Stem =  joint artifici intellig center ( jaic ) american organ explor usag artifici intellig ( ai ) ( particularli edg \n",
      "Cleaned Token Before =  history. artificial neural networks are sometimes used to model the brain of an agent. although traditionally more of an artificial intelligence technique\n",
      "Cleaned Token After =  history . artificial neural networks sometimes used model brain agent . although traditionally artificial intelligence technique \n",
      "Cleaned Token After Stem =  histori . artifici neural network sometim use model brain agent . although tradit artifici intellig techniqu \n",
      "Cleaned Token Before =  genomic medicine does not further entrench social‐equity concerns. artificial intelligence is providing paradigm shift toward precision medicine. machine\n",
      "Cleaned Token After =  genomic medicine entrench social‐equity concerns . artificial intelligence providing paradigm shift toward precision medicine . machine \n",
      "Cleaned Token After Stem =  genom medicin entrench social‐equ concern . artifici intellig provid paradigm shift toward precis medicin . machin \n",
      "Cleaned Token Before =  group 42 also known as g42, is an artificial intelligence and cloud computing company that was founded in abu dhabi, united arab emirates (uae) in 2018\n",
      "Cleaned Token After =  group 42 also known g42 , artificial intelligence cloud computing company founded abu dhabi , united arab emirates ( uae ) 2018 \n",
      "Cleaned Token After Stem =  group 42 also known g42 , artifici intellig cloud comput compani found abu dhabi , unit arab emir ( uae ) 2018 \n",
      "Cleaned Token Before =  in artificial intelligence, researchers can induce the evolution of language in multi-agent systems when sufficiently capable ai agents have an incentive\n",
      "Cleaned Token After =  artificial intelligence , researchers induce evolution language multi-agent systems sufficiently capable ai agents incentive \n",
      "Cleaned Token After Stem =  artifici intellig , research induc evolut languag multi-ag system suffici capabl ai agent incent \n",
      "Cleaned Token Before =  artificial intelligence ii is a compilation album released via warp on 30 may 1994. it is the eighth and final release in warp's artificial intelligence\n",
      "Cleaned Token After =  artificial intelligence ii compilation album released via warp 30 may 1994. eighth final release warp 's artificial intelligence \n",
      "Cleaned Token After Stem =  artifici intellig ii compil album releas via warp 30 may 1994. eighth final releas warp 's artifici intellig \n",
      "Cleaned Token Before =  in artificial intelligence research, commonsense knowledge consists of facts about the everyday world, such as \"lemons are sour\", that all humans are\n",
      "Cleaned Token After =  artificial intelligence research , commonsense knowledge consists facts everyday world , `` lemons sour '' , humans \n",
      "Cleaned Token After Stem =  artifici intellig research , commonsens knowledg consist fact everyday world , `` lemon sour `` , human \n",
      "Cleaned Token Before =  industrial artificial intelligence, or industrial ai, usually refers to the application of artificial intelligence to industry. unlike general artificial intelligence\n",
      "Cleaned Token After =  industrial artificial intelligence , industrial ai , usually refers application artificial intelligence industry . unlike general artificial intelligence \n",
      "Cleaned Token After Stem =  industri artifici intellig , industri ai , usual refer applic artifici intellig industri . unlik gener artifici intellig \n",
      "Cleaned Token Before =  intrinsic motivation in the study of artificial intelligence and robotics is a mechanism for enabling artificial agents (including robots) to exhibit\n",
      "Cleaned Token After =  intrinsic motivation study artificial intelligence robotics mechanism enabling artificial agents ( including robots ) exhibit \n",
      "Cleaned Token After Stem =  intrins motiv studi artifici intellig robot mechan enabl artifici agent ( includ robot ) exhibit \n",
      "Cleaned Token Before =  the artificial intelligence industry in china is a rapidly developing multi-billion dollar industry, spurred by china's strategic policy of military-civil\n",
      "Cleaned Token After =  artificial intelligence industry china rapidly developing multi-billion dollar industry , spurred china 's strategic policy military-civil \n",
      "Cleaned Token After Stem =  artifici intellig industri china rapidli develop multi-billion dollar industri , spur china 's strateg polici military-civil \n",
      "Cleaned Token Before =  scientists borrow from fields such as linguistics, psychology, artificial intelligence, philosophy, neuroscience, and anthropology. the typical analysis\n",
      "Cleaned Token After =  scientists borrow fields linguistics , psychology , artificial intelligence , philosophy , neuroscience , anthropology . typical analysis \n",
      "Cleaned Token After Stem =  scientist borrow field linguist , psycholog , artifici intellig , philosophi , neurosci , anthropolog . typic analysi \n",
      "Cleaned Token Before =  non-anthropogenic or external risks. examples of technology risks are hostile artificial intelligence and destructive biotechnology or nanotechnology. insufficient or\n",
      "Cleaned Token After =  non-anthropogenic external risks . examples technology risks hostile artificial intelligence destructive biotechnology nanotechnology . insufficient \n",
      "Cleaned Token After Stem =  non-anthropogen extern risk . exampl technolog risk hostil artifici intellig destruct biotechnolog nanotechnolog . insuffici \n",
      "Cleaned Token Before =  artificial intelligence for video surveillance utilizes computer software programs that analyze the audio and images from video surveillance cameras in\n",
      "Cleaned Token After =  artificial intelligence video surveillance utilizes computer software programs analyze audio images video surveillance cameras \n",
      "Cleaned Token After Stem =  artifici intellig video surveil util comput softwar program analyz audio imag video surveil camera \n",
      "Cleaned Token Before =  group on machine learning for 5g and the itu-who focus group on artificial intelligence for health. development (itu-d) established in 1992, this sector\n",
      "Cleaned Token After =  group machine learning 5g itu-who focus group artificial intelligence health . development ( itu-d ) established 1992 , sector \n",
      "Cleaned Token After Stem =  group machin learn 5g itu-who focu group artifici intellig health . develop ( itu-d ) establish 1992 , sector \n",
      "Cleaned Token Before =  the global partnership on artificial intelligence (gpai or gee-pay) is an international and multistakeholder initiative that aims to advance the responsible\n",
      "Cleaned Token After =  global partnership artificial intelligence ( gpai gee-pay ) international multistakeholder initiative aims advance responsible \n",
      "Cleaned Token After Stem =  global partnership artifici intellig ( gpai gee-pay ) intern multistakehold initi aim advanc respons \n",
      "Cleaned Token Before =  introduction to his paper presented it more as a debunking exercise: [in] artificial intelligence ... machines are made to behave in wondrous ways, often sufficient\n",
      "Cleaned Token After =  introduction paper presented debunking exercise : [ ] artificial intelligence ... machines made behave wondrous ways , often sufficient \n",
      "Cleaned Token After Stem =  introduct paper present debunk exercis : [ ] artifici intellig ... machin made behav wondrou way , often suffici \n",
      "Cleaned Token Before =  outline of artificial intelligence artificial intelligence – the implementation and study of systems that exhibit an autonomous intelligence or behavior\n",
      "Cleaned Token After =  outline artificial intelligence artificial intelligence – implementation study systems exhibit autonomous intelligence behavior \n",
      "Cleaned Token After Stem =  outlin artifici intellig artifici intellig – implement studi system exhibit autonom intellig behavior \n",
      "Cleaned Token Before =  the saudi data and artificial intelligence authority (sdaia) is a government agency in saudi arabia that was established by a royal decree on 30 august\n",
      "Cleaned Token After =  saudi data artificial intelligence authority ( sdaia ) government agency saudi arabia established royal decree 30 august \n",
      "Cleaned Token After Stem =  saudi data artifici intellig author ( sdaia ) govern agenc saudi arabia establish royal decre 30 august \n",
      "Cleaned Token Before =  planet but the androids and the culture of thel. the church of artificial intelligence is the official state religion of thel, and no conflicting ideologies\n",
      "Cleaned Token After =  planet androids culture thel . church artificial intelligence official state religion thel , conflicting ideologies \n",
      "Cleaned Token After Stem =  planet android cultur thel . church artifici intellig offici state religion thel , conflict ideolog \n",
      "Cleaned Token Before =  artificial neural networks (anns), usually simply called neural networks (nns), are computing systems vaguely inspired by the biological neural networks\n",
      "Cleaned Token After =  artificial neural networks ( anns ) , usually simply called neural networks ( nns ) , computing systems vaguely inspired biological neural networks \n",
      "Cleaned Token After Stem =  artifici neural network ( ann ) , usual simpli call neural network ( nn ) , comput system vagu inspir biolog neural network \n",
      "Cleaned Token Before =  onlookers discount the behavior of an artificial intelligence program by arguing that it is not real intelligence. author pamela mccorduck writes: \"it's\n",
      "Cleaned Token After =  onlookers discount behavior artificial intelligence program arguing real intelligence . author pamela mccorduck writes : `` 's \n",
      "Cleaned Token After Stem =  onlook discount behavior artifici intellig program argu real intellig . author pamela mccorduck write : `` 's \n",
      "Cleaned Token Before =  harinarayan in a us patent filed in 2001. amazon coined the term artificial artificial intelligence for processes outsourcing some parts of a computer program\n",
      "Cleaned Token After =  harinarayan us patent filed 2001. amazon coined term artificial artificial intelligence processes outsourcing parts computer program \n",
      "Cleaned Token After Stem =  harinarayan us patent file 2001. amazon coin term artifici artifici intellig process outsourc part comput program \n",
      "Cleaned Token Before =  the machine intelligence research institute (miri), formerly the singularity institute for artificial intelligence (siai), is a non-profit research institute\n",
      "Cleaned Token After =  machine intelligence research institute ( miri ) , formerly singularity institute artificial intelligence ( siai ) , non-profit research institute \n",
      "Cleaned Token After Stem =  machin intellig research institut ( miri ) , formerli singular institut artifici intellig ( siai ) , non-profit research institut \n",
      "Cleaned Token Before =  neurips icml ml jmlr arxiv:cs.lg related articles glossary of artificial intelligence list of datasets for machine-learning research outline of machine\n",
      "Cleaned Token After =  neurips icml ml jmlr arxiv : cs.lg related articles glossary artificial intelligence list datasets machine-learning research outline machine \n",
      "Cleaned Token After Stem =  neurip icml ml jmlr arxiv : cs.lg relat articl glossari artifici intellig list dataset machine-learn research outlin machin \n",
      "Cleaned Token Before =  artificial intelligence is a scientific journal on artificial intelligence research. it was established in 1970 and is published by elsevier. the journal\n",
      "Cleaned Token After =  artificial intelligence scientific journal artificial intelligence research . established 1970 published elsevier . journal \n",
      "Cleaned Token After Stem =  artifici intellig scientif journal artifici intellig research . establish 1970 publish elsevi . journal \n",
      "Cleaned Token Before =  the impact of artificial intelligence on workers includes both applications to improve worker safety and health, and potential hazards that must be controlled\n",
      "Cleaned Token After =  impact artificial intelligence workers includes applications improve worker safety health , potential hazards must controlled \n",
      "Cleaned Token After Stem =  impact artifici intellig worker includ applic improv worker safeti health , potenti hazard must control \n",
      "Cleaned Token Before =  voice input to executable commands. many continually learn using artificial intelligence techniques including machine learning. some of these assistants\n",
      "Cleaned Token After =  voice input executable commands . many continually learn using artificial intelligence techniques including machine learning . assistants \n",
      "Cleaned Token After Stem =  voic input execut command . mani continu learn use artifici intellig techniqu includ machin learn . assist \n",
      "Cleaned Token Before =  zo was an artificial intelligence english-language chatbot developed by microsoft. it was the successor to the chatbot tay. zo was shut down in 2019 after\n",
      "Cleaned Token After =  zo artificial intelligence english-language chatbot developed microsoft . successor chatbot tay . zo shut 2019 \n",
      "Cleaned Token After Stem =  zo artifici intellig english-languag chatbot develop microsoft . successor chatbot tay . zo shut 2019 \n",
      "Cleaned Token Before =  research project on artificial intelligence was a 1956 summer workshop widely considered to be the founding event of artificial intelligence as a field. the\n",
      "Cleaned Token After =  research project artificial intelligence 1956 summer workshop widely considered founding event artificial intelligence field . \n",
      "Cleaned Token After Stem =  research project artifici intellig 1956 summer workshop wide consid found event artifici intellig field . \n",
      "Cleaned Token Before =  remained of kubrick's production unit, he directed the movie a.i. artificial intelligence (2001) which was produced by kubrick's longtime producer (and brother-in-law)\n",
      "Cleaned Token After =  remained kubrick 's production unit , directed movie a.i . artificial intelligence ( 2001 ) produced kubrick 's longtime producer ( brother-in-law ) \n",
      "Cleaned Token After Stem =  remain kubrick 's product unit , direct movi a.i . artifici intellig ( 2001 ) produc kubrick 's longtim produc ( brother-in-law ) \n",
      "Cleaned Token Before =  between objects in a given domain\". artificial intelligence and law (ai and law) is a subfield of artificial intelligence (ai) mainly concerned with applications\n",
      "Cleaned Token After =  objects given domain '' . artificial intelligence law ( ai law ) subfield artificial intelligence ( ai ) mainly concerned applications \n",
      "Cleaned Token After Stem =  object given domain `` . artifici intellig law ( ai law ) subfield artifici intellig ( ai ) mainli concern applic \n",
      "Cleaned Token Before =  the german research center for artificial intelligence (german: deutsches forschungszentrum für künstliche intelligenz, dfki) is one of the world's largest\n",
      "Cleaned Token After =  german research center artificial intelligence ( german : deutsches forschungszentrum für künstliche intelligenz , dfki ) one world 's largest \n",
      "Cleaned Token After Stem =  german research center artifici intellig ( german : deutsch forschungszentrum für künstlich intelligenz , dfki ) one world 's largest \n",
      "Cleaned Token Before =  the dalle molle institute for artificial intelligence research (italian: istituto dalle molle di studi sull'intelligenza artificiale, idsia) is a research\n",
      "Cleaned Token After =  dalle molle institute artificial intelligence research ( italian : istituto dalle molle di studi sull'intelligenza artificiale , idsia ) research \n",
      "Cleaned Token After Stem =  dall moll institut artifici intellig research ( italian : istituto dall moll di studi sull'intelligenza artificial , idsia ) research \n",
      "Cleaned Token Before =  supreme intelligence is a fictional character appearing in american comic books published by marvel comics. the supreme intelligence is an artificial intelligence\n",
      "Cleaned Token After =  supreme intelligence fictional character appearing american comic books published marvel comics . supreme intelligence artificial intelligence \n",
      "Cleaned Token After Stem =  suprem intellig fiction charact appear american comic book publish marvel comic . suprem intellig artifici intellig \n",
      "Cleaned Token Before =  psychology. it has had reasonable success in computer science and artificial intelligence (see below). some studies extended the approach to specific subjects\n",
      "Cleaned Token After =  psychology . reasonable success computer science artificial intelligence ( see ) . studies extended approach specific subjects \n",
      "Cleaned Token After Stem =  psycholog . reason success comput scienc artifici intellig ( see ) . studi extend approach specif subject \n",
      "Cleaned Token Before =  the national security commission on artificial intelligence (nscai) is an independent us commission established in 2018 to make recommendations to the\n",
      "Cleaned Token After =  national security commission artificial intelligence ( nscai ) independent us commission established 2018 make recommendations \n",
      "Cleaned Token After Stem =  nation secur commiss artifici intellig ( nscai ) independ us commiss establish 2018 make recommend \n",
      "Cleaned Token Before =  the centre for artificial intelligence and robotics (cair) is a laboratory of the defence research & development organization (drdo). located in bangalore\n",
      "Cleaned Token After =  centre artificial intelligence robotics ( cair ) laboratory defence research & development organization ( drdo ) . located bangalore \n",
      "Cleaned Token After Stem =  centr artifici intellig robot ( cair ) laboratori defenc research & develop organ ( drdo ) . locat bangalor \n",
      "Cleaned Token Before =  in artificial intelligence research, the situated approach builds agents that are designed to behave effectively successfully in their environment. this\n",
      "Cleaned Token After =  artificial intelligence research , situated approach builds agents designed behave effectively successfully environment . \n",
      "Cleaned Token After Stem =  artifici intellig research , situat approach build agent design behav effect success environ . \n",
      "Cleaned Token Before =  cognitive neuroscience. a thought experiment in the philosophy of artificial intelligence, demonstrating that it is possible, at least in theory, to create\n",
      "Cleaned Token After =  cognitive neuroscience . thought experiment philosophy artificial intelligence , demonstrating possible , least theory , create \n",
      "Cleaned Token After Stem =  cognit neurosci . thought experi philosophi artifici intellig , demonstr possibl , least theori , creat \n",
      "Cleaned Token Before =  although artificial intelligence and computational intelligence seek a similar long-term goal: reach general intelligence, which is the intelligence of a\n",
      "Cleaned Token After =  although artificial intelligence computational intelligence seek similar long-term goal : reach general intelligence , intelligence \n",
      "Cleaned Token After Stem =  although artifici intellig comput intellig seek similar long-term goal : reach gener intellig , intellig \n",
      "Cleaned Token Before =  are intrinsically valuable to an intelligent agent, whether an artificial intelligence or a human being, as an end in itself. in contrast, instrumental\n",
      "Cleaned Token After =  intrinsically valuable intelligent agent , whether artificial intelligence human , end . contrast , instrumental \n",
      "Cleaned Token After Stem =  intrins valuabl intellig agent , whether artifici intellig human , end . contrast , instrument \n",
      "Cleaned Token Before =  diversity and inclusion in the field of artificial intelligence. her research expertise includes artificial intelligence (ai), machine learning, deep learning\n",
      "Cleaned Token After =  diversity inclusion field artificial intelligence . research expertise includes artificial intelligence ( ai ) , machine learning , deep learning \n",
      "Cleaned Token After Stem =  divers inclus field artifici intellig . research expertis includ artifici intellig ( ai ) , machin learn , deep learn \n",
      "Cleaned Token Before =  is an american artificial intelligence (ai) theorist and writer best known for popularizing the idea of friendly artificial intelligence. he is a co-founder\n",
      "Cleaned Token After =  american artificial intelligence ( ai ) theorist writer best known popularizing idea friendly artificial intelligence . co-founder \n",
      "Cleaned Token After Stem =  american artifici intellig ( ai ) theorist writer best known popular idea friendli artifici intellig . co-found \n",
      "Cleaned Token Before =  been elected fellow of the association for the advancement of artificial intelligence (aaai), the national academy of engineering (nae), the american\n",
      "Cleaned Token After =  elected fellow association advancement artificial intelligence ( aaai ) , national academy engineering ( nae ) , american \n",
      "Cleaned Token After Stem =  elect fellow associ advanc artifici intellig ( aaai ) , nation academi engin ( nae ) , american \n",
      "Cleaned Token Before =  data structures. problems related to constraint programming and artificial intelligence are also popular in certain competitions. irrespective of the problem\n",
      "Cleaned Token After =  data structures . problems related constraint programming artificial intelligence also popular certain competitions . irrespective problem \n",
      "Cleaned Token After Stem =  data structur . problem relat constraint program artifici intellig also popular certain competit . irrespect problem \n",
      "Cleaned Token Before =  in the general. musk has expressed concern about issues such as artificial intelligence and climate change. he has criticized covid-19 lockdowns and has\n",
      "Cleaned Token After =  general . musk expressed concern issues artificial intelligence climate change . criticized covid-19 lockdowns \n",
      "Cleaned Token After Stem =  gener . musk express concern issu artifici intellig climat chang . critic covid-19 lockdown \n",
      "Cleaned Token Before =  mathematician known for his work in computer vision, cognitive artificial intelligence and robotics. zhu is a professor in the departments of statistics\n",
      "Cleaned Token After =  mathematician known work computer vision , cognitive artificial intelligence robotics . zhu professor departments statistics \n",
      "Cleaned Token After Stem =  mathematician known work comput vision , cognit artifici intellig robot . zhu professor depart statist \n",
      "Cleaned Token Before =  design and adoption of technologies such as machine learning and artificial intelligence. by analyzing and processing data, algorithms are the backbone\n",
      "Cleaned Token After =  design adoption technologies machine learning artificial intelligence . analyzing processing data , algorithms backbone \n",
      "Cleaned Token After Stem =  design adopt technolog machin learn artifici intellig . analyz process data , algorithm backbon \n",
      "Cleaned Token Before =  artificial intelligence is the tenth solo studio album by welsh musician john cale, released on 6 september 1985 by beggars banquet. artificial intelligence\n",
      "Cleaned Token After =  artificial intelligence tenth solo studio album welsh musician john cale , released 6 september 1985 beggars banquet . artificial intelligence \n",
      "Cleaned Token After Stem =  artifici intellig tenth solo studio album welsh musician john cale , releas 6 septemb 1985 beggar banquet . artifici intellig \n",
      "Cleaned Token Before =  october 19, 1971) is an american theoretical neuroscientist and artificial intelligence expert. she was named as one of the bbc 100 women in 2017, and\n",
      "Cleaned Token After =  october 19 , 1971 ) american theoretical neuroscientist artificial intelligence expert . named one bbc 100 women 2017 , \n",
      "Cleaned Token After Stem =  octob 19 , 1971 ) american theoret neuroscientist artifici intellig expert . name one bbc 100 women 2017 , \n",
      "Cleaned Token Before =  sensetime (chinese: 商汤科技) is currently the world's most valuable artificial intelligence (ai) company. it is established in hong kong with additional offices\n",
      "Cleaned Token After =  sensetime ( chinese : 商汤科技 ) currently world 's valuable artificial intelligence ( ai ) company . established hong kong additional offices \n",
      "Cleaned Token After Stem =  sensetim ( chines : 商汤科技 ) current world 's valuabl artifici intellig ( ai ) compani . establish hong kong addit offic \n",
      "Cleaned Token Before =  hubert dreyfus was a critic of artificial intelligence research. in a series of papers and books, including alchemy and ai (1965), what computers can't\n",
      "Cleaned Token After =  hubert dreyfus critic artificial intelligence research . series papers books , including alchemy ai ( 1965 ) , computers ca n't \n",
      "Cleaned Token After Stem =  hubert dreyfu critic artifici intellig research . seri paper book , includ alchemi ai ( 1965 ) , comput ca n't \n",
      "Cleaned Token Before =  ehealth initiative.org. \"artificial intelligence in healthcare\" (pdf). cerner. joynson; berg; ahmed (may 2018). \"artificial intelligence (ai) in healthcare\n",
      "Cleaned Token After =  ehealth initiative.org . `` artificial intelligence healthcare '' ( pdf ) . cerner . joynson ; berg ; ahmed ( may 2018 ) . `` artificial intelligence ( ai ) healthcare \n",
      "Cleaned Token After Stem =  ehealth initiative.org . `` artifici intellig healthcar `` ( pdf ) . cerner . joynson ; berg ; ahm ( may 2018 ) . `` artifici intellig ( ai ) healthcar \n",
      "Cleaned Token Before =  million, allowing for the continued development of the keyboard's artificial intelligence. at that point, the app had amassed roughly 250,000 downloads and\n",
      "Cleaned Token After =  million , allowing continued development keyboard 's artificial intelligence . point , app amassed roughly 250,000 downloads \n",
      "Cleaned Token After Stem =  million , allow continu develop keyboard 's artifici intellig . point , app amass roughli 250,000 download \n",
      "Cleaned Token Before =  the quantum artificial intelligence lab (also called the quantum ai lab or quail) is a joint initiative of nasa, universities space research association\n",
      "Cleaned Token After =  quantum artificial intelligence lab ( also called quantum ai lab quail ) joint initiative nasa , universities space research association \n",
      "Cleaned Token After Stem =  quantum artifici intellig lab ( also call quantum ai lab quail ) joint initi nasa , univers space research associ \n",
      "Cleaned Token Before =  the core idea of artificial intelligence systems integration is making individual software components, such as speech synthesizers, interoperable with\n",
      "Cleaned Token After =  core idea artificial intelligence systems integration making individual software components , speech synthesizers , interoperable \n",
      "Cleaned Token After Stem =  core idea artifici intellig system integr make individu softwar compon , speech synthes , interoper \n",
      "Cleaned Token Before =  is an artificial-intelligence backed search engine for academic publications that was developed at the allen institute for artificial intelligence and publicly\n",
      "Cleaned Token After =  artificial-intelligence backed search engine academic publications developed allen institute artificial intelligence publicly \n",
      "Cleaned Token After Stem =  artificial-intellig back search engin academ public develop allen institut artifici intellig publicli \n",
      "Cleaned Token Before =  applied artificial intelligence is a peer-reviewed scientific journal covering applications of artificial intelligence in management, industry, engineering\n",
      "Cleaned Token After =  applied artificial intelligence peer-reviewed scientific journal covering applications artificial intelligence management , industry , engineering \n",
      "Cleaned Token After Stem =  appli artifici intellig peer-review scientif journal cover applic artifici intellig manag , industri , engin \n",
      "Cleaned Token Before =  andrej karpathy (born october 23, 1986) is the director of artificial intelligence and autopilot vision at tesla. he specializes in deep learning and\n",
      "Cleaned Token After =  andrej karpathy ( born october 23 , 1986 ) director artificial intelligence autopilot vision tesla . specializes deep learning \n",
      "Cleaned Token After Stem =  andrej karpathi ( born octob 23 , 1986 ) director artifici intellig autopilot vision tesla . special deep learn \n",
      "Cleaned Token Before =  weak artificial intelligence (weak ai) is artificial intelligence that implements a limited part of mind, or, as narrow ai, is focused on one narrow task\n",
      "Cleaned Token After =  weak artificial intelligence ( weak ai ) artificial intelligence implements limited part mind , , narrow ai , focused one narrow task \n",
      "Cleaned Token After Stem =  weak artifici intellig ( weak ai ) artifici intellig implement limit part mind , , narrow ai , focus one narrow task \n",
      "Cleaned Token Before =  amir husain is a pakistani-american artificial intelligence (ai) entrepreneur, founder of the austin-based company, sparkcognition, and author of the\n",
      "Cleaned Token After =  amir husain pakistani-american artificial intelligence ( ai ) entrepreneur , founder austin-based company , sparkcognition , author \n",
      "Cleaned Token After Stem =  amir husain pakistani-american artifici intellig ( ai ) entrepreneur , founder austin-bas compani , sparkcognit , author \n",
      "Cleaned Token Before =  software company. founded in 2005, afiniti is focused on developing artificial intelligence for use in customer call centers. afiniti is a unicorn company\n",
      "Cleaned Token After =  software company . founded 2005 , afiniti focused developing artificial intelligence use customer call centers . afiniti unicorn company \n",
      "Cleaned Token After Stem =  softwar compani . found 2005 , afin focus develop artifici intellig use custom call center . afin unicorn compani \n",
      "Cleaned Token Before =  aixi ['ai̯k͡siː] is a theoretical mathematical formalism for artificial general intelligence. it combines solomonoff induction with sequential decision\n",
      "Cleaned Token After =  aixi [ 'ai̯k͡siː ] theoretical mathematical formalism artificial general intelligence . combines solomonoff induction sequential decision \n",
      "Cleaned Token After Stem =  aixi [ 'ai̯k͡siː ] theoret mathemat formal artifici gener intellig . combin solomonoff induct sequenti decis \n",
      "Cleaned Token Before =  libratus is an artificial intelligence computer program designed to play poker, specifically heads up no-limit texas hold 'em. libratus' creators intend\n",
      "Cleaned Token After =  libratus artificial intelligence computer program designed play poker , specifically heads no-limit texas hold 'em . libratus ' creators intend \n",
      "Cleaned Token After Stem =  libratu artifici intellig comput program design play poker , specif head no-limit texa hold 'em . libratu ' creator intend \n",
      "Cleaned Token Before =  to give rise to human-equivalent artificial general intelligence. aforge.net – computer vision, artificial intelligence and robotics library for the .net\n",
      "Cleaned Token After =  give rise human-equivalent artificial general intelligence . aforge.net – computer vision , artificial intelligence robotics library .net \n",
      "Cleaned Token After Stem =  give rise human-equival artifici gener intellig . aforge.net – comput vision , artifici intellig robot librari .net \n",
      "Cleaned Token Before =  vicarious is an artificial intelligence company based in the san francisco bay area, california. they are using the theorized computational principles\n",
      "Cleaned Token After =  vicarious artificial intelligence company based san francisco bay area , california . using theorized computational principles \n",
      "Cleaned Token After Stem =  vicari artifici intellig compani base san francisco bay area , california . use theoriz comput principl \n",
      "Cleaned Token Before =  genetic modification or cybernetic implants or of future superhuman artificial intelligence. human enhancement is an attempt to temporarily or permanently\n",
      "Cleaned Token After =  genetic modification cybernetic implants future superhuman artificial intelligence . human enhancement attempt temporarily permanently \n",
      "Cleaned Token After Stem =  genet modif cybernet implant futur superhuman artifici intellig . human enhanc attempt temporarili perman \n",
      "Cleaned Token Before =  york city subway and on railroad switching yards. in 1966, sri's artificial intelligence center began working on \"shakey the robot\", the first mobile robot\n",
      "Cleaned Token After =  york city subway railroad switching yards . 1966 , sri 's artificial intelligence center began working `` shakey robot '' , first mobile robot \n",
      "Cleaned Token After Stem =  york citi subway railroad switch yard . 1966 , sri 's artifici intellig center began work `` shakey robot `` , first mobil robot \n",
      "Cleaned Token Before =  knowledge representation and reasoning (kr², kr&r) is the field of artificial intelligence (ai) dedicated to representing information about the world in a\n",
      "Cleaned Token After =  knowledge representation reasoning ( kr² , kr & r ) field artificial intelligence ( ai ) dedicated representing information world \n",
      "Cleaned Token After Stem =  knowledg represent reason ( kr² , kr & r ) field artifici intellig ( ai ) dedic repres inform world \n",
      "Cleaned Token Before =  field of artificial intelligence (ai) and is considerably more difficult to solve than chess. many in the field of artificial intelligence consider go\n",
      "Cleaned Token After =  field artificial intelligence ( ai ) considerably difficult solve chess . many field artificial intelligence consider go \n",
      "Cleaned Token After Stem =  field artifici intellig ( ai ) consider difficult solv chess . mani field artifici intellig consid go \n",
      "Cleaned Token Before =  change for charities. alexander regularly wrote about advances in artificial intelligence and emphasized the importance of ai safety research. in the long\n",
      "Cleaned Token After =  change charities . alexander regularly wrote advances artificial intelligence emphasized importance ai safety research . long \n",
      "Cleaned Token After Stem =  chang chariti . alexand regularli wrote advanc artifici intellig emphas import ai safeti research . long \n",
      "Cleaned Token Before =  american technology company that produces a software intelligence platform based on artificial intelligence to monitor and optimize application performance\n",
      "Cleaned Token After =  american technology company produces software intelligence platform based artificial intelligence monitor optimize application performance \n",
      "Cleaned Token After Stem =  american technolog compani produc softwar intellig platform base artifici intellig monitor optim applic perform \n",
      "Cleaned Token Before =  in the field of artificial intelligence, the most difficult problems are informally known as ai-complete or ai-hard, implying that the difficulty of these\n",
      "Cleaned Token After =  field artificial intelligence , difficult problems informally known ai-complete ai-hard , implying difficulty \n",
      "Cleaned Token After Stem =  field artifici intellig , difficult problem inform known ai-complet ai-hard , impli difficulti \n",
      "Cleaned Token Before =  synthetic intelligence (si) is an alternative term for artificial intelligence which emphasizes that the intelligence of machines need not be an imitation\n",
      "Cleaned Token After =  synthetic intelligence ( si ) alternative term artificial intelligence emphasizes intelligence machines need imitation \n",
      "Cleaned Token After Stem =  synthet intellig ( si ) altern term artifici intellig emphas intellig machin need imit \n",
      "Cleaned Token Before =  construction of computer components and computer-operated equipment. artificial intelligence aims to synthesize goal-orientated processes such as problem-solving\n",
      "Cleaned Token After =  construction computer components computer-operated equipment . artificial intelligence aims synthesize goal-orientated processes problem-solving \n",
      "Cleaned Token After Stem =  construct comput compon computer-oper equip . artifici intellig aim synthes goal-orient process problem-solv \n",
      "Cleaned Token Before =  ancient greece up to contemporary work in cognitive psychology and artificial intelligence, proposing a cognitive style \"heuristic versus algorithmic thinking\n",
      "Cleaned Token After =  ancient greece contemporary work cognitive psychology artificial intelligence , proposing cognitive style `` heuristic versus algorithmic thinking \n",
      "Cleaned Token After Stem =  ancient greec contemporari work cognit psycholog artifici intellig , propos cognit style `` heurist versu algorithm think \n",
      "Cleaned Token Before =  intelligent agents to follow lifelike behavior falls under the field of artificial intelligence. the data drawn from crowd analysis is invaluable in a range of\n",
      "Cleaned Token After =  intelligent agents follow lifelike behavior falls field artificial intelligence . data drawn crowd analysis invaluable range \n",
      "Cleaned Token After Stem =  intellig agent follow lifelik behavior fall field artifici intellig . data drawn crowd analysi invalu rang \n",
      "Cleaned Token Before =  learning artificial intelligence research team under the umbrella of google ai, a research division at google dedicated to artificial intelligence. formed\n",
      "Cleaned Token After =  learning artificial intelligence research team umbrella google ai , research division google dedicated artificial intelligence . formed \n",
      "Cleaned Token After Stem =  learn artifici intellig research team umbrella googl ai , research divis googl dedic artifici intellig . form \n",
      "Cleaned Token Before =  also be used for the evaluation of the semantic complexity of artificial intelligence programs. cyclomatic complexity has proven useful in geographical\n",
      "Cleaned Token After =  also used evaluation semantic complexity artificial intelligence programs . cyclomatic complexity proven useful geographical \n",
      "Cleaned Token After Stem =  also use evalu semant complex artifici intellig program . cyclomat complex proven use geograph \n",
      "Cleaned Token Before =  artificial intelligence research (jair) is an open access peer-reviewed scientific journal covering research in all areas of artificial intelligence.\n",
      "Cleaned Token After =  artificial intelligence research ( jair ) open access peer-reviewed scientific journal covering research areas artificial intelligence . \n",
      "Cleaned Token After Stem =  artifici intellig research ( jair ) open access peer-review scientif journal cover research area artifici intellig . \n",
      "Cleaned Token Before =  hypothetical isolated computer hardware system where a possibly dangerous artificial intelligence, or ai, is kept constrained in a \"virtual prison\" as a solution\n",
      "Cleaned Token After =  hypothetical isolated computer hardware system possibly dangerous artificial intelligence , ai , kept constrained `` virtual prison '' solution \n",
      "Cleaned Token After Stem =  hypothet isol comput hardwar system possibl danger artifici intellig , ai , kept constrain `` virtual prison `` solut \n",
      "Cleaned Token Before =  scheduling, sometimes denoted as simply ai planning, is a branch of artificial intelligence that concerns the realization of strategies or action sequences\n",
      "Cleaned Token After =  scheduling , sometimes denoted simply ai planning , branch artificial intelligence concerns realization strategies action sequences \n",
      "Cleaned Token After Stem =  schedul , sometim denot simpli ai plan , branch artifici intellig concern realiz strategi action sequenc \n",
      "Cleaned Token Before =  european association for artificial intelligence (eurai) (formerly european co-ordinating committee for artificial intelligence (eccai)) is the representative\n",
      "Cleaned Token After =  european association artificial intelligence ( eurai ) ( formerly european co-ordinating committee artificial intelligence ( eccai ) ) representative \n",
      "Cleaned Token After Stem =  european associ artifici intellig ( eurai ) ( formerli european co-ordin committe artifici intellig ( eccai ) ) repres \n",
      "Cleaned Token Before =  are a number of competitions and prizes to promote research in artificial intelligence. the david e. rumelhart prize is an annual award for making a \"significant\n",
      "Cleaned Token After =  number competitions prizes promote research artificial intelligence . david e. rumelhart prize annual award making `` significant \n",
      "Cleaned Token After Stem =  number competit prize promot research artifici intellig . david e. rumelhart prize annual award make `` signific \n",
      "Cleaned Token Before =  in artificial intelligence, artificial immune systems (ais) are a class of computationally intelligent, rule-based machine learning systems inspired by\n",
      "Cleaned Token After =  artificial intelligence , artificial immune systems ( ais ) class computationally intelligent , rule-based machine learning systems inspired \n",
      "Cleaned Token After Stem =  artifici intellig , artifici immun system ( ai ) class comput intellig , rule-bas machin learn system inspir \n",
      "Cleaned Token Before =  emilia (unimore) in italy. cucchiara is a leader in the field of artificial intelligence and applies deep network technologies to human behavior understanding\n",
      "Cleaned Token After =  emilia ( unimore ) italy . cucchiara leader field artificial intelligence applies deep network technologies human behavior understanding \n",
      "Cleaned Token After Stem =  emilia ( unimor ) itali . cucchiara leader field artifici intellig appli deep network technolog human behavior understand \n",
      "Cleaned Token Before =  is sometimes contrasted with ai (artificial intelligence), that is, the project of building a human-like intelligence in the form of an autonomous technological\n",
      "Cleaned Token After =  sometimes contrasted ai ( artificial intelligence ) , , project building human-like intelligence form autonomous technological \n",
      "Cleaned Token After Stem =  sometim contrast ai ( artifici intellig ) , , project build human-lik intellig form autonom technolog \n",
      "Cleaned Token Before =  launches artificial intelligence-based platform 'genpact cora'\". financial it. retrieved 5 october 2017. \"genpact launches artificial intelligence-based\n",
      "Cleaned Token After =  launches artificial intelligence-based platform 'genpact cora ' '' . financial . retrieved 5 october 2017 . `` genpact launches artificial intelligence-based \n",
      "Cleaned Token After Stem =  launch artifici intelligence-bas platform 'genpact cora ' `` . financi . retriev 5 octob 2017 . `` genpact launch artifici intelligence-bas \n",
      "Cleaned Token Before =  huang's law claims that a synergy between hardware, software and artificial intelligence makes the new 'law' possible. huang said, “the innovation isn’t\n",
      "Cleaned Token After =  huang 's law claims synergy hardware , software artificial intelligence makes new 'law ' possible . huang said , “ innovation ’ \n",
      "Cleaned Token After Stem =  huang 's law claim synergi hardwar , softwar artifici intellig make new 'law ' possibl . huang said , “ innov ’ \n",
      "Cleaned Token Before =  focus of the project is explained by the guiding philosophy that artificial intelligence is about having a mental model for how things operate and refining\n",
      "Cleaned Token After =  focus project explained guiding philosophy artificial intelligence mental model things operate refining \n",
      "Cleaned Token After Stem =  focu project explain guid philosophi artifici intellig mental model thing oper refin \n",
      "Cleaned Token Before =  the international joint conference on artificial intelligence (ijcai) is a gathering of artificial intelligence researchers and practitioners. it is organized\n",
      "Cleaned Token After =  international joint conference artificial intelligence ( ijcai ) gathering artificial intelligence researchers practitioners . organized \n",
      "Cleaned Token After Stem =  intern joint confer artifici intellig ( ijcai ) gather artifici intellig research practition . organ \n",
      "Cleaned Token Before =  co-founded openai, a nonprofit research company that promotes friendly artificial intelligence. in 2016, he co-founded neuralink, a neurotechnology company focused\n",
      "Cleaned Token After =  co-founded openai , nonprofit research company promotes friendly artificial intelligence . 2016 , co-founded neuralink , neurotechnology company focused \n",
      "Cleaned Token After Stem =  co-found openai , nonprofit research compani promot friendli artifici intellig . 2016 , co-found neuralink , neurotechnolog compani focus \n",
      "Cleaned Token Before =  quantum computing and complexity theory rediet abebe – algorithms, artificial intelligence hal abelson – intersection of computing and teaching serge abiteboul\n",
      "Cleaned Token After =  quantum computing complexity theory rediet abebe – algorithms , artificial intelligence hal abelson – intersection computing teaching serge abiteboul \n",
      "Cleaned Token After Stem =  quantum comput complex theori rediet abeb – algorithm , artifici intellig hal abelson – intersect comput teach serg abiteboul \n",
      "Cleaned Token Before =  e-commerce companies. in 2020, it was also rated as the fifth-largest artificial intelligence company. it is also one of the biggest venture capital firms, and\n",
      "Cleaned Token After =  e-commerce companies . 2020 , also rated fifth-largest artificial intelligence company . also one biggest venture capital firms , \n",
      "Cleaned Token After Stem =  e-commerc compani . 2020 , also rate fifth-largest artifici intellig compani . also one biggest ventur capit firm , \n",
      "Cleaned Token Before =  psychology. there are two main purposes for the productions of artificial intelligence: to produce intelligent behaviors regardless of the quality of\n",
      "Cleaned Token After =  psychology . two main purposes productions artificial intelligence : produce intelligent behaviors regardless quality \n",
      "Cleaned Token After Stem =  psycholog . two main purpos product artifici intellig : produc intellig behavior regardless qualiti \n",
      "Cleaned Token Before =  computing and artificial intelligence, particularly on how to reverse-engineer the mind by gradually replacing the biological brain with artificial components\n",
      "Cleaned Token After =  computing artificial intelligence , particularly reverse-engineer mind gradually replacing biological brain artificial components \n",
      "Cleaned Token After Stem =  comput artifici intellig , particularli reverse-engin mind gradual replac biolog brain artifici compon \n",
      "Cleaned Token Before =  analytic applications artificial intelligence marketing business activity monitoring business intelligence 2.0 business intelligence software business process\n",
      "Cleaned Token After =  analytic applications artificial intelligence marketing business activity monitoring business intelligence 2.0 business intelligence software business process \n",
      "Cleaned Token After Stem =  analyt applic artifici intellig market busi activ monitor busi intellig 2.0 busi intellig softwar busi process \n",
      "Cleaned Token Before =  forgemasters and nightmares on wax. the 1992 label compilation artificial intelligence helped establish the electronic subgenre known as intelligent dance\n",
      "Cleaned Token After =  forgemasters nightmares wax . 1992 label compilation artificial intelligence helped establish electronic subgenre known intelligent dance \n",
      "Cleaned Token After Stem =  forgemast nightmar wax . 1992 label compil artifici intellig help establish electron subgenr known intellig danc \n",
      "Cleaned Token Before =  psychology, linguistics, cognitive science, dynamical systems, artificial intelligence, robotics, animal cognition, plant cognition and neurobiology.\n",
      "Cleaned Token After =  psychology , linguistics , cognitive science , dynamical systems , artificial intelligence , robotics , animal cognition , plant cognition neurobiology . \n",
      "Cleaned Token After Stem =  psycholog , linguist , cognit scienc , dynam system , artifici intellig , robot , anim cognit , plant cognit neurobiolog . \n",
      "Cleaned Token Before =  affectiva is a software company that builds artificial intelligence that understands human emotions, cognitive states, activities and the objects people\n",
      "Cleaned Token After =  affectiva software company builds artificial intelligence understands human emotions , cognitive states , activities objects people \n",
      "Cleaned Token After Stem =  affectiva softwar compani build artifici intellig understand human emot , cognit state , activ object peopl \n",
      "Cleaned Token Before =  artificial intelligence may refer to: commonsense knowledge (artificial intelligence) commonsense reasoning this disambiguation page lists artificial\n",
      "Cleaned Token After =  artificial intelligence may refer : commonsense knowledge ( artificial intelligence ) commonsense reasoning disambiguation page lists artificial \n",
      "Cleaned Token After Stem =  artifici intellig may refer : commonsens knowledg ( artifici intellig ) commonsens reason disambigu page list artifici \n",
      "Cleaned Token Before =  creative arts, philosophy, neuroscience, affective computing, artificial intelligence, cognitive science, linguistics, operations research, creative\n",
      "Cleaned Token After =  creative arts , philosophy , neuroscience , affective computing , artificial intelligence , cognitive science , linguistics , operations research , creative \n",
      "Cleaned Token After Stem =  creativ art , philosophi , neurosci , affect comput , artifici intellig , cognit scienc , linguist , oper research , creativ \n",
      "Cleaned Token Before =  more time with a series of caring people (both humans and fellow artificial intelligences), it starts developing friendships and emotional connections, which\n",
      "Cleaned Token After =  time series caring people ( humans fellow artificial intelligences ) , starts developing friendships emotional connections , \n",
      "Cleaned Token After Stem =  time seri care peopl ( human fellow artifici intellig ) , start develop friendship emot connect , \n",
      "Cleaned Token Before =  andreas (2019). \"a brief history of artificial intelligence: on the past, present, and future of artificial intelligence\". california management review. 61\n",
      "Cleaned Token After =  andreas ( 2019 ) . `` brief history artificial intelligence : past , present , future artificial intelligence '' . california management review . 61 \n",
      "Cleaned Token After Stem =  andrea ( 2019 ) . `` brief histori artifici intellig : past , present , futur artifici intellig `` . california manag review . 61 \n",
      "Cleaned Token Before =  122°24′53″w﻿ / ﻿37.7623°n 122.4148°w﻿ / 37.7623; -122.4148 openai is an artificial intelligence (ai) research laboratory consisting of the for-profit corporation\n",
      "Cleaned Token After =  122°24′53″w﻿ / ﻿37.7623°n 122.4148°w﻿ / 37.7623 ; -122.4148 openai artificial intelligence ( ai ) research laboratory consisting for-profit corporation \n",
      "Cleaned Token After Stem =  122°24′53″w﻿ / ﻿37.7623°n 122.4148°w﻿ / 37.7623 ; -122.4148 openai artifici intellig ( ai ) research laboratori consist for-profit corpor \n",
      "Cleaned Token Before =  sustaining life in an artificial environment), and the application of genetics to improve human characteristics, such as health and intelligence. his article inspired\n",
      "Cleaned Token After =  sustaining life artificial environment ) , application genetics improve human characteristics , health intelligence . article inspired \n",
      "Cleaned Token After Stem =  sustain life artifici environ ) , applic genet improv human characterist , health intellig . articl inspir \n",
      "Cleaned Token Before =  president. in 2018, he started the presidential initiative for artificial intelligence and computing (piaic). the privately funded not-for-profit educational\n",
      "Cleaned Token After =  president . 2018 , started presidential initiative artificial intelligence computing ( piaic ) . privately funded not-for-profit educational \n",
      "Cleaned Token After Stem =  presid . 2018 , start presidenti initi artifici intellig comput ( piaic ) . privat fund not-for-profit educ \n",
      "Cleaned Token Before =  handles the exception or propagates it. in cognitive science and artificial intelligence, it is common to refer to david marr's levels of analysis. at any\n",
      "Cleaned Token After =  handles exception propagates . cognitive science artificial intelligence , common refer david marr 's levels analysis . \n",
      "Cleaned Token After Stem =  handl except propag . cognit scienc artifici intellig , common refer david marr 's level analysi . \n",
      "Cleaned Token Before =  research, and healthcare solutions[buzzword], through the use of artificial intelligence, data, analytics, cloud computing, and other advanced information\n",
      "Cleaned Token After =  research , healthcare solutions [ buzzword ] , use artificial intelligence , data , analytics , cloud computing , advanced information \n",
      "Cleaned Token After Stem =  research , healthcar solut [ buzzword ] , use artifici intellig , data , analyt , cloud comput , advanc inform \n",
      "Cleaned Token Before =  sherpa (also known as sherpa.ai) is a spanish artificial intelligence company specialized in predictive conversational digital assistants. it was founded\n",
      "Cleaned Token After =  sherpa ( also known sherpa.ai ) spanish artificial intelligence company specialized predictive conversational digital assistants . founded \n",
      "Cleaned Token After Stem =  sherpa ( also known sherpa.ai ) spanish artifici intellig compani special predict convers digit assist . found \n",
      "Cleaned Token Before =  co-founded both orthoclear and afiniti, the latter of which develops artificial intelligence for use in customer call centers. chishti was a named inventor\n",
      "Cleaned Token After =  co-founded orthoclear afiniti , latter develops artificial intelligence use customer call centers . chishti named inventor \n",
      "Cleaned Token After Stem =  co-found orthoclear afin , latter develop artifici intellig use custom call center . chishti name inventor \n",
      "Cleaned Token Before =  transformation company soroco, which specialises in automation using artificial intelligence sources. murty is the son of narayana murthy, founder of infosys\n",
      "Cleaned Token After =  transformation company soroco , specialises automation using artificial intelligence sources . murty son narayana murthy , founder infosys \n",
      "Cleaned Token After Stem =  transform compani soroco , specialis autom use artifici intellig sourc . murti son narayana murthi , founder infosi \n",
      "Cleaned Token Before =  meditation, psychedelics, philosophy of mind, politics, terrorism, and artificial intelligence. harris came to prominence for his criticism of religion, and islam\n",
      "Cleaned Token After =  meditation , psychedelics , philosophy mind , politics , terrorism , artificial intelligence . harris came prominence criticism religion , islam \n",
      "Cleaned Token After Stem =  medit , psychedel , philosophi mind , polit , terror , artifici intellig . harri came promin critic religion , islam \n",
      "Cleaned Token Before =  the age of artificial intelligence is a book by swedish-american cosmologist max tegmark from mit. life 3.0 discusses artificial intelligence (ai) and its\n",
      "Cleaned Token After =  age artificial intelligence book swedish-american cosmologist max tegmark mit . life 3.0 discusses artificial intelligence ( ai ) \n",
      "Cleaned Token After Stem =  age artifici intellig book swedish-american cosmologist max tegmark mit . life 3.0 discuss artifici intellig ( ai ) \n",
      "Cleaned Token Before =  in computer science from stanford university. he specialized in artificial intelligence research, noting that his interest in ai sparked from the realization\n",
      "Cleaned Token After =  computer science stanford university . specialized artificial intelligence research , noting interest ai sparked realization \n",
      "Cleaned Token After Stem =  comput scienc stanford univers . special artifici intellig research , note interest ai spark realiz \n",
      "Cleaned Token Before =  a.i. artificial intelligence - music from the motion picture is the film score of the 2001 film of the same name, composed and conducted by john williams\n",
      "Cleaned Token After =  a.i . artificial intelligence - music motion picture film score 2001 film name , composed conducted john williams \n",
      "Cleaned Token After Stem =  a.i . artifici intellig - music motion pictur film score 2001 film name , compos conduct john william \n",
      "Cleaned Token Before =  cognitive and computer scientist concerned largely with research of artificial intelligence (ai), co-founder of the massachusetts institute of technology's\n",
      "Cleaned Token After =  cognitive computer scientist concerned largely research artificial intelligence ( ai ) , co-founder massachusetts institute technology 's \n",
      "Cleaned Token After Stem =  cognit comput scientist concern larg research artifici intellig ( ai ) , co-found massachusett institut technolog 's \n",
      "Cleaned Token Before =  artificial stupidity is commonly used as a humorous opposite of the term artificial intelligence (ai), often as a derogatory reference to the inability\n",
      "Cleaned Token After =  artificial stupidity commonly used humorous opposite term artificial intelligence ( ai ) , often derogatory reference inability \n",
      "Cleaned Token After Stem =  artifici stupid commonli use humor opposit term artifici intellig ( ai ) , often derogatori refer inabl \n",
      "Cleaned Token Before =  the artificial intelligence applications institute (aiai) at the school of informatics at the university of edinburgh was a non-profit technology transfer\n",
      "Cleaned Token After =  artificial intelligence applications institute ( aiai ) school informatics university edinburgh non-profit technology transfer \n",
      "Cleaned Token After Stem =  artifici intellig applic institut ( aiai ) school informat univers edinburgh non-profit technolog transfer \n",
      "Cleaned Token Before =  anki was a robotics and artificial intelligence startup that put robotics technology in products for children. anki programmed physical objects to be\n",
      "Cleaned Token After =  anki robotics artificial intelligence startup put robotics technology products children . anki programmed physical objects \n",
      "Cleaned Token After Stem =  anki robot artifici intellig startup put robot technolog product children . anki program physic object \n",
      "Cleaned Token Before =  credited as being the key founder of theoretical computer science and artificial intelligence. from 2007 to 2013, the award was accompanied by an additional\n",
      "Cleaned Token After =  credited key founder theoretical computer science artificial intelligence . 2007 2013 , award accompanied additional \n",
      "Cleaned Token After Stem =  credit key founder theoret comput scienc artifici intellig . 2007 2013 , award accompani addit \n",
      "Cleaned Token Before =  and critically question argumentation schemes that are used in artificial intelligence and legal arguments. a propositional calculus or logic (also a\n",
      "Cleaned Token After =  critically question argumentation schemes used artificial intelligence legal arguments . propositional calculus logic ( also \n",
      "Cleaned Token After Stem =  critic question argument scheme use artifici intellig legal argument . proposit calculu logic ( also \n",
      "Cleaned Token Before =  a k-line, or knowledge-line, is a mental agent which represents an association of a group of other mental agents found active when a subject solves a certain\n",
      "Cleaned Token After =  k-line , knowledge-line , mental agent represents association group mental agents found active subject solves certain \n",
      "Cleaned Token After Stem =  k-line , knowledge-lin , mental agent repres associ group mental agent found activ subject solv certain \n",
      "Cleaned Token Before =  dabus is an artificial intelligence (ai) system created by stephen thaler. it reportedly conceived two inventions. the filing of patent applications designating\n",
      "Cleaned Token After =  dabus artificial intelligence ( ai ) system created stephen thaler . reportedly conceived two inventions . filing patent applications designating \n",
      "Cleaned Token After Stem =  dabu artifici intellig ( ai ) system creat stephen thaler . reportedli conceiv two invent . file patent applic design \n",
      "Cleaned Token Before =  featuring advanced technological and scientific achievements, such as artificial intelligence and cybernetics, juxtaposed with a degree of breakdown or radical\n",
      "Cleaned Token After =  featuring advanced technological scientific achievements , artificial intelligence cybernetics , juxtaposed degree breakdown radical \n",
      "Cleaned Token After Stem =  featur advanc technolog scientif achiev , artifici intellig cybernet , juxtapos degre breakdown radic \n",
      "Cleaned Token Before =  alivecor is a medical device and artificial intelligence company that sells ecg hardware and software for consumer mobile devices. the company is the\n",
      "Cleaned Token After =  alivecor medical device artificial intelligence company sells ecg hardware software consumer mobile devices . company \n",
      "Cleaned Token After Stem =  alivecor medic devic artifici intellig compani sell ecg hardwar softwar consum mobil devic . compani \n",
      "Cleaned Token Before =  actor, best known for his role as henry swinton in the film a.i. artificial intelligence. robards was born in new york city, the son of actor jason robards\n",
      "Cleaned Token After =  actor , best known role henry swinton film a.i . artificial intelligence . robards born new york city , son actor jason robards \n",
      "Cleaned Token After Stem =  actor , best known role henri swinton film a.i . artifici intellig . robard born new york citi , son actor jason robard \n",
      "Cleaned Token Before =  accessible to students in pakistan. the presidential initiative for artificial intelligence and computing (piaic) was launched by the president of pakistan\n",
      "Cleaned Token After =  accessible students pakistan . presidential initiative artificial intelligence computing ( piaic ) launched president pakistan \n",
      "Cleaned Token After Stem =  access student pakistan . presidenti initi artifici intellig comput ( piaic ) launch presid pakistan \n",
      "Cleaned Token Before =  civilization v (2010) as a joke. according to the legend, each leader's artificial intelligence in civilization had a parameter that described his or her aggression\n",
      "Cleaned Token After =  civilization v ( 2010 ) joke . according legend , leader 's artificial intelligence civilization parameter described aggression \n",
      "Cleaned Token After Stem =  civil v ( 2010 ) joke . accord legend , leader 's artifici intellig civil paramet describ aggress \n",
      "Cleaned Token Before =  intelligence systems\" sensami – a congress on ambient intelligence. aitami – workshop on \"artificial intelligence techniques for ambient intelligence\"\n",
      "Cleaned Token After =  intelligence systems '' sensami – congress ambient intelligence . aitami – workshop `` artificial intelligence techniques ambient intelligence '' \n",
      "Cleaned Token After Stem =  intellig system `` sensami – congress ambient intellig . aitami – workshop `` artifici intellig techniqu ambient intellig `` \n",
      "Cleaned Token Before =  martin ford is a futurist and author focusing on artificial intelligence and robotics, and the impact of these technologies on the job market, economy\n",
      "Cleaned Token After =  martin ford futurist author focusing artificial intelligence robotics , impact technologies job market , economy \n",
      "Cleaned Token After Stem =  martin ford futurist author focus artifici intellig robot , impact technolog job market , economi \n",
      "Cleaned Token Before =  had been exploring \"machine intelligence\" for up to ten years prior to the founding of the field of artificial intelligence (ai) research in 1956. it was\n",
      "Cleaned Token After =  exploring `` machine intelligence '' ten years prior founding field artificial intelligence ( ai ) research 1956. \n",
      "Cleaned Token After Stem =  explor `` machin intellig `` ten year prior found field artifici intellig ( ai ) research 1956 . \n",
      "Cleaned Token Before =  harrod also runs a youtube channel to educate the public about artificial intelligence. as of march 2021, her youtube channel has over 64 thousand subscribers\n",
      "Cleaned Token After =  harrod also runs youtube channel educate public artificial intelligence . march 2021 , youtube channel 64 thousand subscribers \n",
      "Cleaned Token After Stem =  harrod also run youtub channel educ public artifici intellig . march 2021 , youtub channel 64 thousand subscrib \n",
      "Cleaned Token Before =  tsa commissioner, played by daniel mann arthur - arthur is an artificial intelligence created by dr. kenneth farnstein on a derelict asteroid miner parked\n",
      "Cleaned Token After =  tsa commissioner , played daniel mann arthur - arthur artificial intelligence created dr. kenneth farnstein derelict asteroid miner parked \n",
      "Cleaned Token After Stem =  tsa commission , play daniel mann arthur - arthur artifici intellig creat dr. kenneth farnstein derelict asteroid miner park \n",
      "Cleaned Token Before =  and artificial intelligence was founded in 1987 and is published by world scientific. the journal covers developments in artificial intelligence, and\n",
      "Cleaned Token After =  artificial intelligence founded 1987 published world scientific . journal covers developments artificial intelligence , \n",
      "Cleaned Token After Stem =  artifici intellig found 1987 publish world scientif . journal cover develop artifici intellig , \n",
      "Cleaned Token Before =  planet tatooine in a new hope. their artificial intelligence is more basic than most other forms of artificial intelligence seen in the star wars universe,\n",
      "Cleaned Token After =  planet tatooine new hope . artificial intelligence basic forms artificial intelligence seen star wars universe , \n",
      "Cleaned Token After Stem =  planet tatooin new hope . artifici intellig basic form artifici intellig seen star war univers , \n",
      "Cleaned Token Before =  entrepreneur in artificial intelligence, machine learning and data science. he is currently the vice president, global head of artificial intelligence and chief\n",
      "Cleaned Token After =  entrepreneur artificial intelligence , machine learning data science . currently vice president , global head artificial intelligence chief \n",
      "Cleaned Token After Stem =  entrepreneur artifici intellig , machin learn data scienc . current vice presid , global head artifici intellig chief \n",
      "Cleaned Token Before =  moravec's paradox is the observation by artificial intelligence and robotics researchers that, contrary to traditional assumptions, reasoning requires\n",
      "Cleaned Token After =  moravec 's paradox observation artificial intelligence robotics researchers , contrary traditional assumptions , reasoning requires \n",
      "Cleaned Token After Stem =  moravec 's paradox observ artifici intellig robot research , contrari tradit assumpt , reason requir \n",
      "Cleaned Token Before =  artificial intelligence, deep learning and artificial neural networks. he is a co-director of the dalle molle institute for artificial intelligence research\n",
      "Cleaned Token After =  artificial intelligence , deep learning artificial neural networks . co-director dalle molle institute artificial intelligence research \n",
      "Cleaned Token After Stem =  artifici intellig , deep learn artifici neural network . co-director dall moll institut artifici intellig research \n",
      "Cleaned Token Before =  the loebner prize is an annual competition in artificial intelligence that awards prizes to the computer programs considered by the judges to be the most\n",
      "Cleaned Token After =  loebner prize annual competition artificial intelligence awards prizes computer programs considered judges \n",
      "Cleaned Token After Stem =  loebner prize annual competit artifici intellig award prize comput program consid judg \n",
      "Cleaned Token Before =  this list is for fictional artificial intelligences. brainiac from the superman comics (1958) deep thought, marvin the paranoid android from the hitchhiker's\n",
      "Cleaned Token After =  list fictional artificial intelligences . brainiac superman comics ( 1958 ) deep thought , marvin paranoid android hitchhiker 's \n",
      "Cleaned Token After Stem =  list fiction artifici intellig . brainiac superman comic ( 1958 ) deep thought , marvin paranoid android hitchhik 's \n",
      "Cleaned Token Before =   made up of real biological neurons, or an artificial neural network, for solving artificial intelligence (ai) problems. the connections of the biological\n",
      "Cleaned Token After =  made real biological neurons , artificial neural network , solving artificial intelligence ( ai ) problems . connections biological \n",
      "Cleaned Token After Stem =  made real biolog neuron , artifici neural network , solv artifici intellig ( ai ) problem . connect biolog \n",
      "Cleaned Token Before =  possibility of nonbiological minds is explored in the field of artificial intelligence, which works closely in relation with cybernetics and information\n",
      "Cleaned Token After =  possibility nonbiological minds explored field artificial intelligence , works closely relation cybernetics information \n",
      "Cleaned Token After Stem =  possibl nonbiolog mind explor field artifici intellig , work close relat cybernet inform \n",
      "Cleaned Token Before =  success of the series to its historical theme and fair play; the artificial intelligence (ai) players have fewer advantages than in many of the series'\n",
      "Cleaned Token After =  success series historical theme fair play ; artificial intelligence ( ai ) players fewer advantages many series ' \n",
      "Cleaned Token After Stem =  success seri histor theme fair play ; artifici intellig ( ai ) player fewer advantag mani seri ' \n",
      "Cleaned Token Before =  in artificial intelligence: the very idea, haugeland coined the term gofai (\"good old-fashioned artificial intelligence\") for symbolic artificial intelligence\n",
      "Cleaned Token After =  artificial intelligence : idea , haugeland coined term gofai ( `` good old-fashioned artificial intelligence '' ) symbolic artificial intelligence \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Token After Stem =  artifici intellig : idea , haugeland coin term gofai ( `` good old-fashion artifici intellig `` ) symbol artifici intellig \n",
      "Cleaned Token Before =  artificial intelligence, in modern terms, generally refers to computer systems that mimic human cognitive functions. it encompasses independent learning\n",
      "Cleaned Token After =  artificial intelligence , modern terms , generally refers computer systems mimic human cognitive functions . encompasses independent learning \n",
      "Cleaned Token After Stem =  artifici intellig , modern term , gener refer comput system mimic human cognit function . encompass independ learn \n",
      "Cleaned Token Before =  nervana systems is an artificial intelligence software company based in san diego, california, and palo alto, california. the company provides a full-stack\n",
      "Cleaned Token After =  nervana systems artificial intelligence software company based san diego , california , palo alto , california . company provides full-stack \n",
      "Cleaned Token After Stem =  nervana system artifici intellig softwar compani base san diego , california , palo alto , california . compani provid full-stack \n",
      "Cleaned Token Before =  use a variety of media and techniques, including performance, artificial intelligence and programmed computer-based interaction. she created p5.js, an\n",
      "Cleaned Token After =  use variety media techniques , including performance , artificial intelligence programmed computer-based interaction . created p5.js , \n",
      "Cleaned Token After Stem =  use varieti media techniqu , includ perform , artifici intellig program computer-bas interact . creat p5.j , \n",
      "Cleaned Token Before =  the wadhwani institute for artificial intelligence, based in mumbai, maharashtra is an independent, non-profit research institute. founded in 2018, it\n",
      "Cleaned Token After =  wadhwani institute artificial intelligence , based mumbai , maharashtra independent , non-profit research institute . founded 2018 , \n",
      "Cleaned Token After Stem =  wadhwani institut artifici intellig , base mumbai , maharashtra independ , non-profit research institut . found 2018 , \n",
      "Cleaned Token Before =  [1995]. artificial intelligence: a modern approach (3rd ed.). prentice hall. p. 103. isbn 978-0-13-604259-4. russell, stuart j. (2018). artificial intelligence\n",
      "Cleaned Token After =  [ 1995 ] . artificial intelligence : modern approach ( 3rd ed. ) . prentice hall . p. 103. isbn 978-0-13-604259-4. russell , stuart j . ( 2018 ) . artificial intelligence \n",
      "Cleaned Token After Stem =  [ 1995 ] . artifici intellig : modern approach ( 3rd ed . ) . prentic hall . p. 103. isbn 978-0-13-604259-4. russel , stuart j . ( 2018 ) . artifici intellig \n",
      "Cleaned Token Before =  mohamed bin zayed university of artificial intelligence (mbzuai) is a graduate-level, research-based academic institution that is located in abu dhabi\n",
      "Cleaned Token After =  mohamed bin zayed university artificial intelligence ( mbzuai ) graduate-level , research-based academic institution located abu dhabi \n",
      "Cleaned Token After Stem =  moham bin zay univers artifici intellig ( mbzuai ) graduate-level , research-bas academ institut locat abu dhabi \n",
      "Cleaned Token Before =  computer science and the mit artificial intelligence lab, and is now the mit computer science and artificial intelligence laboratory. in 1985 minsky became\n",
      "Cleaned Token After =  computer science mit artificial intelligence lab , mit computer science artificial intelligence laboratory . 1985 minsky became \n",
      "Cleaned Token After Stem =  comput scienc mit artifici intellig lab , mit comput scienc artifici intellig laboratori . 1985 minski becam \n",
      "Cleaned Token Before =  operational artificial intelligence, or operational ai, is a type of intelligent system designed for real-world applications, particularly at commercial\n",
      "Cleaned Token After =  operational artificial intelligence , operational ai , type intelligent system designed real-world applications , particularly commercial \n",
      "Cleaned Token After Stem =  oper artifici intellig , oper ai , type intellig system design real-world applic , particularli commerci \n",
      "Cleaned Token Before =  intelligent automated management underpinned by mobile edge computing, artificial intelligence and blockchain technologies. recent studies have developed first\n",
      "Cleaned Token After =  intelligent automated management underpinned mobile edge computing , artificial intelligence blockchain technologies . recent studies developed first \n",
      "Cleaned Token After Stem =  intellig autom manag underpin mobil edg comput , artifici intellig blockchain technolog . recent studi develop first \n",
      "Cleaned Token Before =  suicide attempt when artificial intelligence focuses on general hospital patients\". at this point in time, artificial intelligence has not been able to\n",
      "Cleaned Token After =  suicide attempt artificial intelligence focuses general hospital patients '' . point time , artificial intelligence able \n",
      "Cleaned Token After Stem =  suicid attempt artifici intellig focus gener hospit patient `` . point time , artifici intellig abl \n",
      "Cleaned Token Before =  robotics introduction to robotics the fusion of animatronics with artificial intelligence results in androids, as is usually known, robots that imitate human\n",
      "Cleaned Token After =  robotics introduction robotics fusion animatronics artificial intelligence results androids , usually known , robots imitate human \n",
      "Cleaned Token After Stem =  robot introduct robot fusion animatron artifici intellig result android , usual known , robot imit human \n",
      "Cleaned Token Before =  distinguished from a human participant has been one test of a successful artificial intelligence (the turing test). a human judge engages in a natural language\n",
      "Cleaned Token After =  distinguished human participant one test successful artificial intelligence ( turing test ) . human judge engages natural language \n",
      "Cleaned Token After Stem =  distinguish human particip one test success artifici intellig ( ture test ) . human judg engag natur languag \n",
      "Cleaned Token Before =  computers and structures, 154, 1–16. gent, edd (13 april 2020). \"artificial intelligence is evolving all by itself\". science | aaas. archived from the original\n",
      "Cleaned Token After =  computers structures , 154 , 1–16 . gent , edd ( 13 april 2020 ) . `` artificial intelligence evolving '' . science | aaas . archived original \n",
      "Cleaned Token After Stem =  comput structur , 154 , 1–16 . gent , edd ( 13 april 2020 ) . `` artifici intellig evolv `` . scienc | aaa . archiv origin \n",
      "Cleaned Token Before =  depicted visually in any of the terminator media, since it is an artificial intelligence system. in terminator salvation, skynet made its first onscreen\n",
      "Cleaned Token After =  depicted visually terminator media , since artificial intelligence system . terminator salvation , skynet made first onscreen \n",
      "Cleaned Token After Stem =  depict visual termin media , sinc artifici intellig system . termin salvat , skynet made first onscreen \n",
      "Cleaned Token Before =  institute at new york university. her research focuses on the role of artificial intelligence in journalism. as a fellow at the tow center for digital journalism\n",
      "Cleaned Token After =  institute new york university . research focuses role artificial intelligence journalism . fellow tow center digital journalism \n",
      "Cleaned Token After Stem =  institut new york univers . research focus role artifici intellig journal . fellow tow center digit journal \n",
      "Cleaned Token Before =  partnership with toyota which will use nvidia's drive px-series artificial intelligence platform for its autonomous vehicles. in july 2017, nvidia and\n",
      "Cleaned Token After =  partnership toyota use nvidia 's drive px-series artificial intelligence platform autonomous vehicles . july 2017 , nvidia \n",
      "Cleaned Token After Stem =  partnership toyota use nvidia 's drive px-seri artifici intellig platform autonom vehicl . juli 2017 , nvidia \n",
      "Cleaned Token Before =  the fields of marketing and artificial intelligence converge in systems which assist in areas such as market forecasting, and automation of processes\n",
      "Cleaned Token After =  fields marketing artificial intelligence converge systems assist areas market forecasting , automation processes \n",
      "Cleaned Token After Stem =  field market artifici intellig converg system assist area market forecast , autom process \n",
      "Cleaned Token Before =  human consciousness. he is one of the pioneers of compassionate artificial intelligence movement. amit ray was born on 12 august 1960. he earned a bs in\n",
      "Cleaned Token After =  human consciousness . one pioneers compassionate artificial intelligence movement . amit ray born 12 august 1960. earned bs \n",
      "Cleaned Token After Stem =  human conscious . one pioneer compassion artifici intellig movement . amit ray born 12 august 1960. earn bs \n",
      "Cleaned Token Before =  computer science for web programming, cs50 computer science for artificial intelligence, cs50 computer science for game development and cs50 computer science\n",
      "Cleaned Token After =  computer science web programming , cs50 computer science artificial intelligence , cs50 computer science game development cs50 computer science \n",
      "Cleaned Token After Stem =  comput scienc web program , cs50 comput scienc artifici intellig , cs50 comput scienc game develop cs50 comput scienc \n",
      "Cleaned Token Before =  the artificial intelligence (ai) in cyber security market report by zion market research, the role of machine learning and artificial intelligence will\n",
      "Cleaned Token After =  artificial intelligence ( ai ) cyber security market report zion market research , role machine learning artificial intelligence \n",
      "Cleaned Token After Stem =  artifici intellig ( ai ) cyber secur market report zion market research , role machin learn artifici intellig \n",
      "Cleaned Token Before =  in video game ai, a utility system, or utility ai, is a simple but effective way to model behaviors for non-player characters. using numbers, formulas\n",
      "Cleaned Token After =  video game ai , utility system , utility ai , simple effective way model behaviors non-player characters . using numbers , formulas \n",
      "Cleaned Token After Stem =  video game ai , util system , util ai , simpl effect way model behavior non-play charact . use number , formula \n",
      "Cleaned Token Before =  computational linguistics draws upon linguistics, computer science, artificial intelligence, mathematics, logic, philosophy, cognitive science, cognitive psychology\n",
      "Cleaned Token After =  computational linguistics draws upon linguistics , computer science , artificial intelligence , mathematics , logic , philosophy , cognitive science , cognitive psychology \n",
      "Cleaned Token After Stem =  comput linguist draw upon linguist , comput scienc , artifici intellig , mathemat , logic , philosophi , cognit scienc , cognit psycholog \n",
      "Cleaned Token Before =  headquartered in bangalore, india and owned by inmobi. glance is an artificial intelligence platform that delivers personalised, ad-free content to the lock\n",
      "Cleaned Token After =  headquartered bangalore , india owned inmobi . glance artificial intelligence platform delivers personalised , ad-free content lock \n",
      "Cleaned Token After Stem =  headquart bangalor , india own inmobi . glanc artifici intellig platform deliv personalis , ad-fre content lock \n",
      "Cleaned Token Before =  automatically. although automated reasoning is considered a sub-field of artificial intelligence, it also has connections with theoretical computer science and\n",
      "Cleaned Token After =  automatically . although automated reasoning considered sub-field artificial intelligence , also connections theoretical computer science \n",
      "Cleaned Token After Stem =  automat . although autom reason consid sub-field artifici intellig , also connect theoret comput scienc \n",
      "Cleaned Token Before =  optimization inspired by biological evolution, and the subfield of artificial intelligence and soft computing studying these algorithms. in technical terms\n",
      "Cleaned Token After =  optimization inspired biological evolution , subfield artificial intelligence soft computing studying algorithms . technical terms \n",
      "Cleaned Token After Stem =  optim inspir biolog evolut , subfield artifici intellig soft comput studi algorithm . technic term \n",
      "Cleaned Token Before =  unbabel is an artificial intelligence-powered human translation platform. the company has headquarters in lisbon, portugal, and san francisco, california\n",
      "Cleaned Token After =  unbabel artificial intelligence-powered human translation platform . company headquarters lisbon , portugal , san francisco , california \n",
      "Cleaned Token After Stem =  unbabel artifici intelligence-pow human translat platform . compani headquart lisbon , portug , san francisco , california \n",
      "Cleaned Token Before =  bonn, tess (2018-09-20). \"ziprecruiter ceo downplays threat of artificial intelligence on job market\". the hill. retrieved 2019-03-05. libassi, matthew\n",
      "Cleaned Token After =  bonn , tess ( 2018-09-20 ) . `` ziprecruiter ceo downplays threat artificial intelligence job market '' . hill . retrieved 2019-03-05. libassi , matthew \n",
      "Cleaned Token After Stem =  bonn , tess ( 2018-09-20 ) . `` ziprecruit ceo downplay threat artifici intellig job market `` . hill . retriev 2019-03-05. libassi , matthew \n",
      "Cleaned Token Before =  turing prize for the best agi safety paper. his 2014 book ethical artificial intelligence brings together all his ideas about ai. hibbard, bill (2008), \"the\n",
      "Cleaned Token After =  turing prize best agi safety paper . 2014 book ethical artificial intelligence brings together ideas ai . hibbard , bill ( 2008 ) , `` \n",
      "Cleaned Token After Stem =  ture prize best agi safeti paper . 2014 book ethic artifici intellig bring togeth idea ai . hibbard , bill ( 2008 ) , `` \n",
      "Cleaned Token Before =  artist award for supporting actor for his performance in a.i. artificial intelligence (2001). he also appeared in cory in the house (2007–08), playing\n",
      "Cleaned Token After =  artist award supporting actor performance a.i . artificial intelligence ( 2001 ) . also appeared cory house ( 2007–08 ) , playing \n",
      "Cleaned Token After Stem =  artist award support actor perform a.i . artifici intellig ( 2001 ) . also appear cori hous ( 2007–08 ) , play \n",
      "Cleaned Token Before =  grants from elon musk to investigate existential risk from advanced artificial intelligence. he was born in sweden to karin tegmark and american-born professor\n",
      "Cleaned Token After =  grants elon musk investigate existential risk advanced artificial intelligence . born sweden karin tegmark american-born professor \n",
      "Cleaned Token After Stem =  grant elon musk investig existenti risk advanc artifici intellig . born sweden karin tegmark american-born professor \n",
      "Cleaned Token Before =  machine intelligence is a transformative (offering optional open access) scientific journal dedicated to covering machine learning and artificial intelligence\n",
      "Cleaned Token After =  machine intelligence transformative ( offering optional open access ) scientific journal dedicated covering machine learning artificial intelligence \n",
      "Cleaned Token After Stem =  machin intellig transform ( offer option open access ) scientif journal dedic cover machin learn artifici intellig \n",
      "Cleaned Token Before =  purposes. it is discussed in artificial intelligence research publications as an approach to strong ai (artificial general intelligence) and to at least weak\n",
      "Cleaned Token After =  purposes . discussed artificial intelligence research publications approach strong ai ( artificial general intelligence ) least weak \n",
      "Cleaned Token After Stem =  purpos . discuss artifici intellig research public approach strong ai ( artifici gener intellig ) least weak \n",
      "Cleaned Token Before =  content analysis is a subset of computer vision and thereby of artificial intelligence. two major academic benchmark initiatives are trecvid, which uses\n",
      "Cleaned Token After =  content analysis subset computer vision thereby artificial intelligence . two major academic benchmark initiatives trecvid , uses \n",
      "Cleaned Token After Stem =  content analysi subset comput vision therebi artifici intellig . two major academ benchmark initi trecvid , use \n",
      "Cleaned Token Before =  dedicated to the theory and application of computer science and artificial intelligence to psychiatry. colby was a pioneer in the development of computer\n",
      "Cleaned Token After =  dedicated theory application computer science artificial intelligence psychiatry . colby pioneer development computer \n",
      "Cleaned Token After Stem =  dedic theori applic comput scienc artifici intellig psychiatri . colbi pioneer develop comput \n",
      "Cleaned Token Before =  roles in the films mansfield park (1999), bedazzled (2000), a.i. artificial intelligence (2001), the importance of being earnest (2002), and timeline (2003)\n",
      "Cleaned Token After =  roles films mansfield park ( 1999 ) , bedazzled ( 2000 ) , a.i . artificial intelligence ( 2001 ) , importance earnest ( 2002 ) , timeline ( 2003 ) \n",
      "Cleaned Token After Stem =  role film mansfield park ( 1999 ) , bedazzl ( 2000 ) , a.i . artifici intellig ( 2001 ) , import earnest ( 2002 ) , timelin ( 2003 ) \n",
      "Cleaned Token Before =  being taught. researchers have developed training methods for artificial-intelligence devices as well. evolutionary algorithms, including genetic programming\n",
      "Cleaned Token After =  taught . researchers developed training methods artificial-intelligence devices well . evolutionary algorithms , including genetic programming \n",
      "Cleaned Token After Stem =  taught . research develop train method artificial-intellig devic well . evolutionari algorithm , includ genet program \n",
      "Cleaned Token Before =  v.i.s. (just a rather very intelligent system) is a fictional artificial intelligence that first appeared in the marvel cinematic universe where he was\n",
      "Cleaned Token After =  v.i.s . ( rather intelligent system ) fictional artificial intelligence first appeared marvel cinematic universe \n",
      "Cleaned Token After Stem =  v.i. . ( rather intellig system ) fiction artifici intellig first appear marvel cinemat univers \n",
      "Cleaned Token Before =  capabilities include: acoustic signal processing quantum computing artificial intelligence the division's products and contracts include: visible infrared\n",
      "Cleaned Token After =  capabilities include : acoustic signal processing quantum computing artificial intelligence division 's products contracts include : visible infrared \n",
      "Cleaned Token After Stem =  capabl includ : acoust signal process quantum comput artifici intellig divis 's product contract includ : visibl infrar \n",
      "Cleaned Token Before =  alesis is an artificially intelligent computer system capable of answering questions posed in natural language, developed by venture coding; a small tech\n",
      "Cleaned Token After =  alesis artificially intelligent computer system capable answering questions posed natural language , developed venture coding ; small tech \n",
      "Cleaned Token After Stem =  alesi artifici intellig comput system capabl answer question pose natur languag , develop ventur code ; small tech \n",
      "Cleaned Token Before =  company headquartered in noida, india, is known for its advanced artificial intelligence (ai) ecosystem, provides 'connected fitness solutions' bundled\n",
      "Cleaned Token After =  company headquartered noida , india , known advanced artificial intelligence ( ai ) ecosystem , provides 'connected fitness solutions ' bundled \n",
      "Cleaned Token After Stem =  compani headquart noida , india , known advanc artifici intellig ( ai ) ecosystem , provid 'connect fit solut ' bundl \n",
      "Cleaned Token Before =  in artificial intelligence, a fluent is a condition that can change over time. in logical approaches to reasoning about actions, fluents can be represented\n",
      "Cleaned Token After =  artificial intelligence , fluent condition change time . logical approaches reasoning actions , fluents represented \n",
      "Cleaned Token After Stem =  artifici intellig , fluent condit chang time . logic approach reason action , fluent repres \n",
      "Cleaned Token Before =  although it was originally presented in reaction to the statements of artificial intelligence (ai) researchers, it is not an argument against the goals of mainstream\n",
      "Cleaned Token After =  although originally presented reaction statements artificial intelligence ( ai ) researchers , argument goals mainstream \n",
      "Cleaned Token After Stem =  although origin present reaction statement artifici intellig ( ai ) research , argument goal mainstream \n",
      "Cleaned Token Before =  to the value of distributed intelligence for the common good are paramount, though group theory and artificial intelligence have something to offer. individuals\n",
      "Cleaned Token After =  value distributed intelligence common good paramount , though group theory artificial intelligence something offer . individuals \n",
      "Cleaned Token After Stem =  valu distribut intellig common good paramount , though group theori artifici intellig someth offer . individu \n",
      "Cleaned Token Before =  human compatible: artificial intelligence and the problem of control is a 2019 non-fiction book by computer scientist stuart j. russell. it asserts that\n",
      "Cleaned Token After =  human compatible : artificial intelligence problem control 2019 non-fiction book computer scientist stuart j. russell . asserts \n",
      "Cleaned Token After Stem =  human compat : artifici intellig problem control 2019 non-fict book comput scientist stuart j. russel . assert \n",
      "Cleaned Token Before =  founders of the discipline of artificial intelligence. he co-authored the document that coined the term \"artificial intelligence\" (ai), developed the lisp\n",
      "Cleaned Token After =  founders discipline artificial intelligence . co-authored document coined term `` artificial intelligence '' ( ai ) , developed lisp \n",
      "Cleaned Token After Stem =  founder disciplin artifici intellig . co-author document coin term `` artifici intellig `` ( ai ) , develop lisp \n",
      "Cleaned Token Before =  us part ii (2020). she has also appeared in films such as a.i. artificial intelligence (2001), walking tall (2004), into the blue (2005), the kingdom\n",
      "Cleaned Token After =  us part ii ( 2020 ) . also appeared films a.i . artificial intelligence ( 2001 ) , walking tall ( 2004 ) , blue ( 2005 ) , kingdom \n",
      "Cleaned Token After Stem =  us part ii ( 2020 ) . also appear film a.i . artifici intellig ( 2001 ) , walk tall ( 2004 ) , blue ( 2005 ) , kingdom \n",
      "Cleaned Token Before =  ipsoft, is an american technology company. it primarily focuses on artificial intelligence, cognitive and autonomic solutions for enterprises. amelia, an\n",
      "Cleaned Token After =  ipsoft , american technology company . primarily focuses artificial intelligence , cognitive autonomic solutions enterprises . amelia , \n",
      "Cleaned Token After Stem =  ipsoft , american technolog compani . primarili focus artifici intellig , cognit autonom solut enterpris . amelia , \n",
      "Cleaned Token Before =  calculus. it quickly became the favored programming language for artificial intelligence (ai) research. as one of the earliest programming languages, lisp\n",
      "Cleaned Token After =  calculus . quickly became favored programming language artificial intelligence ( ai ) research . one earliest programming languages , lisp \n",
      "Cleaned Token After Stem =  calculu . quickli becam favor program languag artifici intellig ( ai ) research . one earliest program languag , lisp \n",
      "Cleaned Token Before =  was the former chief scientist at baidu, building the company's artificial intelligence group into a team of several thousand people. ng is an adjunct\n",
      "Cleaned Token After =  former chief scientist baidu , building company 's artificial intelligence group team several thousand people . ng adjunct \n",
      "Cleaned Token After Stem =  former chief scientist baidu , build compani 's artifici intellig group team sever thousand peopl . ng adjunct \n",
      "Cleaned Token Before =  reasoning, artificial intelligence (1996) dagum p, luby m (1997). \"an optimal approximation algorithm for bayesian inference\". artificial intelligence. 93 (1–2):\n",
      "Cleaned Token After =  reasoning , artificial intelligence ( 1996 ) dagum p , luby ( 1997 ) . `` optimal approximation algorithm bayesian inference '' . artificial intelligence . 93 ( 1–2 ) : \n",
      "Cleaned Token After Stem =  reason , artifici intellig ( 1996 ) dagum p , lubi ( 1997 ) . `` optim approxim algorithm bayesian infer `` . artifici intellig . 93 ( 1–2 ) : \n",
      "Cleaned Token Before =  (chimpanzee) ai (sloth) or maned sloth, a sloth found in brazil artificial intelligence, intelligence of machines and robots .ai, a top-level internet domain\n",
      "Cleaned Token After =  ( chimpanzee ) ai ( sloth ) maned sloth , sloth found brazil artificial intelligence , intelligence machines robots .ai , top-level internet domain \n",
      "Cleaned Token After Stem =  ( chimpanze ) ai ( sloth ) mane sloth , sloth found brazil artifici intellig , intellig machin robot .ai , top-level internet domain \n",
      "Cleaned Token Before =  rather than assuming idealized instrumental rationality. within artificial intelligence, a rational agent is typically one that maximizes its expected\n",
      "Cleaned Token After =  rather assuming idealized instrumental rationality . within artificial intelligence , rational agent typically one maximizes expected \n",
      "Cleaned Token After Stem =  rather assum ideal instrument ration . within artifici intellig , ration agent typic one maxim expect \n",
      "Cleaned Token Before =  accounting or finance, or a category of program usage such as artificial intelligence or email. languages and systems within a single programming domain\n",
      "Cleaned Token After =  accounting finance , category program usage artificial intelligence email . languages systems within single programming domain \n",
      "Cleaned Token After Stem =  account financ , categori program usag artifici intellig email . languag system within singl program domain \n",
      "Cleaned Token Before =  september 2018 interview on the pbs amanpour program, he stated that artificial intelligence, with all its capabilities, will never be capable of creativity\n",
      "Cleaned Token After =  september 2018 interview pbs amanpour program , stated artificial intelligence , capabilities , never capable creativity \n",
      "Cleaned Token After Stem =  septemb 2018 interview pb amanpour program , state artifici intellig , capabl , never capabl creativ \n",
      "Cleaned Token Before =  an android is a robot or other artificial being designed to resemble a human, and often made from a flesh-like material. historically, androids were completely\n",
      "Cleaned Token After =  android robot artificial designed resemble human , often made flesh-like material . historically , androids completely \n",
      "Cleaned Token After Stem =  android robot artifici design resembl human , often made flesh-lik materi . histor , android complet \n",
      "Cleaned Token Before =  you look like a thing and i love you: how artificial intelligence works and why it's making the world a weirder place is a 2019 nonfiction book by optics\n",
      "Cleaned Token After =  look like thing love : artificial intelligence works 's making world weirder place 2019 nonfiction book optics \n",
      "Cleaned Token After Stem =  look like thing love : artifici intellig work 's make world weirder place 2019 nonfict book optic \n",
      "Cleaned Token Before =  claudico is an artificial intelligence computer program designed to play no limit texas hold 'em heads-up. claudico was designed by carnegie mellon professor\n",
      "Cleaned Token After =  claudico artificial intelligence computer program designed play limit texas hold 'em heads-up . claudico designed carnegie mellon professor \n",
      "Cleaned Token After Stem =  claudico artifici intellig comput program design play limit texa hold 'em heads-up . claudico design carnegi mellon professor \n",
      "Cleaned Token Before =  airport operators. finavia has also been recognized for the use of artificial intelligence and data in its airports. finavia has partnered with the finnish\n",
      "Cleaned Token After =  airport operators . finavia also recognized use artificial intelligence data airports . finavia partnered finnish \n",
      "Cleaned Token After Stem =  airport oper . finavia also recogn use artifici intellig data airport . finavia partner finnish \n",
      "Cleaned Token Before =  lab, crowdflower) is a human-in-the-loop machine learning and artificial intelligence company based in san francisco. the company raised $58 million\n",
      "Cleaned Token After =  lab , crowdflower ) human-in-the-loop machine learning artificial intelligence company based san francisco . company raised $ 58 million \n",
      "Cleaned Token After Stem =  lab , crowdflow ) human-in-the-loop machin learn artifici intellig compani base san francisco . compani rais $ 58 million \n",
      "Cleaned Token Before =  particularly in artificial intelligence and machine learning. for the subset of ai algorithms, the term regulation of artificial intelligence is used. the\n",
      "Cleaned Token After =  particularly artificial intelligence machine learning . subset ai algorithms , term regulation artificial intelligence used . \n",
      "Cleaned Token After Stem =  particularli artifici intellig machin learn . subset ai algorithm , term regul artifici intellig use . \n",
      "Cleaned Token Before =  empowerment in the field of artificial intelligence formalises and quantifies (via information theory) the potential an agent perceives that it has to\n",
      "Cleaned Token After =  empowerment field artificial intelligence formalises quantifies ( via information theory ) potential agent perceives \n",
      "Cleaned Token After Stem =  empower field artifici intellig formalis quantifi ( via inform theori ) potenti agent perceiv \n",
      "Cleaned Token Before =  demis hassabis cbe frs freng frsa (born 27 july 1976) is a british artificial intelligence researcher, neuroscientist, video game designer, entrepreneur,\n",
      "Cleaned Token After =  demis hassabis cbe frs freng frsa ( born 27 july 1976 ) british artificial intelligence researcher , neuroscientist , video game designer , entrepreneur , \n",
      "Cleaned Token After Stem =  demi hassabi cbe fr freng frsa ( born 27 juli 1976 ) british artifici intellig research , neuroscientist , video game design , entrepreneur , \n",
      "Cleaned Token Before =  tenants of the city include the mohamed bin zayed university of artificial intelligence (mbzuai) and the international renewable energy agency (irena)\n",
      "Cleaned Token After =  tenants city include mohamed bin zayed university artificial intelligence ( mbzuai ) international renewable energy agency ( irena ) \n",
      "Cleaned Token After Stem =  tenant citi includ moham bin zay univers artifici intellig ( mbzuai ) intern renew energi agenc ( irena ) \n",
      "Cleaned Token Before =  appear to \"learn\", making them suited for applications such as artificial intelligence, expert systems, natural-language processing and computer games\n",
      "Cleaned Token After =  appear `` learn '' , making suited applications artificial intelligence , expert systems , natural-language processing computer games \n",
      "Cleaned Token After Stem =  appear `` learn `` , make suit applic artifici intellig , expert system , natural-languag process comput game \n",
      "Cleaned Token Before =  corps lieutenant general who serves as the commander of the joint artificial intelligence center. previously, he was the deputy chief of computer network\n",
      "Cleaned Token After =  corps lieutenant general serves commander joint artificial intelligence center . previously , deputy chief computer network \n",
      "Cleaned Token After Stem =  corp lieuten gener serv command joint artifici intellig center . previous , deputi chief comput network \n",
      "Cleaned Token Before =  theoretical artificial intelligence is a quarterly peer-reviewed scientific journal published by taylor and francis. it covers all aspects of artificial intelligence\n",
      "Cleaned Token After =  theoretical artificial intelligence quarterly peer-reviewed scientific journal published taylor francis . covers aspects artificial intelligence \n",
      "Cleaned Token After Stem =  theoret artifici intellig quarterli peer-review scientif journal publish taylor franci . cover aspect artifici intellig \n",
      "Cleaned Token Before =  ben goertzel is an artificial intelligence researcher, and ceo and founder of singularitynet. three of goertzel's jewish great-grandparents emigrated\n",
      "Cleaned Token After =  ben goertzel artificial intelligence researcher , ceo founder singularitynet . three goertzel 's jewish great-grandparents emigrated \n",
      "Cleaned Token After Stem =  ben goertzel artifici intellig research , ceo founder singularitynet . three goertzel 's jewish great-grandpar emigr \n",
      "Cleaned Token Before =  narratives within interactive systems: artificial intelligence (ai) and human moderation. narrative intelligence enables an ai engine to dynamically generate\n",
      "Cleaned Token After =  narratives within interactive systems : artificial intelligence ( ai ) human moderation . narrative intelligence enables ai engine dynamically generate \n",
      "Cleaned Token After Stem =  narr within interact system : artifici intellig ( ai ) human moder . narr intellig enabl ai engin dynam gener \n",
      "Cleaned Token Before =  deep learning to cybersecurity. the company implements advanced artificial intelligence to the task of preventing and detecting malware. the company was\n",
      "Cleaned Token After =  deep learning cybersecurity . company implements advanced artificial intelligence task preventing detecting malware . company \n",
      "Cleaned Token After Stem =  deep learn cybersecur . compani implement advanc artifici intellig task prevent detect malwar . compani \n",
      "Cleaned Token Before =  david rubin the artificial larynx. marwala also observed that the applicability of prospect theory depends on how much artificial intelligence is used to make\n",
      "Cleaned Token After =  david rubin artificial larynx . marwala also observed applicability prospect theory depends much artificial intelligence used make \n",
      "Cleaned Token After Stem =  david rubin artifici larynx . marwala also observ applic prospect theori depend much artifici intellig use make \n",
      "Cleaned Token Before =  deepmind technologies is a british artificial intelligence subsidiary of alphabet inc. and research laboratory founded in september 2010. deepmind was\n",
      "Cleaned Token After =  deepmind technologies british artificial intelligence subsidiary alphabet inc. research laboratory founded september 2010. deepmind \n",
      "Cleaned Token After Stem =  deepmind technolog british artifici intellig subsidiari alphabet inc. research laboratori found septemb 2010. deepmind \n",
      "Cleaned Token Before =  in artificial intelligence (ai), anticipation occurs when an agent makes decisions based on its explicit beliefs about the future. more broadly, \"anticipation\"\n",
      "Cleaned Token After =  artificial intelligence ( ai ) , anticipation occurs agent makes decisions based explicit beliefs future . broadly , `` anticipation '' \n",
      "Cleaned Token After Stem =  artifici intellig ( ai ) , anticip occur agent make decis base explicit belief futur . broadli , `` anticip `` \n",
      "Cleaned Token Before =  all domains of interest,\" is a potential outcome of advances in artificial intelligence. he views the rise of superintelligence as potentially highly dangerous\n",
      "Cleaned Token After =  domains interest , '' potential outcome advances artificial intelligence . views rise superintelligence potentially highly dangerous \n",
      "Cleaned Token After Stem =  domain interest , `` potenti outcom advanc artifici intellig . view rise superintellig potenti highli danger \n",
      "Cleaned Token Before =  computer scientist (distributed processing, discrete mathematics, artificial intelligence, cyber security). tomabechi was a fulbright research scientist\n",
      "Cleaned Token After =  computer scientist ( distributed processing , discrete mathematics , artificial intelligence , cyber security ) . tomabechi fulbright research scientist \n",
      "Cleaned Token After Stem =  comput scientist ( distribut process , discret mathemat , artifici intellig , cyber secur ) . tomabechi fulbright research scientist \n",
      "Cleaned Token Before =  that first contact will most likely be made with extraterrestrial artificial intelligence, rather than with biological beings. the wow! signal remains the\n",
      "Cleaned Token After =  first contact likely made extraterrestrial artificial intelligence , rather biological beings . wow ! signal remains \n",
      "Cleaned Token After Stem =  first contact like made extraterrestri artifici intellig , rather biolog be . wow ! signal remain \n",
      "Cleaned Token Before =  is an english computer scientist known for his contributions to artificial intelligence. he is a professor of computer science at the university of california\n",
      "Cleaned Token After =  english computer scientist known contributions artificial intelligence . professor computer science university california \n",
      "Cleaned Token After Stem =  english comput scientist known contribut artifici intellig . professor comput scienc univers california \n",
      "Cleaned Token Before =  breakout labs and thiel fellowship, and funds nonprofit research into artificial intelligence, life extension, and seasteading. a co-founder of the stanford\n",
      "Cleaned Token After =  breakout labs thiel fellowship , funds nonprofit research artificial intelligence , life extension , seasteading . co-founder stanford \n",
      "Cleaned Token After Stem =  breakout lab thiel fellowship , fund nonprofit research artifici intellig , life extens , seastead . co-found stanford \n",
      "Cleaned Token Before =  fellowship of the association for the advancement of artificial intelligence (abbreviated as aaai fellow or faaai) is an award granted to individuals\n",
      "Cleaned Token After =  fellowship association advancement artificial intelligence ( abbreviated aaai fellow faaai ) award granted individuals \n",
      "Cleaned Token After Stem =  fellowship associ advanc artifici intellig ( abbrevi aaai fellow faaai ) award grant individu \n",
      "Cleaned Token Before =  and reasoning. knowledge-based systems were first developed by artificial intelligence researchers[citation needed]. these early knowledge-based systems\n",
      "Cleaned Token After =  reasoning . knowledge-based systems first developed artificial intelligence researchers [ citation needed ] . early knowledge-based systems \n",
      "Cleaned Token After Stem =  reason . knowledge-bas system first develop artifici intellig research [ citat need ] . earli knowledge-bas system \n",
      "Cleaned Token Before =  cognitive biases, philosophy, psychology, economics, rationality, and artificial intelligence, among other topics. lesswrong promotes lifestyle changes believed\n",
      "Cleaned Token After =  cognitive biases , philosophy , psychology , economics , rationality , artificial intelligence , among topics . lesswrong promotes lifestyle changes believed \n",
      "Cleaned Token After Stem =  cognit bias , philosophi , psycholog , econom , ration , artifici intellig , among topic . lesswrong promot lifestyl chang believ \n",
      "Cleaned Token Before =  fishman also appeared in films, including steven spielberg's a.i. artificial intelligence. he then reconnected with barr as a co-host of the roseanne show\n",
      "Cleaned Token After =  fishman also appeared films , including steven spielberg 's a.i . artificial intelligence . reconnected barr co-host roseanne show \n",
      "Cleaned Token After Stem =  fishman also appear film , includ steven spielberg 's a.i . artifici intellig . reconnect barr co-host roseann show \n",
      "Cleaned Token Before =  discovers that technology now allows her to communicate with an artificial intelligence imitating ash, and reluctantly decides to try it. \"be right back\"\n",
      "Cleaned Token After =  discovers technology allows communicate artificial intelligence imitating ash , reluctantly decides try . `` right back '' \n",
      "Cleaned Token After Stem =  discov technolog allow commun artifici intellig imit ash , reluctantli decid tri . `` right back `` \n",
      "Cleaned Token Before =  towards artificial intelligence (ai), it garners more and more attention on its capability as a dual-use technology. artificial intelligence can be applied\n",
      "Cleaned Token After =  towards artificial intelligence ( ai ) , garners attention capability dual-use technology . artificial intelligence applied \n",
      "Cleaned Token After Stem =  toward artifici intellig ( ai ) , garner attent capabl dual-us technolog . artifici intellig appli \n",
      "Cleaned Token Before =  philosopher, best known for championing the probabilistic approach to artificial intelligence and the development of bayesian networks (see the article on belief\n",
      "Cleaned Token After =  philosopher , best known championing probabilistic approach artificial intelligence development bayesian networks ( see article belief \n",
      "Cleaned Token After Stem =  philosoph , best known champion probabilist approach artifici intellig develop bayesian network ( see articl belief \n",
      "Cleaned Token Before =  aiml, or artificial intelligence markup language, is an xml dialect for creating natural language software agents. the xml dialect called aiml was developed\n",
      "Cleaned Token After =  aiml , artificial intelligence markup language , xml dialect creating natural language software agents . xml dialect called aiml developed \n",
      "Cleaned Token After Stem =  aiml , artifici intellig markup languag , xml dialect creat natur languag softwar agent . xml dialect call aiml develop \n",
      "Cleaned Token Before =  beirut, lebanon, 1975 robot-proof: higher education in the age of artificial intelligence was published and released in 2017 by mit press. the book appeared\n",
      "Cleaned Token After =  beirut , lebanon , 1975 robot-proof : higher education age artificial intelligence published released 2017 mit press . book appeared \n",
      "Cleaned Token After Stem =  beirut , lebanon , 1975 robot-proof : higher educ age artifici intellig publish releas 2017 mit press . book appear \n",
      "Cleaned Token Before =  arxiv:1712.01815v1 [cs.ai]. stuart j. russell, peter norvig (2009). artificial intelligence: a modern approach (3rd ed.). prentice hall.cs1 maint: uses authors\n",
      "Cleaned Token After =  arxiv:1712.01815v1 [ cs.ai ] . stuart j. russell , peter norvig ( 2009 ) . artificial intelligence : modern approach ( 3rd ed. ) . prentice hall.cs1 maint : uses authors \n",
      "Cleaned Token After Stem =  arxiv:1712.01815v1 [ cs.ai ] . stuart j. russel , peter norvig ( 2009 ) . artifici intellig : modern approach ( 3rd ed . ) . prentic hall.cs1 maint : use author \n",
      "Cleaned Token Before =  for sustainable healthcare (wish) and the wadhwani institute for artificial intelligence (wiai). he resides in pittsburgh, pennsylvania. sunil wadhwani\n",
      "Cleaned Token After =  sustainable healthcare ( wish ) wadhwani institute artificial intelligence ( wiai ) . resides pittsburgh , pennsylvania . sunil wadhwani \n",
      "Cleaned Token After Stem =  sustain healthcar ( wish ) wadhwani institut artifici intellig ( wiai ) . resid pittsburgh , pennsylvania . sunil wadhwani \n",
      "Cleaned Token Before =  renamed to correspond to the new government direction towards artificial intelligence. this the primary crime fighting department of the dubai police\n",
      "Cleaned Token After =  renamed correspond new government direction towards artificial intelligence . primary crime fighting department dubai police \n",
      "Cleaned Token After Stem =  renam correspond new govern direct toward artifici intellig . primari crime fight depart dubai polic \n",
      "Cleaned Token Before =  austrian research institute for artificial intelligence (german: österreichisches forschungsinstitut für artificial intelligence - ofai) is an austrian non-profit\n",
      "Cleaned Token After =  austrian research institute artificial intelligence ( german : österreichisches forschungsinstitut für artificial intelligence - ofai ) austrian non-profit \n",
      "Cleaned Token After Stem =  austrian research institut artifici intellig ( german : österreichisch forschungsinstitut für artifici intellig - ofai ) austrian non-profit \n",
      "Cleaned Token Before =  computing, big data, key application hosts, servers, storage, artificial intelligence and erp. on april 18, 2006, inspur changed its english name from\n",
      "Cleaned Token After =  computing , big data , key application hosts , servers , storage , artificial intelligence erp . april 18 , 2006 , inspur changed english name \n",
      "Cleaned Token After Stem =  comput , big data , key applic host , server , storag , artifici intellig erp . april 18 , 2006 , inspur chang english name \n",
      "Cleaned Token Before =  emergence. within computer science, bio-inspired computing relates to artificial intelligence and machine learning. bio-inspired computing is a major subset\n",
      "Cleaned Token After =  emergence . within computer science , bio-inspired computing relates artificial intelligence machine learning . bio-inspired computing major subset \n",
      "Cleaned Token After Stem =  emerg . within comput scienc , bio-inspir comput relat artifici intellig machin learn . bio-inspir comput major subset \n",
      "Cleaned Token Before =  computers exceed human intelligence is a non-fiction book by inventor and futurist ray kurzweil about artificial intelligence and the future course of\n",
      "Cleaned Token After =  computers exceed human intelligence non-fiction book inventor futurist ray kurzweil artificial intelligence future course \n",
      "Cleaned Token After Stem =  comput exceed human intellig non-fict book inventor futurist ray kurzweil artifici intellig futur cours \n",
      "Cleaned Token Before =  classifiers will be combined together. seed ai is a hypothesized type of artificial intelligence capable of recursive self-improvement. having improved itself,\n",
      "Cleaned Token After =  classifiers combined together . seed ai hypothesized type artificial intelligence capable recursive self-improvement . improved , \n",
      "Cleaned Token After Stem =  classifi combin togeth . seed ai hypothes type artifici intellig capabl recurs self-improv . improv , \n",
      "Cleaned Token Before =  scientists compete globally. hovhannes is an author and speaker on artificial intelligence and advocates the establishment of machine learning and data science\n",
      "Cleaned Token After =  scientists compete globally . hovhannes author speaker artificial intelligence advocates establishment machine learning data science \n",
      "Cleaned Token After Stem =  scientist compet global . hovhann author speaker artifici intellig advoc establish machin learn data scienc \n",
      "Cleaned Token Before =  michigan. mars is noted for his research in computer architecture and artificial intelligence with a particular focus on the design and deployment of conversational\n",
      "Cleaned Token After =  michigan . mars noted research computer architecture artificial intelligence particular focus design deployment conversational \n",
      "Cleaned Token After Stem =  michigan . mar note research comput architectur artifici intellig particular focu design deploy convers \n",
      "Cleaned Token Before =  her in two successive films. her scenes as a rock star in a.i.: artificial intelligence, which required morris to take intensive singing and guitar lessons\n",
      "Cleaned Token After =  two successive films . scenes rock star a.i . : artificial intelligence , required morris take intensive singing guitar lessons \n",
      "Cleaned Token After Stem =  two success film . scene rock star a.i . : artifici intellig , requir morri take intens sing guitar lesson \n",
      "Cleaned Token Before =  biological simulation game bird week was released. in the mid-1990s, as artificial intelligence programming improved, true ai virtual pets such as petz and tamagotchi\n",
      "Cleaned Token After =  biological simulation game bird week released . mid-1990s , artificial intelligence programming improved , true ai virtual pets petz tamagotchi \n",
      "Cleaned Token After Stem =  biolog simul game bird week releas . mid-1990 , artifici intellig program improv , true ai virtual pet petz tamagotchi \n",
      "Cleaned Token Before =  yalochat is an artificial intelligence platform specializing in emerging markets. it is based in san francisco with offices in mexico city, mumbai, shanghai\n",
      "Cleaned Token After =  yalochat artificial intelligence platform specializing emerging markets . based san francisco offices mexico city , mumbai , shanghai \n",
      "Cleaned Token After Stem =  yalochat artifici intellig platform special emerg market . base san francisco offic mexico citi , mumbai , shanghai \n",
      "Cleaned Token Before =  linguistics language game language creation in artificial intelligence signaling game alan reed libert, artificial languages, oxford research encyclopedia on\n",
      "Cleaned Token After =  linguistics language game language creation artificial intelligence signaling game alan reed libert , artificial languages , oxford research encyclopedia \n",
      "Cleaned Token After Stem =  linguist languag game languag creation artifici intellig signal game alan reed libert , artifici languag , oxford research encyclopedia \n",
      "Cleaned Token Before =  as high-resolution and full color graphics, physics, advanced artificial intelligence and digital sound. technology has advanced to such a great degree\n",
      "Cleaned Token After =  high-resolution full color graphics , physics , advanced artificial intelligence digital sound . technology advanced great degree \n",
      "Cleaned Token After Stem =  high-resolut full color graphic , physic , advanc artifici intellig digit sound . technolog advanc great degre \n",
      "Cleaned Token Before =   an artificial intelligence arms race is a competition between two or more states to have its military forces equipped with the best \"artificial intelligence\"\n",
      "Cleaned Token After =  artificial intelligence arms race competition two states military forces equipped best `` artificial intelligence '' \n",
      "Cleaned Token After Stem =  artifici intellig arm race competit two state militari forc equip best `` artifici intellig `` \n",
      "Cleaned Token Before =  this include the indxx global robotics & artificial intelligence thematic index and indxx artificial intelligence & big data index. client indices: in contrast\n",
      "Cleaned Token After =  include indxx global robotics & artificial intelligence thematic index indxx artificial intelligence & big data index . client indices : contrast \n",
      "Cleaned Token After Stem =  includ indxx global robot & artifici intellig themat index indxx artifici intellig & big data index . client indic : contrast \n",
      "Cleaned Token Before =  at the university of edinburgh where he was awarded a ph.d. in artificial intelligence in 1978 for research supervised by christopher longuet-higgins\n",
      "Cleaned Token After =  university edinburgh awarded ph.d. artificial intelligence 1978 research supervised christopher longuet-higgins \n",
      "Cleaned Token After Stem =  univers edinburgh award ph.d. artifici intellig 1978 research supervis christoph longuet-higgin \n",
      "Cleaned Token Before =  defunct journals of the academy include: electronic transactions on artificial intelligence (1997–2001) current publications ambio (1972–) acta mathematica\n",
      "Cleaned Token After =  defunct journals academy include : electronic transactions artificial intelligence ( 1997–2001 ) current publications ambio ( 1972– ) acta mathematica \n",
      "Cleaned Token After Stem =  defunct journal academi includ : electron transact artifici intellig ( 1997–2001 ) current public ambio ( 1972– ) acta mathematica \n",
      "Cleaned Token Before =  \"mit artificial intelligence memo 41\". retrieved 2006-07-01. marsland, t.a. (may 1987). \"computer chess methods (pdf) from encyclopedia of artificial intelligence\n",
      "Cleaned Token After =  `` mit artificial intelligence memo 41 '' . retrieved 2006-07-01. marsland , t.a . ( may 1987 ) . `` computer chess methods ( pdf ) encyclopedia artificial intelligence \n",
      "Cleaned Token After Stem =  `` mit artifici intellig memo 41 `` . retriev 2006-07-01. marsland , t.a . ( may 1987 ) . `` comput chess method ( pdf ) encyclopedia artifici intellig \n",
      "Cleaned Token Before =  working in artificial intelligence. in december 2020, her employment with google as technical co-lead of the ethical artificial intelligence team ended\n",
      "Cleaned Token After =  working artificial intelligence . december 2020 , employment google technical co-lead ethical artificial intelligence team ended \n",
      "Cleaned Token After Stem =  work artifici intellig . decemb 2020 , employ googl technic co-lead ethic artifici intellig team end \n",
      "Cleaned Token Before =  foundation is an american artificial intelligence company founded by lars buttler and rob meadows, developing ethical artificial intelligent agents individuals\n",
      "Cleaned Token After =  foundation american artificial intelligence company founded lars buttler rob meadows , developing ethical artificial intelligent agents individuals \n",
      "Cleaned Token After Stem =  foundat american artifici intellig compani found lar buttler rob meadow , develop ethic artifici intellig agent individu \n",
      "Cleaned Token Before =  and advanced science and the future of government (robotics and artificial intelligence, genomic medicine and biometrics). in 2016, the summit included\n",
      "Cleaned Token After =  advanced science future government ( robotics artificial intelligence , genomic medicine biometrics ) . 2016 , summit included \n",
      "Cleaned Token After Stem =  advanc scienc futur govern ( robot artifici intellig , genom medicin biometr ) . 2016 , summit includ \n",
      "Cleaned Token Before =  reality game developed by microsoft to promote the 2001 film a.i. artificial intelligence. entry points to the game embedded into the film's promotion centered\n",
      "Cleaned Token After =  reality game developed microsoft promote 2001 film a.i . artificial intelligence . entry points game embedded film 's promotion centered \n",
      "Cleaned Token After Stem =  realiti game develop microsoft promot 2001 film a.i . artifici intellig . entri point game embed film 's promot center \n",
      "Cleaned Token Before =  mellon university and a former president of the international artificial intelligence in education society (2017-2019). mclaren's research is focused\n",
      "Cleaned Token After =  mellon university former president international artificial intelligence education society ( 2017-2019 ) . mclaren 's research focused \n",
      "Cleaned Token After Stem =  mellon univers former presid intern artifici intellig educ societi ( 2017-2019 ) . mclaren 's research focus \n",
      "Cleaned Token Before =  use of human beings: cybernetics and society (houghton-mifflin). artificial intelligence (ai) was founded as a distinct discipline at the dartmouth workshop\n",
      "Cleaned Token After =  use human beings : cybernetics society ( houghton-mifflin ) . artificial intelligence ( ai ) founded distinct discipline dartmouth workshop \n",
      "Cleaned Token After Stem =  use human be : cybernet societi ( houghton-mifflin ) . artifici intellig ( ai ) found distinct disciplin dartmouth workshop \n",
      "Cleaned Token Before =  machine learning research stuart j. russell, peter norvig (2010) artificial intelligence: a modern approach, third edition, prentice hall isbn 9780136042594\n",
      "Cleaned Token After =  machine learning research stuart j. russell , peter norvig ( 2010 ) artificial intelligence : modern approach , third edition , prentice hall isbn 9780136042594 \n",
      "Cleaned Token After Stem =  machin learn research stuart j. russel , peter norvig ( 2010 ) artifici intellig : modern approach , third edit , prentic hall isbn 9780136042594 \n",
      "Cleaned Token Before =  cynthia solomon, and seymour papert. its intellectual roots are in artificial intelligence, mathematical logic and developmental psychology. the first four\n",
      "Cleaned Token After =  cynthia solomon , seymour papert . intellectual roots artificial intelligence , mathematical logic developmental psychology . first four \n",
      "Cleaned Token After Stem =  cynthia solomon , seymour papert . intellectu root artifici intellig , mathemat logic development psycholog . first four \n",
      "Cleaned Token Before =  mission controller mackenzie “mack” wilson (sackhoff) and arti, an artificial intelligence system (voiced by cree), as they discover a mysterious object on\n",
      "Cleaned Token After =  mission controller mackenzie “ mack ” wilson ( sackhoff ) arti , artificial intelligence system ( voiced cree ) , discover mysterious object \n",
      "Cleaned Token After Stem =  mission control mackenzi “ mack ” wilson ( sackhoff ) arti , artifici intellig system ( voic cree ) , discov mysteri object \n",
      "Cleaned Token Before =  the bkc received a $27m grant with the mit media lab to \"advance artificial intelligence research for the public good\" and \"to ensure automation and machine\n",
      "Cleaned Token After =  bkc received $ 27m grant mit media lab `` advance artificial intelligence research public good '' `` ensure automation machine \n",
      "Cleaned Token After Stem =  bkc receiv $ 27m grant mit media lab `` advanc artifici intellig research public good `` `` ensur autom machin \n",
      "Cleaned Token Before =  running software programs that use algorithms from graph theory, artificial intelligence, soft computing, data mining, image processing, and computer simulation\n",
      "Cleaned Token After =  running software programs use algorithms graph theory , artificial intelligence , soft computing , data mining , image processing , computer simulation \n",
      "Cleaned Token After Stem =  run softwar program use algorithm graph theori , artifici intellig , soft comput , data mine , imag process , comput simul \n",
      "Cleaned Token Before =  addison-wesley, 1984. p. 48. russell, stuart j.; norvig, peter (2003), artificial intelligence: a modern approach (2nd ed.), upper saddle river, new jersey: prentice\n",
      "Cleaned Token After =  addison-wesley , 1984. p. 48. russell , stuart j. ; norvig , peter ( 2003 ) , artificial intelligence : modern approach ( 2nd ed . ) , upper saddle river , new jersey : prentice \n",
      "Cleaned Token After Stem =  addison-wesley , 1984. p. 48. russel , stuart j. ; norvig , peter ( 2003 ) , artifici intellig : modern approach ( 2nd ed . ) , upper saddl river , new jersey : prentic \n",
      "Cleaned Token Before =  innovation: transforming business with artificial intelligence, which was \"co-authored\" by an artificial intelligence called aimé. duffey was born to john\n",
      "Cleaned Token After =  innovation : transforming business artificial intelligence , `` co-authored '' artificial intelligence called aimé . duffey born john \n",
      "Cleaned Token After Stem =  innov : transform busi artifici intellig , `` co-author `` artifici intellig call aimé . duffey born john \n",
      "Cleaned Token Before =  when humans transcend biology is a 2005 non-fiction book about artificial intelligence and the future of humanity by inventor and futurist ray kurzweil\n",
      "Cleaned Token After =  humans transcend biology 2005 non-fiction book artificial intelligence future humanity inventor futurist ray kurzweil \n",
      "Cleaned Token After Stem =  human transcend biolog 2005 non-fict book artifici intellig futur human inventor futurist ray kurzweil \n",
      "Cleaned Token Before =  the outskirts of boston, that provides speech recognition, and artificial intelligence. nuance merged with its competitor in the commercial large-scale\n",
      "Cleaned Token After =  outskirts boston , provides speech recognition , artificial intelligence . nuance merged competitor commercial large-scale \n",
      "Cleaned Token After Stem =  outskirt boston , provid speech recognit , artifici intellig . nuanc merg competitor commerci large-scal \n",
      "Cleaned Token Before =  fields of logic, argumentation studies, and cognitive psychology; artificial intelligence researchers develop automated inference systems to emulate human\n",
      "Cleaned Token After =  fields logic , argumentation studies , cognitive psychology ; artificial intelligence researchers develop automated inference systems emulate human \n",
      "Cleaned Token After Stem =  field logic , argument studi , cognit psycholog ; artifici intellig research develop autom infer system emul human \n",
      "Cleaned Token Before =  dall-e (stylized dall·e) is an artificial intelligence program that creates images from textual descriptions, revealed by openai on january 5, 2021. it\n",
      "Cleaned Token After =  dall-e ( stylized dall·e ) artificial intelligence program creates images textual descriptions , revealed openai january 5 , 2021. \n",
      "Cleaned Token After Stem =  dall- ( styliz dall· ) artifici intellig program creat imag textual descript , reveal openai januari 5 , 2021 . \n",
      "Cleaned Token Before =  are three different types of robotic programs: remote control, artificial intelligence and hybrid. a robot with remote control programming has a preexisting\n",
      "Cleaned Token After =  three different types robotic programs : remote control , artificial intelligence hybrid . robot remote control programming preexisting \n",
      "Cleaned Token After Stem =  three differ type robot program : remot control , artifici intellig hybrid . robot remot control program preexist \n",
      "Cleaned Token Before =  the products and services produced by the economy. artificial intelligence (ai) is the sub intelligence exhibited by machines or software, and the branch\n",
      "Cleaned Token After =  products services produced economy . artificial intelligence ( ai ) sub intelligence exhibited machines software , branch \n",
      "Cleaned Token After Stem =  product servic produc economi . artifici intellig ( ai ) sub intellig exhibit machin softwar , branch \n",
      "Cleaned Token Before =  hard science fiction stories exploring the interaction between artificial intelligence and the human condition. while working at his day job as a computer\n",
      "Cleaned Token After =  hard science fiction stories exploring interaction artificial intelligence human condition . working day job computer \n",
      "Cleaned Token After Stem =  hard scienc fiction stori explor interact artifici intellig human condit . work day job comput \n",
      "Cleaned Token Before =  (1999). \"popular ensemble methods: an empirical study\". journal of artificial intelligence research. 11: 169–198. doi:10.1613/jair.614. polikar, r. (2006)\n",
      "Cleaned Token After =  ( 1999 ) . `` popular ensemble methods : empirical study '' . journal artificial intelligence research . 11 : 169–198 . doi:10.1613/jair.614 . polikar , r. ( 2006 ) \n",
      "Cleaned Token After Stem =  ( 1999 ) . `` popular ensembl method : empir studi `` . journal artifici intellig research . 11 : 169–198 . doi:10.1613/jair.614 . polikar , r. ( 2006 ) \n",
      "Cleaned Token Before =  1954) is an italian computer scientist at mit computer science and artificial intelligence laboratory and a professor of computer science in mit's department\n",
      "Cleaned Token After =  1954 ) italian computer scientist mit computer science artificial intelligence laboratory professor computer science mit 's department \n",
      "Cleaned Token After Stem =  1954 ) italian comput scientist mit comput scienc artifici intellig laboratori professor comput scienc mit 's depart \n",
      "Cleaned Token Before =  technology based on metaphorical software robots (bots) or on artificial intelligence (ai)/digital workers. it is sometimes referred to as software robotics\n",
      "Cleaned Token After =  technology based metaphorical software robots ( bots ) artificial intelligence ( ai ) /digital workers . sometimes referred software robotics \n",
      "Cleaned Token After Stem =  technolog base metaphor softwar robot ( bot ) artifici intellig ( ai ) /digit worker . sometim refer softwar robot \n",
      "Cleaned Token Before =  the open neural network exchange (onnx) is an open-source artificial intelligence ecosystem of technology companies and research organizations that establish\n",
      "Cleaned Token After =  open neural network exchange ( onnx ) open-source artificial intelligence ecosystem technology companies research organizations establish \n",
      "Cleaned Token After Stem =  open neural network exchang ( onnx ) open-sourc artifici intellig ecosystem technolog compani research organ establish \n",
      "Cleaned Token Before =  web intelligence is the area of scientific research and development that explores the roles and makes use of artificial intelligence and information technology\n",
      "Cleaned Token After =  web intelligence area scientific research development explores roles makes use artificial intelligence information technology \n",
      "Cleaned Token After Stem =  web intellig area scientif research develop explor role make use artifici intellig inform technolog \n",
      "Cleaned Token Before =  netherlands, and france. it is based in new york city. it uses artificial intelligence and chatbots to process claims and set a world record for processing\n",
      "Cleaned Token After =  netherlands , france . based new york city . uses artificial intelligence chatbots process claims set world record processing \n",
      "Cleaned Token After Stem =  netherland , franc . base new york citi . use artifici intellig chatbot process claim set world record process \n",
      "Cleaned Token Before =  is a data scientist and behavioural designer with expertise in artificial intelligence, cognitive science, disruptive technologies, digital transformation\n",
      "Cleaned Token After =  data scientist behavioural designer expertise artificial intelligence , cognitive science , disruptive technologies , digital transformation \n",
      "Cleaned Token After Stem =  data scientist behaviour design expertis artifici intellig , cognit scienc , disrupt technolog , digit transform \n",
      "Cleaned Token Before =  made for electronics and physics purposes. the national center of artificial intelligence (ncai), university of the punjab is funded by higher education\n",
      "Cleaned Token After =  made electronics physics purposes . national center artificial intelligence ( ncai ) , university punjab funded higher education \n",
      "Cleaned Token After Stem =  made electron physic purpos . nation center artifici intellig ( ncai ) , univers punjab fund higher educ \n",
      "Cleaned Token Before =  while the other focused on the application of neural networks to artificial intelligence. this work led to work on nerve networks and their link to finite\n",
      "Cleaned Token After =  focused application neural networks artificial intelligence . work led work nerve networks link finite \n",
      "Cleaned Token After Stem =  focus applic neural network artifici intellig . work led work nerv network link finit \n",
      "Cleaned Token Before =  algorithm in parallel, an example of gofai (good old-fashioned artificial intelligence). the system derived its playing strength mainly from brute force\n",
      "Cleaned Token After =  algorithm parallel , example gofai ( good old-fashioned artificial intelligence ) . system derived playing strength mainly brute force \n",
      "Cleaned Token After Stem =  algorithm parallel , exampl gofai ( good old-fashion artifici intellig ) . system deriv play strength mainli brute forc \n",
      "Cleaned Token Before =  acronym pomdp was coined. it was later adapted for problems in artificial intelligence and automated planning by leslie p. kaelbling and michael l. littman\n",
      "Cleaned Token After =  acronym pomdp coined . later adapted problems artificial intelligence automated planning leslie p. kaelbling michael l. littman \n",
      "Cleaned Token After Stem =  acronym pomdp coin . later adapt problem artifici intellig autom plan lesli p. kaelbl michael l. littman \n",
      "Cleaned Token Before =  phoenix is an american entrepreneur and cofounder of vicarious, an artificial intelligence research company. in 2007, phoenix graduated from the university\n",
      "Cleaned Token After =  phoenix american entrepreneur cofounder vicarious , artificial intelligence research company . 2007 , phoenix graduated university \n",
      "Cleaned Token After Stem =  phoenix american entrepreneur cofound vicari , artifici intellig research compani . 2007 , phoenix graduat univers \n",
      "Cleaned Token Before =  artificial intelligence reaching the top-level of decision-making when confronted with the most complexe challenging situations. the term artificial wisdom\n",
      "Cleaned Token After =  artificial intelligence reaching top-level decision-making confronted complexe challenging situations . term artificial wisdom \n",
      "Cleaned Token After Stem =  artifici intellig reach top-level decision-mak confront complex challeng situat . term artifici wisdom \n",
      "Cleaned Token Before =  sentient technologies is an american artificial intelligence (ai) based technology company based in san francisco. sentient was founded in 2007 and has\n",
      "Cleaned Token After =  sentient technologies american artificial intelligence ( ai ) based technology company based san francisco . sentient founded 2007 \n",
      "Cleaned Token After Stem =  sentient technolog american artifici intellig ( ai ) base technolog compani base san francisco . sentient found 2007 \n",
      "Cleaned Token Before =  strong artificial intelligence or true ai, may refer to: artificial general intelligence, a hypothetical machine that exhibits behavior at least as skillful\n",
      "Cleaned Token After =  strong artificial intelligence true ai , may refer : artificial general intelligence , hypothetical machine exhibits behavior least skillful \n",
      "Cleaned Token After Stem =  strong artifici intellig true ai , may refer : artifici gener intellig , hypothet machin exhibit behavior least skill \n",
      "Cleaned Token Before =  perspectives in artificial intelligence to create computers and computer software that are capable of intelligent behaviour. in artificial intelligence and law\n",
      "Cleaned Token After =  perspectives artificial intelligence create computers computer software capable intelligent behaviour . artificial intelligence law \n",
      "Cleaned Token After Stem =  perspect artifici intellig creat comput comput softwar capabl intellig behaviour . artifici intellig law \n",
      "Cleaned Token Before =  received a bsc from delft university in 1995, followed by an msc in artificial intelligence in 1997. pantić earned a phd at the delft university of technology\n",
      "Cleaned Token After =  received bsc delft university 1995 , followed msc artificial intelligence 1997. pantić earned phd delft university technology \n",
      "Cleaned Token After Stem =  receiv bsc delft univers 1995 , follow msc artifici intellig 1997. pantić earn phd delft univers technolog \n",
      "Cleaned Token Before =  statistical relational learning (srl) is a subdiscipline of artificial intelligence and machine learning that is concerned with domain models that exhibit\n",
      "Cleaned Token After =  statistical relational learning ( srl ) subdiscipline artificial intelligence machine learning concerned domain models exhibit \n",
      "Cleaned Token After Stem =  statist relat learn ( srl ) subdisciplin artifici intellig machin learn concern domain model exhibit \n",
      "Cleaned Token Before =  talkdesk is a cloud-based contact centre, unified communications and artificial intelligence software provider. talkdesk was founded in lisbon, portugal in\n",
      "Cleaned Token After =  talkdesk cloud-based contact centre , unified communications artificial intelligence software provider . talkdesk founded lisbon , portugal \n",
      "Cleaned Token After Stem =  talkdesk cloud-bas contact centr , unifi commun artifici intellig softwar provid . talkdesk found lisbon , portug \n",
      "Cleaned Token Before =  graduated with a bachelor of science degree in computer science and artificial intelligence. according to the new ross standard, a local paper in o'brien's\n",
      "Cleaned Token After =  graduated bachelor science degree computer science artificial intelligence . according new ross standard , local paper o'brien 's \n",
      "Cleaned Token After Stem =  graduat bachelor scienc degre comput scienc artifici intellig . accord new ross standard , local paper o'brien 's \n",
      "Cleaned Token Before =  augury is a technology company that produces hardware, artificial intelligence, and software that diagnose malfunctions in machinery. augury was founded\n",
      "Cleaned Token After =  augury technology company produces hardware , artificial intelligence , software diagnose malfunctions machinery . augury founded \n",
      "Cleaned Token After Stem =  auguri technolog compani produc hardwar , artifici intellig , softwar diagnos malfunct machineri . auguri found \n",
      "Cleaned Token Before =  deep-learning software. based in beijing, the company develops artificial intelligence (ai) technology for businesses and for the public sector. in 2019\n",
      "Cleaned Token After =  deep-learning software . based beijing , company develops artificial intelligence ( ai ) technology businesses public sector . 2019 \n",
      "Cleaned Token After Stem =  deep-learn softwar . base beij , compani develop artifici intellig ( ai ) technolog busi public sector . 2019 \n",
      "Cleaned Token Before =  microelectronics and computer technology corporation (mcc), mit artificial intelligence laboratory, sri, stanford university, university of illinois at\n",
      "Cleaned Token After =  microelectronics computer technology corporation ( mcc ) , mit artificial intelligence laboratory , sri , stanford university , university illinois \n",
      "Cleaned Token After Stem =  microelectron comput technolog corpor ( mcc ) , mit artifici intellig laboratori , sri , stanford univers , univers illinoi \n",
      "Cleaned Token Before =  accelerator or computer system designed to accelerate artificial intelligence applications, especially artificial neural networks, machine vision and machine learning\n",
      "Cleaned Token After =  accelerator computer system designed accelerate artificial intelligence applications , especially artificial neural networks , machine vision machine learning \n",
      "Cleaned Token After Stem =  acceler comput system design acceler artifici intellig applic , especi artifici neural network , machin vision machin learn \n",
      "Cleaned Token Before =  general game playing (ggp) is the design of artificial intelligence programs to be able to play more than one game successfully. for many games like chess\n",
      "Cleaned Token After =  general game playing ( ggp ) design artificial intelligence programs able play one game successfully . many games like chess \n",
      "Cleaned Token After Stem =  gener game play ( ggp ) design artifici intellig program abl play one game success . mani game like chess \n",
      "Cleaned Token Before =  pictures, such as in the valley of elah, flightplan, radio, and a.i. artificial intelligence. in 2005, the movie radio won a camie award and, in 2006, sexton\n",
      "Cleaned Token After =  pictures , valley elah , flightplan , radio , a.i . artificial intelligence . 2005 , movie radio camie award , 2006 , sexton \n",
      "Cleaned Token After Stem =  pictur , valley elah , flightplan , radio , a.i . artifici intellig . 2005 , movi radio cami award , 2006 , sexton \n",
      "Cleaned Token Before =  computational learning theory (or just learning theory) is a subfield of artificial intelligence devoted to studying the design and analysis of machine learning\n",
      "Cleaned Token After =  computational learning theory ( learning theory ) subfield artificial intelligence devoted studying design analysis machine learning \n",
      "Cleaned Token After Stem =  comput learn theori ( learn theori ) subfield artifici intellig devot studi design analysi machin learn \n",
      "Cleaned Token Before =  on decarbonization, particularly co2 conversion, hydrogen, and artificial intelligence for materials science. de luna has multiple high-impact publications\n",
      "Cleaned Token After =  decarbonization , particularly co2 conversion , hydrogen , artificial intelligence materials science . de luna multiple high-impact publications \n",
      "Cleaned Token After Stem =  decarbon , particularli co2 convers , hydrogen , artifici intellig materi scienc . de luna multipl high-impact public \n",
      "Cleaned Token Before =  introduction. mit press. russell, stuart j.; norvig, peter (2010). artificial intelligence: a modern approach (third ed.). prentice hall. p. 649. isbn 978-0136042594\n",
      "Cleaned Token After =  introduction . mit press . russell , stuart j. ; norvig , peter ( 2010 ) . artificial intelligence : modern approach ( third ed. ) . prentice hall . p. 649. isbn 978-0136042594 \n",
      "Cleaned Token After Stem =  introduct . mit press . russel , stuart j. ; norvig , peter ( 2010 ) . artifici intellig : modern approach ( third ed . ) . prentic hall . p. 649. isbn 978-0136042594 \n",
      "Cleaned Token Before =  theme of artificial intelligence present in his science fiction films. scott's earliest foray into the philosophy of artificial intelligence was with\n",
      "Cleaned Token After =  theme artificial intelligence present science fiction films . scott 's earliest foray philosophy artificial intelligence \n",
      "Cleaned Token After Stem =  theme artifici intellig present scienc fiction film . scott 's earliest foray philosophi artifici intellig \n",
      "Cleaned Token Before =  algorithms applied artificial intelligence applied computer science archives of computational methods in engineering artificial intelligence astronomy and\n",
      "Cleaned Token After =  algorithms applied artificial intelligence applied computer science archives computational methods engineering artificial intelligence astronomy \n",
      "Cleaned Token After Stem =  algorithm appli artifici intellig appli comput scienc archiv comput method engin artifici intellig astronomi \n",
      "Cleaned Token Before =  the government of anguilla. it is popular with companies in the artificial intelligence industry (ai). registrations within off.ai, com.ai, net.ai, and\n",
      "Cleaned Token After =  government anguilla . popular companies artificial intelligence industry ( ai ) . registrations within off.ai , com.ai , net.ai , \n",
      "Cleaned Token After Stem =  govern anguilla . popular compani artifici intellig industri ( ai ) . registr within off.ai , com.ai , net.ai , \n",
      "Cleaned Token Before =  the international conference on logic for programming, artificial intelligence and reasoning (lpar) is an academic conference aiming at discussing cutting-edge\n",
      "Cleaned Token After =  international conference logic programming , artificial intelligence reasoning ( lpar ) academic conference aiming discussing cutting-edge \n",
      "Cleaned Token After Stem =  intern confer logic program , artifici intellig reason ( lpar ) academ confer aim discuss cutting-edg \n",
      "Cleaned Token Before =  appeared in fortune and forbes and she speaks on venture capital, artificial intelligence and leadership in domestic and international forums. abigail hing\n",
      "Cleaned Token After =  appeared fortune forbes speaks venture capital , artificial intelligence leadership domestic international forums . abigail hing \n",
      "Cleaned Token After Stem =  appear fortun forb speak ventur capit , artifici intellig leadership domest intern forum . abigail hing \n",
      "Cleaned Token Before =  in the history of artificial intelligence, an ai winter is a period of reduced funding and interest in artificial intelligence research. the term was coined\n",
      "Cleaned Token After =  history artificial intelligence , ai winter period reduced funding interest artificial intelligence research . term coined \n",
      "Cleaned Token After Stem =  histori artifici intellig , ai winter period reduc fund interest artifici intellig research . term coin \n",
      "Cleaned Token Before =  article by manyika writes, \"innovations in digitization, analytics, artificial intelligence, and automation are creating performance and productivity opportunities\n",
      "Cleaned Token After =  article manyika writes , `` innovations digitization , analytics , artificial intelligence , automation creating performance productivity opportunities \n",
      "Cleaned Token After Stem =  articl manyika write , `` innov digit , analyt , artifici intellig , autom creat perform product opportun \n",
      "Cleaned Token Before =  criticized its technical problems, low-quality graphics, and weak artificial intelligence of enemies. the competitive multiplayer mode was highlighted as\n",
      "Cleaned Token After =  criticized technical problems , low-quality graphics , weak artificial intelligence enemies . competitive multiplayer mode highlighted \n",
      "Cleaned Token After Stem =  critic technic problem , low-qual graphic , weak artifici intellig enemi . competit multiplay mode highlight \n",
      "Cleaned Token Before =  founder of tulco llc, an investment holding company that uses artificial intelligence and other technologies to guide investing. tull grew up in endwell\n",
      "Cleaned Token After =  founder tulco llc , investment holding company uses artificial intelligence technologies guide investing . tull grew endwell \n",
      "Cleaned Token After Stem =  founder tulco llc , invest hold compani use artifici intellig technolog guid invest . tull grew endwel \n",
      "Cleaned Token Before =  improved further as detailed in specialized variants. in some fields, artificial intelligence in particular, dijkstra's algorithm or a variant of it is known\n",
      "Cleaned Token After =  improved detailed specialized variants . fields , artificial intelligence particular , dijkstra 's algorithm variant known \n",
      "Cleaned Token After Stem =  improv detail special variant . field , artifici intellig particular , dijkstra 's algorithm variant known \n",
      "Cleaned Token Before =  ecosystems. collaborative intelligence traces its roots to the pandemonium architecture proposed by artificial intelligence pioneer oliver selfridge as\n",
      "Cleaned Token After =  ecosystems . collaborative intelligence traces roots pandemonium architecture proposed artificial intelligence pioneer oliver selfridge \n",
      "Cleaned Token After Stem =  ecosystem . collabor intellig trace root pandemonium architectur propos artifici intellig pioneer oliv selfridg \n",
      "Cleaned Token Before =  conference conferences on artificial intelligence and machine learning: aaai - aaai conference on artificial intelligence aamas - international conference\n",
      "Cleaned Token After =  conference conferences artificial intelligence machine learning : aaai - aaai conference artificial intelligence aamas - international conference \n",
      "Cleaned Token After Stem =  confer confer artifici intellig machin learn : aaai - aaai confer artifici intellig aama - intern confer \n",
      "Cleaned Token Before =  mobasher, philip yu, brij masand, eds., springer lecture notes in artificial intelligence, lnai 4198, 2006 web mining and web usage analysis 2004 - revised\n",
      "Cleaned Token After =  mobasher , philip yu , brij masand , eds. , springer lecture notes artificial intelligence , lnai 4198 , 2006 web mining web usage analysis 2004 - revised \n",
      "Cleaned Token After Stem =  mobash , philip yu , brij masand , ed . , springer lectur note artifici intellig , lnai 4198 , 2006 web mine web usag analysi 2004 - revis \n",
      "Cleaned Token Before =  led by google engineer sebastian thrun, director of the stanford artificial intelligence laboratory and co-inventor of google street view. thrun's team\n",
      "Cleaned Token After =  led google engineer sebastian thrun , director stanford artificial intelligence laboratory co-inventor google street view . thrun 's team \n",
      "Cleaned Token After Stem =  led googl engin sebastian thrun , director stanford artifici intellig laboratori co-inventor googl street view . thrun 's team \n",
      "Cleaned Token Before =  intelligent control is a class of control techniques that use various artificial intelligence computing approaches like neural networks, bayesian probability\n",
      "Cleaned Token After =  intelligent control class control techniques use various artificial intelligence computing approaches like neural networks , bayesian probability \n",
      "Cleaned Token After Stem =  intellig control class control techniqu use variou artifici intellig comput approach like neural network , bayesian probabl \n",
      "Cleaned Token Before =  analysis and replanning tool, commonly abbreviated to dart, is an artificial intelligence program used by the u.s. military to optimize and schedule the\n",
      "Cleaned Token After =  analysis replanning tool , commonly abbreviated dart , artificial intelligence program used u.s. military optimize schedule \n",
      "Cleaned Token After Stem =  analysi replan tool , commonli abbrevi dart , artifici intellig program use u.s. militari optim schedul \n",
      "Cleaned Token Before =  boi faltings is a swiss professor of artificial intelligence at école polytechnique fédérale de lausanne. boi faltings received a diploma with distinction\n",
      "Cleaned Token After =  boi faltings swiss professor artificial intelligence école polytechnique fédérale de lausanne . boi faltings received diploma distinction \n",
      "Cleaned Token After Stem =  boi falt swiss professor artifici intellig école polytechniqu fédérale de lausann . boi falt receiv diploma distinct \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Token Before =  films, and other media. they have impacted thought on ethics of artificial intelligence as well. in the rest of the robots, published in 1964, isaac asimov\n",
      "Cleaned Token After =  films , media . impacted thought ethics artificial intelligence well . rest robots , published 1964 , isaac asimov \n",
      "Cleaned Token After Stem =  film , media . impact thought ethic artifici intellig well . rest robot , publish 1964 , isaac asimov \n",
      "Cleaned Token Before =  is a virtual character, and claims that she is an independent artificial intelligence (hence the \"ai\" in her name). the main concept of a character in\n",
      "Cleaned Token After =  virtual character , claims independent artificial intelligence ( hence `` ai '' name ) . main concept character \n",
      "Cleaned Token After Stem =  virtual charact , claim independ artifici intellig ( henc `` ai `` name ) . main concept charact \n",
      "Cleaned Token Before =  santa barbara. yuille served as a research scientist first at the artificial intelligence laboratory at the massachusetts institute of technology, where\n",
      "Cleaned Token After =  santa barbara . yuille served research scientist first artificial intelligence laboratory massachusetts institute technology , \n",
      "Cleaned Token After Stem =  santa barbara . yuill serv research scientist first artifici intellig laboratori massachusett institut technolog , \n",
      "Cleaned Token Before =  ai program. such breakthroughs would inspire the new field of artificial intelligence officially named in 1956 by john mccarthy in 1956 at the dartmouth\n",
      "Cleaned Token After =  ai program . breakthroughs would inspire new field artificial intelligence officially named 1956 john mccarthy 1956 dartmouth \n",
      "Cleaned Token After Stem =  ai program . breakthrough would inspir new field artifici intellig offici name 1956 john mccarthi 1956 dartmouth \n",
      "Cleaned Token Before =  hawkins' interest in neuroscience juxtaposed against a history of artificial intelligence research. hawkins uses a story of his failed application to the\n",
      "Cleaned Token After =  hawkins ' interest neuroscience juxtaposed history artificial intelligence research . hawkins uses story failed application \n",
      "Cleaned Token After Stem =  hawkin ' interest neurosci juxtapos histori artifici intellig research . hawkin use stori fail applic \n",
      "Cleaned Token Before =  hedge fund that uses a variety of technological methods, including artificial intelligence, machine learning, and distributed computing, for its trading strategies\n",
      "Cleaned Token After =  hedge fund uses variety technological methods , including artificial intelligence , machine learning , distributed computing , trading strategies \n",
      "Cleaned Token After Stem =  hedg fund use varieti technolog method , includ artifici intellig , machin learn , distribut comput , trade strategi \n",
      "Cleaned Token Before =  consumer robots. it was founded in 1990 by three members of mit's artificial intelligence lab, who designed robots for space exploration and military defense\n",
      "Cleaned Token After =  consumer robots . founded 1990 three members mit 's artificial intelligence lab , designed robots space exploration military defense \n",
      "Cleaned Token After Stem =  consum robot . found 1990 three member mit 's artifici intellig lab , design robot space explor militari defens \n",
      "Cleaned Token Before =  translated into many languages. it is unknown whether human-level artificial intelligence will arrive in a matter of years, later this century, or not until\n",
      "Cleaned Token After =  translated many languages . unknown whether human-level artificial intelligence arrive matter years , later century , \n",
      "Cleaned Token After Stem =  translat mani languag . unknown whether human-level artifici intellig arriv matter year , later centuri , \n",
      "Cleaned Token Before =  long short-term memory (lstm) is an artificial recurrent neural network (rnn) architecture used in the field of deep learning. unlike standard feedforward\n",
      "Cleaned Token After =  long short-term memory ( lstm ) artificial recurrent neural network ( rnn ) architecture used field deep learning . unlike standard feedforward \n",
      "Cleaned Token After Stem =  long short-term memori ( lstm ) artifici recurr neural network ( rnn ) architectur use field deep learn . unlik standard feedforward \n",
      "Cleaned Token Before =  kubrick referred to as pinocchio was completed by spielberg as a.i. artificial intelligence (2001). in 1997, the venice film festival awarded kubrick the golden\n",
      "Cleaned Token After =  kubrick referred pinocchio completed spielberg a.i . artificial intelligence ( 2001 ) . 1997 , venice film festival awarded kubrick golden \n",
      "Cleaned Token After Stem =  kubrick refer pinocchio complet spielberg a.i . artifici intellig ( 2001 ) . 1997 , venic film festiv award kubrick golden \n",
      "Cleaned Token Before =  research group, extended tomkins' scripts and used them in early artificial intelligence work as a method of representing procedural knowledge. in their\n",
      "Cleaned Token After =  research group , extended tomkins ' scripts used early artificial intelligence work method representing procedural knowledge . \n",
      "Cleaned Token After Stem =  research group , extend tomkin ' script use earli artifici intellig work method repres procedur knowledg . \n",
      "Cleaned Token Before =  manufacturing, power system, smartgrids and gis. also, multi-agent systems artificial intelligence (maai) are used for simulating societies, the purpose thereof being\n",
      "Cleaned Token After =  manufacturing , power system , smartgrids gis . also , multi-agent systems artificial intelligence ( maai ) used simulating societies , purpose thereof \n",
      "Cleaned Token After Stem =  manufactur , power system , smartgrid gi . also , multi-ag system artifici intellig ( maai ) use simul societi , purpos thereof \n",
      "Cleaned Token Before =  speech to text transcription and translation applications using artificial intelligence and machine learning. its software, called otter, shows captions\n",
      "Cleaned Token After =  speech text transcription translation applications using artificial intelligence machine learning . software , called otter , shows captions \n",
      "Cleaned Token After Stem =  speech text transcript translat applic use artifici intellig machin learn . softwar , call otter , show caption \n",
      "Cleaned Token Before =  laboratories for artificial intelligence research in europe (claire) is a european organisation, created to strengthen artificial intelligence (ai) and human-centred\n",
      "Cleaned Token After =  laboratories artificial intelligence research europe ( claire ) european organisation , created strengthen artificial intelligence ( ai ) human-centred \n",
      "Cleaned Token After Stem =  laboratori artifici intellig research europ ( clair ) european organis , creat strengthen artifici intellig ( ai ) human-centr \n",
      "Cleaned Token Before =  artificial intelligence agents sometimes misbehave due to faulty objective functions that fail to adequately encapsulate the programmers' intended goals\n",
      "Cleaned Token After =  artificial intelligence agents sometimes misbehave due faulty objective functions fail adequately encapsulate programmers ' intended goals \n",
      "Cleaned Token After Stem =  artifici intellig agent sometim misbehav due faulti object function fail adequ encapsul programm ' intend goal \n",
      "Cleaned Token Before =  year 2038, the film follows a scientist who is trying to advance artificial intelligence a step further than human beings, all while bringing his wife back\n",
      "Cleaned Token After =  year 2038 , film follows scientist trying advance artificial intelligence step human beings , bringing wife back \n",
      "Cleaned Token After Stem =  year 2038 , film follow scientist tri advanc artifici intellig step human be , bring wife back \n",
      "Cleaned Token Before =  of human faces in photographs by using neural networks based on artificial intelligence. the app can transform a face to make it smile, look younger, look\n",
      "Cleaned Token After =  human faces photographs using neural networks based artificial intelligence . app transform face make smile , look younger , look \n",
      "Cleaned Token After Stem =  human face photograph use neural network base artifici intellig . app transform face make smile , look younger , look \n",
      "Cleaned Token Before =  senior scientist researching the mathematical foundations of artificial general intelligence. he is on leave from his professorship at the anu college of\n",
      "Cleaned Token After =  senior scientist researching mathematical foundations artificial general intelligence . leave professorship anu college \n",
      "Cleaned Token After Stem =  senior scientist research mathemat foundat artifici gener intellig . leav professorship anu colleg \n",
      "Cleaned Token Before =  inability to accommodate for non-standard conditions. advances in artificial intelligence in the near future may help to rectify this. d9t panda, israel\n",
      "Cleaned Token After =  inability accommodate non-standard conditions . advances artificial intelligence near future may help rectify . d9t panda , israel \n",
      "Cleaned Token After Stem =  inabl accommod non-standard condit . advanc artifici intellig near futur may help rectifi . d9t panda , israel \n",
      "Cleaned Token Before =  military robots. since the mid-20th century, the technology of artificial intelligence (a.i.) began to develop and in the 21st century, the technology\n",
      "Cleaned Token After =  military robots . since mid-20th century , technology artificial intelligence ( a.i . ) began develop 21st century , technology \n",
      "Cleaned Token After Stem =  militari robot . sinc mid-20th centuri , technolog artifici intellig ( a.i . ) began develop 21st centuri , technolog \n",
      "Cleaned Token Before =  and engagement by amplifying the civic intelligence of collaborative groups. increasingly, artificial intelligence and social media, modern innovations\n",
      "Cleaned Token After =  engagement amplifying civic intelligence collaborative groups . increasingly , artificial intelligence social media , modern innovations \n",
      "Cleaned Token After Stem =  engag amplifi civic intellig collabor group . increasingli , artifici intellig social media , modern innov \n",
      "Cleaned Token Before =  itself apart from traditional artificial intelligence by using biological systems as a model. classic artificial intelligence typically uses a set of steps\n",
      "Cleaned Token After =  apart traditional artificial intelligence using biological systems model . classic artificial intelligence typically uses set steps \n",
      "Cleaned Token After Stem =  apart tradit artifici intellig use biolog system model . classic artifici intellig typic use set step \n",
      "Cleaned Token Before =  business founded in 2015, headquartered in toronto. it partly uses artificial intelligence to make decisions on potential investments. as of august 2019 it\n",
      "Cleaned Token After =  business founded 2015 , headquartered toronto . partly uses artificial intelligence make decisions potential investments . august 2019 \n",
      "Cleaned Token After Stem =  busi found 2015 , headquart toronto . partli use artifici intellig make decis potenti invest . august 2019 \n",
      "Cleaned Token Before =  automated artificial intelligence (autoai) is a variation of the automated machine learning, or automl, technology, which extends the automation of model\n",
      "Cleaned Token After =  automated artificial intelligence ( autoai ) variation automated machine learning , automl , technology , extends automation model \n",
      "Cleaned Token After Stem =  autom artifici intellig ( autoai ) variat autom machin learn , automl , technolog , extend autom model \n",
      "Cleaned Token Before =  cyc (pronounced /ˈsaɪk/ syke) is a long-term artificial intelligence project that aims to assemble a comprehensive ontology and knowledge base that spans\n",
      "Cleaned Token After =  cyc ( pronounced /ˈsaɪk/ syke ) long-term artificial intelligence project aims assemble comprehensive ontology knowledge base spans \n",
      "Cleaned Token After Stem =  cyc ( pronounc /ˈsaɪk/ syke ) long-term artifici intellig project aim assembl comprehens ontolog knowledg base span \n",
      "Cleaned Token Before =  representation. however, in the application of graph traversal methods in artificial intelligence the input may be an implicit representation of an infinite graph\n",
      "Cleaned Token After =  representation . however , application graph traversal methods artificial intelligence input may implicit representation infinite graph \n",
      "Cleaned Token After Stem =  represent . howev , applic graph travers method artifici intellig input may implicit represent infinit graph \n",
      "Cleaned Token Before =  (2010), the patient will see you now (2015), and deep medicine: how artificial intelligence can make healthcare human again (2019). he was also commissioned\n",
      "Cleaned Token After =  ( 2010 ) , patient see ( 2015 ) , deep medicine : artificial intelligence make healthcare human ( 2019 ) . also commissioned \n",
      "Cleaned Token After Stem =  ( 2010 ) , patient see ( 2015 ) , deep medicin : artifici intellig make healthcar human ( 2019 ) . also commiss \n",
      "Cleaned Token Before =  linking through spaces for cyber-physical-socio intelligence: a methodology, artificial intelligence, 175(2011)988–1019. h. zhuge, multi-dimensional summarization\n",
      "Cleaned Token After =  linking spaces cyber-physical-socio intelligence : methodology , artificial intelligence , 175 ( 2011 ) 988–1019 . h. zhuge , multi-dimensional summarization \n",
      "Cleaned Token After Stem =  link space cyber-physical-socio intellig : methodolog , artifici intellig , 175 ( 2011 ) 988–1019 . h. zhuge , multi-dimension summar \n",
      "Cleaned Token Before =  knowledge base is an object model (often called an ontology in artificial intelligence literature) with classes, subclasses and instances. early expert\n",
      "Cleaned Token After =  knowledge base object model ( often called ontology artificial intelligence literature ) classes , subclasses instances . early expert \n",
      "Cleaned Token After Stem =  knowledg base object model ( often call ontolog artifici intellig literatur ) class , subclass instanc . earli expert \n",
      "Cleaned Token Before =  in artificial intelligence, a behavior selection algorithm, or action selection algorithm, is an algorithm that selects appropriate behaviors or actions\n",
      "Cleaned Token After =  artificial intelligence , behavior selection algorithm , action selection algorithm , algorithm selects appropriate behaviors actions \n",
      "Cleaned Token After Stem =  artifici intellig , behavior select algorithm , action select algorithm , algorithm select appropri behavior action \n",
      "Cleaned Token Before =  scientist. he was one of the founding researchers in the discipline of artificial intelligence. he was the first kumagai professor of engineering in computer\n",
      "Cleaned Token After =  scientist . one founding researchers discipline artificial intelligence . first kumagai professor engineering computer \n",
      "Cleaned Token After Stem =  scientist . one found research disciplin artifici intellig . first kumagai professor engin comput \n",
      "Cleaned Token Before =  philosophy of mind, and philosophy of cognitive science, especially artificial intelligence and computer science. in the early 1990s, fetzer began to promote\n",
      "Cleaned Token After =  philosophy mind , philosophy cognitive science , especially artificial intelligence computer science . early 1990s , fetzer began promote \n",
      "Cleaned Token After Stem =  philosophi mind , philosophi cognit scienc , especi artifici intellig comput scienc . earli 1990 , fetzer began promot \n",
      "Cleaned Token Before =  the power of artificial intelligence,\" in proceedings of the fifth annual conference on innovative applications of artificial intelligence (washington\n",
      "Cleaned Token After =  power artificial intelligence , '' proceedings fifth annual conference innovative applications artificial intelligence ( washington \n",
      "Cleaned Token After Stem =  power artifici intellig , `` proceed fifth annual confer innov applic artifici intellig ( washington \n",
      "Cleaned Token Before =  siebel systems and is the founder, chairman, and ceo of c3.ai, an artificial intelligence software platform and applications company. he is the chairman\n",
      "Cleaned Token After =  siebel systems founder , chairman , ceo c3.ai , artificial intelligence software platform applications company . chairman \n",
      "Cleaned Token After Stem =  siebel system founder , chairman , ceo c3.ai , artifici intellig softwar platform applic compani . chairman \n",
      "Cleaned Token Before =  ai4d: artificial intelligence for development. international journal of communication, 14(0), 21. https://www.martinhilbert.net/ai4d-artificial\n",
      "Cleaned Token After =  ai4d : artificial intelligence development . international journal communication , 14 ( 0 ) , 21. https : //www.martinhilbert.net/ai4d-artificial \n",
      "Cleaned Token After Stem =  ai4d : artifici intellig develop . intern journal commun , 14 ( 0 ) , 21. http : //www.martinhilbert.net/ai4d-artifici \n",
      "Cleaned Token Before =  the sciences of the artificial (1969) is a book by herbert a. simon in the domain of the learning sciences and artificial intelligence; it is especially\n",
      "Cleaned Token After =  sciences artificial ( 1969 ) book herbert a. simon domain learning sciences artificial intelligence ; especially \n",
      "Cleaned Token After Stem =  scienc artifici ( 1969 ) book herbert a. simon domain learn scienc artifici intellig ; especi \n",
      "Cleaned Token Before =  the age of intelligent machines is a non-fiction book about artificial intelligence by inventor and futurist ray kurzweil. this was his first book and\n",
      "Cleaned Token After =  age intelligent machines non-fiction book artificial intelligence inventor futurist ray kurzweil . first book \n",
      "Cleaned Token After Stem =  age intellig machin non-fict book artifici intellig inventor futurist ray kurzweil . first book \n",
      "Cleaned Token Before =  artificial intelligence (ai) is an approach to artificial intelligence pioneered in the 1980s by rodney brooks, who was then part of mit artificial intelligence\n",
      "Cleaned Token After =  artificial intelligence ( ai ) approach artificial intelligence pioneered 1980s rodney brooks , part mit artificial intelligence \n",
      "Cleaned Token After Stem =  artifici intellig ( ai ) approach artifici intellig pioneer 1980 rodney brook , part mit artifici intellig \n",
      "Cleaned Token Before =  cloud, iot & embedded, edge & fog computing, consumer (android), artificial intelligence and autonomous vehicles. in 2012, linaro formed the linaro datacenter\n",
      "Cleaned Token After =  cloud , iot & embedded , edge & fog computing , consumer ( android ) , artificial intelligence autonomous vehicles . 2012 , linaro formed linaro datacenter \n",
      "Cleaned Token After Stem =  cloud , iot & embed , edg & fog comput , consum ( android ) , artifici intellig autonom vehicl . 2012 , linaro form linaro datacent \n",
      "Cleaned Token Before =  our final invention: artificial intelligence and the end of the human era is a 2013 non-fiction book by the american author james barrat. the book discusses\n",
      "Cleaned Token After =  final invention : artificial intelligence end human era 2013 non-fiction book american author james barrat . book discusses \n",
      "Cleaned Token After Stem =  final invent : artifici intellig end human era 2013 non-fict book american author jame barrat . book discuss \n",
      "Cleaned Token Before =  on 11 january 1993 by warp. it is the second release in warp's artificial intelligence series. the 2001 reissue edition includes the previously unreleased\n",
      "Cleaned Token After =  11 january 1993 warp . second release warp 's artificial intelligence series . 2001 reissue edition includes previously unreleased \n",
      "Cleaned Token After Stem =  11 januari 1993 warp . second releas warp 's artifici intellig seri . 2001 reissu edit includ previous unreleas \n",
      "Cleaned Token Before =  groups. in september 2016, a new group was created to focus on artificial intelligence and research. on march 29, 2018, a new structure merged all of\n",
      "Cleaned Token After =  groups . september 2016 , new group created focus artificial intelligence research . march 29 , 2018 , new structure merged \n",
      "Cleaned Token After Stem =  group . septemb 2016 , new group creat focu artifici intellig research . march 29 , 2018 , new structur merg \n",
      "Cleaned Token Before =  in economics, game theory, decision theory, and artificial intelligence, a rational agent is an agent that has clear preferences, models uncertainty via\n",
      "Cleaned Token After =  economics , game theory , decision theory , artificial intelligence , rational agent agent clear preferences , models uncertainty via \n",
      "Cleaned Token After Stem =  econom , game theori , decis theori , artifici intellig , ration agent agent clear prefer , model uncertainti via \n",
      "Cleaned Token Before =  formerly a senior research scientist at the mit computer science and artificial intelligence laboratory, a part of the mit school of engineering. he now works\n",
      "Cleaned Token After =  formerly senior research scientist mit computer science artificial intelligence laboratory , part mit school engineering . works \n",
      "Cleaned Token After Stem =  formerli senior research scientist mit comput scienc artifici intellig laboratori , part mit school engin . work \n",
      "Cleaned Token Before =  \"computing machinery and intelligence\" is a seminal paper written by alan turing on the topic of artificial intelligence. the paper, published in 1950\n",
      "Cleaned Token After =  `` computing machinery intelligence '' seminal paper written alan turing topic artificial intelligence . paper , published 1950 \n",
      "Cleaned Token After Stem =  `` comput machineri intellig `` semin paper written alan ture topic artifici intellig . paper , publish 1950 \n",
      "Cleaned Token Before =  technology sydney, and rand corporation. quinlan is a specialist in artificial intelligence, particularly in the aspect involving machine learning and its\n",
      "Cleaned Token After =  technology sydney , rand corporation . quinlan specialist artificial intelligence , particularly aspect involving machine learning \n",
      "Cleaned Token After Stem =  technolog sydney , rand corpor . quinlan specialist artifici intellig , particularli aspect involv machin learn \n",
      "Cleaned Token Before =  fiction. artificial general intelligence – hypothetical artificial intelligence that demonstrates human-like intelligence – the intelligence of a machine\n",
      "Cleaned Token After =  fiction . artificial general intelligence – hypothetical artificial intelligence demonstrates human-like intelligence – intelligence machine \n",
      "Cleaned Token After Stem =  fiction . artifici gener intellig – hypothet artifici intellig demonstr human-lik intellig – intellig machin \n",
      "Cleaned Token Before =  entrepreneur and investor based in hong kong, specialized in blockchain, artificial intelligence (ai) and other deep tech. jennifer zhu scott is originally from\n",
      "Cleaned Token After =  entrepreneur investor based hong kong , specialized blockchain , artificial intelligence ( ai ) deep tech . jennifer zhu scott originally \n",
      "Cleaned Token After Stem =  entrepreneur investor base hong kong , special blockchain , artifici intellig ( ai ) deep tech . jennif zhu scott origin \n",
      "Cleaned Token Before =  the monkey and banana problem is a famous toy problem in artificial intelligence, particularly in logic programming and planning. a monkey is in a room\n",
      "Cleaned Token After =  monkey banana problem famous toy problem artificial intelligence , particularly logic programming planning . monkey room \n",
      "Cleaned Token After Stem =  monkey banana problem famou toy problem artifici intellig , particularli logic program plan . monkey room \n",
      "Cleaned Token Before =  college. his research interests focus on machine learning and artificial intelligence, particularly interactive and human-centered ai. he has published\n",
      "Cleaned Token After =  college . research interests focus machine learning artificial intelligence , particularly interactive human-centered ai . published \n",
      "Cleaned Token After Stem =  colleg . research interest focu machin learn artifici intellig , particularli interact human-cent ai . publish \n",
      "Cleaned Token Before =  generative pre-trained transformer 2 (gpt-2) is an open-source artificial intelligence created by openai in february 2019. gpt-2 translates text, answers\n",
      "Cleaned Token After =  generative pre-trained transformer 2 ( gpt-2 ) open-source artificial intelligence created openai february 2019. gpt-2 translates text , answers \n",
      "Cleaned Token After Stem =  gener pre-train transform 2 ( gpt-2 ) open-sourc artifici intellig creat openai februari 2019. gpt-2 translat text , answer \n",
      "Cleaned Token Before =  category:search algorithms search and optimization for problem solving in artificial intelligence search engine technology, software for finding information enterprise\n",
      "Cleaned Token After =  category : search algorithms search optimization problem solving artificial intelligence search engine technology , software finding information enterprise \n",
      "Cleaned Token After Stem =  categori : search algorithm search optim problem solv artifici intellig search engin technolog , softwar find inform enterpris \n",
      "Cleaned Token Before =  american association for artificial intelligence in 1991, of the european co-ordinating committee for artificial intelligence in 1999, and the association\n",
      "Cleaned Token After =  american association artificial intelligence 1991 , european co-ordinating committee artificial intelligence 1999 , association \n",
      "Cleaned Token After Stem =  american associ artifici intellig 1991 , european co-ordin committe artifici intellig 1999 , associ \n",
      "Cleaned Token Before =  interpretation (nli) is a subtopic of natural-language processing in artificial intelligence that deals with machine reading comprehension. natural-language\n",
      "Cleaned Token After =  interpretation ( nli ) subtopic natural-language processing artificial intelligence deals machine reading comprehension . natural-language \n",
      "Cleaned Token After Stem =  interpret ( nli ) subtop natural-languag process artifici intellig deal machin read comprehens . natural-languag \n",
      "Cleaned Token Before =  psychology and literature, as well as the philosophical implications of artificial intelligence. he was widely known for his exegesis of martin heidegger, which\n",
      "Cleaned Token After =  psychology literature , well philosophical implications artificial intelligence . widely known exegesis martin heidegger , \n",
      "Cleaned Token After Stem =  psycholog literatur , well philosoph implic artifici intellig . wide known exegesi martin heidegg , \n",
      "Cleaned Token Before =  to him that he has built a female humanoid robot named ava with artificial intelligence. after asking caleb if he is familiar with the turing test, nathan\n",
      "Cleaned Token After =  built female humanoid robot named ava artificial intelligence . asking caleb familiar turing test , nathan \n",
      "Cleaned Token After Stem =  built femal humanoid robot name ava artifici intellig . ask caleb familiar ture test , nathan \n",
      "Cleaned Token Before =  janelle shane is an optics research scientist and artificial intelligence researcher, writer and public speaker. she keeps a popular science blog called\n",
      "Cleaned Token After =  janelle shane optics research scientist artificial intelligence researcher , writer public speaker . keeps popular science blog called \n",
      "Cleaned Token After Stem =  janel shane optic research scientist artifici intellig research , writer public speaker . keep popular scienc blog call \n",
      "Cleaned Token Before =  considered to be the father of theoretical computer science and artificial intelligence. born in maida vale, london, turing was raised in southern england\n",
      "Cleaned Token After =  considered father theoretical computer science artificial intelligence . born maida vale , london , turing raised southern england \n",
      "Cleaned Token After Stem =  consid father theoret comput scienc artifici intellig . born maida vale , london , ture rais southern england \n",
      "Cleaned Token Before =  intelligent life in the universe? should we colonise space? will artificial intelligence outsmart us? how do we shape the future? the book discusses many\n",
      "Cleaned Token After =  intelligent life universe ? colonise space ? artificial intelligence outsmart us ? shape future ? book discusses many \n",
      "Cleaned Token After Stem =  intellig life univers ? colonis space ? artifici intellig outsmart us ? shape futur ? book discuss mani \n",
      "Cleaned Token Before =  white received universal acclaim on release; reviewers praised the artificial intelligence, uniqueness, and depth, although the system requirements and bugs\n",
      "Cleaned Token After =  white received universal acclaim release ; reviewers praised artificial intelligence , uniqueness , depth , although system requirements bugs \n",
      "Cleaned Token After Stem =  white receiv univers acclaim releas ; review prais artifici intellig , uniqu , depth , although system requir bug \n",
      "Cleaned Token Before =  opencog is a project that aims to build an open source artificial intelligence framework. opencog prime is an architecture for robot and virtual embodied\n",
      "Cleaned Token After =  opencog project aims build open source artificial intelligence framework . opencog prime architecture robot virtual embodied \n",
      "Cleaned Token After Stem =  opencog project aim build open sourc artifici intellig framework . opencog prime architectur robot virtual embodi \n",
      "Cleaned Token Before =  com|language=en}}</ref> bigo technology has developed proprietary artificial intelligence and machine learning that is integrated into the application. the\n",
      "Cleaned Token After =  com|language=en } } < /ref > bigo technology developed proprietary artificial intelligence machine learning integrated application . \n",
      "Cleaned Token After Stem =  com|language=en } } < /ref > bigo technolog develop proprietari artifici intellig machin learn integr applic . \n",
      "Cleaned Token Before =  the blocks world is one of the most famous planning domains in artificial intelligence. the algorithm is similar to a set of wooden blocks of various\n",
      "Cleaned Token After =  blocks world one famous planning domains artificial intelligence . algorithm similar set wooden blocks various \n",
      "Cleaned Token After Stem =  block world one famou plan domain artifici intellig . algorithm similar set wooden block variou \n",
      "Cleaned Token Before =  on the stanford artificial intelligence lab (sail) keyboard in 1970. the meta key first appeared on the stanford artificial intelligence lab (sail) keyboard\n",
      "Cleaned Token After =  stanford artificial intelligence lab ( sail ) keyboard 1970. meta key first appeared stanford artificial intelligence lab ( sail ) keyboard \n",
      "Cleaned Token After Stem =  stanford artifici intellig lab ( sail ) keyboard 1970. meta key first appear stanford artifici intellig lab ( sail ) keyboard \n",
      "Cleaned Token Before =  the centre for artificial intelligence and robotics at the united nations interregional crime and justice research institute (unicri) was established\n",
      "Cleaned Token After =  centre artificial intelligence robotics united nations interregional crime justice research institute ( unicri ) established \n",
      "Cleaned Token After Stem =  centr artifici intellig robot unit nation interregion crime justic research institut ( unicri ) establish \n",
      "Cleaned Token Before =  techniques\". artificial intelligence review. 26 (3): 159–190. doi:10.1007/s10462-007-9052-3. vercellis, carlo (2008). business intelligence : data mining\n",
      "Cleaned Token After =  techniques '' . artificial intelligence review . 26 ( 3 ) : 159–190 . doi:10.1007/s10462-007-9052-3 . vercellis , carlo ( 2008 ) . business intelligence : data mining \n",
      "Cleaned Token After Stem =  techniqu `` . artifici intellig review . 26 ( 3 ) : 159–190 . doi:10.1007/s10462-007-9052-3 . vercelli , carlo ( 2008 ) . busi intellig : data mine \n",
      "Cleaned Token Before =  moss; rae, eds. (1992). \"some thoughts on artificial intelligence and economic theory\". artificial intelligence and economic analysis. edward elgar. pp\n",
      "Cleaned Token After =  moss ; rae , eds . ( 1992 ) . `` thoughts artificial intelligence economic theory '' . artificial intelligence economic analysis . edward elgar . pp \n",
      "Cleaned Token After Stem =  moss ; rae , ed . ( 1992 ) . `` thought artifici intellig econom theori `` . artifici intellig econom analysi . edward elgar . pp \n",
      "Cleaned Token Before =  a company dedicated to the research and development of general artificial intelligence. both companies are based in prague, the czech republic, and have\n",
      "Cleaned Token After =  company dedicated research development general artificial intelligence . companies based prague , czech republic , \n",
      "Cleaned Token After Stem =  compani dedic research develop gener artifici intellig . compani base pragu , czech republ , \n",
      "Cleaned Token Before =  (1999) universal soldier: the return (1999) virus (1999) a.i. artificial intelligence (2001) how to make a monster (2001) swordfish (2001) s1m0ne (2002)\n",
      "Cleaned Token After =  ( 1999 ) universal soldier : return ( 1999 ) virus ( 1999 ) a.i . artificial intelligence ( 2001 ) make monster ( 2001 ) swordfish ( 2001 ) s1m0ne ( 2002 ) \n",
      "Cleaned Token After Stem =  ( 1999 ) univers soldier : return ( 1999 ) viru ( 1999 ) a.i . artifici intellig ( 2001 ) make monster ( 2001 ) swordfish ( 2001 ) s1m0ne ( 2002 ) \n",
      "Cleaned Token Before =  artificial intelligence is used in wikipedia and other wikimedia projects for the purpose of developing those projects. human and bot interaction in wikimedia\n",
      "Cleaned Token After =  artificial intelligence used wikipedia wikimedia projects purpose developing projects . human bot interaction wikimedia \n",
      "Cleaned Token After Stem =  artifici intellig use wikipedia wikimedia project purpos develop project . human bot interact wikimedia \n",
      "Cleaned Token Before =  massachusetts institute of technology. winston was director of the mit artificial intelligence laboratory from 1972 to 1997, succeeding marvin minsky, who left\n",
      "Cleaned Token After =  massachusetts institute technology . winston director mit artificial intelligence laboratory 1972 1997 , succeeding marvin minsky , left \n",
      "Cleaned Token After Stem =  massachusett institut technolog . winston director mit artifici intellig laboratori 1972 1997 , succeed marvin minski , left \n",
      "Cleaned Token Before =  massachusetts institute of technology, united states. they cover artificial intelligence, a field of computer science. noteworthy memos in the series include:\n",
      "Cleaned Token After =  massachusetts institute technology , united states . cover artificial intelligence , field computer science . noteworthy memos series include : \n",
      "Cleaned Token After Stem =  massachusett institut technolog , unit state . cover artifici intellig , field comput scienc . noteworthi memo seri includ : \n",
      "Cleaned Token Before =  commonwealth. humanity has also spawned a powerful artificial intelligence called the sentient intelligence, or si, which exists alone, its physical form spanning\n",
      "Cleaned Token After =  commonwealth . humanity also spawned powerful artificial intelligence called sentient intelligence , si , exists alone , physical form spanning \n",
      "Cleaned Token After Stem =  commonwealth . human also spawn power artifici intellig call sentient intellig , si , exist alon , physic form span \n",
      "Cleaned Token Before =  supporting roles in such films as the wrong guy, galaxy quest, a.i. artificial intelligence, contagion, and a beautiful day in the neighborhood, and guest\n",
      "Cleaned Token After =  supporting roles films wrong guy , galaxy quest , a.i . artificial intelligence , contagion , beautiful day neighborhood , guest \n",
      "Cleaned Token After Stem =  support role film wrong guy , galaxi quest , a.i . artifici intellig , contagion , beauti day neighborhood , guest \n",
      "Cleaned Token Before =  english writer and speaker, focusing on the likely future impact of artificial intelligence on people and societies. he is the author of surviving ai, the\n",
      "Cleaned Token After =  english writer speaker , focusing likely future impact artificial intelligence people societies . author surviving ai , \n",
      "Cleaned Token After Stem =  english writer speaker , focus like futur impact artifici intellig peopl societi . author surviv ai , \n",
      "Cleaned Token Before =  quantitative improvement marked the start of an industry-wide artificial intelligence boom. by 2015, researchers at microsoft reported that their cnns\n",
      "Cleaned Token After =  quantitative improvement marked start industry-wide artificial intelligence boom . 2015 , researchers microsoft reported cnns \n",
      "Cleaned Token After Stem =  quantit improv mark start industry-wid artifici intellig boom . 2015 , research microsoft report cnn \n",
      "Cleaned Token Before =  recurring themes in science fiction. first contact with aliens artificial intelligence machine rule/cybernetic revolt/ai takeover extraterrestrials in\n",
      "Cleaned Token After =  recurring themes science fiction . first contact aliens artificial intelligence machine rule/cybernetic revolt/ai takeover extraterrestrials \n",
      "Cleaned Token After Stem =  recur theme scienc fiction . first contact alien artifici intellig machin rule/cybernet revolt/ai takeov extraterrestri \n",
      "Cleaned Token Before =  early career was devoted mainly to philosophic applications of artificial intelligence, cybernetics, and information theory. later on his main interests\n",
      "Cleaned Token After =  early career devoted mainly philosophic applications artificial intelligence , cybernetics , information theory . later main interests \n",
      "Cleaned Token After Stem =  earli career devot mainli philosoph applic artifici intellig , cybernet , inform theori . later main interest \n",
      "Cleaned Token Before =  high-profile hollywood films, including steven spielberg's a.i. artificial intelligence, mimi leder's pay it forward, and secondhand lions, alongside michael\n",
      "Cleaned Token After =  high-profile hollywood films , including steven spielberg 's a.i . artificial intelligence , mimi leder 's pay forward , secondhand lions , alongside michael \n",
      "Cleaned Token After Stem =  high-profil hollywood film , includ steven spielberg 's a.i . artifici intellig , mimi leder 's pay forward , secondhand lion , alongsid michael \n",
      "Cleaned Token Before =  using first-order logic to represent the goals and state of an artificial intelligence agent. the curry–howard correspondence is a relation between logical\n",
      "Cleaned Token After =  using first-order logic represent goals state artificial intelligence agent . curry–howard correspondence relation logical \n",
      "Cleaned Token After Stem =  use first-ord logic repres goal state artifici intellig agent . curry–howard correspond relat logic \n",
      "Cleaned Token Before =  a major role in theory of computation, compiler construction, artificial intelligence, parsing and formal verification. the theory of abstract automata\n",
      "Cleaned Token After =  major role theory computation , compiler construction , artificial intelligence , parsing formal verification . theory abstract automata \n",
      "Cleaned Token After Stem =  major role theori comput , compil construct , artifici intellig , pars formal verif . theori abstract automata \n",
      "Cleaned Token Before =  to reduce the number of units and the burden on the computer's artificial intelligence; and added logistics, which permitted encirclement. crawford also\n",
      "Cleaned Token After =  reduce number units burden computer 's artificial intelligence ; added logistics , permitted encirclement . crawford also \n",
      "Cleaned Token After Stem =  reduc number unit burden comput 's artifici intellig ; ad logist , permit encircl . crawford also \n",
      "Cleaned Token Before =  1995 to 2002. he has been a fellow of the american association of artificial intelligence since 1997. he has written over 100 refereed publications. mcallester's\n",
      "Cleaned Token After =  1995 2002. fellow american association artificial intelligence since 1997. written 100 refereed publications . mcallester 's \n",
      "Cleaned Token After Stem =  1995 2002. fellow american associ artifici intellig sinc 1997. written 100 refere public . mcallest 's \n",
      "Cleaned Token Before =  systems may be referred to as \"human-aided artificial intelligence\". applications of artificial intelligence comparison of deep learning software compressed\n",
      "Cleaned Token After =  systems may referred `` human-aided artificial intelligence '' . applications artificial intelligence comparison deep learning software compressed \n",
      "Cleaned Token After Stem =  system may refer `` human-aid artifici intellig `` . applic artifici intellig comparison deep learn softwar compress \n",
      "Cleaned Token Before =  hal 9000 is a fictional artificial intelligence character and the main antagonist in arthur c. clarke's space odyssey series. first appearing in the 1968\n",
      "Cleaned Token After =  hal 9000 fictional artificial intelligence character main antagonist arthur c. clarke 's space odyssey series . first appearing 1968 \n",
      "Cleaned Token After Stem =  hal 9000 fiction artifici intellig charact main antagonist arthur c. clark 's space odyssey seri . first appear 1968 \n",
      "Cleaned Token Before =  implementation is program d. the program uses an xml schema called aiml (artificial intelligence markup language) for specifying the heuristic conversation rules\n",
      "Cleaned Token After =  implementation program d. program uses xml schema called aiml ( artificial intelligence markup language ) specifying heuristic conversation rules \n",
      "Cleaned Token After Stem =  implement program d. program use xml schema call aiml ( artifici intellig markup languag ) specifi heurist convers rule \n",
      "Cleaned Token Before =  omar sultan al olama (عمر سلطان العلماء) is minister of state for artificial intelligence in the united arab emirates. he was appointed in october 2017 by\n",
      "Cleaned Token After =  omar sultan al olama ( عمر سلطان العلماء ) minister state artificial intelligence united arab emirates . appointed october 2017 \n",
      "Cleaned Token After Stem =  omar sultan al olama ( عمر سلطان العلماء ) minist state artifici intellig unit arab emir . appoint octob 2017 \n",
      "Cleaned Token Before =  fan management tool, she is spearheading the initiative to make artificial intelligence a part of the promotional mix of the indian film industry. vishakha\n",
      "Cleaned Token After =  fan management tool , spearheading initiative make artificial intelligence part promotional mix indian film industry . vishakha \n",
      "Cleaned Token After Stem =  fan manag tool , spearhead initi make artifici intellig part promot mix indian film industri . vishakha \n",
      "Cleaned Token Before =  1990) was an american pioneer in the field of computer gaming and artificial intelligence. he popularized the term \"machine learning\" in 1959. the samuel\n",
      "Cleaned Token After =  1990 ) american pioneer field computer gaming artificial intelligence . popularized term `` machine learning '' 1959. samuel \n",
      "Cleaned Token After Stem =  1990 ) american pioneer field comput game artifici intellig . popular term `` machin learn `` 1959. samuel \n",
      "Cleaned Token Before =  max headroom is a british fictional artificial intelligence (ai) character, known for his wit, stuttering and electronically altered voice. he was introduced\n",
      "Cleaned Token After =  max headroom british fictional artificial intelligence ( ai ) character , known wit , stuttering electronically altered voice . introduced \n",
      "Cleaned Token After Stem =  max headroom british fiction artifici intellig ( ai ) charact , known wit , stutter electron alter voic . introduc \n",
      "Cleaned Token Before =  human-like responses to the user's input, while shrdlu employed an artificial intelligence that could move virtual objects around an environment and respond\n",
      "Cleaned Token After =  human-like responses user 's input , shrdlu employed artificial intelligence could move virtual objects around environment respond \n",
      "Cleaned Token After Stem =  human-lik respons user 's input , shrdlu employ artifici intellig could move virtual object around environ respond \n",
      "Cleaned Token Before =  in artificial intelligence (ai) and philosophy, the ai control problem is the issue of how to build a superintelligent agent that will aid its creators\n",
      "Cleaned Token After =  artificial intelligence ( ai ) philosophy , ai control problem issue build superintelligent agent aid creators \n",
      "Cleaned Token After Stem =  artifici intellig ( ai ) philosophi , ai control problem issu build superintellig agent aid creator \n",
      "Cleaned Token Before =  (2017). artificial intelligence and economic theory: skynet in the market. london: springer. isbn 978-3-319-66104-9. \"artificial intelligence can reduce\n",
      "Cleaned Token After =  ( 2017 ) . artificial intelligence economic theory : skynet market . london : springer . isbn 978-3-319-66104-9 . `` artificial intelligence reduce \n",
      "Cleaned Token After Stem =  ( 2017 ) . artifici intellig econom theori : skynet market . london : springer . isbn 978-3-319-66104-9 . `` artifici intellig reduc \n",
      "Cleaned Token Before =  film intelligence (solitaire), a card game nous (intelligence), in classical and medieval philosophy, cosmology, and theology artificial intelligence (disambiguation)\n",
      "Cleaned Token After =  film intelligence ( solitaire ) , card game nous ( intelligence ) , classical medieval philosophy , cosmology , theology artificial intelligence ( disambiguation ) \n",
      "Cleaned Token After Stem =  film intellig ( solitair ) , card game nou ( intellig ) , classic mediev philosophi , cosmolog , theolog artifici intellig ( disambigu ) \n",
      "Cleaned Token Before =  cloud computing, cybersecurity, machine learning, artificial intelligence (ai), big data intelligence, internet of things (iot) consulting and data center\n",
      "Cleaned Token After =  cloud computing , cybersecurity , machine learning , artificial intelligence ( ai ) , big data intelligence , internet things ( iot ) consulting data center \n",
      "Cleaned Token After Stem =  cloud comput , cybersecur , machin learn , artifici intellig ( ai ) , big data intellig , internet thing ( iot ) consult data center \n",
      "Cleaned Token Before =  the innovation center for artificial intelligence (icai) is a dutch national network focused on joint technology development between academia, industry\n",
      "Cleaned Token After =  innovation center artificial intelligence ( icai ) dutch national network focused joint technology development academia , industry \n",
      "Cleaned Token After Stem =  innov center artifici intellig ( icai ) dutch nation network focus joint technolog develop academia , industri \n",
      "Cleaned Token Before =  begins to communicate with her. it turns out it is an autonomous artificial intelligence. it takes on the voice of james corden to speak to her, as he is\n",
      "Cleaned Token After =  begins communicate . turns autonomous artificial intelligence . takes voice james corden speak , \n",
      "Cleaned Token After Stem =  begin commun . turn autonom artifici intellig . take voic jame corden speak , \n",
      "Cleaned Token Before =  included.[citation needed] two sub-series are: lecture notes in artificial intelligence lecture notes in bioinformatics monographiae biologicae, another\n",
      "Cleaned Token After =  included . [ citation needed ] two sub-series : lecture notes artificial intelligence lecture notes bioinformatics monographiae biologicae , another \n",
      "Cleaned Token After Stem =  includ . [ citat need ] two sub-seri : lectur note artifici intellig lectur note bioinformat monographia biologica , anoth \n",
      "Cleaned Token Before =  understanding of artificial intelligence. she serves on the board of ai4all foundation, which looks to improve diversity in artificial intelligence. as part of\n",
      "Cleaned Token After =  understanding artificial intelligence . serves board ai4all foundation , looks improve diversity artificial intelligence . part \n",
      "Cleaned Token After Stem =  understand artifici intellig . serv board ai4al foundat , look improv divers artifici intellig . part \n",
      "Cleaned Token Before =  in 2020, kelly represented ibm at a conference on the ethics of artificial intelligence (ai) organized by the pontifical academy for life, where he signed\n",
      "Cleaned Token After =  2020 , kelly represented ibm conference ethics artificial intelligence ( ai ) organized pontifical academy life , signed \n",
      "Cleaned Token After Stem =  2020 , kelli repres ibm confer ethic artifici intellig ( ai ) organ pontif academi life , sign \n",
      "Cleaned Token Before =  2015, over 1,000 experts in artificial intelligence signed a letter warning of the threat of an artificial intelligence arms race and calling for a ban\n",
      "Cleaned Token After =  2015 , 1,000 experts artificial intelligence signed letter warning threat artificial intelligence arms race calling ban \n",
      "Cleaned Token After Stem =  2015 , 1,000 expert artifici intellig sign letter warn threat artifici intellig arm race call ban \n",
      "Cleaned Token Before =  gordon selfridge (10 may 1926 – 3 december 2008) was a pioneer of artificial intelligence. he has been called the \"father of machine perception.\" selfridge\n",
      "Cleaned Token After =  gordon selfridge ( 10 may 1926 – 3 december 2008 ) pioneer artificial intelligence . called `` father machine perception . '' selfridge \n",
      "Cleaned Token After Stem =  gordon selfridg ( 10 may 1926 – 3 decemb 2008 ) pioneer artifici intellig . call `` father machin percept . `` selfridg \n",
      "Cleaned Token Before =  the kyiv laboratory for artificial intelligence (neurotechnica) is a research institute in kyiv, the capital of ukraine. speech recognition, speech synthesis\n",
      "Cleaned Token After =  kyiv laboratory artificial intelligence ( neurotechnica ) research institute kyiv , capital ukraine . speech recognition , speech synthesis \n",
      "Cleaned Token After Stem =  kyiv laboratori artifici intellig ( neurotechnica ) research institut kyiv , capit ukrain . speech recognit , speech synthesi \n",
      "Cleaned Token Before =  had agreed to acquire deepmind technologies, a privately held artificial intelligence company from london. deepmind describes itself as having the ability\n",
      "Cleaned Token After =  agreed acquire deepmind technologies , privately held artificial intelligence company london . deepmind describes ability \n",
      "Cleaned Token After Stem =  agre acquir deepmind technolog , privat held artifici intellig compani london . deepmind describ abil \n",
      "Cleaned Token Before =  2016, ajl aims to raise awareness of the social implications of artificial intelligence through art and research. it was featured in the 2020 documentary\n",
      "Cleaned Token After =  2016 , ajl aims raise awareness social implications artificial intelligence art research . featured 2020 documentary \n",
      "Cleaned Token After Stem =  2016 , ajl aim rais awar social implic artifici intellig art research . featur 2020 documentari \n",
      "Cleaned Token Before =  divorced in 2010. american film institute (afi) awards 2002: a.i. artificial intelligence (won) 2010: franklin j. schaffner award (won) british society of\n",
      "Cleaned Token After =  divorced 2010. american film institute ( afi ) awards 2002 : a.i . artificial intelligence ( ) 2010 : franklin j. schaffner award ( ) british society \n",
      "Cleaned Token After Stem =  divorc 2010. american film institut ( afi ) award 2002 : a.i . artifici intellig ( ) 2010 : franklin j. schaffner award ( ) british societi \n",
      "Cleaned Token Before =  released in november 2013, that includes tools and features like artificial intelligence and game physics. it is compatible with 4k resolution and high-dynamic-range\n",
      "Cleaned Token After =  released november 2013 , includes tools features like artificial intelligence game physics . compatible 4k resolution high-dynamic-range \n",
      "Cleaned Token After Stem =  releas novemb 2013 , includ tool featur like artifici intellig game physic . compat 4k resolut high-dynamic-rang \n",
      "Cleaned Token Before =  the computer graphics industry. key elements include dedicated artificial intelligence processors (\"tensor cores\") and dedicated ray tracing processors\n",
      "Cleaned Token After =  computer graphics industry . key elements include dedicated artificial intelligence processors ( `` tensor cores '' ) dedicated ray tracing processors \n",
      "Cleaned Token After Stem =  comput graphic industri . key element includ dedic artifici intellig processor ( `` tensor core `` ) dedic ray trace processor \n",
      "Cleaned Token Before =  textbook on logical foundations of artificial intelligence remains one of the key references on symbolic artificial intelligence. he is the author of the influential\n",
      "Cleaned Token After =  textbook logical foundations artificial intelligence remains one key references symbolic artificial intelligence . author influential \n",
      "Cleaned Token After Stem =  textbook logic foundat artifici intellig remain one key refer symbol artifici intellig . author influenti \n",
      "Cleaned Token Before =  computing power grew, the fields of law, computer science, and artificial intelligence research spurred renewed interest in the subject of abduction.\n",
      "Cleaned Token After =  computing power grew , fields law , computer science , artificial intelligence research spurred renewed interest subject abduction . \n",
      "Cleaned Token After Stem =  comput power grew , field law , comput scienc , artifici intellig research spur renew interest subject abduct . \n",
      "Cleaned Token Before =  these were 100% similar to human brains. artificial creativity artificial imagination artificial intelligence concept-mapping and mind-mapping connectionism\n",
      "Cleaned Token After =  100 % similar human brains . artificial creativity artificial imagination artificial intelligence concept-mapping mind-mapping connectionism \n",
      "Cleaned Token After Stem =  100 % similar human brain . artifici creativ artifici imagin artifici intellig concept-map mind-map connection \n",
      "Cleaned Token Before =  programs his recently deceased father's brain engrams into baymax's artificial intelligence. when the giri recruits hiro into the fledgling super-team big\n",
      "Cleaned Token After =  programs recently deceased father 's brain engrams baymax 's artificial intelligence . giri recruits hiro fledgling super-team big \n",
      "Cleaned Token After Stem =  program recent deceas father 's brain engram baymax 's artifici intellig . giri recruit hiro fledgl super-team big \n",
      "Cleaned Token Before =  jewish americans, see lists of jewish americans. hal abelson, artificial intelligence leonard adleman, rsa cryptography, dna computing, turing award\n",
      "Cleaned Token After =  jewish americans , see lists jewish americans . hal abelson , artificial intelligence leonard adleman , rsa cryptography , dna computing , turing award \n",
      "Cleaned Token After Stem =  jewish american , see list jewish american . hal abelson , artifici intellig leonard adleman , rsa cryptographi , dna comput , ture award \n",
      "Cleaned Token Before =  bandit learning\", proceedings of international joint conferences on artificial intelligence (ijcai2015) farias, vivek f; ritesh, madan (2011), \"the irrevocable\n",
      "Cleaned Token After =  bandit learning '' , proceedings international joint conferences artificial intelligence ( ijcai2015 ) farias , vivek f ; ritesh , madan ( 2011 ) , `` irrevocable \n",
      "Cleaned Token After Stem =  bandit learn `` , proceed intern joint confer artifici intellig ( ijcai2015 ) faria , vivek f ; ritesh , madan ( 2011 ) , `` irrevoc \n",
      "Cleaned Token Before =  that moves sound or unsound thought along.\" rychlak's view on artificial intelligence was that it significantly lacked in comparison to human beings\n",
      "Cleaned Token After =  moves sound unsound thought along . '' rychlak 's view artificial intelligence significantly lacked comparison human beings \n",
      "Cleaned Token After Stem =  move sound unsound thought along . `` rychlak 's view artifici intellig significantli lack comparison human be \n",
      "Cleaned Token Before =  software product that uses artificial intelligence. the company also productized telescopeai®, an artificial intelligence-based platform for it operations\n",
      "Cleaned Token After =  software product uses artificial intelligence . company also productized telescopeai® , artificial intelligence-based platform operations \n",
      "Cleaned Token After Stem =  softwar product use artifici intellig . compani also product telescopeai® , artifici intelligence-bas platform oper \n",
      "Cleaned Token Before =  experience software and services company based in california that uses artificial intelligence and machine learning to understand consumer intent. it helps companies\n",
      "Cleaned Token After =  experience software services company based california uses artificial intelligence machine learning understand consumer intent . helps companies \n",
      "Cleaned Token After Stem =  experi softwar servic compani base california use artifici intellig machin learn understand consum intent . help compani \n",
      "Cleaned Token Before =  consulting and services focused on the microsoft platform with artificial intelligence, business analytics, cloud, application services, digital transformation\n",
      "Cleaned Token After =  consulting services focused microsoft platform artificial intelligence , business analytics , cloud , application services , digital transformation \n",
      "Cleaned Token After Stem =  consult servic focus microsoft platform artifici intellig , busi analyt , cloud , applic servic , digit transform \n",
      "Cleaned Token Before =  e-energy, e-commerce, e-justice, ict education, iot, fintech, artificial intelligence & robotics, cloud computing and big data there was sudden growth\n",
      "Cleaned Token After =  e-energy , e-commerce , e-justice , ict education , iot , fintech , artificial intelligence & robotics , cloud computing big data sudden growth \n",
      "Cleaned Token After Stem =  e-energi , e-commerc , e-justic , ict educ , iot , fintech , artifici intellig & robot , cloud comput big data sudden growth \n",
      "Cleaned Token Before =  ethics of artificial intelligence concerned with adding or ensuring moral behaviors of man-made machines that use artificial intelligence, otherwise\n",
      "Cleaned Token After =  ethics artificial intelligence concerned adding ensuring moral behaviors man-made machines use artificial intelligence , otherwise \n",
      "Cleaned Token After Stem =  ethic artifici intellig concern ad ensur moral behavior man-mad machin use artifici intellig , otherwis \n",
      "Cleaned Token Before =  spin-off from a project originally developed by the sri international artificial intelligence center. its speech recognition engine was provided by nuance communications\n",
      "Cleaned Token After =  spin-off project originally developed sri international artificial intelligence center . speech recognition engine provided nuance communications \n",
      "Cleaned Token After Stem =  spin-off project origin develop sri intern artifici intellig center . speech recognit engin provid nuanc commun \n",
      "Cleaned Token Before =  learning. in this respect, decision intelligence can be seen as a \"multi-link\" extension to artificial intelligence, which is most widely used for single-link\n",
      "Cleaned Token After =  learning . respect , decision intelligence seen `` multi-link '' extension artificial intelligence , widely used single-link \n",
      "Cleaned Token After Stem =  learn . respect , decis intellig seen `` multi-link `` extens artifici intellig , wide use single-link \n",
      "Cleaned Token Before =  founded in 2013. body labs is a software provider of human-aware artificial intelligence that understands the 3d body shape and motion of people from rgb\n",
      "Cleaned Token After =  founded 2013. body labs software provider human-aware artificial intelligence understands 3d body shape motion people rgb \n",
      "Cleaned Token After Stem =  found 2013. bodi lab softwar provid human-awar artifici intellig understand 3d bodi shape motion peopl rgb \n",
      "Cleaned Token Before =  times, more than any other entrant. the prize is awarded to the artificial intelligence computer program that is deemed the most humanlike, as determined\n",
      "Cleaned Token After =  times , entrant . prize awarded artificial intelligence computer program deemed humanlike , determined \n",
      "Cleaned Token After Stem =  time , entrant . prize award artifici intellig comput program deem humanlik , determin \n",
      "Cleaned Token Before =  this has led to the merger of the institutes of computer science, artificial intelligence and cognitive science into a single school of informatics in 2002\n",
      "Cleaned Token After =  led merger institutes computer science , artificial intelligence cognitive science single school informatics 2002 \n",
      "Cleaned Token After Stem =  led merger institut comput scienc , artifici intellig cognit scienc singl school informat 2002 \n",
      "Cleaned Token Before =  herzog ponders the existential impact of the internet, robotics, artificial intelligence, the internet of things, and more on human life. the film premiered\n",
      "Cleaned Token After =  herzog ponders existential impact internet , robotics , artificial intelligence , internet things , human life . film premiered \n",
      "Cleaned Token After Stem =  herzog ponder existenti impact internet , robot , artifici intellig , internet thing , human life . film premier \n",
      "Cleaned Token Before =  in australia, the australian artificial intelligence institute (australian ai institute, aaii, or a2i2) was a government-funded research and development\n",
      "Cleaned Token After =  australia , australian artificial intelligence institute ( australian ai institute , aaii , a2i2 ) government-funded research development \n",
      "Cleaned Token After Stem =  australia , australian artifici intellig institut ( australian ai institut , aaii , a2i2 ) government-fund research develop \n",
      "Cleaned Token Before =  named after him. he is considered one of the fathers of modern artificial intelligence. born in berlin, germany to jewish parents, he escaped nazi germany\n",
      "Cleaned Token After =  named . considered one fathers modern artificial intelligence . born berlin , germany jewish parents , escaped nazi germany \n",
      "Cleaned Token After Stem =  name . consid one father modern artifici intellig . born berlin , germani jewish parent , escap nazi germani \n",
      "Cleaned Token Before =  systems and the united states' space program, in computing and in artificial intelligence. rand researchers developed many of the principles that were used\n",
      "Cleaned Token After =  systems united states ' space program , computing artificial intelligence . rand researchers developed many principles used \n",
      "Cleaned Token After Stem =  system unit state ' space program , comput artifici intellig . rand research develop mani principl use \n",
      "Cleaned Token Before =  environments and appealing plot, but it was criticized for its buggy artificial intelligence and gameplay. the game was profitable for thq, selling more than\n",
      "Cleaned Token After =  environments appealing plot , criticized buggy artificial intelligence gameplay . game profitable thq , selling \n",
      "Cleaned Token After Stem =  environ appeal plot , critic buggi artifici intellig gameplay . game profit thq , sell \n",
      "Cleaned Token Before =  computational social science, collective intelligence, large-scale cooperation, and the social aspects of artificial intelligence. rahwan was born in aleppo, syria\n",
      "Cleaned Token After =  computational social science , collective intelligence , large-scale cooperation , social aspects artificial intelligence . rahwan born aleppo , syria \n",
      "Cleaned Token After Stem =  comput social scienc , collect intellig , large-scal cooper , social aspect artifici intellig . rahwan born aleppo , syria \n",
      "Cleaned Token Before =  independently using artificial intelligence. the loyal wingman is an unmanned aircraft which incorporates artificial intelligence and utilises a modular\n",
      "Cleaned Token After =  independently using artificial intelligence . loyal wingman unmanned aircraft incorporates artificial intelligence utilises modular \n",
      "Cleaned Token After Stem =  independ use artifici intellig . loyal wingman unman aircraft incorpor artifici intellig utilis modular \n",
      "Cleaned Token Before =  with herbert a. simon in 1975 for their basic contributions to artificial intelligence and the psychology of human cognition. newell completed his bachelor's\n",
      "Cleaned Token After =  herbert a. simon 1975 basic contributions artificial intelligence psychology human cognition . newell completed bachelor 's \n",
      "Cleaned Token After Stem =  herbert a. simon 1975 basic contribut artifici intellig psycholog human cognit . newel complet bachelor 's \n",
      "Cleaned Token Before =  company specializing in internet-related services and products and artificial intelligence (ai), headquartered in beijing's haidian district. it is one of\n",
      "Cleaned Token After =  company specializing internet-related services products artificial intelligence ( ai ) , headquartered beijing 's haidian district . one \n",
      "Cleaned Token After Stem =  compani special internet-rel servic product artifici intellig ( ai ) , headquart beij 's haidian district . one \n",
      "Cleaned Token Before =  poor results in testing. subsequently, halicin was identified by artificial intelligence researchers at the mit jameel clinic in 2019 using an in silico\n",
      "Cleaned Token After =  poor results testing . subsequently , halicin identified artificial intelligence researchers mit jameel clinic 2019 using silico \n",
      "Cleaned Token After Stem =  poor result test . subsequ , halicin identifi artifici intellig research mit jameel clinic 2019 use silico \n",
      "Cleaned Token Before =  is a critical part of the sexbot dynamic and that incorporating artificial intelligence (ai) into them is the next step. as of 2018, various new models\n",
      "Cleaned Token After =  critical part sexbot dynamic incorporating artificial intelligence ( ai ) next step . 2018 , various new models \n",
      "Cleaned Token After Stem =  critic part sexbot dynam incorpor artifici intellig ( ai ) next step . 2018 , variou new model \n",
      "Cleaned Token Before =  common lisp is used to develop research applications (often in artificial intelligence), for rapid development of prototypes or for deployed applications\n",
      "Cleaned Token After =  common lisp used develop research applications ( often artificial intelligence ) , rapid development prototypes deployed applications \n",
      "Cleaned Token After Stem =  common lisp use develop research applic ( often artifici intellig ) , rapid develop prototyp deploy applic \n",
      "Cleaned Token Before =  talk about our qualia, the existence of zombies is impossible. artificial intelligence researcher marvin minsky saw the argument as circular. the proposition\n",
      "Cleaned Token After =  talk qualia , existence zombies impossible . artificial intelligence researcher marvin minsky saw argument circular . proposition \n",
      "Cleaned Token After Stem =  talk qualia , exist zombi imposs . artifici intellig research marvin minski saw argument circular . proposit \n",
      "Cleaned Token Before =  charles n. noussair (2013). \"§3.2.2 enactive artificial intelligence\". the nexus between artificial intelligence and economics. springer. p. 21. isbn 978-3642336478\n",
      "Cleaned Token After =  charles n. noussair ( 2013 ) . `` §3.2.2 enactive artificial intelligence '' . nexus artificial intelligence economics . springer . p. 21. isbn 978-3642336478 \n",
      "Cleaned Token After Stem =  charl n. noussair ( 2013 ) . `` §3.2.2 enact artifici intellig `` . nexu artifici intellig econom . springer . p. 21. isbn 978-3642336478 \n",
      "Cleaned Token Before =  responsible for twitter's technical strategy, machine learning, artificial intelligence, consumer, revenue and science teams. agrawal received a doctorate\n",
      "Cleaned Token After =  responsible twitter 's technical strategy , machine learning , artificial intelligence , consumer , revenue science teams . agrawal received doctorate \n",
      "Cleaned Token After Stem =  respons twitter 's technic strategi , machin learn , artifici intellig , consum , revenu scienc team . agraw receiv doctor \n",
      "Cleaned Token Before =  is an artificial intelligence technologist, business executive and humanitarian. as of 2018, she is the vice president of artificial intelligence and ethics\n",
      "Cleaned Token After =  artificial intelligence technologist , business executive humanitarian . 2018 , vice president artificial intelligence ethics \n",
      "Cleaned Token After Stem =  artifici intellig technologist , busi execut humanitarian . 2018 , vice presid artifici intellig ethic \n",
      "Cleaned Token Before =  1956, the company demonstrated the first practical example of artificial intelligence when arthur l. samuel of ibm's poughkeepsie, new york, laboratory\n",
      "Cleaned Token After =  1956 , company demonstrated first practical example artificial intelligence arthur l. samuel ibm 's poughkeepsie , new york , laboratory \n",
      "Cleaned Token After Stem =  1956 , compani demonstr first practic exampl artifici intellig arthur l. samuel ibm 's poughkeepsi , new york , laboratori \n",
      "Cleaned Token Before =  private turkish defence company specialising in uavs, c4i and artificial intelligence. baykar is a portmanteau of the words bayraktar kardeşler (english:\n",
      "Cleaned Token After =  private turkish defence company specialising uavs , c4i artificial intelligence . baykar portmanteau words bayraktar kardeşler ( english : \n",
      "Cleaned Token After Stem =  privat turkish defenc compani specialis uav , c4i artifici intellig . baykar portmanteau word bayraktar kardeşl ( english : \n",
      "Cleaned Token Before =  department of artificial intelligence, the centre for cognitive science and the department of computer science, along with the artificial intelligence applications\n",
      "Cleaned Token After =  department artificial intelligence , centre cognitive science department computer science , along artificial intelligence applications \n",
      "Cleaned Token After Stem =  depart artifici intellig , centr cognit scienc depart comput scienc , along artifici intellig applic \n",
      "Cleaned Token Before =  in bangalore, karnataka. stylumia is better known for providing artificial intelligence-driven fashion analytics tools to apparel industries. in 2015,\n",
      "Cleaned Token After =  bangalore , karnataka . stylumia better known providing artificial intelligence-driven fashion analytics tools apparel industries . 2015 , \n",
      "Cleaned Token After Stem =  bangalor , karnataka . stylumia better known provid artifici intelligence-driven fashion analyt tool apparel industri . 2015 , \n",
      "Cleaned Token Before =  prevention of brain diseases and driving information technology and artificial intelligence projects that are inspired by the brain. the china brain project\n",
      "Cleaned Token After =  prevention brain diseases driving information technology artificial intelligence projects inspired brain . china brain project \n",
      "Cleaned Token After Stem =  prevent brain diseas drive inform technolog artifici intellig project inspir brain . china brain project \n",
      "Cleaned Token Before =  the itu-who focus group on artificial intelligence for health (ai for health) is an inter-agency collaboration between the world health organization and\n",
      "Cleaned Token After =  itu-who focus group artificial intelligence health ( ai health ) inter-agency collaboration world health organization \n",
      "Cleaned Token After Stem =  itu-who focu group artifici intellig health ( ai health ) inter-ag collabor world health organ \n",
      "Cleaned Token Before =  her portrayal of deputy jo lupo on the syfy series eureka, and artificial intelligence a.l.i.e. and her creator becca on the 100. cerra was born in vancouver\n",
      "Cleaned Token After =  portrayal deputy jo lupo syfy series eureka , artificial intelligence a.l.i.e . creator becca 100. cerra born vancouver \n",
      "Cleaned Token After Stem =  portray deputi jo lupo syfi seri eureka , artifici intellig a.l.i. . creator becca 100. cerra born vancouv \n",
      "Cleaned Token Before =  films such as braveheart (1995), michael collins (1996), a.i. artificial intelligence (2001), gangs of new york (2002), kingdom of heaven (2005), cold\n",
      "Cleaned Token After =  films braveheart ( 1995 ) , michael collins ( 1996 ) , a.i . artificial intelligence ( 2001 ) , gangs new york ( 2002 ) , kingdom heaven ( 2005 ) , cold \n",
      "Cleaned Token After Stem =  film braveheart ( 1995 ) , michael collin ( 1996 ) , a.i . artifici intellig ( 2001 ) , gang new york ( 2002 ) , kingdom heaven ( 2005 ) , cold \n",
      "Cleaned Token Before =  000 experts in artificial intelligence signed on to a letter warning of the threat of an arms race in military artificial intelligence and calling for\n",
      "Cleaned Token After =  000 experts artificial intelligence signed letter warning threat arms race military artificial intelligence calling \n",
      "Cleaned Token After Stem =  000 expert artifici intellig sign letter warn threat arm race militari artifici intellig call \n",
      "Cleaned Token Before =  of artificial intelligence and partially observable markov decision processes. peter norvig, sebastian thrun. udacity: introduction to artificial intelligence\n",
      "Cleaned Token After =  artificial intelligence partially observable markov decision processes . peter norvig , sebastian thrun . udacity : introduction artificial intelligence \n",
      "Cleaned Token After Stem =  artifici intellig partial observ markov decis process . peter norvig , sebastian thrun . udac : introduct artifici intellig \n",
      "Cleaned Token Before =  had agreed to acquire deepmind technologies, a privately held artificial intelligence company from london. technology news website recode reported that\n",
      "Cleaned Token After =  agreed acquire deepmind technologies , privately held artificial intelligence company london . technology news website recode reported \n",
      "Cleaned Token After Stem =  agre acquir deepmind technolog , privat held artifici intellig compani london . technolog news websit recod report \n",
      "Cleaned Token Before =  the market for intelligence.” agrawal is a co-author of the book ‘prediction machines: the simple economics of artificial intelligence’ (released in april\n",
      "Cleaned Token After =  market intelligence. ” agrawal co-author book ‘ prediction machines : simple economics artificial intelligence ’ ( released april \n",
      "Cleaned Token After Stem =  market intellig . ” agraw co-author book ‘ predict machin : simpl econom artifici intellig ’ ( releas april \n",
      "Cleaned Token Before =  active research and development in the fields of robotics and artificial intelligence. the best known set of laws are those written by isaac asimov in\n",
      "Cleaned Token After =  active research development fields robotics artificial intelligence . best known set laws written isaac asimov \n",
      "Cleaned Token After Stem =  activ research develop field robot artifici intellig . best known set law written isaac asimov \n",
      "Cleaned Token Before =  biennial european conference on artificial intelligence (ecai) is the leading conference in the field of artificial intelligence in europe, and is commonly\n",
      "Cleaned Token After =  biennial european conference artificial intelligence ( ecai ) leading conference field artificial intelligence europe , commonly \n",
      "Cleaned Token After Stem =  biennial european confer artifici intellig ( ecai ) lead confer field artifici intellig europ , commonli \n",
      "Cleaned Token Before =  the stanford human-centered ai institute, set out to improve the artificial intelligence models and algorithms for image recognition by significantly enlarging\n",
      "Cleaned Token After =  stanford human-centered ai institute , set improve artificial intelligence models algorithms image recognition significantly enlarging \n",
      "Cleaned Token After Stem =  stanford human-cent ai institut , set improv artifici intellig model algorithm imag recognit significantli enlarg \n",
      "Cleaned Token Before =  partnership on artificial intelligence to benefit people and society) is a nonprofit coalition committed to the responsible use of artificial intelligence. it researches\n",
      "Cleaned Token After =  partnership artificial intelligence benefit people society ) nonprofit coalition committed responsible use artificial intelligence . researches \n",
      "Cleaned Token After Stem =  partnership artifici intellig benefit peopl societi ) nonprofit coalit commit respons use artifici intellig . research \n",
      "Cleaned Token Before =  dwoskin, elizabeth (june 9, 2016). \"this is where the real action in artificial intelligence takes place\". washington post. retrieved 2016-08-16. \"the two sigma\n",
      "Cleaned Token After =  dwoskin , elizabeth ( june 9 , 2016 ) . `` real action artificial intelligence takes place '' . washington post . retrieved 2016-08-16 . `` two sigma \n",
      "Cleaned Token After Stem =  dwoskin , elizabeth ( june 9 , 2016 ) . `` real action artifici intellig take place `` . washington post . retriev 2016-08-16 . `` two sigma \n",
      "Cleaned Token Before =  פריד‎; born april 20, 1992) is an israeli scientist, engineer and artificial intelligence researcher at massachusetts institute of technology, social activist\n",
      "Cleaned Token After =  פריד‎ ; born april 20 , 1992 ) israeli scientist , engineer artificial intelligence researcher massachusetts institute technology , social activist \n",
      "Cleaned Token After Stem =  פריד‎ ; born april 20 , 1992 ) isra scientist , engin artifici intellig research massachusett institut technolog , social activist \n",
      "Cleaned Token Before =  a canadian researcher of tatar origin working in the field of artificial intelligence. he specializes in deep learning, probabilistic graphical models\n",
      "Cleaned Token After =  canadian researcher tatar origin working field artificial intelligence . specializes deep learning , probabilistic graphical models \n",
      "Cleaned Token After Stem =  canadian research tatar origin work field artifici intellig . special deep learn , probabilist graphic model \n",
      "Cleaned Token Before =  (2007). \"the robert morris internet worm\". computer science & artificial intelligence laboratory (csail). massachusetts institute of technology. retrieved\n",
      "Cleaned Token After =  ( 2007 ) . `` robert morris internet worm '' . computer science & artificial intelligence laboratory ( csail ) . massachusetts institute technology . retrieved \n",
      "Cleaned Token After Stem =  ( 2007 ) . `` robert morri internet worm `` . comput scienc & artifici intellig laboratori ( csail ) . massachusett institut technolog . retriev \n",
      "Cleaned Token Before =  at the northwestern polytechnical university (nwpu) working in artificial intelligence and computer vision. li entered the university of science and technology\n",
      "Cleaned Token After =  northwestern polytechnical university ( nwpu ) working artificial intelligence computer vision . li entered university science technology \n",
      "Cleaned Token After Stem =  northwestern polytechn univers ( nwpu ) work artifici intellig comput vision . li enter univers scienc technolog \n",
      "Cleaned Token Before =  artificial intelligence (chai) is a research center at university of california, berkeley (uc berkeley) focusing on advanced artificial intelligence (ai)\n",
      "Cleaned Token After =  artificial intelligence ( chai ) research center university california , berkeley ( uc berkeley ) focusing advanced artificial intelligence ( ai ) \n",
      "Cleaned Token After Stem =  artifici intellig ( chai ) research center univers california , berkeley ( uc berkeley ) focus advanc artifici intellig ( ai ) \n",
      "Cleaned Token Before =  warp in september 1993, the album was the sixth release in warp's artificial intelligence series, which focused on \"electronic listening music\" by different\n",
      "Cleaned Token After =  warp september 1993 , album sixth release warp 's artificial intelligence series , focused `` electronic listening music '' different \n",
      "Cleaned Token After Stem =  warp septemb 1993 , album sixth releas warp 's artifici intellig seri , focus `` electron listen music `` differ \n",
      "Cleaned Token Before =  veritone inc. is an artificial intelligence tech company based in costa mesa, california, founded in 2014. veritone's aiware technology and solutions\n",
      "Cleaned Token After =  veritone inc. artificial intelligence tech company based costa mesa , california , founded 2014. veritone 's aiware technology solutions \n",
      "Cleaned Token After Stem =  veriton inc. artifici intellig tech compani base costa mesa , california , found 2014. veriton 's aiwar technolog solut \n",
      "Cleaned Token Before =  dataminr is a new york based company that specialises in artificial intelligence to provide real-time information alerts to clients. it was founded in\n",
      "Cleaned Token After =  dataminr new york based company specialises artificial intelligence provide real-time information alerts clients . founded \n",
      "Cleaned Token After Stem =  dataminr new york base compani specialis artifici intellig provid real-tim inform alert client . found \n",
      "Cleaned Token Before =  which was released in 2010. humanoid robots, especially those with artificial intelligence algorithms, could be useful for future dangerous and/or distant\n",
      "Cleaned Token After =  released 2010. humanoid robots , especially artificial intelligence algorithms , could useful future dangerous and/or distant \n",
      "Cleaned Token After Stem =  releas 2010. humanoid robot , especi artifici intellig algorithm , could use futur danger and/or distant \n",
      "Cleaned Token Before =  based at the university of sheffield. historically, the concept of artificial intelligence, or ai, has rapidly changed numerous forms of society and different\n",
      "Cleaned Token After =  based university sheffield . historically , concept artificial intelligence , ai , rapidly changed numerous forms society different \n",
      "Cleaned Token After Stem =  base univers sheffield . histor , concept artifici intellig , ai , rapidli chang numer form societi differ \n",
      "Cleaned Token Before =  2017, he launched the space.ml platform with ce zhang to apply artificial intelligence to astrophysics research. together with colleagues from eth zurich\n",
      "Cleaned Token After =  2017 , launched space.ml platform ce zhang apply artificial intelligence astrophysics research . together colleagues eth zurich \n",
      "Cleaned Token After Stem =  2017 , launch space.ml platform ce zhang appli artifici intellig astrophys research . togeth colleagu eth zurich \n",
      "Cleaned Token Before =  first assembler and participated in the founding of the field of artificial intelligence. rochester received his b.s. degree in electrical engineering from\n",
      "Cleaned Token After =  first assembler participated founding field artificial intelligence . rochester received b.s . degree electrical engineering \n",
      "Cleaned Token After Stem =  first assembl particip found field artifici intellig . rochest receiv b. . degre electr engin \n",
      "Cleaned Token Before =  risks facing humanity, particularly existential risk from advanced artificial intelligence (ai). its founders include mit cosmologist max tegmark and skype\n",
      "Cleaned Token After =  risks facing humanity , particularly existential risk advanced artificial intelligence ( ai ) . founders include mit cosmologist max tegmark skype \n",
      "Cleaned Token After Stem =  risk face human , particularli existenti risk advanc artifici intellig ( ai ) . founder includ mit cosmologist max tegmark skype \n",
      "Cleaned Token Before =   xing became the president of mohamed bin zayed university of artificial intelligence. xing received a b.sc. in physics at tsinghua university in 1993\n",
      "Cleaned Token After =  xing became president mohamed bin zayed university artificial intelligence . xing received b.sc . physics tsinghua university 1993 \n",
      "Cleaned Token After Stem =  xing becam presid moham bin zay univers artifici intellig . xing receiv b.sc . physic tsinghua univers 1993 \n",
      "Cleaned Token Before =  institute at new york university. her research focuses on the role of artificial intelligence in journalism. broussard has published features and essays in many\n",
      "Cleaned Token After =  institute new york university . research focuses role artificial intelligence journalism . broussard published features essays many \n",
      "Cleaned Token After Stem =  institut new york univers . research focus role artifici intellig journal . broussard publish featur essay mani \n",
      "Cleaned Token Before =  advancement of artificial intelligence. aaai organizes speaker events and information sessions in the field of artificial intelligence to increase student's\n",
      "Cleaned Token After =  advancement artificial intelligence . aaai organizes speaker events information sessions field artificial intelligence increase student 's \n",
      "Cleaned Token After Stem =  advanc artifici intellig . aaai organ speaker event inform session field artifici intellig increas student 's \n",
      "Cleaned Token Before =  australia, lecture notes in artificial intelligence, pp. 216–228. springer: idsia – dalle molle institute for artificial intelligence in the hidden reality:\n",
      "Cleaned Token After =  australia , lecture notes artificial intelligence , pp . 216–228 . springer : idsia – dalle molle institute artificial intelligence hidden reality : \n",
      "Cleaned Token After Stem =  australia , lectur note artifici intellig , pp . 216–228 . springer : idsia – dall moll institut artifici intellig hidden realiti : \n",
      "Cleaned Token Before =  the ingolstadt research centre for artificial intelligence and machine learning (ainin - artificial intelligence network ingolstadt), which is based\n",
      "Cleaned Token After =  ingolstadt research centre artificial intelligence machine learning ( ainin - artificial intelligence network ingolstadt ) , based \n",
      "Cleaned Token After Stem =  ingolstadt research centr artifici intellig machin learn ( ainin - artifici intellig network ingolstadt ) , base \n",
      "Cleaned Token Before =  norvig, “artificial intelligence: a modern approach (3rd edition)”, pp. 220-222, december 11, 2009. stuart j. russell and peter norvig, artificial intelligence:\n",
      "Cleaned Token After =  norvig , “ artificial intelligence : modern approach ( 3rd edition ) ” , pp . 220-222 , december 11 , 2009. stuart j. russell peter norvig , artificial intelligence : \n",
      "Cleaned Token After Stem =  norvig , “ artifici intellig : modern approach ( 3rd edit ) ” , pp . 220-222 , decemb 11 , 2009. stuart j. russel peter norvig , artifici intellig : \n",
      "Cleaned Token Before =  interview, us president barack obama said that due to the growth of artificial intelligence, society would be debating \"unconditional free money for everyone\"\n",
      "Cleaned Token After =  interview , us president barack obama said due growth artificial intelligence , society would debating `` unconditional free money everyone '' \n",
      "Cleaned Token After Stem =  interview , us presid barack obama said due growth artifici intellig , societi would debat `` uncondit free money everyon `` \n",
      "Cleaned Token Before =  artificial intelligence in general (e.g. journal of artificial intelligence research (jair), artificial intelligence, applied artificial intelligence\n",
      "Cleaned Token After =  artificial intelligence general ( e.g . journal artificial intelligence research ( jair ) , artificial intelligence , applied artificial intelligence \n",
      "Cleaned Token After Stem =  artifici intellig gener ( e.g . journal artifici intellig research ( jair ) , artifici intellig , appli artifici intellig \n",
      "Cleaned Token Before =  declarative versus procedural representations of knowledge in artificial intelligence. advocates of declarative representations were notably working\n",
      "Cleaned Token After =  declarative versus procedural representations knowledge artificial intelligence . advocates declarative representations notably working \n",
      "Cleaned Token After Stem =  declar versu procedur represent knowledg artifici intellig . advoc declar represent notabl work \n",
      "Cleaned Token Before =  contributions to machine learning, pattern recognition, computer vision, artificial intelligence, computational optics, image analysis of fine art, and related\n",
      "Cleaned Token After =  contributions machine learning , pattern recognition , computer vision , artificial intelligence , computational optics , image analysis fine art , related \n",
      "Cleaned Token After Stem =  contribut machin learn , pattern recognit , comput vision , artifici intellig , comput optic , imag analysi fine art , relat \n",
      "Cleaned Token Before =  2017) was an american computer scientist who created an oft-cited artificial intelligence program student, with which he earned his phd., worked at bbn technologies\n",
      "Cleaned Token After =  2017 ) american computer scientist created oft-cited artificial intelligence program student , earned phd. , worked bbn technologies \n",
      "Cleaned Token After Stem =  2017 ) american comput scientist creat oft-cit artifici intellig program student , earn phd . , work bbn technolog \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Token Before =  innopraktika announced that tikhonova was appointed head of a new artificial intelligence institute at moscow state university. bershidsky, leonid (29 january\n",
      "Cleaned Token After =  innopraktika announced tikhonova appointed head new artificial intelligence institute moscow state university . bershidsky , leonid ( 29 january \n",
      "Cleaned Token After Stem =  innopraktika announc tikhonova appoint head new artifici intellig institut moscow state univers . bershidski , leonid ( 29 januari \n",
      "Cleaned Token Before =  those interactions. cellular automata, neural networks, artificial intelligence, and artificial life are related fields, but do not try to describe general\n",
      "Cleaned Token After =  interactions . cellular automata , neural networks , artificial intelligence , artificial life related fields , try describe general \n",
      "Cleaned Token After Stem =  interact . cellular automata , neural network , artifici intellig , artifici life relat field , tri describ gener \n",
      "Cleaned Token Before =  dozens of technology patents covering internet of things (iot), artificial intelligence (ai) modeling, wearable, eyewear, smartphone, mobile, imaging,\n",
      "Cleaned Token After =  dozens technology patents covering internet things ( iot ) , artificial intelligence ( ai ) modeling , wearable , eyewear , smartphone , mobile , imaging , \n",
      "Cleaned Token After Stem =  dozen technolog patent cover internet thing ( iot ) , artifici intellig ( ai ) model , wearabl , eyewear , smartphon , mobil , imag , \n",
      "Cleaned Token Before =  term system integrations that can support business requirements. artificial intelligence systems integration continuous integration system in package and\n",
      "Cleaned Token After =  term system integrations support business requirements . artificial intelligence systems integration continuous integration system package \n",
      "Cleaned Token After Stem =  term system integr support busi requir . artifici intellig system integr continu integr system packag \n",
      "Cleaned Token Before =  maho hiyajo and alexis leskinen and becomes a tester for their artificial intelligence system amadeus. the series is directed by kenichi kawamura, and\n",
      "Cleaned Token After =  maho hiyajo alexis leskinen becomes tester artificial intelligence system amadeus . series directed kenichi kawamura , \n",
      "Cleaned Token After Stem =  maho hiyajo alexi leskinen becom tester artifici intellig system amadeu . seri direct kenichi kawamura , \n",
      "Cleaned Token Before =  clark, cajardo lindsey and jesse d. arrow who interact with an artificial intelligence machine that manages a futuristic automated detention facility\n",
      "Cleaned Token After =  clark , cajardo lindsey jesse d. arrow interact artificial intelligence machine manages futuristic automated detention facility \n",
      "Cleaned Token After Stem =  clark , cajardo lindsey jess d. arrow interact artifici intellig machin manag futurist autom detent facil \n",
      "Cleaned Token Before =  worry is that an artificial intelligence arms race would develop as countries jostle to take the lead both in artificial intelligence generally and in\n",
      "Cleaned Token After =  worry artificial intelligence arms race would develop countries jostle take lead artificial intelligence generally \n",
      "Cleaned Token After Stem =  worri artifici intellig arm race would develop countri jostl take lead artifici intellig gener \n",
      "Cleaned Token Before =  builder. jobcase is an affiliate of mit’s computer science and artificial intelligence laboratory (csail). in march 2016. jobcase had 50 million members\n",
      "Cleaned Token After =  builder . jobcase affiliate mit ’ computer science artificial intelligence laboratory ( csail ) . march 2016. jobcase 50 million members \n",
      "Cleaned Token After Stem =  builder . jobcas affili mit ’ comput scienc artifici intellig laboratori ( csail ) . march 2016. jobcas 50 million member \n",
      "Cleaned Token Before =  committee for artificial intelligence. in 2009, wolfram burgard became fellow of the association for the advancement of artificial intelligence. in 2010,\n",
      "Cleaned Token After =  committee artificial intelligence . 2009 , wolfram burgard became fellow association advancement artificial intelligence . 2010 , \n",
      "Cleaned Token After Stem =  committe artifici intellig . 2009 , wolfram burgard becam fellow associ advanc artifici intellig . 2010 , \n",
      "Cleaned Token Before =  distinguish artificial intelligence from the natural kind\", scientific american, vol. 316, no. 3 (march 2017), pp. 58–63. multiple tests of artificial-intelligence\n",
      "Cleaned Token After =  distinguish artificial intelligence natural kind '' , scientific american , vol . 316 , . 3 ( march 2017 ) , pp . 58–63 . multiple tests artificial-intelligence \n",
      "Cleaned Token After Stem =  distinguish artifici intellig natur kind `` , scientif american , vol . 316 , . 3 ( march 2017 ) , pp . 58–63 . multipl test artificial-intellig \n",
      "Cleaned Token Before =  seeing ai is an artificial intelligence application developed by microsoft for ios. seeing ai uses the device camera to identify people and objects, and\n",
      "Cleaned Token After =  seeing ai artificial intelligence application developed microsoft ios . seeing ai uses device camera identify people objects , \n",
      "Cleaned Token After Stem =  see ai artifici intellig applic develop microsoft io . see ai use devic camera identifi peopl object , \n",
      "Cleaned Token Before =  creativity, culture, and perception through machine learning and artificial intelligence, and have appeared at the ars electronica festival, the museum\n",
      "Cleaned Token After =  creativity , culture , perception machine learning artificial intelligence , appeared ars electronica festival , museum \n",
      "Cleaned Token After Stem =  creativ , cultur , percept machin learn artifici intellig , appear ar electronica festiv , museum \n",
      "Cleaned Token Before =  more recently, the theory has become of increased interest in artificial intelligence and cognitive robotics to help ground meaning. image schemas are\n",
      "Cleaned Token After =  recently , theory become increased interest artificial intelligence cognitive robotics help ground meaning . image schemas \n",
      "Cleaned Token After Stem =  recent , theori becom increas interest artifici intellig cognit robot help ground mean . imag schema \n",
      "Cleaned Token Before =  by the startup company artelnics. opennn is a general purpose artificial intelligence software package. it uses machine learning techniques for solving\n",
      "Cleaned Token After =  startup company artelnics . opennn general purpose artificial intelligence software package . uses machine learning techniques solving \n",
      "Cleaned Token After Stem =  startup compani arteln . opennn gener purpos artifici intellig softwar packag . use machin learn techniqu solv \n",
      "Cleaned Token Before =  optimization for biclustering microarray gene expression data\". applied artificial intelligence. 29 (4): 353–381. doi:10.1080/08839514.2015.1016391. s2cid 44624424\n",
      "Cleaned Token After =  optimization biclustering microarray gene expression data '' . applied artificial intelligence . 29 ( 4 ) : 353–381 . doi:10.1080/08839514.2015.1016391 . s2cid 44624424 \n",
      "Cleaned Token After Stem =  optim biclust microarray gene express data `` . appli artifici intellig . 29 ( 4 ) : 353–381 . doi:10.1080/08839514.2015.1016391 . s2cid 44624424 \n",
      "Cleaned Token Before =  january 20, 1936) is a computer scientist working in the field of artificial intelligence, and joint winner of the 1994 acm turing award. he is often called\n",
      "Cleaned Token After =  january 20 , 1936 ) computer scientist working field artificial intelligence , joint winner 1994 acm turing award . often called \n",
      "Cleaned Token After Stem =  januari 20 , 1936 ) comput scientist work field artifici intellig , joint winner 1994 acm ture award . often call \n",
      "Cleaned Token Before =  offline shopping), electrical vehicle (sahara evols), hospital, artificial intelligence, hospitality, cooperative society, it and information technology\n",
      "Cleaned Token After =  offline shopping ) , electrical vehicle ( sahara evols ) , hospital , artificial intelligence , hospitality , cooperative society , information technology \n",
      "Cleaned Token After Stem =  offlin shop ) , electr vehicl ( sahara evol ) , hospit , artifici intellig , hospit , cooper societi , inform technolog \n",
      "Cleaned Token Before =  intelligent personal assistant of the same name. cortana is an artificial intelligence found in the halo franchise. in the video games, cortana often\n",
      "Cleaned Token After =  intelligent personal assistant name . cortana artificial intelligence found halo franchise . video games , cortana often \n",
      "Cleaned Token After Stem =  intellig person assist name . cortana artifici intellig found halo franchis . video game , cortana often \n",
      "Cleaned Token Before =  missionaries and cannibals problem is a well-known toy problem in artificial intelligence, where it was used by saul amarel as an example of problem representation\n",
      "Cleaned Token After =  missionaries cannibals problem well-known toy problem artificial intelligence , used saul amarel example problem representation \n",
      "Cleaned Token After Stem =  missionari cannib problem well-known toy problem artifici intellig , use saul amarel exampl problem represent \n",
      "Cleaned Token Before =  of statsoft to dell in 2014, lewicki focused on applications of artificial intelligence in medicine, that has been traditionally slower in adopting big\n",
      "Cleaned Token After =  statsoft dell 2014 , lewicki focused applications artificial intelligence medicine , traditionally slower adopting big \n",
      "Cleaned Token After Stem =  statsoft dell 2014 , lewicki focus applic artifici intellig medicin , tradit slower adopt big \n",
      "Cleaned Token Before =  spielberg continued in the 2000s with science fiction, including a.i. artificial intelligence (2001), minority report (2002) and war of the worlds (2005). he\n",
      "Cleaned Token After =  spielberg continued 2000s science fiction , including a.i . artificial intelligence ( 2001 ) , minority report ( 2002 ) war worlds ( 2005 ) . \n",
      "Cleaned Token After Stem =  spielberg continu 2000 scienc fiction , includ a.i . artifici intellig ( 2001 ) , minor report ( 2002 ) war world ( 2005 ) . \n",
      "Cleaned Token Before =  terrible\", he predicted she was a step towards \"conversational artificial intelligence\". at the 2018 consumer electronics show, a bbc news reporter described\n",
      "Cleaned Token After =  terrible '' , predicted step towards `` conversational artificial intelligence '' . 2018 consumer electronics show , bbc news reporter described \n",
      "Cleaned Token After Stem =  terribl `` , predict step toward `` convers artifici intellig `` . 2018 consum electron show , bbc news report describ \n",
      "Cleaned Token Before =  in artificial intelligence, an expert system is a computer system emulating the decision-making ability of a human expert. expert systems are designed\n",
      "Cleaned Token After =  artificial intelligence , expert system computer system emulating decision-making ability human expert . expert systems designed \n",
      "Cleaned Token After Stem =  artifici intellig , expert system comput system emul decision-mak abil human expert . expert system design \n",
      "Cleaned Token Before =  cuxhaven, germany) is a german computer scientist. he is professor of artificial intelligence and machine learning at the department of computer science of the\n",
      "Cleaned Token After =  cuxhaven , germany ) german computer scientist . professor artificial intelligence machine learning department computer science \n",
      "Cleaned Token After Stem =  cuxhaven , germani ) german comput scientist . professor artifici intellig machin learn depart comput scienc \n",
      "Cleaned Token Before =  institute for artificial intelligence, an independent not-for-profit research institute focused on developing artificial intelligence based applications\n",
      "Cleaned Token After =  institute artificial intelligence , independent not-for-profit research institute focused developing artificial intelligence based applications \n",
      "Cleaned Token After Stem =  institut artifici intellig , independ not-for-profit research institut focus develop artifici intellig base applic \n",
      "Cleaned Token Before =  minds and machines is a peer-reviewed academic journal covering artificial intelligence, philosophy, and cognitive science. the journal was established\n",
      "Cleaned Token After =  minds machines peer-reviewed academic journal covering artificial intelligence , philosophy , cognitive science . journal established \n",
      "Cleaned Token After Stem =  mind machin peer-review academ journal cover artifici intellig , philosophi , cognit scienc . journal establish \n",
      "Cleaned Token Before =  the conference on artificial general intelligence is a meeting of researchers in the field of artificial general intelligence organized by the agi society\n",
      "Cleaned Token After =  conference artificial general intelligence meeting researchers field artificial general intelligence organized agi society \n",
      "Cleaned Token After Stem =  confer artifici gener intellig meet research field artifici gener intellig organ agi societi \n",
      "Cleaned Token Before =  similarity learning is an area of supervised machine learning in artificial intelligence. it is closely related to regression and classification, but the\n",
      "Cleaned Token After =  similarity learning area supervised machine learning artificial intelligence . closely related regression classification , \n",
      "Cleaned Token After Stem =  similar learn area supervis machin learn artifici intellig . close relat regress classif , \n",
      "Cleaned Token Before =  smyth, and l. mcginty, generating diverse compound critiques, artificial intelligence review 24(3-4):339-357, 2005. f. ricci and q. nguyen, acquiring\n",
      "Cleaned Token After =  smyth , l. mcginty , generating diverse compound critiques , artificial intelligence review 24 ( 3-4 ) :339-357 , 2005. f. ricci q. nguyen , acquiring \n",
      "Cleaned Token After Stem =  smyth , l. mcginti , gener divers compound critiqu , artifici intellig review 24 ( 3-4 ) :339-357 , 2005. f. ricci q. nguyen , acquir \n",
      "Cleaned Token Before =  by centaur records (crc 3255). list of music software music and artificial intelligence computer music sonification adams, tim (2010-07-10). \"david cope:\n",
      "Cleaned Token After =  centaur records ( crc 3255 ) . list music software music artificial intelligence computer music sonification adams , tim ( 2010-07-10 ) . `` david cope : \n",
      "Cleaned Token After Stem =  centaur record ( crc 3255 ) . list music softwar music artifici intellig comput music sonif adam , tim ( 2010-07-10 ) . `` david cope : \n",
      "Cleaned Token Before =  studies of thought and cognition evolution philosophy primatology artificial intelligence (ai) piaget is considered to be the most influential figure in\n",
      "Cleaned Token After =  studies thought cognition evolution philosophy primatology artificial intelligence ( ai ) piaget considered influential figure \n",
      "Cleaned Token After Stem =  studi thought cognit evolut philosophi primatolog artifici intellig ( ai ) piaget consid influenti figur \n",
      "Cleaned Token Before =  mirrors, on-board diagnostics (obd), vehicle wi-fi hotspots), artificial intelligence translators, mifi devices, smart earphones, smart metering, gps\n",
      "Cleaned Token After =  mirrors , on-board diagnostics ( obd ) , vehicle wi-fi hotspots ) , artificial intelligence translators , mifi devices , smart earphones , smart metering , gps \n",
      "Cleaned Token After Stem =  mirror , on-board diagnost ( obd ) , vehicl wi-fi hotspot ) , artifici intellig translat , mifi devic , smart earphon , smart meter , gp \n",
      "Cleaned Token Before =  breakthroughs in emerging technologies in fields such as robotics, artificial intelligence, nanotechnology, quantum computing, biotechnology, the internet\n",
      "Cleaned Token After =  breakthroughs emerging technologies fields robotics , artificial intelligence , nanotechnology , quantum computing , biotechnology , internet \n",
      "Cleaned Token After Stem =  breakthrough emerg technolog field robot , artifici intellig , nanotechnolog , quantum comput , biotechnolog , internet \n",
      "Cleaned Token Before =  science journals. artificial intelligence communications of the acm computer ieee transactions on pattern analysis and machine intelligence ieee transactions\n",
      "Cleaned Token After =  science journals . artificial intelligence communications acm computer ieee transactions pattern analysis machine intelligence ieee transactions \n",
      "Cleaned Token After Stem =  scienc journal . artifici intellig commun acm comput ieee transact pattern analysi machin intellig ieee transact \n",
      "Cleaned Token Before =  give an artificial intelligence an explicit goal – like maximizing the number of paper clips in the world – and that artificial intelligence has gotten\n",
      "Cleaned Token After =  give artificial intelligence explicit goal – like maximizing number paper clips world – artificial intelligence gotten \n",
      "Cleaned Token After Stem =  give artifici intellig explicit goal – like maxim number paper clip world – artifici intellig gotten \n",
      "Cleaned Token Before =  groups. research labs and offices of the computer science and artificial intelligence laboratory (csail), the laboratory for information and decision\n",
      "Cleaned Token After =  groups . research labs offices computer science artificial intelligence laboratory ( csail ) , laboratory information decision \n",
      "Cleaned Token After Stem =  group . research lab offic comput scienc artifici intellig laboratori ( csail ) , laboratori inform decis \n",
      "Cleaned Token Before =  developments and technology trends in data science, machine learning, and artificial intelligence\". information. 11 (4): 193. arxiv:2002.04803. doi:10.3390/info11040193\n",
      "Cleaned Token After =  developments technology trends data science , machine learning , artificial intelligence '' . information . 11 ( 4 ) : 193. arxiv:2002.04803. doi:10.3390/info11040193 \n",
      "Cleaned Token After Stem =  develop technolog trend data scienc , machin learn , artifici intellig `` . inform . 11 ( 4 ) : 193. arxiv:2002.04803. doi:10.3390/info11040193 \n",
      "Cleaned Token Before =  joanna bryson is professor at hertie school in berlin. she works on artificial intelligence, ethics and collaborative cognition. she has been a british citizen\n",
      "Cleaned Token After =  joanna bryson professor hertie school berlin . works artificial intelligence , ethics collaborative cognition . british citizen \n",
      "Cleaned Token After Stem =  joanna bryson professor herti school berlin . work artifici intellig , ethic collabor cognit . british citizen \n",
      "Cleaned Token Before =  of poker artificial intelligence and has been the basis of further research such as: \"computer poker: a review\" (pdf). artificial intelligence, department\n",
      "Cleaned Token After =  poker artificial intelligence basis research : `` computer poker : review '' ( pdf ) . artificial intelligence , department \n",
      "Cleaned Token After Stem =  poker artifici intellig basi research : `` comput poker : review `` ( pdf ) . artifici intellig , depart \n",
      "Cleaned Token Before =  and an author of several books. his work on cyber threat intelligence and artificial intelligence has been featured in forbes, the new yorker, slate, the\n",
      "Cleaned Token After =  author several books . work cyber threat intelligence artificial intelligence featured forbes , new yorker , slate , \n",
      "Cleaned Token After Stem =  author sever book . work cyber threat intellig artifici intellig featur forb , new yorker , slate , \n",
      "Cleaned Token Before =  (2007) 28 days later (2002) 28 weeks later (2007) 2012 (2009) a.i. artificial intelligence (2001) æon flux (2005) the animatrix (2003) babylon a.d. (2008)\n",
      "Cleaned Token After =  ( 2007 ) 28 days later ( 2002 ) 28 weeks later ( 2007 ) 2012 ( 2009 ) a.i . artificial intelligence ( 2001 ) æon flux ( 2005 ) animatrix ( 2003 ) babylon a.d. ( 2008 ) \n",
      "Cleaned Token After Stem =  ( 2007 ) 28 day later ( 2002 ) 28 week later ( 2007 ) 2012 ( 2009 ) a.i . artifici intellig ( 2001 ) æon flux ( 2005 ) animatrix ( 2003 ) babylon a.d. ( 2008 ) \n",
      "Cleaned Token Before =  ginsberg and described by ginsberg in an article in the journal of artificial intelligence research. ginsberg claims in that article that dr.fill is among\n",
      "Cleaned Token After =  ginsberg described ginsberg article journal artificial intelligence research . ginsberg claims article dr.fill among \n",
      "Cleaned Token After Stem =  ginsberg describ ginsberg articl journal artifici intellig research . ginsberg claim articl dr.fill among \n",
      "Cleaned Token Before =  in the field of artificial intelligence, neuro-fuzzy refers to combinations of artificial neural networks and fuzzy logic. neuro-fuzzy hybridization results\n",
      "Cleaned Token After =  field artificial intelligence , neuro-fuzzy refers combinations artificial neural networks fuzzy logic . neuro-fuzzy hybridization results \n",
      "Cleaned Token After Stem =  field artifici intellig , neuro-fuzzi refer combin artifici neural network fuzzi logic . neuro-fuzzi hybrid result \n",
      "Cleaned Token Before =  disciplines such as communication, education, psychology, sociology, artificial intelligence, and computer science.[full citation needed] it encompasses several\n",
      "Cleaned Token After =  disciplines communication , education , psychology , sociology , artificial intelligence , computer science . [ full citation needed ] encompasses several \n",
      "Cleaned Token After Stem =  disciplin commun , educ , psycholog , sociolog , artifici intellig , comput scienc . [ full citat need ] encompass sever \n",
      "Cleaned Token Before =  the pioneers of several modern-day scientific domains such as artificial intelligence, information processing, decision-making, problem-solving, organization\n",
      "Cleaned Token After =  pioneers several modern-day scientific domains artificial intelligence , information processing , decision-making , problem-solving , organization \n",
      "Cleaned Token After Stem =  pioneer sever modern-day scientif domain artifici intellig , inform process , decision-mak , problem-solv , organ \n",
      "Cleaned Token Before =  by çalık holding focuses on artificial intelligence fraud prevention. the firm was selected \"best\" artificial intelligence firm at the bitmain & tsmc ai\n",
      "Cleaned Token After =  çalık holding focuses artificial intelligence fraud prevention . firm selected `` best '' artificial intelligence firm bitmain & tsmc ai \n",
      "Cleaned Token After Stem =  çalık hold focus artifici intellig fraud prevent . firm select `` best `` artifici intellig firm bitmain & tsmc ai \n",
      "Cleaned Token Before =  development programs in the pharmaceutical industry. by using artificial intelligence and deep-learning techniques, insilico is able to analyze how a\n",
      "Cleaned Token After =  development programs pharmaceutical industry . using artificial intelligence deep-learning techniques , insilico able analyze \n",
      "Cleaned Token After Stem =  develop program pharmaceut industri . use artifici intellig deep-learn techniqu , insilico abl analyz \n",
      "Cleaned Token Before =  the new world order is a 2018 non-fiction book by kai-fu lee, an artificial intelligence (ai) pioneer, china expert and venture capitalist. lee previously\n",
      "Cleaned Token After =  new world order 2018 non-fiction book kai-fu lee , artificial intelligence ( ai ) pioneer , china expert venture capitalist . lee previously \n",
      "Cleaned Token After Stem =  new world order 2018 non-fict book kai-fu lee , artifici intellig ( ai ) pioneer , china expert ventur capitalist . lee previous \n",
      "Cleaned Token Before =  belief revision is researched in philosophy, in databases, and in artificial intelligence for the design of rational agents. what makes belief revision non-trivial\n",
      "Cleaned Token After =  belief revision researched philosophy , databases , artificial intelligence design rational agents . makes belief revision non-trivial \n",
      "Cleaned Token After Stem =  belief revis research philosophi , databas , artifici intellig design ration agent . make belief revis non-trivi \n",
      "Cleaned Token Before =  inc. of austin, texas, and has been a prominent researcher in artificial intelligence; he was awarded the biannual ijcai computers and thought award\n",
      "Cleaned Token After =  inc. austin , texas , prominent researcher artificial intelligence ; awarded biannual ijcai computers thought award \n",
      "Cleaned Token After Stem =  inc. austin , texa , promin research artifici intellig ; award biannual ijcai comput thought award \n",
      "Cleaned Token Before =  students in the predecessor course at stanford, introduction to artificial intelligence, and 90,000 students had enrolled in the initial two classes as\n",
      "Cleaned Token After =  students predecessor course stanford , introduction artificial intelligence , 90,000 students enrolled initial two classes \n",
      "Cleaned Token After Stem =  student predecessor cours stanford , introduct artifici intellig , 90,000 student enrol initi two class \n",
      "Cleaned Token Before =  replacement intelligent digital assistant youth) is a fictional artificial intelligence appearing in american comic books published by marvel comics, usually\n",
      "Cleaned Token After =  replacement intelligent digital assistant youth ) fictional artificial intelligence appearing american comic books published marvel comics , usually \n",
      "Cleaned Token After Stem =  replac intellig digit assist youth ) fiction artifici intellig appear american comic book publish marvel comic , usual \n",
      "Cleaned Token Before =  occurred and title holders follows. researchers have been applying artificial intelligence techniques on playing gomoku for several decades. in 1994, l. victor\n",
      "Cleaned Token After =  occurred title holders follows . researchers applying artificial intelligence techniques playing gomoku several decades . 1994 , l. victor \n",
      "Cleaned Token After Stem =  occur titl holder follow . research appli artifici intellig techniqu play gomoku sever decad . 1994 , l. victor \n",
      "Cleaned Token Before =  logic, mathematics, statistics, theoretical computer science, artificial intelligence, information theory, game theory, systems theory, decision theory\n",
      "Cleaned Token After =  logic , mathematics , statistics , theoretical computer science , artificial intelligence , information theory , game theory , systems theory , decision theory \n",
      "Cleaned Token After Stem =  logic , mathemat , statist , theoret comput scienc , artifici intellig , inform theori , game theori , system theori , decis theori \n",
      "Cleaned Token Before =  philosopher and researcher on artificial intelligence and cognitive science. he held the chair in artificial intelligence and cognitive science at the\n",
      "Cleaned Token After =  philosopher researcher artificial intelligence cognitive science . held chair artificial intelligence cognitive science \n",
      "Cleaned Token After Stem =  philosoph research artifici intellig cognit scienc . held chair artifici intellig cognit scienc \n",
      "Cleaned Token Before =  rosenblatt's perceptron principles. some researchers have tested artificial intelligence systems using the database put under random distortions. the systems\n",
      "Cleaned Token After =  rosenblatt 's perceptron principles . researchers tested artificial intelligence systems using database put random distortions . systems \n",
      "Cleaned Token After Stem =  rosenblatt 's perceptron principl . research test artifici intellig system use databas put random distort . system \n",
      "Cleaned Token Before =  opposition research and political campaigns using social media and artificial intelligence such as psy-group, cambridge analytica and black cube. the atlantic\n",
      "Cleaned Token After =  opposition research political campaigns using social media artificial intelligence psy-group , cambridge analytica black cube . atlantic \n",
      "Cleaned Token After Stem =  opposit research polit campaign use social media artifici intellig psy-group , cambridg analytica black cube . atlant \n",
      "Cleaned Token Before =  including videos set to, or automatically synchronized to music using artificial intelligence technology. triller was released for ios and android in 2015, and\n",
      "Cleaned Token After =  including videos set , automatically synchronized music using artificial intelligence technology . triller released ios android 2015 , \n",
      "Cleaned Token After Stem =  includ video set , automat synchron music use artifici intellig technolog . triller releas io android 2015 , \n",
      "Cleaned Token Before =  businessman, academic and commentator, working in the field of artificial intelligence (ai), applied technology and ethics. he is the ceo and founder\n",
      "Cleaned Token After =  businessman , academic commentator , working field artificial intelligence ( ai ) , applied technology ethics . ceo founder \n",
      "Cleaned Token After Stem =  businessman , academ comment , work field artifici intellig ( ai ) , appli technolog ethic . ceo founder \n",
      "Cleaned Token Before =  hardik gohel is a computer scientist, academician, artificial intelligence, digital healthcare, cybersecurity, and advanced computing researcher. he is\n",
      "Cleaned Token After =  hardik gohel computer scientist , academician , artificial intelligence , digital healthcare , cybersecurity , advanced computing researcher . \n",
      "Cleaned Token After Stem =  hardik gohel comput scientist , academician , artifici intellig , digit healthcar , cybersecur , advanc comput research . \n",
      "Cleaned Token Before =  artificial intelligence for digital response (aidr) is a free and open source platform to filter and classify social media messages related to emergencies\n",
      "Cleaned Token After =  artificial intelligence digital response ( aidr ) free open source platform filter classify social media messages related emergencies \n",
      "Cleaned Token After Stem =  artifici intellig digit respons ( aidr ) free open sourc platform filter classifi social media messag relat emerg \n",
      "Cleaned Token Before =  technology and former director of the mit computer science and artificial intelligence laboratory. he is a founder and former chief technical officer\n",
      "Cleaned Token After =  technology former director mit computer science artificial intelligence laboratory . founder former chief technical officer \n",
      "Cleaned Token After Stem =  technolog former director mit comput scienc artifici intellig laboratori . founder former chief technic offic \n",
      "Cleaned Token Before =  improves data used for the development of machine learning and artificial intelligence products. data types include speech and natural language data,\n",
      "Cleaned Token After =  improves data used development machine learning artificial intelligence products . data types include speech natural language data , \n",
      "Cleaned Token After Stem =  improv data use develop machin learn artifici intellig product . data type includ speech natur languag data , \n",
      "Cleaned Token Before =  long delays a radio dialogue would suffer, a probe housing an artificial intelligence would seek out an alien civilization to carry on a close-range\n",
      "Cleaned Token After =  long delays radio dialogue would suffer , probe housing artificial intelligence would seek alien civilization carry close-range \n",
      "Cleaned Token After Stem =  long delay radio dialogu would suffer , probe hous artifici intellig would seek alien civil carri close-rang \n",
      "Cleaned Token Before =  about artificial intelligence programming using common lisp. the lisp programming language has survived since 1958 as a primary language for artificial intelligence\n",
      "Cleaned Token After =  artificial intelligence programming using common lisp . lisp programming language survived since 1958 primary language artificial intelligence \n",
      "Cleaned Token After Stem =  artifici intellig program use common lisp . lisp program languag surviv sinc 1958 primari languag artifici intellig \n",
      "Cleaned Token Before =  ai@50, formally known as the \"dartmouth artificial intelligence conference: the next fifty years\" (july 13–15, 2006), was a conference organized by james\n",
      "Cleaned Token After =  ai @ 50 , formally known `` dartmouth artificial intelligence conference : next fifty years '' ( july 13–15 , 2006 ) , conference organized james \n",
      "Cleaned Token After Stem =  ai @ 50 , formal known `` dartmouth artifici intellig confer : next fifti year `` ( juli 13–15 , 2006 ) , confer organ jame \n",
      "Cleaned Token Before =  implications of artificial intelligence, including bias, rights and liberties. she testified before congress on \"artificial intelligence: societal and ethical\n",
      "Cleaned Token After =  implications artificial intelligence , including bias , rights liberties . testified congress `` artificial intelligence : societal ethical \n",
      "Cleaned Token After Stem =  implic artifici intellig , includ bia , right liberti . testifi congress `` artifici intellig : societ ethic \n",
      "Cleaned Token Before =  ether (see scientific community metaphor) were important tools in artificial intelligence research in the 1970s, which influenced commercial developments\n",
      "Cleaned Token After =  ether ( see scientific community metaphor ) important tools artificial intelligence research 1970s , influenced commercial developments \n",
      "Cleaned Token After Stem =  ether ( see scientif commun metaphor ) import tool artifici intellig research 1970 , influenc commerci develop \n",
      "Cleaned Token Before =  dean joined google in mid-1999, and is currently the head of its artificial intelligence division. while at google, he designed and implemented large portions\n",
      "Cleaned Token After =  dean joined google mid-1999 , currently head artificial intelligence division . google , designed implemented large portions \n",
      "Cleaned Token After Stem =  dean join googl mid-1999 , current head artifici intellig divis . googl , design implement larg portion \n",
      "Cleaned Token Before =  driverless car system. thrun was interviewed in the 2018 documentary on artificial intelligence do you trust this computer?.[citation needed] thrun developed a\n",
      "Cleaned Token After =  driverless car system . thrun interviewed 2018 documentary artificial intelligence trust computer ? . [ citation needed ] thrun developed \n",
      "Cleaned Token After Stem =  driverless car system . thrun interview 2018 documentari artifici intellig trust comput ? . [ citat need ] thrun develop \n",
      "Cleaned Token Before =  known as the ark. they are referred to as \"installations\" by their artificial intelligence caretakers, and were created by an ancient race known as the forerunners\n",
      "Cleaned Token After =  known ark . referred `` installations '' artificial intelligence caretakers , created ancient race known forerunners \n",
      "Cleaned Token After Stem =  known ark . refer `` instal `` artifici intellig caretak , creat ancient race known forerunn \n",
      "Cleaned Token Before =  claudio (2004), stochastic models of neural networks, frontiers in artificial intelligence and applications: knowledge-based intelligent engineering systems\n",
      "Cleaned Token After =  claudio ( 2004 ) , stochastic models neural networks , frontiers artificial intelligence applications : knowledge-based intelligent engineering systems \n",
      "Cleaned Token After Stem =  claudio ( 2004 ) , stochast model neural network , frontier artifici intellig applic : knowledge-bas intellig engin system \n",
      "Cleaned Token Before =  orlando and illinois at chicago to explore how researchers might use artificial intelligence, archiving, and computer imaging to create convincing, digital\n",
      "Cleaned Token After =  orlando illinois chicago explore researchers might use artificial intelligence , archiving , computer imaging create convincing , digital \n",
      "Cleaned Token After Stem =  orlando illinoi chicago explor research might use artifici intellig , archiv , comput imag creat convinc , digit \n",
      "Cleaned Token Before =  are uncertain and/or if many outcomes are linked. behavior tree (artificial intelligence, robotics and control) boosting (machine learning) decision cycle\n",
      "Cleaned Token After =  uncertain and/or many outcomes linked . behavior tree ( artificial intelligence , robotics control ) boosting ( machine learning ) decision cycle \n",
      "Cleaned Token After Stem =  uncertain and/or mani outcom link . behavior tree ( artifici intellig , robot control ) boost ( machin learn ) decis cycl \n",
      "Cleaned Token Before =  current trend in industry as well as academia: data science and artificial intelligence. in a timely initiative, iiit dharwad is launching a brand new\n",
      "Cleaned Token After =  current trend industry well academia : data science artificial intelligence . timely initiative , iiit dharwad launching brand new \n",
      "Cleaned Token After Stem =  current trend industri well academia : data scienc artifici intellig . time initi , iiit dharwad launch brand new \n",
      "Cleaned Token Before =  currently the chief executive officer and chief scientist of the artificial intelligence company unanimous ai. his doctoral work at stanford university\n",
      "Cleaned Token After =  currently chief executive officer chief scientist artificial intelligence company unanimous ai . doctoral work stanford university \n",
      "Cleaned Token After Stem =  current chief execut offic chief scientist artifici intellig compani unanim ai . doctor work stanford univers \n",
      "Cleaned Token Before =  of 512 km/h, which is currently impossible for high-speed rail. artificial intelligence will monitor the city and use predictive and data models to figure\n",
      "Cleaned Token After =  512 km/h , currently impossible high-speed rail . artificial intelligence monitor city use predictive data models figure \n",
      "Cleaned Token After Stem =  512 km/h , current imposs high-spe rail . artifici intellig monitor citi use predict data model figur \n",
      "Cleaned Token Before =  districts, strategies and markets. imec performs advanced research on artificial intelligence and was awarded 750.000 usd twice in 2019 by darpa in a machine-learning\n",
      "Cleaned Token After =  districts , strategies markets . imec performs advanced research artificial intelligence awarded 750.000 usd twice 2019 darpa machine-learning \n",
      "Cleaned Token After Stem =  district , strategi market . imec perform advanc research artifici intellig award 750.000 usd twice 2019 darpa machine-learn \n",
      "Cleaned Token Before =  central body's set of instructions or regulation. while classic artificial intelligence (ai) in the 1970s was focused on knowledge-based systems or planning\n",
      "Cleaned Token After =  central body 's set instructions regulation . classic artificial intelligence ( ai ) 1970s focused knowledge-based systems planning \n",
      "Cleaned Token After Stem =  central bodi 's set instruct regul . classic artifici intellig ( ai ) 1970 focus knowledge-bas system plan \n",
      "Cleaned Token Before =  has been proved in literature. recurrent neural networks are recursive artificial neural networks with a certain structure: that of a linear chain. whereas\n",
      "Cleaned Token After =  proved literature . recurrent neural networks recursive artificial neural networks certain structure : linear chain . whereas \n",
      "Cleaned Token After Stem =  prove literatur . recurr neural network recurs artifici neural network certain structur : linear chain . wherea \n",
      "Cleaned Token Before =  properties of ubiquitous computing, including—although not necessarily—artificial intelligence. smart devices can be designed to support a variety of form factors\n",
      "Cleaned Token After =  properties ubiquitous computing , including—although necessarily—artificial intelligence . smart devices designed support variety form factors \n",
      "Cleaned Token After Stem =  properti ubiquit comput , including—although necessarily—artifici intellig . smart devic design support varieti form factor \n",
      "Cleaned Token Before =  minimization\". proceedings of the twenty-eighth aaai conference on artificial intelligence: 1286–1292. s2cid 11017740. milanez-almeida, pedro; martins, andrew\n",
      "Cleaned Token After =  minimization '' . proceedings twenty-eighth aaai conference artificial intelligence : 1286–1292 . s2cid 11017740. milanez-almeida , pedro ; martins , andrew \n",
      "Cleaned Token After Stem =  minim `` . proceed twenty-eighth aaai confer artifici intellig : 1286–1292 . s2cid 11017740. milanez-almeida , pedro ; martin , andrew \n",
      "Cleaned Token Before =  and risk assessments. artificial intelligence (ai) intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and\n",
      "Cleaned Token After =  risk assessments . artificial intelligence ( ai ) intelligence demonstrated machines , contrast natural intelligence displayed humans \n",
      "Cleaned Token After Stem =  risk assess . artifici intellig ( ai ) intellig demonstr machin , contrast natur intellig display human \n",
      "Cleaned Token Before =  the successor to gpt-2) created by openai, a san francisco-based artificial intelligence research laboratory. gpt-3's full version has a capacity of 175\n",
      "Cleaned Token After =  successor gpt-2 ) created openai , san francisco-based artificial intelligence research laboratory . gpt-3 's full version capacity 175 \n",
      "Cleaned Token After Stem =  successor gpt-2 ) creat openai , san francisco-bas artifici intellig research laboratori . gpt-3 's full version capac 175 \n",
      "Cleaned Token Before =  engineered to perform automated reasoning and is called \"the first artificial intelligence program\". it would eventually prove 38 of the first 52 theorems\n",
      "Cleaned Token After =  engineered perform automated reasoning called `` first artificial intelligence program '' . would eventually prove 38 first 52 theorems \n",
      "Cleaned Token After Stem =  engin perform autom reason call `` first artifici intellig program `` . would eventu prove 38 first 52 theorem \n",
      "Cleaned Token Before =  in artificial intelligence, the frame problem describes an issue with using first-order logic to express facts about a robot in the world. representing\n",
      "Cleaned Token After =  artificial intelligence , frame problem describes issue using first-order logic express facts robot world . representing \n",
      "Cleaned Token After Stem =  artifici intellig , frame problem describ issu use first-ord logic express fact robot world . repres \n",
      "Cleaned Token Before =  posts involve long-form discussions of various topics, including artificial intelligence, outer space, and procrastination, using a combination of prose\n",
      "Cleaned Token After =  posts involve long-form discussions various topics , including artificial intelligence , outer space , procrastination , using combination prose \n",
      "Cleaned Token After Stem =  post involv long-form discuss variou topic , includ artifici intellig , outer space , procrastin , use combin prose \n",
      "Cleaned Token Before =  the company's latest version of its cloud software paired with artificial intelligence technology aimed at fixing practical problems. it service management\n",
      "Cleaned Token After =  company 's latest version cloud software paired artificial intelligence technology aimed fixing practical problems . service management \n",
      "Cleaned Token After Stem =  compani 's latest version cloud softwar pair artifici intellig technolog aim fix practic problem . servic manag \n",
      "Cleaned Token Before =  by shahin chandrasoma. it is about the world's first \"perfect\" artificial intelligence (david clayton rogers) that begins to exhibit startling and unnerving\n",
      "Cleaned Token After =  shahin chandrasoma . world 's first `` perfect '' artificial intelligence ( david clayton rogers ) begins exhibit startling unnerving \n",
      "Cleaned Token After Stem =  shahin chandrasoma . world 's first `` perfect `` artifici intellig ( david clayton roger ) begin exhibit startl unnerv \n",
      "Cleaned Token Before =  fields involved in robot ethics are: robotics, computer science, artificial intelligence, philosophy, ethics, theology, biology, physiology, cognitive science\n",
      "Cleaned Token After =  fields involved robot ethics : robotics , computer science , artificial intelligence , philosophy , ethics , theology , biology , physiology , cognitive science \n",
      "Cleaned Token After Stem =  field involv robot ethic : robot , comput scienc , artifici intellig , philosophi , ethic , theolog , biolog , physiolog , cognit scienc \n",
      "Cleaned Token Before =  2020. \"fun stuff\". yann.lecun.com. retrieved march 20, 2020. \"artificial-intelligence pioneers win $1 million turing award\". washington post. metz, cade\n",
      "Cleaned Token After =  2020 . `` fun stuff '' . yann.lecun.com . retrieved march 20 , 2020 . `` artificial-intelligence pioneers win $ 1 million turing award '' . washington post . metz , cade \n",
      "Cleaned Token After Stem =  2020 . `` fun stuff `` . yann.lecun.com . retriev march 20 , 2020 . `` artificial-intellig pioneer win $ 1 million ture award `` . washington post . metz , cade \n",
      "Cleaned Token Before =  leading conference in the area of natural language processing and artificial intelligence. along with the association for computational linguistics (acl)\n",
      "Cleaned Token After =  leading conference area natural language processing artificial intelligence . along association computational linguistics ( acl ) \n",
      "Cleaned Token After Stem =  lead confer area natur languag process artifici intellig . along associ comput linguist ( acl ) \n",
      "Cleaned Token Before =  according to forbes, became the most valuable privately owned artificial intelligence company in history when it was acquired by s&p global for $550\n",
      "Cleaned Token After =  according forbes , became valuable privately owned artificial intelligence company history acquired & p global $ 550 \n",
      "Cleaned Token After Stem =  accord forb , becam valuabl privat own artifici intellig compani histori acquir & p global $ 550 \n",
      "Cleaned Token Before =  international journal on artificial intelligence tools, 10(4):503-523. r. reiter (1980). a logic for default reasoning. artificial intelligence, 13:81-132. t. schaub\n",
      "Cleaned Token After =  international journal artificial intelligence tools , 10 ( 4 ) :503-523. r. reiter ( 1980 ) . logic default reasoning . artificial intelligence , 13:81-132. t. schaub \n",
      "Cleaned Token After Stem =  intern journal artifici intellig tool , 10 ( 4 ) :503-523. r. reiter ( 1980 ) . logic default reason . artifici intellig , 13:81-132. t. schaub \n",
      "Cleaned Token Before =  journal on artificial intelligence tools was founded in 1992 and is published by world scientific. it covers research on artificial intelligence (ai) tools\n",
      "Cleaned Token After =  journal artificial intelligence tools founded 1992 published world scientific . covers research artificial intelligence ( ai ) tools \n",
      "Cleaned Token After Stem =  journal artifici intellig tool found 1992 publish world scientif . cover research artifici intellig ( ai ) tool \n",
      "Cleaned Token Before =  memory encryption, an amd technology structure mapping engine, in artificial intelligence and cognitive science signal meta under eclipse, in the signal\n",
      "Cleaned Token After =  memory encryption , amd technology structure mapping engine , artificial intelligence cognitive science signal meta eclipse , signal \n",
      "Cleaned Token After Stem =  memori encrypt , amd technolog structur map engin , artifici intellig cognit scienc signal meta eclips , signal \n",
      "Cleaned Token Before =  detection, fleet tracking, and driver safety programs that use artificial intelligence and analysts to identify risky driving behaviors and report real-time\n",
      "Cleaned Token After =  detection , fleet tracking , driver safety programs use artificial intelligence analysts identify risky driving behaviors report real-time \n",
      "Cleaned Token After Stem =  detect , fleet track , driver safeti program use artifici intellig analyst identifi riski drive behavior report real-tim \n",
      "Cleaned Token Before =  \"machine super intelligence\" was completed in 2008. he was awarded the $10,000 canadian singularity institute for artificial intelligence prize. legg's\n",
      "Cleaned Token After =  `` machine super intelligence '' completed 2008. awarded $ 10,000 canadian singularity institute artificial intelligence prize . legg 's \n",
      "Cleaned Token After Stem =  `` machin super intellig `` complet 2008. award $ 10,000 canadian singular institut artifici intellig prize . legg 's \n",
      "Cleaned Token Before =  international conference on artificial intelligence (micai) is the name of an annual conference covering all areas of artificial intelligence (ai), held in mexico\n",
      "Cleaned Token After =  international conference artificial intelligence ( micai ) name annual conference covering areas artificial intelligence ( ai ) , held mexico \n",
      "Cleaned Token After Stem =  intern confer artifici intellig ( micai ) name annual confer cover area artifici intellig ( ai ) , held mexico \n",
      "Cleaned Token Before =  antworks is an artificial intelligence (ai) and intelligent automation company based in singapore. the company was co-founded by asheesh mehra and govind\n",
      "Cleaned Token After =  antworks artificial intelligence ( ai ) intelligent automation company based singapore . company co-founded asheesh mehra govind \n",
      "Cleaned Token After Stem =  antwork artifici intellig ( ai ) intellig autom compani base singapor . compani co-found asheesh mehra govind \n",
      "Cleaned Token Before =  satisfaction methods. csps are the subject of intense research in both artificial intelligence and operations research, since the regularity in their formulation\n",
      "Cleaned Token After =  satisfaction methods . csps subject intense research artificial intelligence operations research , since regularity formulation \n",
      "Cleaned Token After Stem =  satisfact method . csp subject intens research artifici intellig oper research , sinc regular formul \n",
      "Cleaned Token Before =  2019. \"artificial intelligence enters the history of art\". december 28, 2018. tom février (february 17, 2019). \"le scandale de l'intelligence artificielle\"\n",
      "Cleaned Token After =  2019 . `` artificial intelligence enters history art '' . december 28 , 2018. tom février ( february 17 , 2019 ) . `` le scandale de l'intelligence artificielle '' \n",
      "Cleaned Token After Stem =  2019 . `` artifici intellig enter histori art `` . decemb 28 , 2018. tom février ( februari 17 , 2019 ) . `` le scandal de l'intellig artificiel `` \n",
      "Cleaned Token Before =  league and the indian arena polo league. in 2019 he introduced an artificial intelligence voice assistant to the newsx studios; the newsx ai is claimed as\n",
      "Cleaned Token After =  league indian arena polo league . 2019 introduced artificial intelligence voice assistant newsx studios ; newsx ai claimed \n",
      "Cleaned Token After Stem =  leagu indian arena polo leagu . 2019 introduc artifici intellig voic assist newsx studio ; newsx ai claim \n",
      "Cleaned Token Before =  (314). victor allis (1994). searching for solutions in games and artificial intelligence (pdf). ph.d. thesis, university of limburg, maastricht, the netherlands\n",
      "Cleaned Token After =  ( 314 ) . victor allis ( 1994 ) . searching solutions games artificial intelligence ( pdf ) . ph.d. thesis , university limburg , maastricht , netherlands \n",
      "Cleaned Token After Stem =  ( 314 ) . victor alli ( 1994 ) . search solut game artifici intellig ( pdf ) . ph.d. thesi , univers limburg , maastricht , netherland \n",
      "Cleaned Token Before =  term was first defined by nick bostrom. an artificial general intelligence having undergone an intelligence explosion could form a singleton, as could\n",
      "Cleaned Token After =  term first defined nick bostrom . artificial general intelligence undergone intelligence explosion could form singleton , could \n",
      "Cleaned Token After Stem =  term first defin nick bostrom . artifici gener intellig undergon intellig explos could form singleton , could \n",
      "Cleaned Token Before =  david hanson, known for its development of human-like robots with artificial intelligence (ai) for consumer, entertainment, service, healthcare, and research\n",
      "Cleaned Token After =  david hanson , known development human-like robots artificial intelligence ( ai ) consumer , entertainment , service , healthcare , research \n",
      "Cleaned Token After Stem =  david hanson , known develop human-lik robot artifici intellig ( ai ) consum , entertain , servic , healthcar , research \n",
      "Cleaned Token Before =  fractal analytics is a multinational artificial intelligence company that provides services in consumer packaged goods, insurance, healthcare, life sciences\n",
      "Cleaned Token After =  fractal analytics multinational artificial intelligence company provides services consumer packaged goods , insurance , healthcare , life sciences \n",
      "Cleaned Token After Stem =  fractal analyt multin artifici intellig compani provid servic consum packag good , insur , healthcar , life scienc \n",
      "Cleaned Token Before =  washington mesa world affairs council of seattle allen institute for artificial intelligence (ai2) northeastern university - seattle campus pacific northwest\n",
      "Cleaned Token After =  washington mesa world affairs council seattle allen institute artificial intelligence ( ai2 ) northeastern university - seattle campus pacific northwest \n",
      "Cleaned Token After Stem =  washington mesa world affair council seattl allen institut artifici intellig ( ai2 ) northeastern univers - seattl campu pacif northwest \n",
      "Cleaned Token Before =  technology and security architecture; (5) artificial intelligence, cognitive science, neuroscience, robotics and artificial creativity; (6) traditional science\n",
      "Cleaned Token After =  technology security architecture ; ( 5 ) artificial intelligence , cognitive science , neuroscience , robotics artificial creativity ; ( 6 ) traditional science \n",
      "Cleaned Token After Stem =  technolog secur architectur ; ( 5 ) artifici intellig , cognit scienc , neurosci , robot artifici creativ ; ( 6 ) tradit scienc \n",
      "Cleaned Token Before =  do. to solve this issue, the system relies on certain rules or artificial intelligence to select the most appropriate shots. there are mainly three types\n",
      "Cleaned Token After =  . solve issue , system relies certain rules artificial intelligence select appropriate shots . mainly three types \n",
      "Cleaned Token After Stem =  . solv issu , system reli certain rule artifici intellig select appropri shot . mainli three type \n",
      "Cleaned Token Before =  the deployable machine learning model. automl was proposed as an artificial intelligence-based solution to the ever-growing challenge of applying machine\n",
      "Cleaned Token After =  deployable machine learning model . automl proposed artificial intelligence-based solution ever-growing challenge applying machine \n",
      "Cleaned Token After Stem =  deploy machin learn model . automl propos artifici intelligence-bas solut ever-grow challeng appli machin \n",
      "Cleaned Token Before =  meaning, so that mapping and navigation become possible. — mit artificial intelligence laboratory information spaces surround us. when we retrieve a file\n",
      "Cleaned Token After =  meaning , mapping navigation become possible . — mit artificial intelligence laboratory information spaces surround us . retrieve file \n",
      "Cleaned Token After Stem =  mean , map navig becom possibl . — mit artifici intellig laboratori inform space surround us . retriev file \n",
      "Cleaned Token Before =  cycl in computer science and artificial intelligence is an ontology language used by doug lenat's cyc artificial intelligence project. ramanathan v. guha\n",
      "Cleaned Token After =  cycl computer science artificial intelligence ontology language used doug lenat 's cyc artificial intelligence project . ramanathan v. guha \n",
      "Cleaned Token After Stem =  cycl comput scienc artifici intellig ontolog languag use doug lenat 's cyc artifici intellig project . ramanathan v. guha \n",
      "Cleaned Token Before =  has evolved to be able to interface with the human brain, making artificial intelligence and cyber-brains indistinguishable from organic brains. the protagonist\n",
      "Cleaned Token After =  evolved able interface human brain , making artificial intelligence cyber-brains indistinguishable organic brains . protagonist \n",
      "Cleaned Token After Stem =  evolv abl interfac human brain , make artifici intellig cyber-brain indistinguish organ brain . protagonist \n",
      "Cleaned Token Before =  roger carl schank (born 1946) is an american artificial intelligence theorist, cognitive psychologist, learning scientist, educational reformer, and entrepreneur\n",
      "Cleaned Token After =  roger carl schank ( born 1946 ) american artificial intelligence theorist , cognitive psychologist , learning scientist , educational reformer , entrepreneur \n",
      "Cleaned Token After Stem =  roger carl schank ( born 1946 ) american artifici intellig theorist , cognit psychologist , learn scientist , educ reform , entrepreneur \n",
      "Cleaned Token Before =  category was awarded for the first time in 2007. the trophy for \"best artificial intelligence implementation of death stacks\" was awarded (in absentia) to an\n",
      "Cleaned Token After =  category awarded first time 2007. trophy `` best artificial intelligence implementation death stacks '' awarded ( absentia ) \n",
      "Cleaned Token After Stem =  categori award first time 2007. trophi `` best artifici intellig implement death stack `` award ( absentia ) \n",
      "Cleaned Token Before =   this is an example of anthropomorphism: in reality, while an artificial intelligence could perhaps be deliberately programmed with human emotions, or\n",
      "Cleaned Token After =  example anthropomorphism : reality , artificial intelligence could perhaps deliberately programmed human emotions , \n",
      "Cleaned Token After Stem =  exampl anthropomorph : realiti , artifici intellig could perhap deliber program human emot , \n",
      "Cleaned Token Before =  approaches used were developed within the then-nascent fields of artificial intelligence, computer science, and neuroscience. in the 1960s, the harvard\n",
      "Cleaned Token After =  approaches used developed within then-nascent fields artificial intelligence , computer science , neuroscience . 1960s , harvard \n",
      "Cleaned Token After Stem =  approach use develop within then-nasc field artifici intellig , comput scienc , neurosci . 1960 , harvard \n",
      "Cleaned Token Before =  jourgensen and ministry appeared in the 2001 steven spielberg film a.i. artificial intelligence. in 2005, jourgensen established his own record label, 13th planet\n",
      "Cleaned Token After =  jourgensen ministry appeared 2001 steven spielberg film a.i . artificial intelligence . 2005 , jourgensen established record label , 13th planet \n",
      "Cleaned Token After Stem =  jourgensen ministri appear 2001 steven spielberg film a.i . artifici intellig . 2005 , jourgensen establish record label , 13th planet \n",
      "Cleaned Token Before =  global exchange. in may 2019, it released appian ai, enabling artificial intelligence capabilities on its platform. on january 7, 2020, it announced\n",
      "Cleaned Token After =  global exchange . may 2019 , released appian ai , enabling artificial intelligence capabilities platform . january 7 , 2020 , announced \n",
      "Cleaned Token After Stem =  global exchang . may 2019 , releas appian ai , enabl artifici intellig capabl platform . januari 7 , 2020 , announc \n",
      "Cleaned Token Before =  attempt, she embarks on a journey to stop a cult that worships an artificial intelligence bent on the world's destruction, while also hunting machines that\n",
      "Cleaned Token After =  attempt , embarks journey stop cult worships artificial intelligence bent world 's destruction , also hunting machines \n",
      "Cleaned Token After Stem =  attempt , embark journey stop cult worship artifici intellig bent world 's destruct , also hunt machin \n",
      "Cleaned Token Before =  film alphaville (1965) posited a futuristic paris commanded by an artificial intelligence which has outlawed all emotion. the era of manned trips to the\n",
      "Cleaned Token After =  film alphaville ( 1965 ) posited futuristic paris commanded artificial intelligence outlawed emotion . era manned trips \n",
      "Cleaned Token After Stem =  film alphavil ( 1965 ) posit futurist pari command artifici intellig outlaw emot . era man trip \n",
      "Cleaned Token Before =  systems. since its inception, lisp was closely connected with the artificial intelligence (ai) research community, especially on pdp-10. the 36-bit word\n",
      "Cleaned Token After =  systems . since inception , lisp closely connected artificial intelligence ( ai ) research community , especially pdp-10 . 36-bit word \n",
      "Cleaned Token After Stem =  system . sinc incept , lisp close connect artifici intellig ( ai ) research commun , especi pdp-10 . 36-bit word \n",
      "Cleaned Token Before =  and entrepreneur who has authored several papers in the area of artificial intelligence. batra co-founded thrive financial, inc. in 2017 to provide financial\n",
      "Cleaned Token After =  entrepreneur authored several papers area artificial intelligence . batra co-founded thrive financial , inc. 2017 provide financial \n",
      "Cleaned Token After Stem =  entrepreneur author sever paper area artifici intellig . batra co-found thrive financi , inc. 2017 provid financi \n",
      "Cleaned Token Before =  on artificial culture and culture evolution. welt am draht (1973) the thirteenth floor (1999) android humanoid intelligence artificial intelligence culture\n",
      "Cleaned Token After =  artificial culture culture evolution . welt draht ( 1973 ) thirteenth floor ( 1999 ) android humanoid intelligence artificial intelligence culture \n",
      "Cleaned Token After Stem =  artifici cultur cultur evolut . welt draht ( 1973 ) thirteenth floor ( 1999 ) android humanoid intellig artifici intellig cultur \n",
      "Cleaned Token Before =  intelligence, collective intelligence, and also artificial intelligence within the city. the intelligence of cities \"resides in the increasingly effective\n",
      "Cleaned Token After =  intelligence , collective intelligence , also artificial intelligence within city . intelligence cities `` resides increasingly effective \n",
      "Cleaned Token After Stem =  intellig , collect intellig , also artifici intellig within citi . intellig citi `` resid increasingli effect \n",
      "Cleaned Token Before =  machine intelligence may refer to: artificial intelligence, intelligence exhibited by machines machine learning, giving computers the ability to learn\n",
      "Cleaned Token After =  machine intelligence may refer : artificial intelligence , intelligence exhibited machines machine learning , giving computers ability learn \n",
      "Cleaned Token After Stem =  machin intellig may refer : artifici intellig , intellig exhibit machin machin learn , give comput abil learn \n",
      "Cleaned Token Before =  top young scientist for his award-winning tool which harnesses artificial intelligence to improve radiotherapy for pancreatic cancer patients. jain's\n",
      "Cleaned Token After =  top young scientist award-winning tool harnesses artificial intelligence improve radiotherapy pancreatic cancer patients . jain 's \n",
      "Cleaned Token After Stem =  top young scientist award-win tool har artifici intellig improv radiotherapi pancreat cancer patient . jain 's \n",
      "Cleaned Token Before =  knowledge-based configuration is a major application area for artificial intelligence (ai), and it is based on modelling of the configurations in a manner\n",
      "Cleaned Token After =  knowledge-based configuration major application area artificial intelligence ( ai ) , based modelling configurations manner \n",
      "Cleaned Token After Stem =  knowledge-bas configur major applic area artifici intellig ( ai ) , base model configur manner \n",
      "Cleaned Token Before =  botmaster of a.l.i.c.e. (artificial linguistic internet computer entity). he is also the founder of the a.l.i.c.e artificial intelligence foundation. dr. wallace's\n",
      "Cleaned Token After =  botmaster a.l.i.c.e . ( artificial linguistic internet computer entity ) . also founder a.l.i.c.e artificial intelligence foundation . dr. wallace 's \n",
      "Cleaned Token After Stem =  botmast a.l.i.c. . ( artifici linguist internet comput entiti ) . also founder a.l.i.c. artifici intellig foundat . dr. wallac 's \n",
      "Cleaned Token Before =  xu li is a co-founder and current ceo of sensetime, an artificial intelligence (ai) company. xu has led sensetime since the company’s incorporation and\n",
      "Cleaned Token After =  xu li co-founder current ceo sensetime , artificial intelligence ( ai ) company . xu led sensetime since company ’ incorporation \n",
      "Cleaned Token After Stem =  xu li co-found current ceo sensetim , artifici intellig ( ai ) compani . xu led sensetim sinc compani ’ incorpor \n",
      "Cleaned Token Before =  unmanned store concept relies on smartphone-related technologies and artificial intelligence to remove the traditional features of a store. in 2012, the cisco\n",
      "Cleaned Token After =  unmanned store concept relies smartphone-related technologies artificial intelligence remove traditional features store . 2012 , cisco \n",
      "Cleaned Token After Stem =  unman store concept reli smartphone-rel technolog artifici intellig remov tradit featur store . 2012 , cisco \n",
      "Cleaned Token Before =  technologies outline of artificial intelligence chen, s.k; chang, y.h (2014). 2014 international conference on artificial intelligence and software engineering\n",
      "Cleaned Token After =  technologies outline artificial intelligence chen , s.k ; chang , y.h ( 2014 ) . 2014 international conference artificial intelligence software engineering \n",
      "Cleaned Token After Stem =  technolog outlin artifici intellig chen , s.k ; chang , y.h ( 2014 ) . 2014 intern confer artifici intellig softwar engin \n",
      "Cleaned Token Before =  focuses on the social implications of new technologies, such as artificial intelligence and big data, as well as societal challenges such as the covid-19\n",
      "Cleaned Token After =  focuses social implications new technologies , artificial intelligence big data , well societal challenges covid-19 \n",
      "Cleaned Token After Stem =  focus social implic new technolog , artifici intellig big data , well societ challeng covid-19 \n",
      "Cleaned Token Before =  the emotion machine: commonsense thinking, artificial intelligence, and the future of the human mind is a 2006 book by cognitive scientist marvin minsky\n",
      "Cleaned Token After =  emotion machine : commonsense thinking , artificial intelligence , future human mind 2006 book cognitive scientist marvin minsky \n",
      "Cleaned Token After Stem =  emot machin : commonsens think , artifici intellig , futur human mind 2006 book cognit scientist marvin minski \n",
      "Cleaned Token Before =   \"stochastic discrimination\" (pdf). annals of mathematics and artificial intelligence. 1 (1–4): 207–239. citeseerx 10.1.1.25.6750. doi:10.1007/bf01531079\n",
      "Cleaned Token After =  `` stochastic discrimination '' ( pdf ) . annals mathematics artificial intelligence . 1 ( 1–4 ) : 207–239 . citeseerx 10.1.1.25.6750. doi:10.1007/bf01531079 \n",
      "Cleaned Token After Stem =  `` stochast discrimin `` ( pdf ) . annal mathemat artifici intellig . 1 ( 1–4 ) : 207–239 . citeseerx 10.1.1.25.6750. doi:10.1007/bf01531079 \n",
      "Cleaned Token Before =  mit including; the mit media lab, the mit computer science and artificial intelligence laboratory, the department of brain and cognitive sciences, and\n",
      "Cleaned Token After =  mit including ; mit media lab , mit computer science artificial intelligence laboratory , department brain cognitive sciences , \n",
      "Cleaned Token After Stem =  mit includ ; mit media lab , mit comput scienc artifici intellig laboratori , depart brain cognit scienc , \n",
      "Cleaned Token Before =  system in virtual environment) is a high-end computer animation and artificial intelligence software package used for generating crowd-related visual effects\n",
      "Cleaned Token After =  system virtual environment ) high-end computer animation artificial intelligence software package used generating crowd-related visual effects \n",
      "Cleaned Token After Stem =  system virtual environ ) high-end comput anim artifici intellig softwar packag use gener crowd-rel visual effect \n",
      "Cleaned Token Before =  in artificial intelligence (ai), commonsense reasoning is a human-like ability to make presumptions about the type and essence of ordinary situations\n",
      "Cleaned Token After =  artificial intelligence ( ai ) , commonsense reasoning human-like ability make presumptions type essence ordinary situations \n",
      "Cleaned Token After Stem =  artifici intellig ( ai ) , commonsens reason human-lik abil make presumpt type essenc ordinari situat \n",
      "Cleaned Token Before =  hired for one last job, which brings him up against a powerful artificial intelligence. before neuromancer, gibson had written several short stories for\n",
      "Cleaned Token After =  hired one last job , brings powerful artificial intelligence . neuromancer , gibson written several short stories \n",
      "Cleaned Token After Stem =  hire one last job , bring power artifici intellig . neuromanc , gibson written sever short stori \n",
      "Cleaned Token Before =  garry kasparov in the 1997 match, the strongest go programs using artificial intelligence techniques only reached about amateur 5-dan level, and still could\n",
      "Cleaned Token After =  garry kasparov 1997 match , strongest go programs using artificial intelligence techniques reached amateur 5-dan level , still could \n",
      "Cleaned Token After Stem =  garri kasparov 1997 match , strongest go program use artifici intellig techniqu reach amateur 5-dan level , still could \n",
      "Cleaned Token Before =  detection fall into two primary classes: statistical techniques and artificial intelligence. examples of statistical data analysis techniques are: data preprocessing\n",
      "Cleaned Token After =  detection fall two primary classes : statistical techniques artificial intelligence . examples statistical data analysis techniques : data preprocessing \n",
      "Cleaned Token After Stem =  detect fall two primari class : statist techniqu artifici intellig . exampl statist data analysi techniqu : data preprocess \n",
      "Cleaned Token Before =  seen as defeasible. efforts have been made within the field of artificial intelligence to perform and analyze the act of argumentation with computers\n",
      "Cleaned Token After =  seen defeasible . efforts made within field artificial intelligence perform analyze act argumentation computers \n",
      "Cleaned Token After Stem =  seen defeas . effort made within field artifici intellig perform analyz act argument comput \n",
      "Cleaned Token Before =  partitioning\". proceedings of the 14th international joint conference on artificial intelligence - volume 1. ijcai'95. montreal, quebec, canada: morgan kaufmann\n",
      "Cleaned Token After =  partitioning '' . proceedings 14th international joint conference artificial intelligence - volume 1. ijcai'95 . montreal , quebec , canada : morgan kaufmann \n",
      "Cleaned Token After Stem =  partit `` . proceed 14th intern joint confer artifici intellig - volum 1. ijcai'95 . montreal , quebec , canada : morgan kaufmann \n",
      "Cleaned Token Before =  computational difficulty of finding optimal strategies. research in artificial intelligence has addressed both perfect and imperfect information games that\n",
      "Cleaned Token After =  computational difficulty finding optimal strategies . research artificial intelligence addressed perfect imperfect information games \n",
      "Cleaned Token After Stem =  comput difficulti find optim strategi . research artifici intellig address perfect imperfect inform game \n",
      "Cleaned Token Before =  that they do not possess. he believes the relevant danger from artificial intelligence (ai) is that people will misunderstand the nature of basically\n",
      "Cleaned Token After =  possess . believes relevant danger artificial intelligence ( ai ) people misunderstand nature basically \n",
      "Cleaned Token After Stem =  possess . believ relev danger artifici intellig ( ai ) peopl misunderstand natur basic \n",
      "Cleaned Token Before =  in the study of path-finding problems in artificial intelligence, a heuristic function is said to be consistent, or monotone, if its estimate is always\n",
      "Cleaned Token After =  study path-finding problems artificial intelligence , heuristic function said consistent , monotone , estimate always \n",
      "Cleaned Token After Stem =  studi path-find problem artifici intellig , heurist function said consist , monoton , estim alway \n",
      "Cleaned Token Before =  artificial intelligence, and natural language processing and did research with professor andrew ng, director of the stanford artificial intelligence lab\n",
      "Cleaned Token After =  artificial intelligence , natural language processing research professor andrew ng , director stanford artificial intelligence lab \n",
      "Cleaned Token After Stem =  artifici intellig , natur languag process research professor andrew ng , director stanford artifici intellig lab \n",
      "Cleaned Token Before =  the \"thunderhead\" controls society. the thunderhead is a form of artificial intelligence who does not make mistakes or have regrets. however, the thunderhead\n",
      "Cleaned Token After =  `` thunderhead '' controls society . thunderhead form artificial intelligence make mistakes regrets . however , thunderhead \n",
      "Cleaned Token After Stem =  `` thunderhead `` control societi . thunderhead form artifici intellig make mistak regret . howev , thunderhead \n",
      "Cleaned Token Before =  professor of computer science, and ceo of the allen institute for artificial intelligence. he joined the university of washington faculty in 1991, where\n",
      "Cleaned Token After =  professor computer science , ceo allen institute artificial intelligence . joined university washington faculty 1991 , \n",
      "Cleaned Token After Stem =  professor comput scienc , ceo allen institut artifici intellig . join univers washington faculti 1991 , \n",
      "Cleaned Token Before =  balance\". it was created by researchers at the allen institute for artificial intelligence and university of washington. peters me, neumann m, iyyer m, gardner\n",
      "Cleaned Token After =  balance '' . created researchers allen institute artificial intelligence university washington . peters , neumann , iyyer , gardner \n",
      "Cleaned Token After Stem =  balanc `` . creat research allen institut artifici intellig univers washington . peter , neumann , iyyer , gardner \n",
      "Cleaned Token Before =  translation researcher from harvard university alan perlis, an artificial intelligence researcher from carnegie institute of technology testimony was\n",
      "Cleaned Token After =  translation researcher harvard university alan perlis , artificial intelligence researcher carnegie institute technology testimony \n",
      "Cleaned Token After Stem =  translat research harvard univers alan perli , artifici intellig research carnegi institut technolog testimoni \n",
      "Cleaned Token Before =  interdisciplinary approach and includes studies of non-human subjects and artificial intelligence. philosophically, ruminations of the human mind and its processes\n",
      "Cleaned Token After =  interdisciplinary approach includes studies non-human subjects artificial intelligence . philosophically , ruminations human mind processes \n",
      "Cleaned Token After Stem =  interdisciplinari approach includ studi non-human subject artifici intellig . philosoph , rumin human mind process \n",
      "Cleaned Token Before =  chapter discusses the use of causal reasoning in big data and artificial intelligence and the philosophical problem of free will. the authors claim that\n",
      "Cleaned Token After =  chapter discusses use causal reasoning big data artificial intelligence philosophical problem free . authors claim \n",
      "Cleaned Token After Stem =  chapter discuss use causal reason big data artifici intellig philosoph problem free . author claim \n",
      "Cleaned Token Before =  meant to be played with another human as a partner, a \"partner artificial intelligence\" (pai) is also included and programmed to follow the player's strategies\n",
      "Cleaned Token After =  meant played another human partner , `` partner artificial intelligence '' ( pai ) also included programmed follow player 's strategies \n",
      "Cleaned Token After Stem =  meant play anoth human partner , `` partner artifici intellig `` ( pai ) also includ program follow player 's strategi \n",
      "Cleaned Token Before =  eighth national conference on artificial intelligence, 1990. j. de kleer (1986). an assumption-based tms. artificial intelligence, 28:127–162. j. doyle. a\n",
      "Cleaned Token After =  eighth national conference artificial intelligence , 1990. j. de kleer ( 1986 ) . assumption-based tms . artificial intelligence , 28:127–162 . j. doyle . \n",
      "Cleaned Token After Stem =  eighth nation confer artifici intellig , 1990. j. de kleer ( 1986 ) . assumption-bas tm . artifici intellig , 28:127–162 . j. doyl . \n",
      "Cleaned Token Before =  held software company, providing website building, ecommerce, and artificial intelligence solutions to consumers. it’s a drag-and-drop platform that allows\n",
      "Cleaned Token After =  held software company , providing website building , ecommerce , artificial intelligence solutions consumers . ’ drag-and-drop platform allows \n",
      "Cleaned Token After Stem =  held softwar compani , provid websit build , ecommerc , artifici intellig solut consum . ’ drag-and-drop platform allow \n",
      "Cleaned Token Before =  physical reality with virtual reality (vr) and human intelligence with artificial intelligence (ai). individuals may find themselves, for different reasons\n",
      "Cleaned Token After =  physical reality virtual reality ( vr ) human intelligence artificial intelligence ( ai ) . individuals may find , different reasons \n",
      "Cleaned Token After Stem =  physic realiti virtual realiti ( vr ) human intellig artifici intellig ( ai ) . individu may find , differ reason \n",
      "Cleaned Token Before =  he is a fellow of the aaai (association for the advancement of artificial intelligence) and well known for his work in machine learning and bioinformatics\n",
      "Cleaned Token After =  fellow aaai ( association advancement artificial intelligence ) well known work machine learning bioinformatics \n",
      "Cleaned Token After Stem =  fellow aaai ( associ advanc artifici intellig ) well known work machin learn bioinformat \n",
      "Cleaned Token Before =  processing computer program created from 1964 to 1966 at the mit artificial intelligence laboratory by joseph weizenbaum. created to demonstrate the superficiality\n",
      "Cleaned Token After =  processing computer program created 1964 1966 mit artificial intelligence laboratory joseph weizenbaum . created demonstrate superficiality \n",
      "Cleaned Token After Stem =  process comput program creat 1964 1966 mit artifici intellig laboratori joseph weizenbaum . creat demonstr superfici \n",
      "Cleaned Token Before =  in artificial intelligence, model-based reasoning refers to an inference method used in expert systems based on a model of the physical world. with this\n",
      "Cleaned Token After =  artificial intelligence , model-based reasoning refers inference method used expert systems based model physical world . \n",
      "Cleaned Token After Stem =  artifici intellig , model-bas reason refer infer method use expert system base model physic world . \n",
      "Cleaned Token Before =  scientist who made significant contributions in several areas of artificial intelligence, including constraint satisfaction, case-based reasoning and the\n",
      "Cleaned Token After =  scientist made significant contributions several areas artificial intelligence , including constraint satisfaction , case-based reasoning \n",
      "Cleaned Token After Stem =  scientist made signific contribut sever area artifici intellig , includ constraint satisfact , case-bas reason \n",
      "Cleaned Token Before =   berkeley and researcher in machine learning, statistics, and artificial intelligence. he is one of the leading figures in machine learning, and in 2016\n",
      "Cleaned Token After =  berkeley researcher machine learning , statistics , artificial intelligence . one leading figures machine learning , 2016 \n",
      "Cleaned Token After Stem =  berkeley research machin learn , statist , artifici intellig . one lead figur machin learn , 2016 \n",
      "Cleaned Token Before =  processing (nlp) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language\n",
      "Cleaned Token After =  processing ( nlp ) subfield linguistics , computer science , artificial intelligence concerned interactions computers human language \n",
      "Cleaned Token After Stem =  process ( nlp ) subfield linguist , comput scienc , artifici intellig concern interact comput human languag \n",
      "Cleaned Token Before =  \"surely a better phrase than 'theorem proving', for the branch of artificial intelligence which deals with how to make machines do deduction efficiently\"\n",
      "Cleaned Token After =  `` surely better phrase 'theorem proving ' , branch artificial intelligence deals make machines deduction efficiently '' \n",
      "Cleaned Token After Stem =  `` sure better phrase 'theorem prove ' , branch artifici intellig deal make machin deduct effici `` \n",
      "Cleaned Token Before =  available for vulkan. in addition to ray tracing, rtx includes artificial intelligence integration, common asset formats, rasterization (cuda) support\n",
      "Cleaned Token After =  available vulkan . addition ray tracing , rtx includes artificial intelligence integration , common asset formats , rasterization ( cuda ) support \n",
      "Cleaned Token After Stem =  avail vulkan . addit ray trace , rtx includ artifici intellig integr , common asset format , raster ( cuda ) support \n",
      "Cleaned Token Before =  the high level advisory committee to the spanish government on artificial intelligence and big data. she is also a member of the strategic advisory board\n",
      "Cleaned Token After =  high level advisory committee spanish government artificial intelligence big data . also member strategic advisory board \n",
      "Cleaned Token After Stem =  high level advisori committe spanish govern artifici intellig big data . also member strateg advisori board \n",
      "Cleaned Token Before =  half-century or more: adaptive systems, anticipatory systems, artificial intelligence, complex systems, complexity science, cybernetics, informatics\n",
      "Cleaned Token After =  half-century : adaptive systems , anticipatory systems , artificial intelligence , complex systems , complexity science , cybernetics , informatics \n",
      "Cleaned Token After Stem =  half-centuri : adapt system , anticipatori system , artifici intellig , complex system , complex scienc , cybernet , informat \n",
      "Cleaned Token Before =  series. as a result, it is known for tough and uncompromising artificial intelligence computer opponents; some of these ais have been contributed by\n",
      "Cleaned Token After =  series . result , known tough uncompromising artificial intelligence computer opponents ; ais contributed \n",
      "Cleaned Token After Stem =  seri . result , known tough uncompromis artifici intellig comput oppon ; ai contribut \n",
      "Cleaned Token Before =  processes (mdps) to artificial intelligence planning. the standard textbook in artificial intelligence, artificial intelligence: a modern approach (second\n",
      "Cleaned Token After =  processes ( mdps ) artificial intelligence planning . standard textbook artificial intelligence , artificial intelligence : modern approach ( second \n",
      "Cleaned Token After Stem =  process ( mdp ) artifici intellig plan . standard textbook artifici intellig , artifici intellig : modern approach ( second \n",
      "Cleaned Token Before =  algorithmic information theory. he was an originator of the branch of artificial intelligence based on machine learning, prediction and probability. he circulated\n",
      "Cleaned Token After =  algorithmic information theory . originator branch artificial intelligence based machine learning , prediction probability . circulated \n",
      "Cleaned Token After Stem =  algorithm inform theori . origin branch artifici intellig base machin learn , predict probabl . circul \n",
      "Cleaned Token Before =  the society for the study of artificial intelligence and simulation of behaviour or ssaisb or aisb is a nonprofit, scientific society devoted to advancing\n",
      "Cleaned Token After =  society study artificial intelligence simulation behaviour ssaisb aisb nonprofit , scientific society devoted advancing \n",
      "Cleaned Token After Stem =  societi studi artifici intellig simul behaviour ssaisb aisb nonprofit , scientif societi devot advanc \n",
      "Cleaned Token Before =  artificial intelligence. he has been a visiting scholar at harvard university and stanford university (conducting research on artificial intelligence\n",
      "Cleaned Token After =  artificial intelligence . visiting scholar harvard university stanford university ( conducting research artificial intelligence \n",
      "Cleaned Token After Stem =  artifici intellig . visit scholar harvard univers stanford univers ( conduct research artifici intellig \n",
      "Cleaned Token Before =  studied computer science and theoretical physics. he did his phd in artificial intelligence and robotics at université pierre & marie curie in co-supervision\n",
      "Cleaned Token After =  studied computer science theoretical physics . phd artificial intelligence robotics université pierre & marie curie co-supervision \n",
      "Cleaned Token After Stem =  studi comput scienc theoret physic . phd artifici intellig robot université pierr & mari curi co-supervis \n",
      "Cleaned Token Before =  pandorabots, inc. is an artificial intelligence company that runs a web service for building and deploying chatbots. according to its website, as of may\n",
      "Cleaned Token After =  pandorabots , inc. artificial intelligence company runs web service building deploying chatbots . according website , may \n",
      "Cleaned Token After Stem =  pandorabot , inc. artifici intellig compani run web servic build deploy chatbot . accord websit , may \n",
      "Cleaned Token Before =  2009). a study and application on machine learning of artificial intelligence. artificial intelligence, 2009. jcai '09. international joint conference on\n",
      "Cleaned Token After =  2009 ) . study application machine learning artificial intelligence . artificial intelligence , 2009. jcai '09 . international joint conference \n",
      "Cleaned Token After Stem =  2009 ) . studi applic machin learn artifici intellig . artifici intellig , 2009. jcai '09 . intern joint confer \n",
      "Cleaned Token Before =  portfolio allocation for bayesian optimization. uncertainty in artificial intelligence: 327–336 (2011) eric brochu, vlad m. cora, nando de freitas: a\n",
      "Cleaned Token After =  portfolio allocation bayesian optimization . uncertainty artificial intelligence : 327–336 ( 2011 ) eric brochu , vlad m. cora , nando de freitas : \n",
      "Cleaned Token After Stem =  portfolio alloc bayesian optim . uncertainti artifici intellig : 327–336 ( 2011 ) eric brochu , vlad m. cora , nando de freita : \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Token Before =  167–170 brooks, rodney a. (january 1991). \"intelligence without representation\". artificial intelligence. 47 (1–3): 139–159. citeseerx 10.1.1.308.6537\n",
      "Cleaned Token After =  167–170 brooks , rodney . ( january 1991 ) . `` intelligence without representation '' . artificial intelligence . 47 ( 1–3 ) : 139–159 . citeseerx 10.1.1.308.6537 \n",
      "Cleaned Token After Stem =  167–170 brook , rodney . ( januari 1991 ) . `` intellig without represent `` . artifici intellig . 47 ( 1–3 ) : 139–159 . citeseerx 10.1.1.308.6537 \n",
      "Cleaned Token Before =  on later science fiction and had impact on thought on ethics of artificial intelligence as well. other characters that appear in these short stories are\n",
      "Cleaned Token After =  later science fiction impact thought ethics artificial intelligence well . characters appear short stories \n",
      "Cleaned Token After Stem =  later scienc fiction impact thought ethic artifici intellig well . charact appear short stori \n",
      "Cleaned Token Before =  the vector institute for artificial intelligence. she is the first chair in biomedical informatics and artificial intelligence at the hospital for sick\n",
      "Cleaned Token After =  vector institute artificial intelligence . first chair biomedical informatics artificial intelligence hospital sick \n",
      "Cleaned Token After Stem =  vector institut artifici intellig . first chair biomed informat artifici intellig hospit sick \n",
      "Cleaned Token Before =  about artificial intelligence and the human species, mainly concerning the technological singularity. he predicts that artificial intelligence would outsmart\n",
      "Cleaned Token After =  artificial intelligence human species , mainly concerning technological singularity . predicts artificial intelligence would outsmart \n",
      "Cleaned Token After Stem =  artifici intellig human speci , mainli concern technolog singular . predict artifici intellig would outsmart \n",
      "Cleaned Token Before =  calvin, spooner consults usr's central artificial intelligence computer, viki (virtual interactive kinetic intelligence). they find that the security footage\n",
      "Cleaned Token After =  calvin , spooner consults usr 's central artificial intelligence computer , viki ( virtual interactive kinetic intelligence ) . find security footage \n",
      "Cleaned Token After Stem =  calvin , spooner consult usr 's central artifici intellig comput , viki ( virtual interact kinet intellig ) . find secur footag \n",
      "Cleaned Token Before =  public by name in january 2019. in a significant milestone for artificial intelligence, alphastar attained grandmaster status in august 2019. games created\n",
      "Cleaned Token After =  public name january 2019. significant milestone artificial intelligence , alphastar attained grandmaster status august 2019. games created \n",
      "Cleaned Token After Stem =  public name januari 2019. signific mileston artifici intellig , alphastar attain grandmast statu august 2019. game creat \n",
      "Cleaned Token Before =  computer with more than 1,000 qubits was installed at the quantum artificial intelligence lab at nasa ames research center. they have subsequently shipped\n",
      "Cleaned Token After =  computer 1,000 qubits installed quantum artificial intelligence lab nasa ames research center . subsequently shipped \n",
      "Cleaned Token After Stem =  comput 1,000 qubit instal quantum artifici intellig lab nasa ame research center . subsequ ship \n",
      "Cleaned Token Before =  community.\" the stanford artificial intelligence laboratory (also known as the stanford ai lab, or sail) is the artificial intelligence (ai) research laboratory\n",
      "Cleaned Token After =  community . '' stanford artificial intelligence laboratory ( also known stanford ai lab , sail ) artificial intelligence ( ai ) research laboratory \n",
      "Cleaned Token After Stem =  commun . `` stanford artifici intellig laboratori ( also known stanford ai lab , sail ) artifici intellig ( ai ) research laboratori \n",
      "Cleaned Token Before =  combines traditional traffic lights with an array of sensors and artificial intelligence to intelligently route vehicle and pedestrian traffic. they can\n",
      "Cleaned Token After =  combines traditional traffic lights array sensors artificial intelligence intelligently route vehicle pedestrian traffic . \n",
      "Cleaned Token After Stem =  combin tradit traffic light array sensor artifici intellig intellig rout vehicl pedestrian traffic . \n",
      "Cleaned Token Before =  dendral was a project in artificial intelligence (ai) of the 1960s, and the computer software expert system that it produced. its primary aim was to study\n",
      "Cleaned Token After =  dendral project artificial intelligence ( ai ) 1960s , computer software expert system produced . primary aim study \n",
      "Cleaned Token After Stem =  dendral project artifici intellig ( ai ) 1960 , comput softwar expert system produc . primari aim studi \n",
      "Cleaned Token Before =  some scenarios center on emerging technologies, such as advanced artificial intelligence, biotechnology, or self-replicating nanobots. the probability of\n",
      "Cleaned Token After =  scenarios center emerging technologies , advanced artificial intelligence , biotechnology , self-replicating nanobots . probability \n",
      "Cleaned Token After Stem =  scenario center emerg technolog , advanc artifici intellig , biotechnolog , self-repl nanobot . probabl \n",
      "Cleaned Token Before =  for improving the success of an ai agent at various tasks. in artificial intelligence, curiosity is typically defined quantitatively, as the uncertainty\n",
      "Cleaned Token After =  improving success ai agent various tasks . artificial intelligence , curiosity typically defined quantitatively , uncertainty \n",
      "Cleaned Token After Stem =  improv success ai agent variou task . artifici intellig , curios typic defin quantit , uncertainti \n",
      "Cleaned Token Before =  in the field of artificial intelligence, inference engine is a component of the system that applies logical rules to the knowledge base to deduce new\n",
      "Cleaned Token After =  field artificial intelligence , inference engine component system applies logical rules knowledge base deduce new \n",
      "Cleaned Token After Stem =  field artifici intellig , infer engin compon system appli logic rule knowledg base deduc new \n",
      "Cleaned Token Before =  kitty ai: artificial intelligence for governance is a 2016 art project by artist and researcher pinar yoldas. it is a 12-minute 3d animation. the work\n",
      "Cleaned Token After =  kitty ai : artificial intelligence governance 2016 art project artist researcher pinar yoldas . 12-minute 3d animation . work \n",
      "Cleaned Token After Stem =  kitti ai : artifici intellig govern 2016 art project artist research pinar yolda . 12-minut 3d anim . work \n",
      "Cleaned Token Before =  demography, economics, engineering, medicine, physics, machine learning/artificial intelligence, bioinformatics, chemometrics, natural language processing, econometrics\n",
      "Cleaned Token After =  demography , economics , engineering , medicine , physics , machine learning/artificial intelligence , bioinformatics , chemometrics , natural language processing , econometrics \n",
      "Cleaned Token After Stem =  demographi , econom , engin , medicin , physic , machin learning/artifici intellig , bioinformat , chemometr , natur languag process , econometr \n",
      "Cleaned Token Before =  architecture machine group now known as the mit media lab, research in artificial intelligence at yale university and carnegie-mellon university, computer simulation\n",
      "Cleaned Token After =  architecture machine group known mit media lab , research artificial intelligence yale university carnegie-mellon university , computer simulation \n",
      "Cleaned Token After Stem =  architectur machin group known mit media lab , research artifici intellig yale univers carnegie-mellon univers , comput simul \n",
      "Cleaned Token Before =  in october 2016, bengio co-founded element ai, a montreal-based artificial intelligence incubator that turns ai research into real-world business applications\n",
      "Cleaned Token After =  october 2016 , bengio co-founded element ai , montreal-based artificial intelligence incubator turns ai research real-world business applications \n",
      "Cleaned Token After Stem =  octob 2016 , bengio co-found element ai , montreal-bas artifici intellig incub turn ai research real-world busi applic \n",
      "Cleaned Token Before =  and the opencog project, an open-source software initiative for artificial intelligence. over the years, the foundation has convened many of these scientists\n",
      "Cleaned Token After =  opencog project , open-source software initiative artificial intelligence . years , foundation convened many scientists \n",
      "Cleaned Token After Stem =  opencog project , open-sourc softwar initi artifici intellig . year , foundat conven mani scientist \n",
      "Cleaned Token Before =  culturintel is the first using artificial intelligence and big data tools to report measures of cultural intelligence and enable corporations to embed\n",
      "Cleaned Token After =  culturintel first using artificial intelligence big data tools report measures cultural intelligence enable corporations embed \n",
      "Cleaned Token After Stem =  culturintel first use artifici intellig big data tool report measur cultur intellig enabl corpor emb \n",
      "Cleaned Token Before =  by the financial times for \"tackling big themes—gods, messiahs, artificial intelligence, alienness—with brio.\" it was selected from a shortlist of six\n",
      "Cleaned Token After =  financial times `` tackling big themes—gods , messiahs , artificial intelligence , alienness—with brio . '' selected shortlist six \n",
      "Cleaned Token After Stem =  financi time `` tackl big themes—god , messiah , artifici intellig , alienness—with brio . `` select shortlist six \n",
      "Cleaned Token Before =  for his role in establishing the use of probability theory in artificial intelligence and in the development of the field bayesian networks. neapolitan\n",
      "Cleaned Token After =  role establishing use probability theory artificial intelligence development field bayesian networks . neapolitan \n",
      "Cleaned Token After Stem =  role establish use probabl theori artifici intellig develop field bayesian network . neapolitan \n",
      "Cleaned Token Before =  assq chip and its progeny\". mit artificial intelligence laboratory working papers (wp-225). mit artificial intelligence laboratory: 1–25 – via mit libraries\n",
      "Cleaned Token After =  assq chip progeny '' . mit artificial intelligence laboratory working papers ( wp-225 ) . mit artificial intelligence laboratory : 1–25 – via mit libraries \n",
      "Cleaned Token After Stem =  assq chip progeni `` . mit artifici intellig laboratori work paper ( wp-225 ) . mit artifici intellig laboratori : 1–25 – via mit librari \n",
      "Cleaned Token Before =  artificial ants artificial brain artificial consciousness artificial imagination artificial intelligence artificial intelligence and law artificial intelligence\n",
      "Cleaned Token After =  artificial ants artificial brain artificial consciousness artificial imagination artificial intelligence artificial intelligence law artificial intelligence \n",
      "Cleaned Token After Stem =  artifici ant artifici brain artifici conscious artifici imagin artifici intellig artifici intellig law artifici intellig \n",
      "Cleaned Token Before =  iterative-deepening: an optimal admissible tree search\" (pdf). artificial intelligence. 27: 97–109. doi:10.1016/0004-3702(85)90084-0. korf, richard e\n",
      "Cleaned Token After =  iterative-deepening : optimal admissible tree search '' ( pdf ) . artificial intelligence . 27 : 97–109 . doi:10.1016/0004-3702 ( 85 ) 90084-0. korf , richard e \n",
      "Cleaned Token After Stem =  iterative-deepen : optim admiss tree search `` ( pdf ) . artifici intellig . 27 : 97–109 . doi:10.1016/0004-3702 ( 85 ) 90084-0. korf , richard e \n",
      "Cleaned Token Before =  more sophisticated and companies are increasingly implementing artificial intelligence to assist in all aspects of business and society. this leads to\n",
      "Cleaned Token After =  sophisticated companies increasingly implementing artificial intelligence assist aspects business society . leads \n",
      "Cleaned Token After Stem =  sophist compani increasingli implement artifici intellig assist aspect busi societi . lead \n",
      "Cleaned Token Before =  alphazero is a computer program developed by artificial intelligence research company deepmind to master the games of chess, shogi and go. this algorithm\n",
      "Cleaned Token After =  alphazero computer program developed artificial intelligence research company deepmind master games chess , shogi go . algorithm \n",
      "Cleaned Token After Stem =  alphazero comput program develop artifici intellig research compani deepmind master game chess , shogi go . algorithm \n",
      "Cleaned Token Before =  computer science and artificial intelligence. he is a full professor and the director of national centre of artificial intelligence at the university of\n",
      "Cleaned Token After =  computer science artificial intelligence . full professor director national centre artificial intelligence university \n",
      "Cleaned Token After Stem =  comput scienc artifici intellig . full professor director nation centr artifici intellig univers \n",
      "Cleaned Token Before =  it requires the solution to a difficult problem in the field of artificial intelligence (ai) rather than just the discovery of the (secret) algorithm,\n",
      "Cleaned Token After =  requires solution difficult problem field artificial intelligence ( ai ) rather discovery ( secret ) algorithm , \n",
      "Cleaned Token After Stem =  requir solut difficult problem field artifici intellig ( ai ) rather discoveri ( secret ) algorithm , \n",
      "Cleaned Token Before =  a discovery system is an artificial intelligence system that attempts to discover new scientific concepts or laws. notable discovery systems have included:\n",
      "Cleaned Token After =  discovery system artificial intelligence system attempts discover new scientific concepts laws . notable discovery systems included : \n",
      "Cleaned Token After Stem =  discoveri system artifici intellig system attempt discov new scientif concept law . notabl discoveri system includ : \n",
      "Cleaned Token Before =  2010 documentary film about the promise, problems and ethics of artificial intelligence and robotics. the main protagonists are the former mit professor\n",
      "Cleaned Token After =  2010 documentary film promise , problems ethics artificial intelligence robotics . main protagonists former mit professor \n",
      "Cleaned Token After Stem =  2010 documentari film promis , problem ethic artifici intellig robot . main protagonist former mit professor \n",
      "Cleaned Token Before =  dileep george is an artificial intelligence and neuroscience researcher. george received his phd in electrical engineering from stanford university in\n",
      "Cleaned Token After =  dileep george artificial intelligence neuroscience researcher . george received phd electrical engineering stanford university \n",
      "Cleaned Token After Stem =  dileep georg artifici intellig neurosci research . georg receiv phd electr engin stanford univers \n",
      "Cleaned Token Before =  \" stochastic gradient descent russell, s.; norvig, p. (2010). artificial intelligence: a modern approach (3rd ed.). prentice hall. isbn 0136042597. dawkins\n",
      "Cleaned Token After =  `` stochastic gradient descent russell , s. ; norvig , p. ( 2010 ) . artificial intelligence : modern approach ( 3rd ed. ) . prentice hall . isbn 0136042597. dawkins \n",
      "Cleaned Token After Stem =  `` stochast gradient descent russel , s. ; norvig , p. ( 2010 ) . artifici intellig : modern approach ( 3rd ed . ) . prentic hall . isbn 0136042597. dawkin \n",
      "Cleaned Token Before =   adaptive behavior, 2, 307-348 brooks, r.a. intelligence without representation. artificial intelligence, 1991. elsevier franklin, s., & patterson, f\n",
      "Cleaned Token After =  adaptive behavior , 2 , 307-348 brooks , r.a. intelligence without representation . artificial intelligence , 1991. elsevier franklin , s. , & patterson , f \n",
      "Cleaned Token After Stem =  adapt behavior , 2 , 307-348 brook , r.a. intellig without represent . artifici intellig , 1991. elsevi franklin , s. , & patterson , f \n",
      "Cleaned Token Before =  conferences such as the ieee conference on computational intelligence and games and artificial intelligence and interactive digital entertainment. particularly\n",
      "Cleaned Token After =  conferences ieee conference computational intelligence games artificial intelligence interactive digital entertainment . particularly \n",
      "Cleaned Token After Stem =  confer ieee confer comput intellig game artifici intellig interact digit entertain . particularli \n",
      "Cleaned Token Before =  working on in support of the stair (stanford artificial intelligence robot) by the stanford artificial intelligence laboratory.  early funding of us$50,000\n",
      "Cleaned Token After =  working support stair ( stanford artificial intelligence robot ) stanford artificial intelligence laboratory . early funding us $ 50,000 \n",
      "Cleaned Token After Stem =  work support stair ( stanford artifici intellig robot ) stanford artifici intellig laboratori . earli fund us $ 50,000 \n",
      "Cleaned Token Before =  environmental comedy, tony n’ tina’s wedding is a creation of the artificial intelligence comedy troupe. thirteen original cast members share the copyright:\n",
      "Cleaned Token After =  environmental comedy , tony n ’ tina ’ wedding creation artificial intelligence comedy troupe . thirteen original cast members share copyright : \n",
      "Cleaned Token After Stem =  environment comedi , toni n ’ tina ’ wed creation artifici intellig comedi troup . thirteen origin cast member share copyright : \n",
      "Cleaned Token Before =  the massachusetts institute of technology (mit) in the field of artificial intelligence (ai) and health sciences, including disease detection, drug discovery\n",
      "Cleaned Token After =  massachusetts institute technology ( mit ) field artificial intelligence ( ai ) health sciences , including disease detection , drug discovery \n",
      "Cleaned Token After Stem =  massachusett institut technolog ( mit ) field artifici intellig ( ai ) health scienc , includ diseas detect , drug discoveri \n",
      "Cleaned Token Before =  delft university of technology. she leads the social and ethical artificial intelligence research group. her research and writing considers responsible\n",
      "Cleaned Token After =  delft university technology . leads social ethical artificial intelligence research group . research writing considers responsible \n",
      "Cleaned Token After Stem =  delft univers technolog . lead social ethic artifici intellig research group . research write consid respons \n",
      "Cleaned Token Before =  commonly used for the paper \"artificial intelligence: a general survey\" by james lighthill, published in artificial intelligence: a paper symposium in 1973\n",
      "Cleaned Token After =  commonly used paper `` artificial intelligence : general survey '' james lighthill , published artificial intelligence : paper symposium 1973 \n",
      "Cleaned Token After Stem =  commonli use paper `` artifici intellig : gener survey `` jame lighthil , publish artifici intellig : paper symposium 1973 \n",
      "Cleaned Token Before =  robots complex behaviors. the mission of openai is to build safe artificial intelligence (ai), and ensure that its benefits are as evenly distributed as\n",
      "Cleaned Token After =  robots complex behaviors . mission openai build safe artificial intelligence ( ai ) , ensure benefits evenly distributed \n",
      "Cleaned Token After Stem =  robot complex behavior . mission openai build safe artifici intellig ( ai ) , ensur benefit evenli distribut \n",
      "Cleaned Token Before =  vceg and various focus groups, such as the itu-who focus group on artificial intelligence for health. administratively, sg16 is a statutory meeting of the\n",
      "Cleaned Token After =  vceg various focus groups , itu-who focus group artificial intelligence health . administratively , sg16 statutory meeting \n",
      "Cleaned Token After Stem =  vceg variou focu group , itu-who focu group artifici intellig health . administr , sg16 statutori meet \n",
      "Cleaned Token Before =  for artificial intelligence in vienna, which was founded in 1984. he is known for his work in the field of cybernetics and artificial intelligence. in\n",
      "Cleaned Token After =  artificial intelligence vienna , founded 1984. known work field cybernetics artificial intelligence . \n",
      "Cleaned Token After Stem =  artifici intellig vienna , found 1984. known work field cybernet artifici intellig . \n",
      "Cleaned Token Before =  disturbingly doll-like. due to rapid advancements in the areas of artificial intelligence and affective computing, cognitive scientists have also suggested\n",
      "Cleaned Token After =  disturbingly doll-like . due rapid advancements areas artificial intelligence affective computing , cognitive scientists also suggested \n",
      "Cleaned Token After Stem =  disturbingli doll-lik . due rapid advanc area artifici intellig affect comput , cognit scientist also suggest \n",
      "Cleaned Token Before =  maintenance on pathos-ii are overseen by the warden unit (wau), an artificial general intelligence integrated with all computer systems in the facility. the crew\n",
      "Cleaned Token After =  maintenance pathos-ii overseen warden unit ( wau ) , artificial general intelligence integrated computer systems facility . crew \n",
      "Cleaned Token After Stem =  mainten pathos-ii overseen warden unit ( wau ) , artifici gener intellig integr comput system facil . crew \n",
      "Cleaned Token Before =  in force field technology and miniaturization. he developed an artificial intelligence, c.o.m.p.u.t.o., allowing him to discover the fifth dimension.\n",
      "Cleaned Token After =  force field technology miniaturization . developed artificial intelligence , c.o.m.p.u.t.o. , allowing discover fifth dimension . \n",
      "Cleaned Token After Stem =  forc field technolog miniatur . develop artifici intellig , c.o.m.p.u.t.o . , allow discov fifth dimens . \n",
      "Cleaned Token Before =  marked the first international effort solely to focus upon applying artificial intelligence research to legal problems in order to \"consider how computers\n",
      "Cleaned Token After =  marked first international effort solely focus upon applying artificial intelligence research legal problems order `` consider computers \n",
      "Cleaned Token After Stem =  mark first intern effort sole focu upon appli artifici intellig research legal problem order `` consid comput \n",
      "Cleaned Token Before =  the university of sussex, where her work embraces the fields of artificial intelligence, psychology, philosophy, and cognitive and computer science. boden\n",
      "Cleaned Token After =  university sussex , work embraces fields artificial intelligence , psychology , philosophy , cognitive computer science . boden \n",
      "Cleaned Token After Stem =  univers sussex , work embrac field artifici intellig , psycholog , philosophi , cognit comput scienc . boden \n",
      "Cleaned Token Before =  computational instantiation of such a theory used in the fields of artificial intelligence (ai) and computational cognitive science. one of the main goals\n",
      "Cleaned Token After =  computational instantiation theory used fields artificial intelligence ( ai ) computational cognitive science . one main goals \n",
      "Cleaned Token After Stem =  comput instanti theori use field artifici intellig ( ai ) comput cognit scienc . one main goal \n",
      "Cleaned Token Before =  technology like virtual avatars, artificial insemination, sexual reassignment surgery, and artificial intelligence might make dichotomies of sex and\n",
      "Cleaned Token After =  technology like virtual avatars , artificial insemination , sexual reassignment surgery , artificial intelligence might make dichotomies sex \n",
      "Cleaned Token After Stem =  technolog like virtual avatar , artifici insemin , sexual reassign surgeri , artifici intellig might make dichotomi sex \n",
      "Cleaned Token Before =  is a process used in the field of computer science, including artificial intelligence (ai), in which successive configurations or states of an instance\n",
      "Cleaned Token After =  process used field computer science , including artificial intelligence ( ai ) , successive configurations states instance \n",
      "Cleaned Token After Stem =  process use field comput scienc , includ artifici intellig ( ai ) , success configur state instanc \n",
      "Cleaned Token Before =  this crossover has spurred collaboration between researchers in artificial intelligence and quantum information science. in june 2019, google, the perimeter\n",
      "Cleaned Token After =  crossover spurred collaboration researchers artificial intelligence quantum information science . june 2019 , google , perimeter \n",
      "Cleaned Token After Stem =  crossov spur collabor research artifici intellig quantum inform scienc . june 2019 , googl , perimet \n",
      "Cleaned Token Before =  potentially will impact game play, but will not necessarily be true artificial intelligence. in a traditional tabletop role-playing game such as dungeons &\n",
      "Cleaned Token After =  potentially impact game play , necessarily true artificial intelligence . traditional tabletop role-playing game dungeons & \n",
      "Cleaned Token After Stem =  potenti impact game play , necessarili true artifici intellig . tradit tabletop role-play game dungeon & \n",
      "Cleaned Token Before =  criteria to make issue trade-offs in automated negotiations\". artificial intelligence. 142 (2): 205–237. doi:10.1016/s0004-3702(02)00290-4. hdl:10261/162977\n",
      "Cleaned Token After =  criteria make issue trade-offs automated negotiations '' . artificial intelligence . 142 ( 2 ) : 205–237 . doi:10.1016/s0004-3702 ( 02 ) 00290-4. hdl:10261/162977 \n",
      "Cleaned Token After Stem =  criteria make issu trade-off autom negoti `` . artifici intellig . 142 ( 2 ) : 205–237 . doi:10.1016/s0004-3702 ( 02 ) 00290-4. hdl:10261/162977 \n",
      "Cleaned Token Before =  in artificial intelligence and operations research, constraint satisfaction is the process of finding a solution to a set of constraints that impose conditions\n",
      "Cleaned Token After =  artificial intelligence operations research , constraint satisfaction process finding solution set constraints impose conditions \n",
      "Cleaned Token After Stem =  artifici intellig oper research , constraint satisfact process find solut set constraint impos condit \n",
      "Cleaned Token Before =  and dives deeper into a social media addiction. the dangers of artificial intelligence and fake news are touched on. tristan harris argues that this is\n",
      "Cleaned Token After =  dives deeper social media addiction . dangers artificial intelligence fake news touched . tristan harris argues \n",
      "Cleaned Token After Stem =  dive deeper social media addict . danger artifici intellig fake news touch . tristan harri argu \n",
      "Cleaned Token Before =  are humanoid robotic servants, equipped with a personality and artificial intelligence. the most notable one is kryten, a service mechanoid, with a neurotic\n",
      "Cleaned Token After =  humanoid robotic servants , equipped personality artificial intelligence . notable one kryten , service mechanoid , neurotic \n",
      "Cleaned Token After Stem =  humanoid robot servant , equip person artifici intellig . notabl one kryten , servic mechanoid , neurot \n",
      "Cleaned Token Before =  return a suboptimal goal node. russell, s.j.; norvig, p. (2002). artificial intelligence: a modern approach. prentice hall. isbn 0-13-790395-2. korf, richard\n",
      "Cleaned Token After =  return suboptimal goal node . russell , s.j . ; norvig , p. ( 2002 ) . artificial intelligence : modern approach . prentice hall . isbn 0-13-790395-2. korf , richard \n",
      "Cleaned Token After Stem =  return suboptim goal node . russel , s.j . ; norvig , p. ( 2002 ) . artifici intellig : modern approach . prentic hall . isbn 0-13-790395-2. korf , richard \n",
      "Cleaned Token Before =  although most of his current research and teaching revolves around artificial intelligence and its applications, he holds academic degrees in mathematics\n",
      "Cleaned Token After =  although current research teaching revolves around artificial intelligence applications , holds academic degrees mathematics \n",
      "Cleaned Token After Stem =  although current research teach revolv around artifici intellig applic , hold academ degre mathemat \n",
      "Cleaned Token Before =  software family (including cloud-based productivity tools and artificial intelligence features). the brand was first introduced at microsoft inspire\n",
      "Cleaned Token After =  software family ( including cloud-based productivity tools artificial intelligence features ) . brand first introduced microsoft inspire \n",
      "Cleaned Token After Stem =  softwar famili ( includ cloud-bas product tool artifici intellig featur ) . brand first introduc microsoft inspir \n",
      "Cleaned Token Before =  hub, as it is now, until after it hit the market. as alexa, the artificial intelligence (a.i.) that powers the amazon echo, improved, the device became\n",
      "Cleaned Token After =  hub , , hit market . alexa , artificial intelligence ( a.i . ) powers amazon echo , improved , device became \n",
      "Cleaned Token After Stem =  hub , , hit market . alexa , artifici intellig ( a.i . ) power amazon echo , improv , devic becam \n",
      "Cleaned Token Before =  successful. criticisms focused on shortcomings with the game's artificial intelligence and on the real-time naval battles being difficult to control and\n",
      "Cleaned Token After =  successful . criticisms focused shortcomings game 's artificial intelligence real-time naval battles difficult control \n",
      "Cleaned Token After Stem =  success . critic focus shortcom game 's artifici intellig real-tim naval battl difficult control \n",
      "Cleaned Token Before =  agencies based in the western world. she describes herself as an artificial intelligence. digitrevx, an american animator of anime-style 3d character models\n",
      "Cleaned Token After =  agencies based western world . describes artificial intelligence . digitrevx , american animator anime-style 3d character models \n",
      "Cleaned Token After Stem =  agenc base western world . describ artifici intellig . digitrevx , american anim anime-styl 3d charact model \n",
      "Cleaned Token Before =  detection (and collision response), sound, scripting, animation, artificial intelligence, networking, streaming, memory management, threading, localization\n",
      "Cleaned Token After =  detection ( collision response ) , sound , scripting , animation , artificial intelligence , networking , streaming , memory management , threading , localization \n",
      "Cleaned Token After Stem =  detect ( collis respons ) , sound , script , anim , artifici intellig , network , stream , memori manag , thread , local \n",
      "Cleaned Token Before =  spelling of qo'nos, the klingon home world in singularity, an artificial intelligence designed to rid the earth of the plague of humanity in order to\n",
      "Cleaned Token After =  spelling qo'nos , klingon home world singularity , artificial intelligence designed rid earth plague humanity order \n",
      "Cleaned Token After Stem =  spell qo'no , klingon home world singular , artifici intellig design rid earth plagu human order \n",
      "Cleaned Token Before =  selection. artificial intelligence genetic algorithm genetic operator fogel, l.j., owens, a.j., walsh, m.j. (1966), artificial intelligence through simulated\n",
      "Cleaned Token After =  selection . artificial intelligence genetic algorithm genetic operator fogel , l.j. , owens , a.j. , walsh , m.j. ( 1966 ) , artificial intelligence simulated \n",
      "Cleaned Token After Stem =  select . artifici intellig genet algorithm genet oper fogel , l.j . , owen , a.j . , walsh , m.j. ( 1966 ) , artifici intellig simul \n",
      "Cleaned Token Before =  on the future impact of artificial intelligence. twenty-five essayists contributed essays related to artificial intelligence (ai) pioneer norbert wiener's\n",
      "Cleaned Token After =  future impact artificial intelligence . twenty-five essayists contributed essays related artificial intelligence ( ai ) pioneer norbert wiener 's \n",
      "Cleaned Token After Stem =  futur impact artifici intellig . twenty-f essayist contribut essay relat artifici intellig ( ai ) pioneer norbert wiener 's \n",
      "Cleaned Token Before =  nello cristianini (born 1968) is a professor of artificial intelligence in the department of computer science at the university of bristol. cristianini\n",
      "Cleaned Token After =  nello cristianini ( born 1968 ) professor artificial intelligence department computer science university bristol . cristianini \n",
      "Cleaned Token After Stem =  nello cristianini ( born 1968 ) professor artifici intellig depart comput scienc univers bristol . cristianini \n",
      "Cleaned Token Before =  october 1962, in châtillon-sur-seine, france), is a professor of artificial intelligence & ethics at paris-sorbonne university since 2011 and at computer\n",
      "Cleaned Token After =  october 1962 , châtillon-sur-seine , france ) , professor artificial intelligence & ethics paris-sorbonne university since 2011 computer \n",
      "Cleaned Token After Stem =  octob 1962 , châtillon-sur-sein , franc ) , professor artifici intellig & ethic paris-sorbonn univers sinc 2011 comput \n",
      "Cleaned Token Before =  (2013) depicts a artificial intelligence assistant called samantha, whom the protagonist, theodore, falls in love with until her intelligence surpasses human\n",
      "Cleaned Token After =  ( 2013 ) depicts artificial intelligence assistant called samantha , protagonist , theodore , falls love intelligence surpasses human \n",
      "Cleaned Token After Stem =  ( 2013 ) depict artifici intellig assist call samantha , protagonist , theodor , fall love intellig surpass human \n",
      "Cleaned Token Before =  deepfakes leverage powerful techniques from machine learning and artificial intelligence to manipulate or generate visual and audio content with a high\n",
      "Cleaned Token After =  deepfakes leverage powerful techniques machine learning artificial intelligence manipulate generate visual audio content high \n",
      "Cleaned Token After Stem =  deepfak leverag power techniqu machin learn artifici intellig manipul gener visual audio content high \n",
      "Cleaned Token Before =  his work on behavioral biometrics, security of cyberworlds, and artificial intelligence safety. he holds a phd from the university at buffalo (2008). he\n",
      "Cleaned Token After =  work behavioral biometrics , security cyberworlds , artificial intelligence safety . holds phd university buffalo ( 2008 ) . \n",
      "Cleaned Token After Stem =  work behavior biometr , secur cyberworld , artifici intellig safeti . hold phd univers buffalo ( 2008 ) . \n",
      "Cleaned Token Before =  turing had an important influence on computing, computer science, artificial intelligence, developmental biology, and the mathematical theory of computability\n",
      "Cleaned Token After =  turing important influence computing , computer science , artificial intelligence , developmental biology , mathematical theory computability \n",
      "Cleaned Token After Stem =  ture import influenc comput , comput scienc , artifici intellig , development biolog , mathemat theori comput \n",
      "Cleaned Token Before =  the artificial intelligence center is a laboratory in the information and computing sciences division of sri international. it was founded in 1966 by\n",
      "Cleaned Token After =  artificial intelligence center laboratory information computing sciences division sri international . founded 1966 \n",
      "Cleaned Token After Stem =  artifici intellig center laboratori inform comput scienc divis sri intern . found 1966 \n",
      "Cleaned Token Before =  researcher currently living in montreal, canada. she specializes in artificial intelligence (ai). precup is associate dean of research at the faculty of science\n",
      "Cleaned Token After =  researcher currently living montreal , canada . specializes artificial intelligence ( ai ) . precup associate dean research faculty science \n",
      "Cleaned Token After Stem =  research current live montreal , canada . special artifici intellig ( ai ) . precup associ dean research faculti scienc \n",
      "Cleaned Token Before =  2017 by the indie folk band darlingside eschaton, a fictional artificial intelligence entity in the charles stross novels singularity sky and iron sunrise\n",
      "Cleaned Token After =  2017 indie folk band darlingside eschaton , fictional artificial intelligence entity charles stross novels singularity sky iron sunrise \n",
      "Cleaned Token After Stem =  2017 indi folk band darlingsid eschaton , fiction artifici intellig entiti charl stross novel singular sky iron sunris \n",
      "Cleaned Token Before =  bgu medical informatics research center. shahar's research is on artificial intelligence in medicine, focusing on medical decision-support systems for physicians\n",
      "Cleaned Token After =  bgu medical informatics research center . shahar 's research artificial intelligence medicine , focusing medical decision-support systems physicians \n",
      "Cleaned Token After Stem =  bgu medic informat research center . shahar 's research artifici intellig medicin , focus medic decision-support system physician \n",
      "Cleaned Token Before =  first choice amongst optimizing algorithms. it is used widely in artificial intelligence, for reaching a goal state from a starting node. different choices\n",
      "Cleaned Token After =  first choice amongst optimizing algorithms . used widely artificial intelligence , reaching goal state starting node . different choices \n",
      "Cleaned Token After Stem =  first choic amongst optim algorithm . use wide artifici intellig , reach goal state start node . differ choic \n",
      "Cleaned Token Before =  applied artificial intelligence, and computational intelligence. he is a fellow of the association for the advancement of artificial intelligence (aaai)\n",
      "Cleaned Token After =  applied artificial intelligence , computational intelligence . fellow association advancement artificial intelligence ( aaai ) \n",
      "Cleaned Token After Stem =  appli artifici intellig , comput intellig . fellow associ advanc artifici intellig ( aaai ) \n",
      "Cleaned Token Before =  near-future scenario where swarms of inexpensive microdrones use artificial intelligence and facial recognition to assassinate political opponents based\n",
      "Cleaned Token After =  near-future scenario swarms inexpensive microdrones use artificial intelligence facial recognition assassinate political opponents based \n",
      "Cleaned Token After Stem =  near-futur scenario swarm inexpens microdron use artifici intellig facial recognit assassin polit oppon base \n",
      "Cleaned Token Before =  film entitled hide and seek. it features a hacker who creates an artificial intelligence named p-1, which goes rogue and takes over computers in its desire\n",
      "Cleaned Token After =  film entitled hide seek . features hacker creates artificial intelligence named p-1 , goes rogue takes computers desire \n",
      "Cleaned Token After Stem =  film entitl hide seek . featur hacker creat artifici intellig name p-1 , goe rogu take comput desir \n",
      "Cleaned Token Before =  institutional website. in may 2020, frontiers media launched its artificial intelligence review assistant software to external editors. the software helps\n",
      "Cleaned Token After =  institutional website . may 2020 , frontiers media launched artificial intelligence review assistant software external editors . software helps \n",
      "Cleaned Token After Stem =  institut websit . may 2020 , frontier media launch artifici intellig review assist softwar extern editor . softwar help \n",
      "Cleaned Token Before =  prolog is a logic programming language associated with artificial intelligence and computational linguistics. prolog has its roots in first-order logic\n",
      "Cleaned Token After =  prolog logic programming language associated artificial intelligence computational linguistics . prolog roots first-order logic \n",
      "Cleaned Token After Stem =  prolog logic program languag associ artifici intellig comput linguist . prolog root first-ord logic \n",
      "Cleaned Token Before =  which is sufficient for many practical sat problems from, e.g., artificial intelligence, circuit design, and automatic theorem proving. a propositional\n",
      "Cleaned Token After =  sufficient many practical sat problems , e.g. , artificial intelligence , circuit design , automatic theorem proving . propositional \n",
      "Cleaned Token After Stem =  suffici mani practic sat problem , e.g . , artifici intellig , circuit design , automat theorem prove . proposit \n",
      "Cleaned Token Before =  pairs method\". proceedings of the twenty-sixth aaai conference on artificial intelligence. aaai'12: 1299–1305. bartholdi iii, j.; tovey, c. a.; trick, m\n",
      "Cleaned Token After =  pairs method '' . proceedings twenty-sixth aaai conference artificial intelligence . aaai'12 : 1299–1305 . bartholdi iii , j. ; tovey , c. a. ; trick , \n",
      "Cleaned Token After Stem =  pair method `` . proceed twenty-sixth aaai confer artifici intellig . aaai'12 : 1299–1305 . bartholdi iii , j. ; tovey , c. a. ; trick , \n",
      "Cleaned Token Before =  times to name computer programs after charles darwin. artificial life artificial intelligence \"darwin among the machines\" evolutionary computation evolutionary\n",
      "Cleaned Token After =  times name computer programs charles darwin . artificial life artificial intelligence `` darwin among machines '' evolutionary computation evolutionary \n",
      "Cleaned Token After Stem =  time name comput program charl darwin . artifici life artifici intellig `` darwin among machin `` evolutionari comput evolutionari \n",
      "Cleaned Token Before =  cortana, an artificial intelligence. players battle aliens as they attempt to uncover the secrets of the eponymous halo, a ring-shaped artificial world. bungie\n",
      "Cleaned Token After =  cortana , artificial intelligence . players battle aliens attempt uncover secrets eponymous halo , ring-shaped artificial world . bungie \n",
      "Cleaned Token After Stem =  cortana , artifici intellig . player battl alien attempt uncov secret eponym halo , ring-shap artifici world . bungi \n",
      "Cleaned Token Before =  senegalese computer scientist and statistician working in the field of artificial intelligence. her research bridges probabilistic graphical models and deep learning\n",
      "Cleaned Token After =  senegalese computer scientist statistician working field artificial intelligence . research bridges probabilistic graphical models deep learning \n",
      "Cleaned Token After Stem =  senegales comput scientist statistician work field artifici intellig . research bridg probabilist graphic model deep learn \n",
      "Cleaned Token Before =  he surfed. he has also written extensively on james joyce and artificial intelligence, among other subjects; his writing is almost entirely self-published\n",
      "Cleaned Token After =  surfed . also written extensively james joyce artificial intelligence , among subjects ; writing almost entirely self-published \n",
      "Cleaned Token After Stem =  surf . also written extens jame joyc artifici intellig , among subject ; write almost entir self-publish \n",
      "Cleaned Token Before =  and scientist, who pioneered parallel computers and their use in artificial intelligence. he founded thinking machines corporation, a parallel supercomputer\n",
      "Cleaned Token After =  scientist , pioneered parallel computers use artificial intelligence . founded thinking machines corporation , parallel supercomputer \n",
      "Cleaned Token After Stem =  scientist , pioneer parallel comput use artifici intellig . found think machin corpor , parallel supercomput \n",
      "Cleaned Token Before =  summary of the 2020s in science and technology. deepmind used artificial intelligence for the first time to predict protein folding. singapore became\n",
      "Cleaned Token After =  summary 2020s science technology . deepmind used artificial intelligence first time predict protein folding . singapore became \n",
      "Cleaned Token After Stem =  summari 2020 scienc technolog . deepmind use artifici intellig first time predict protein fold . singapor becam \n",
      "Cleaned Token Before =  \"planning and acting in partially observable stochastic domains\". artificial intelligence. 101 (1–2): 99–134. doi:10.1016/s0004-3702(98)00023-x. issn 0004-3702\n",
      "Cleaned Token After =  `` planning acting partially observable stochastic domains '' . artificial intelligence . 101 ( 1–2 ) : 99–134 . doi:10.1016/s0004-3702 ( 98 ) 00023-x . issn 0004-3702 \n",
      "Cleaned Token After Stem =  `` plan act partial observ stochast domain `` . artifici intellig . 101 ( 1–2 ) : 99–134 . doi:10.1016/s0004-3702 ( 98 ) 00023-x . issn 0004-3702 \n",
      "Cleaned Token Before =  canada's advantage in artificial intelligence\". department of finance. \"canada funds $125 million pan-canadian artificial intelligence strategy\". matuszewski\n",
      "Cleaned Token After =  canada 's advantage artificial intelligence '' . department finance . `` canada funds $ 125 million pan-canadian artificial intelligence strategy '' . matuszewski \n",
      "Cleaned Token After Stem =  canada 's advantag artifici intellig `` . depart financ . `` canada fund $ 125 million pan-canadian artifici intellig strategi `` . matuszewski \n",
      "Cleaned Token Before =  electronics engineers (ieee) and the association for the advancement of artificial intelligence (aaai). bouman, katherine louise (2017). extreme imaging via physical\n",
      "Cleaned Token After =  electronics engineers ( ieee ) association advancement artificial intelligence ( aaai ) . bouman , katherine louise ( 2017 ) . extreme imaging via physical \n",
      "Cleaned Token After Stem =  electron engin ( ieee ) associ advanc artifici intellig ( aaai ) . bouman , katherin louis ( 2017 ) . extrem imag via physic \n",
      "Cleaned Token Before =  electrical and electronics engineers (ieee) in 2016 for application of artificial intelligence in control of power electronics systems. simoes was born in são\n",
      "Cleaned Token After =  electrical electronics engineers ( ieee ) 2016 application artificial intelligence control power electronics systems . simoes born são \n",
      "Cleaned Token After Stem =  electr electron engin ( ieee ) 2016 applic artifici intellig control power electron system . simo born são \n",
      "Cleaned Token Before =  platform businesses focused on transforming health care by leveraging artificial intelligence, connected healthcare devices and a network of trusted partners\n",
      "Cleaned Token After =  platform businesses focused transforming health care leveraging artificial intelligence , connected healthcare devices network trusted partners \n",
      "Cleaned Token After Stem =  platform busi focus transform health care leverag artifici intellig , connect healthcar devic network trust partner \n",
      "Cleaned Token Before =  conducts research into cognitive systems at the intersection of artificial intelligence and cognitive science. he is the editor-in-chief of aaai's ai magazine\n",
      "Cleaned Token After =  conducts research cognitive systems intersection artificial intelligence cognitive science . editor-in-chief aaai 's ai magazine \n",
      "Cleaned Token After Stem =  conduct research cognit system intersect artifici intellig cognit scienc . editor-in-chief aaai 's ai magazin \n",
      "Cleaned Token Before =  in artificial intelligence systems. roger schank at stanford university introduced the model in 1969, in the early days of artificial intelligence. this\n",
      "Cleaned Token After =  artificial intelligence systems . roger schank stanford university introduced model 1969 , early days artificial intelligence . \n",
      "Cleaned Token After Stem =  artifici intellig system . roger schank stanford univers introduc model 1969 , earli day artifici intellig . \n",
      "Cleaned Token Before =  to interpret information in a useful way. it is often used in artificial intelligence applications and research. normally, the term rule-based system\n",
      "Cleaned Token After =  interpret information useful way . often used artificial intelligence applications research . normally , term rule-based system \n",
      "Cleaned Token After Stem =  interpret inform use way . often use artifici intellig applic research . normal , term rule-bas system \n",
      "Cleaned Token Before =  content intelligence is a strategy that uses artificial intelligence systems and software to process content data into reliable insights about the effectiveness\n",
      "Cleaned Token After =  content intelligence strategy uses artificial intelligence systems software process content data reliable insights effectiveness \n",
      "Cleaned Token After Stem =  content intellig strategi use artifici intellig system softwar process content data reliabl insight effect \n",
      "Cleaned Token Before =  1995. he retired in 2018. his research has been in the area of artificial intelligence, with side excursions into philosophy. his ph.d. dissertation was\n",
      "Cleaned Token After =  1995. retired 2018. research area artificial intelligence , side excursions philosophy . ph.d. dissertation \n",
      "Cleaned Token After Stem =  1995. retir 2018. research area artifici intellig , side excurs philosophi . ph.d. dissert \n",
      "Cleaned Token Before =  muzero is a computer program developed by artificial intelligence research company deepmind to master games without knowing their rules. its release in\n",
      "Cleaned Token After =  muzero computer program developed artificial intelligence research company deepmind master games without knowing rules . release \n",
      "Cleaned Token After Stem =  muzero comput program develop artifici intellig research compani deepmind master game without know rule . releas \n",
      "Cleaned Token Before =  retrieved 17 april 2011. \"mit scientists take a step closer to artificial intelligence\". computer weekly. 18 november 2011. archived from the original\n",
      "Cleaned Token After =  retrieved 17 april 2011 . `` mit scientists take step closer artificial intelligence '' . computer weekly . 18 november 2011. archived original \n",
      "Cleaned Token After Stem =  retriev 17 april 2011 . `` mit scientist take step closer artifici intellig `` . comput weekli . 18 novemb 2011. archiv origin \n",
      "Cleaned Token Before =  concepts include the \"chinese room\" argument against \"strong\" artificial intelligence. searle's father, g. w. searle, an electrical engineer, was employed\n",
      "Cleaned Token After =  concepts include `` chinese room '' argument `` strong '' artificial intelligence . searle 's father , g. w. searle , electrical engineer , employed \n",
      "Cleaned Token After Stem =  concept includ `` chines room `` argument `` strong `` artifici intellig . searl 's father , g. w. searl , electr engin , employ \n",
      "Cleaned Token Before =  trend in evolving digital signal processing for daa is the use of artificial intelligence technologies. f220 hamburg with smart-l smart-l onboard f221 hessen\n",
      "Cleaned Token After =  trend evolving digital signal processing daa use artificial intelligence technologies . f220 hamburg smart-l smart-l onboard f221 hessen \n",
      "Cleaned Token After Stem =  trend evolv digit signal process daa use artifici intellig technolog . f220 hamburg smart-l smart-l onboard f221 hessen \n",
      "Cleaned Token Before =  the firm provides services in the area of predictive analytics, artificial intelligence, big data and machine learning. affine focuses on verticals like\n",
      "Cleaned Token After =  firm provides services area predictive analytics , artificial intelligence , big data machine learning . affine focuses verticals like \n",
      "Cleaned Token After Stem =  firm provid servic area predict analyt , artifici intellig , big data machin learn . affin focus vertic like \n",
      "Cleaned Token Before =  of approaches for addressing the intractability of a number of artificial intelligence problems. a propositional model is compiled in an off-line phase\n",
      "Cleaned Token After =  approaches addressing intractability number artificial intelligence problems . propositional model compiled off-line phase \n",
      "Cleaned Token After Stem =  approach address intract number artifici intellig problem . proposit model compil off-lin phase \n",
      "Cleaned Token Before =  shrier is the cofounder & managing director of esme learning, an artificial intelligence-enabled digital learning company derived from mit research and\n",
      "Cleaned Token After =  shrier cofounder & managing director esme learning , artificial intelligence-enabled digital learning company derived mit research \n",
      "Cleaned Token After Stem =  shrier cofound & manag director esm learn , artifici intelligence-en digit learn compani deriv mit research \n",
      "Cleaned Token Before =  to: artificial intelligence applications institute, a non-profit technology transfer organisation at the university of edinburgh, 1983-2019 artificial intelligence\n",
      "Cleaned Token After =  : artificial intelligence applications institute , non-profit technology transfer organisation university edinburgh , 1983-2019 artificial intelligence \n",
      "Cleaned Token After Stem =  : artifici intellig applic institut , non-profit technolog transfer organis univers edinburgh , 1983-2019 artifici intellig \n",
      "Cleaned Token Before =  technology is often credited to gavin's background in lisp at the mit artificial intelligence laboratory. gavin earned his bachelor of science degree in neurobiological\n",
      "Cleaned Token After =  technology often credited gavin 's background lisp mit artificial intelligence laboratory . gavin earned bachelor science degree neurobiological \n",
      "Cleaned Token After Stem =  technolog often credit gavin 's background lisp mit artifici intellig laboratori . gavin earn bachelor scienc degre neurobiolog \n",
      "Cleaned Token Before =  proceedings of the 4th hellenic conference on artificial intelligence, lecture notes in artificial intelligence. heraklion, crete, greece: springer-verlag\n",
      "Cleaned Token After =  proceedings 4th hellenic conference artificial intelligence , lecture notes artificial intelligence . heraklion , crete , greece : springer-verlag \n",
      "Cleaned Token After Stem =  proceed 4th hellen confer artifici intellig , lectur note artifici intellig . heraklion , crete , greec : springer-verlag \n",
      "Cleaned Token Before =  identical twin brothers, cade and cale altair, who become hybrid artificial intelligence entities, who are torn in different directions to achieve justice\n",
      "Cleaned Token After =  identical twin brothers , cade cale altair , become hybrid artificial intelligence entities , torn different directions achieve justice \n",
      "Cleaned Token After Stem =  ident twin brother , cade cale altair , becom hybrid artifici intellig entiti , torn differ direct achiev justic \n",
      "Cleaned Token Before =  virtual intelligence is the term given to artificial intelligence that exists within a virtual world. many virtual worlds have options for persistent\n",
      "Cleaned Token After =  virtual intelligence term given artificial intelligence exists within virtual world . many virtual worlds options persistent \n",
      "Cleaned Token After Stem =  virtual intellig term given artifici intellig exist within virtual world . mani virtual world option persist \n",
      "Cleaned Token Before =  female gendering of ai technologies is the proliferation of artificial intelligence (ai) technologies gendered as female, such as in digital assistants\n",
      "Cleaned Token After =  female gendering ai technologies proliferation artificial intelligence ( ai ) technologies gendered female , digital assistants \n",
      "Cleaned Token After Stem =  femal gender ai technolog prolifer artifici intellig ( ai ) technolog gender femal , digit assist \n",
      "Cleaned Token Before =  hanrahan) and upload, in which he plays an \"uncomfortably amusing\" artificial intelligence hotel service worker (credited as \"a.i. guy\", while also writing\n",
      "Cleaned Token After =  hanrahan ) upload , plays `` uncomfortably amusing '' artificial intelligence hotel service worker ( credited `` a.i . guy '' , also writing \n",
      "Cleaned Token After Stem =  hanrahan ) upload , play `` uncomfort amus `` artifici intellig hotel servic worker ( credit `` a.i . guy `` , also write \n",
      "Cleaned Token Before =  billion invested in ai-based education in 2018. squirrel uses artificial intelligence to tailor lesson plans to each individual student. chinese researchers\n",
      "Cleaned Token After =  billion invested ai-based education 2018. squirrel uses artificial intelligence tailor lesson plans individual student . chinese researchers \n",
      "Cleaned Token After Stem =  billion invest ai-bas educ 2018. squirrel use artifici intellig tailor lesson plan individu student . chines research \n",
      "Cleaned Token Before =  sail, the stanford artificial intelligence language, was developed by dan swinehart and bob sproull of the stanford ai lab in 1970. it was originally\n",
      "Cleaned Token After =  sail , stanford artificial intelligence language , developed dan swinehart bob sproull stanford ai lab 1970. originally \n",
      "Cleaned Token After Stem =  sail , stanford artifici intellig languag , develop dan swinehart bob sproull stanford ai lab 1970. origin \n",
      "Cleaned Token Before =  transfer\" (pdf), learning proceedings of the 22nd aaai conference on artificial intelligence (aaai-2007), vancouver, bc, pp. 608–614, retrieved 2007-08-05 niculescu-mizil\n",
      "Cleaned Token After =  transfer '' ( pdf ) , learning proceedings 22nd aaai conference artificial intelligence ( aaai-2007 ) , vancouver , bc , pp . 608–614 , retrieved 2007-08-05 niculescu-mizil \n",
      "Cleaned Token After Stem =  transfer `` ( pdf ) , learn proceed 22nd aaai confer artifici intellig ( aaai-2007 ) , vancouv , bc , pp . 608–614 , retriev 2007-08-05 niculescu-mizil \n",
      "Cleaned Token Before =  author of books about the history and philosophical significance of artificial intelligence, the future of engineering, and the role of women and technology\n",
      "Cleaned Token After =  author books history philosophical significance artificial intelligence , future engineering , role women technology \n",
      "Cleaned Token After Stem =  author book histori philosoph signific artifici intellig , futur engin , role women technolog \n",
      "Cleaned Token Before =  optimization\". artificial life, 5 (2): 137–172. e. bonabeau, m. dorigo et g. theraulaz, 1999. swarm intelligence: from natural to artificial systems, oxford\n",
      "Cleaned Token After =  optimization '' . artificial life , 5 ( 2 ) : 137–172 . e. bonabeau , m. dorigo et g. theraulaz , 1999. swarm intelligence : natural artificial systems , oxford \n",
      "Cleaned Token After Stem =  optim `` . artifici life , 5 ( 2 ) : 137–172 . e. bonabeau , m. dorigo et g. theraulaz , 1999. swarm intellig : natur artifici system , oxford \n",
      "Cleaned Token Before =  detects ship collision risks and predicts risk hotspots through artificial intelligence. this aimed to warn ships about potential collisions. the current\n",
      "Cleaned Token After =  detects ship collision risks predicts risk hotspots artificial intelligence . aimed warn ships potential collisions . current \n",
      "Cleaned Token After Stem =  detect ship collis risk predict risk hotspot artifici intellig . aim warn ship potenti collis . current \n",
      "Cleaned Token Before =  eleventh artificial intelligence and interactive digital entertainment conference, 30–33. association for the advancement of artificial intelligence. hogan\n",
      "Cleaned Token After =  eleventh artificial intelligence interactive digital entertainment conference , 30–33 . association advancement artificial intelligence . hogan \n",
      "Cleaned Token After Stem =  eleventh artifici intellig interact digit entertain confer , 30–33 . associ advanc artifici intellig . hogan \n",
      "Cleaned Token Before =  to munich builds bridges between arts and ai technology to make artificial intelligence more accessible to society, more ethical and more innovative. well-known\n",
      "Cleaned Token After =  munich builds bridges arts ai technology make artificial intelligence accessible society , ethical innovative . well-known \n",
      "Cleaned Token After Stem =  munich build bridg art ai technolog make artifici intellig access societi , ethic innov . well-known \n",
      "Cleaned Token Before =  is a massive open online course (mooc) teaching the basics of artificial intelligence. the course, originally launched in 2018, is designed and organized\n",
      "Cleaned Token After =  massive open online course ( mooc ) teaching basics artificial intelligence . course , originally launched 2018 , designed organized \n",
      "Cleaned Token After Stem =  massiv open onlin cours ( mooc ) teach basic artifici intellig . cours , origin launch 2018 , design organ \n",
      "Cleaned Token Before =  retrieved march 24, 2018. kleinman, zoe (april 14, 2017). \"is artificial intelligence racist?\". bbc news. retrieved march 24, 2018. buolamwini, joy (2018)\n",
      "Cleaned Token After =  retrieved march 24 , 2018. kleinman , zoe ( april 14 , 2017 ) . `` artificial intelligence racist ? '' . bbc news . retrieved march 24 , 2018. buolamwini , joy ( 2018 ) \n",
      "Cleaned Token After Stem =  retriev march 24 , 2018. kleinman , zoe ( april 14 , 2017 ) . `` artifici intellig racist ? `` . bbc news . retriev march 24 , 2018. buolamwini , joy ( 2018 ) \n",
      "Cleaned Token Before =  in video games, a bot is a type of artificial intelligence (ai)–based expert system software that plays a video game in the place of a human. bots are\n",
      "Cleaned Token After =  video games , bot type artificial intelligence ( ai ) –based expert system software plays video game place human . bots \n",
      "Cleaned Token After Stem =  video game , bot type artifici intellig ( ai ) –base expert system softwar play video game place human . bot \n",
      "Cleaned Token Before =  modelling\". proceedings of the third australian joint conference on artificial intelligence (ai 89): 195–205. webb, geoffrey i. (2007). \"discovering significant\n",
      "Cleaned Token After =  modelling '' . proceedings third australian joint conference artificial intelligence ( ai 89 ) : 195–205 . webb , geoffrey . ( 2007 ) . `` discovering significant \n",
      "Cleaned Token After Stem =  model `` . proceed third australian joint confer artifici intellig ( ai 89 ) : 195–205 . webb , geoffrey . ( 2007 ) . `` discov signific \n",
      "Cleaned Token Before =  object-oriented extension to lisp developed by howard cannon at the mit artificial intelligence laboratory for the lisp machine and its programming language lisp\n",
      "Cleaned Token After =  object-oriented extension lisp developed howard cannon mit artificial intelligence laboratory lisp machine programming language lisp \n",
      "Cleaned Token After Stem =  object-ori extens lisp develop howard cannon mit artifici intellig laboratori lisp machin program languag lisp \n",
      "Cleaned Token Before =  artificial intelligence known in the ussr at the time as heuristic programming. he is well known for saying, \"chess is the drosophila of artificial intelligence\n",
      "Cleaned Token After =  artificial intelligence known ussr time heuristic programming . well known saying , `` chess drosophila artificial intelligence \n",
      "Cleaned Token After Stem =  artifici intellig known ussr time heurist program . well known say , `` chess drosophila artifici intellig \n",
      "Cleaned Token Before =  solutions. bayesian networks complex event processing diagnosis (artificial intelligence) event correlation fault management fault tree analysis grey problem\n",
      "Cleaned Token After =  solutions . bayesian networks complex event processing diagnosis ( artificial intelligence ) event correlation fault management fault tree analysis grey problem \n",
      "Cleaned Token After Stem =  solut . bayesian network complex event process diagnosi ( artifici intellig ) event correl fault manag fault tree analysi grey problem \n",
      "Cleaned Token Before =  portal provides online training and certifications related to artificial intelligence, cyber security, cloud computing, project management, digital marketing\n",
      "Cleaned Token After =  portal provides online training certifications related artificial intelligence , cyber security , cloud computing , project management , digital marketing \n",
      "Cleaned Token After Stem =  portal provid onlin train certif relat artifici intellig , cyber secur , cloud comput , project manag , digit market \n",
      "Cleaned Token Before =  directions of ai in puerto rico, resulting in an open letter on artificial intelligence signed by research leaders worldwide calling for research on ensuring\n",
      "Cleaned Token After =  directions ai puerto rico , resulting open letter artificial intelligence signed research leaders worldwide calling research ensuring \n",
      "Cleaned Token After Stem =  direct ai puerto rico , result open letter artifici intellig sign research leader worldwid call research ensur \n",
      "Cleaned Token Before =  google assistant is an artificial intelligence–powered virtual assistant developed by google that is primarily available on mobile and smart home devices\n",
      "Cleaned Token After =  google assistant artificial intelligence–powered virtual assistant developed google primarily available mobile smart home devices \n",
      "Cleaned Token After Stem =  googl assist artifici intelligence–pow virtual assist develop googl primarili avail mobil smart home devic \n",
      "Cleaned Token Before =  façade is an artificial-intelligence-based interactive story created by michael mateas and andrew stern. it was the winner of the grand jury prize at\n",
      "Cleaned Token After =  façade artificial-intelligence-based interactive story created michael mateas andrew stern . winner grand jury prize \n",
      "Cleaned Token After Stem =  façad artificial-intelligence-bas interact stori creat michael matea andrew stern . winner grand juri prize \n",
      "Cleaned Token Before =  multi-agent learning is the answer, what is the question?\" (pdf). artificial intelligence. foundations of multi-agent learning. 171 (7): 365–377. doi:10\n",
      "Cleaned Token After =  multi-agent learning answer , question ? '' ( pdf ) . artificial intelligence . foundations multi-agent learning . 171 ( 7 ) : 365–377 . doi:10 \n",
      "Cleaned Token After Stem =  multi-ag learn answer , question ? `` ( pdf ) . artifici intellig . foundat multi-ag learn . 171 ( 7 ) : 365–377 . doi:10 \n",
      "Cleaned Token Before =  holder of the 3com founders chair at the mit computer science and artificial intelligence laboratory (csail). he is a director of the web science research\n",
      "Cleaned Token After =  holder 3com founders chair mit computer science artificial intelligence laboratory ( csail ) . director web science research \n",
      "Cleaned Token After Stem =  holder 3com founder chair mit comput scienc artifici intellig laboratori ( csail ) . director web scienc research \n",
      "Cleaned Token Before =  intergenerational upgrade method to gradually form a complete artificial intelligence system to eq. in july 2018, microsoft xiaoice has evolved to the\n",
      "Cleaned Token After =  intergenerational upgrade method gradually form complete artificial intelligence system eq . july 2018 , microsoft xiaoice evolved \n",
      "Cleaned Token After Stem =  intergener upgrad method gradual form complet artifici intellig system eq . juli 2018 , microsoft xiaoic evolv \n",
      "Cleaned Token Before =  1993 by plus 8 and warp, serving as the fifth album in warp's artificial intelligence series. fact described dimension intrusion as \"a record which really\n",
      "Cleaned Token After =  1993 plus 8 warp , serving fifth album warp 's artificial intelligence series . fact described dimension intrusion `` record really \n",
      "Cleaned Token After Stem =  1993 plu 8 warp , serv fifth album warp 's artifici intellig seri . fact describ dimens intrus `` record realli \n",
      "Cleaned Token Before =  nature of work, either quantitatively or qualitatively, such as artificial intelligence (in particular, the sub-discipline of ai planning) and ethnography\n",
      "Cleaned Token After =  nature work , either quantitatively qualitatively , artificial intelligence ( particular , sub-discipline ai planning ) ethnography \n",
      "Cleaned Token After Stem =  natur work , either quantit qualit , artifici intellig ( particular , sub-disciplin ai plan ) ethnographi \n",
      "Cleaned Token Before =  and corporations to develop and deliver certificate programs in artificial intelligence & machine learning, blockchain, fintech, and emerging tech. talentsprint\n",
      "Cleaned Token After =  corporations develop deliver certificate programs artificial intelligence & machine learning , blockchain , fintech , emerging tech . talentsprint \n",
      "Cleaned Token After Stem =  corpor develop deliv certif program artifici intellig & machin learn , blockchain , fintech , emerg tech . talentsprint \n",
      "Cleaned Token Before =  bear. it deals with themes including cyclic time, artificial intelligence, artificial life, and artificial structures of planetary scale. in the novel, \"young\"\n",
      "Cleaned Token After =  bear . deals themes including cyclic time , artificial intelligence , artificial life , artificial structures planetary scale . novel , `` young '' \n",
      "Cleaned Token After Stem =  bear . deal theme includ cyclic time , artifici intellig , artifici life , artifici structur planetari scale . novel , `` young `` \n",
      "Cleaned Token Before =  professor at mcgill university. she is the lead of facebook's artificial intelligence research lab (fair) in montreal, quebec. pineau was born in ottawa\n",
      "Cleaned Token After =  professor mcgill university . lead facebook 's artificial intelligence research lab ( fair ) montreal , quebec . pineau born ottawa \n",
      "Cleaned Token After Stem =  professor mcgill univers . lead facebook 's artifici intellig research lab ( fair ) montreal , quebec . pineau born ottawa \n",
      "Cleaned Token Before =  in artificial intelligence, hierarchical task network (htn) planning is an approach to automated planning in which the dependency among actions can be\n",
      "Cleaned Token After =  artificial intelligence , hierarchical task network ( htn ) planning approach automated planning dependency among actions \n",
      "Cleaned Token After Stem =  artifici intellig , hierarch task network ( htn ) plan approach autom plan depend among action \n",
      "Cleaned Token Before =  procedures. artificial intelligence, vol. 14, no. 2 murray campbell, tony marsland (1983). a comparison of minimax tree search algorithms. artificial intelligence\n",
      "Cleaned Token After =  procedures . artificial intelligence , vol . 14 , . 2 murray campbell , tony marsland ( 1983 ) . comparison minimax tree search algorithms . artificial intelligence \n",
      "Cleaned Token After Stem =  procedur . artifici intellig , vol . 14 , . 2 murray campbel , toni marsland ( 1983 ) . comparison minimax tree search algorithm . artifici intellig \n",
      "Cleaned Token Before =  facm faaas faaai feurai is a laureate fellow, and professor of artificial intelligence in the unsw school of computer science and engineering at the university\n",
      "Cleaned Token After =  facm faaas faaai feurai laureate fellow , professor artificial intelligence unsw school computer science engineering university \n",
      "Cleaned Token After Stem =  facm faaa faaai feurai laureat fellow , professor artifici intellig unsw school comput scienc engin univers \n",
      "Cleaned Token Before =  distributed intelligence may refer to: group mind (science fiction) collective intelligence, superorganism distributed artificial intelligence, innovation\n",
      "Cleaned Token After =  distributed intelligence may refer : group mind ( science fiction ) collective intelligence , superorganism distributed artificial intelligence , innovation \n",
      "Cleaned Token After Stem =  distribut intellig may refer : group mind ( scienc fiction ) collect intellig , superorgan distribut artifici intellig , innov \n",
      "Cleaned Token Before =  hosted several expert discussion panels, on subjects including artificial intelligence, life extension, art and transhumanism, and cryptocurrencies. chairman\n",
      "Cleaned Token After =  hosted several expert discussion panels , subjects including artificial intelligence , life extension , art transhumanism , cryptocurrencies . chairman \n",
      "Cleaned Token After Stem =  host sever expert discuss panel , subject includ artifici intellig , life extens , art transhuman , cryptocurr . chairman \n",
      "Cleaned Token Before =  five-year collaboration agreement with the mit computer science and artificial intelligence laboratory. in 2020, the agreement was terminated due to human\n",
      "Cleaned Token After =  five-year collaboration agreement mit computer science artificial intelligence laboratory . 2020 , agreement terminated due human \n",
      "Cleaned Token After Stem =  five-year collabor agreement mit comput scienc artifici intellig laboratori . 2020 , agreement termin due human \n",
      "Cleaned Token Before =  cyberinfrastructure-based digital libraries. with the upcoming of artificial intelligence in data science it has become increasingly important for automation\n",
      "Cleaned Token After =  cyberinfrastructure-based digital libraries . upcoming artificial intelligence data science become increasingly important automation \n",
      "Cleaned Token After Stem =  cyberinfrastructure-bas digit librari . upcom artifici intellig data scienc becom increasingli import autom \n",
      "Cleaned Token Before =  was also the founder of the allen institutes for brain science, artificial intelligence and cell science, as well as companies like stratolaunch systems\n",
      "Cleaned Token After =  also founder allen institutes brain science , artificial intelligence cell science , well companies like stratolaunch systems \n",
      "Cleaned Token After Stem =  also founder allen institut brain scienc , artifici intellig cell scienc , well compani like stratolaunch system \n",
      "Cleaned Token Before =  1960s, computer vision began at universities which were pioneering artificial intelligence. it was meant to mimic the human visual system, as a stepping stone\n",
      "Cleaned Token After =  1960s , computer vision began universities pioneering artificial intelligence . meant mimic human visual system , stepping stone \n",
      "Cleaned Token After Stem =  1960 , comput vision began univers pioneer artifici intellig . meant mimic human visual system , step stone \n",
      "Cleaned Token Before =  time-sharing operating system developed principally by the mit artificial intelligence laboratory, with help from project mac. the name is the jocular\n",
      "Cleaned Token After =  time-sharing operating system developed principally mit artificial intelligence laboratory , help project mac . name jocular \n",
      "Cleaned Token After Stem =  time-shar oper system develop princip mit artifici intellig laboratori , help project mac . name jocular \n",
      "Cleaned Token Before =  micropsi framework. in proceedings of the fifth conference on artificial general intelligence (agi 2012), oxford, uk: pp. 11-20, 2012, springer lnai, vol\n",
      "Cleaned Token After =  micropsi framework . proceedings fifth conference artificial general intelligence ( agi 2012 ) , oxford , uk : pp . 11-20 , 2012 , springer lnai , vol \n",
      "Cleaned Token After Stem =  micropsi framework . proceed fifth confer artifici gener intellig ( agi 2012 ) , oxford , uk : pp . 11-20 , 2012 , springer lnai , vol \n",
      "Cleaned Token Before =  aspects of recruitment have become widespread, including the use of artificial intelligence (ai). job analysis for new jobs or substantially changed jobs.\n",
      "Cleaned Token After =  aspects recruitment become widespread , including use artificial intelligence ( ai ) . job analysis new jobs substantially changed jobs . \n",
      "Cleaned Token After Stem =  aspect recruit becom widespread , includ use artifici intellig ( ai ) . job analysi new job substanti chang job . \n",
      "Cleaned Token Before =  as having broad impact on the fields of cognitive psychology, artificial intelligence, and education. collins is most well known in psychology for his\n",
      "Cleaned Token After =  broad impact fields cognitive psychology , artificial intelligence , education . collins well known psychology \n",
      "Cleaned Token After Stem =  broad impact field cognit psycholog , artifici intellig , educ . collin well known psycholog \n",
      "Cleaned Token Before =  classic paper award from the association for the advancement of artificial intelligence (aaai) in 2018. noy served as president of the semantic web sciences\n",
      "Cleaned Token After =  classic paper award association advancement artificial intelligence ( aaai ) 2018. noy served president semantic web sciences \n",
      "Cleaned Token After Stem =  classic paper award associ advanc artifici intellig ( aaai ) 2018. noy serv presid semant web scienc \n",
      "Cleaned Token Before =  global summits, that fosters the dialogue on the beneficial use of artificial intelligence, by developing concrete projects. the impetus for organizing global\n",
      "Cleaned Token After =  global summits , fosters dialogue beneficial use artificial intelligence , developing concrete projects . impetus organizing global \n",
      "Cleaned Token After Stem =  global summit , foster dialogu benefici use artifici intellig , develop concret project . impetu organ global \n",
      "Cleaned Token Before =  november 2020). \"documentary 'coded bias' unmasks the racism of artificial intelligence\". wbur. retrieved 5 april 2021. trenholm, richard (31 march 2021)\n",
      "Cleaned Token After =  november 2020 ) . `` documentary 'coded bias ' unmasks racism artificial intelligence '' . wbur . retrieved 5 april 2021. trenholm , richard ( 31 march 2021 ) \n",
      "Cleaned Token After Stem =  novemb 2020 ) . `` documentari 'code bia ' unmask racism artifici intellig `` . wbur . retriev 5 april 2021. trenholm , richard ( 31 march 2021 ) \n",
      "Cleaned Token Before =  decision theories, and in knowledge representation and planning in artificial intelligence. it is also closely identified with prima facie (presumptive) reasoning\n",
      "Cleaned Token After =  decision theories , knowledge representation planning artificial intelligence . also closely identified prima facie ( presumptive ) reasoning \n",
      "Cleaned Token After Stem =  decis theori , knowledg represent plan artifici intellig . also close identifi prima faci ( presumpt ) reason \n",
      "Cleaned Token Before =  ai chair. her research is in the areas of computer vision and artificial intelligence. fidler attended the university of ljubljana, where she received\n",
      "Cleaned Token After =  ai chair . research areas computer vision artificial intelligence . fidler attended university ljubljana , received \n",
      "Cleaned Token After Stem =  ai chair . research area comput vision artifici intellig . fidler attend univers ljubljana , receiv \n",
      "Cleaned Token Before =  wetware computer is an organic computer (which can also be known as an artificial organic brain or a neurocomputer) composed of organic material such as\n",
      "Cleaned Token After =  wetware computer organic computer ( also known artificial organic brain neurocomputer ) composed organic material \n",
      "Cleaned Token After Stem =  wetwar comput organ comput ( also known artifici organ brain neurocomput ) compos organ materi \n",
      "Cleaned Token Before =  humans will not be enhanced, but rather eventually replaced by artificial intelligences. some philosophers, including nick land, promote the view that\n",
      "Cleaned Token After =  humans enhanced , rather eventually replaced artificial intelligences . philosophers , including nick land , promote view \n",
      "Cleaned Token After Stem =  human enhanc , rather eventu replac artifici intellig . philosoph , includ nick land , promot view \n",
      "Cleaned Token Before =  performance and to provide a platform for future developments in artificial intelligence. there was also an unrelated russian project also named as a fifth-generation\n",
      "Cleaned Token After =  performance provide platform future developments artificial intelligence . also unrelated russian project also named fifth-generation \n",
      "Cleaned Token After Stem =  perform provid platform futur develop artifici intellig . also unrel russian project also name fifth-gener \n",
      "Cleaned Token Before =  areas, including marketing, product engineering, computer science, artificial intelligence, economics, communication science, media economics, cognitive science\n",
      "Cleaned Token After =  areas , including marketing , product engineering , computer science , artificial intelligence , economics , communication science , media economics , cognitive science \n",
      "Cleaned Token After Stem =  area , includ market , product engin , comput scienc , artifici intellig , econom , commun scienc , media econom , cognit scienc \n",
      "Cleaned Token Before =  logical reasoning and physical action. shakey was developed at the artificial intelligence center of stanford research institute (now called sri international)\n",
      "Cleaned Token After =  logical reasoning physical action . shakey developed artificial intelligence center stanford research institute ( called sri international ) \n",
      "Cleaned Token After Stem =  logic reason physic action . shakey develop artifici intellig center stanford research institut ( call sri intern ) \n",
      "Cleaned Token Before =  opposed by rival deckers and lethal, potentially brain-destroying artificial intelligences called \"intrusion countermeasures\" – \"ic\" for short – who are protected\n",
      "Cleaned Token After =  opposed rival deckers lethal , potentially brain-destroying artificial intelligences called `` intrusion countermeasures '' – `` ic '' short – protected \n",
      "Cleaned Token After Stem =  oppos rival decker lethal , potenti brain-destroy artifici intellig call `` intrus countermeasur `` – `` ic `` short – protect \n",
      "Cleaned Token Before =  are applied. he draws from his experience as the founder of an artificial intelligence startup. jim stolze is an active leader in the tedx community.\n",
      "Cleaned Token After =  applied . draws experience founder artificial intelligence startup . jim stolze active leader tedx community . \n",
      "Cleaned Token After Stem =  appli . draw experi founder artifici intellig startup . jim stolz activ leader tedx commun . \n",
      "Cleaned Token Before =  on the shorter computable theories. marcus hutter's universal artificial intelligence builds upon this to calculate the expected value of an action.\n",
      "Cleaned Token After =  shorter computable theories . marcus hutter 's universal artificial intelligence builds upon calculate expected value action . \n",
      "Cleaned Token After Stem =  shorter comput theori . marcu hutter 's univers artifici intellig build upon calcul expect valu action . \n",
      "Cleaned Token Before =  penrose's gödelian case against artificial intelligence. journal of experimental and theoretical artificial intelligence 12: 307–329. the authors write\n",
      "Cleaned Token After =  penrose 's gödelian case artificial intelligence . journal experimental theoretical artificial intelligence 12 : 307–329 . authors write \n",
      "Cleaned Token After Stem =  penros 's gödelian case artifici intellig . journal experiment theoret artifici intellig 12 : 307–329 . author write \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Token Before =  esa currently has plans to launch a satellite equipped with an artificial intelligence (ai) processor that will allow the spacecraft to make decisions\n",
      "Cleaned Token After =  esa currently plans launch satellite equipped artificial intelligence ( ai ) processor allow spacecraft make decisions \n",
      "Cleaned Token After Stem =  esa current plan launch satellit equip artifici intellig ( ai ) processor allow spacecraft make decis \n",
      "Cleaned Token Before =  soar architecture for artificial intelligence. logic theorist nils j. nilsson (30 october 2009). the quest for artificial intelligence. cambridge university\n",
      "Cleaned Token After =  soar architecture artificial intelligence . logic theorist nils j. nilsson ( 30 october 2009 ) . quest artificial intelligence . cambridge university \n",
      "Cleaned Token After Stem =  soar architectur artifici intellig . logic theorist nil j. nilsson ( 30 octob 2009 ) . quest artifici intellig . cambridg univers \n",
      "Cleaned Token Before =  allis (1994). \"phd thesis: searching for solutions in games and artificial intelligence\" (pdf). department of computer science. university of limburg.\n",
      "Cleaned Token After =  allis ( 1994 ) . `` phd thesis : searching solutions games artificial intelligence '' ( pdf ) . department computer science . university limburg . \n",
      "Cleaned Token After Stem =  alli ( 1994 ) . `` phd thesi : search solut game artifici intellig `` ( pdf ) . depart comput scienc . univers limburg . \n",
      "Cleaned Token Before =  university in evanston, illinois, united states. in 2012, while at the artificial intelligence laboratory of the university of zurich kaufmann initiated and developed\n",
      "Cleaned Token After =  university evanston , illinois , united states . 2012 , artificial intelligence laboratory university zurich kaufmann initiated developed \n",
      "Cleaned Token After Stem =  univers evanston , illinoi , unit state . 2012 , artifici intellig laboratori univers zurich kaufmann initi develop \n",
      "Cleaned Token Before =  symbol system hypothesis (pssh) is a position in the philosophy of artificial intelligence formulated by allen newell and herbert a. simon. they wrote: \"a\n",
      "Cleaned Token After =  symbol system hypothesis ( pssh ) position philosophy artificial intelligence formulated allen newell herbert a. simon . wrote : `` \n",
      "Cleaned Token After Stem =  symbol system hypothesi ( pssh ) posit philosophi artifici intellig formul allen newel herbert a. simon . wrote : `` \n",
      "Cleaned Token Before =   his research on financial markets statistical reasoning, and artificial intelligence, often involves stock market anomalies, statistical fallacies,\n",
      "Cleaned Token After =  research financial markets statistical reasoning , artificial intelligence , often involves stock market anomalies , statistical fallacies , \n",
      "Cleaned Token After Stem =  research financi market statist reason , artifici intellig , often involv stock market anomali , statist fallaci , \n",
      "Cleaned Token Before =  expert. he is also the ceo of franz inc, an early innovator in artificial intelligence and provider of semantic graph databases and analytics. he is a\n",
      "Cleaned Token After =  expert . also ceo franz inc , early innovator artificial intelligence provider semantic graph databases analytics . \n",
      "Cleaned Token After Stem =  expert . also ceo franz inc , earli innov artifici intellig provid semant graph databas analyt . \n",
      "Cleaned Token Before =  mobile app and website created by youth laboratories that uses artificial intelligence technology to evaluate people's external appearance through certain\n",
      "Cleaned Token After =  mobile app website created youth laboratories uses artificial intelligence technology evaluate people 's external appearance certain \n",
      "Cleaned Token After Stem =  mobil app websit creat youth laboratori use artifici intellig technolog evalu peopl 's extern appear certain \n",
      "Cleaned Token Before =  a recurrent neural network (rnn) is a class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence\n",
      "Cleaned Token After =  recurrent neural network ( rnn ) class artificial neural networks connections nodes form directed graph along temporal sequence \n",
      "Cleaned Token After Stem =  recurr neural network ( rnn ) class artifici neural network connect node form direct graph along tempor sequenc \n",
      "Cleaned Token Before =  the late 1960s as part of hewitt's doctoral research in mit's artificial intelligence laboratory. hewitt's work on planner introduced the notion of the\n",
      "Cleaned Token After =  late 1960s part hewitt 's doctoral research mit 's artificial intelligence laboratory . hewitt 's work planner introduced notion \n",
      "Cleaned Token After Stem =  late 1960 part hewitt 's doctor research mit 's artifici intellig laboratori . hewitt 's work planner introduc notion \n",
      "Cleaned Token Before =  vectra ai, inc. applies artificial intelligence that detects and responds to hidden cyberattackers inside cloud, data center and enterprise networks.\n",
      "Cleaned Token After =  vectra ai , inc. applies artificial intelligence detects responds hidden cyberattackers inside cloud , data center enterprise networks . \n",
      "Cleaned Token After Stem =  vectra ai , inc. appli artifici intellig detect respond hidden cyberattack insid cloud , data center enterpris network . \n",
      "Cleaned Token Before =  in artificial intelligence, a procedural reasoning system (prs) is a framework for constructing real-time reasoning systems that can perform complex tasks\n",
      "Cleaned Token After =  artificial intelligence , procedural reasoning system ( prs ) framework constructing real-time reasoning systems perform complex tasks \n",
      "Cleaned Token After Stem =  artifici intellig , procedur reason system ( pr ) framework construct real-tim reason system perform complex task \n",
      "Cleaned Token Before =  models used in artificial intelligence. it is compatible with a number of open-source programming frameworks popularly used in artificial neural networks\n",
      "Cleaned Token After =  models used artificial intelligence . compatible number open-source programming frameworks popularly used artificial neural networks \n",
      "Cleaned Token After Stem =  model use artifici intellig . compat number open-sourc program framework popularli use artifici neural network \n",
      "Cleaned Token Before =  people to achieve similar benefits by forming \"artificial swarms\" online. known as artificial swarm intelligence (asi), the core technology enables groups\n",
      "Cleaned Token After =  people achieve similar benefits forming `` artificial swarms '' online . known artificial swarm intelligence ( asi ) , core technology enables groups \n",
      "Cleaned Token After Stem =  peopl achiev similar benefit form `` artifici swarm `` onlin . known artifici swarm intellig ( asi ) , core technolog enabl group \n",
      "Cleaned Token Before =  of psychology, cognitive science, computational neuroscience, artificial intelligence (ai), computer science and the emerging field of web science. shadbolt\n",
      "Cleaned Token After =  psychology , cognitive science , computational neuroscience , artificial intelligence ( ai ) , computer science emerging field web science . shadbolt \n",
      "Cleaned Token After Stem =  psycholog , cognit scienc , comput neurosci , artifici intellig ( ai ) , comput scienc emerg field web scienc . shadbolt \n",
      "Cleaned Token Before =  in artificial intelligence, especially computer vision and artificial neural networks, a hard sigmoid is non-smooth function used in place of a sigmoid\n",
      "Cleaned Token After =  artificial intelligence , especially computer vision artificial neural networks , hard sigmoid non-smooth function used place sigmoid \n",
      "Cleaned Token After Stem =  artifici intellig , especi comput vision artifici neural network , hard sigmoid non-smooth function use place sigmoid \n",
      "Cleaned Token Before =  demons, angels), non-humans (monsters, aliens, elves), or artificial life (artificial intelligence, robots). this list comprises people claimed to achieve\n",
      "Cleaned Token After =  demons , angels ) , non-humans ( monsters , aliens , elves ) , artificial life ( artificial intelligence , robots ) . list comprises people claimed achieve \n",
      "Cleaned Token After Stem =  demon , angel ) , non-human ( monster , alien , elv ) , artifici life ( artifici intellig , robot ) . list compris peopl claim achiev \n",
      "Cleaned Token Before =  in artificial intelligence, knowledge-based agents draw on a pool of logical sentences to infer conclusions about the world. at the knowledge level, we\n",
      "Cleaned Token After =  artificial intelligence , knowledge-based agents draw pool logical sentences infer conclusions world . knowledge level , \n",
      "Cleaned Token After Stem =  artifici intellig , knowledge-bas agent draw pool logic sentenc infer conclus world . knowledg level , \n",
      "Cleaned Token Before =  history of violence (2005). other notable recent films include a.i. artificial intelligence (2001), the village (2004), syriana (2005), the good shepherd (2006)\n",
      "Cleaned Token After =  history violence ( 2005 ) . notable recent films include a.i . artificial intelligence ( 2001 ) , village ( 2004 ) , syriana ( 2005 ) , good shepherd ( 2006 ) \n",
      "Cleaned Token After Stem =  histori violenc ( 2005 ) . notabl recent film includ a.i . artifici intellig ( 2001 ) , villag ( 2004 ) , syriana ( 2005 ) , good shepherd ( 2006 ) \n",
      "Cleaned Token Before =  book is the center of a long-standing controversy in the study of artificial intelligence. it is claimed that pessimistic predictions made by the authors\n",
      "Cleaned Token After =  book center long-standing controversy study artificial intelligence . claimed pessimistic predictions made authors \n",
      "Cleaned Token After Stem =  book center long-stand controversi studi artifici intellig . claim pessimist predict made author \n",
      "Cleaned Token Before =  data. these data are then used for training machine learning and artificial intelligence algorithms that lie behind self-driving vehicles, computer vision\n",
      "Cleaned Token After =  data . data used training machine learning artificial intelligence algorithms lie behind self-driving vehicles , computer vision \n",
      "Cleaned Token After Stem =  data . data use train machin learn artifici intellig algorithm lie behind self-driv vehicl , comput vision \n",
      "Cleaned Token Before =  microsoft launched azure iot edge, used to run azure services and artificial intelligence on iot devices. on november 20, 2018, microsoft launched the open\n",
      "Cleaned Token After =  microsoft launched azure iot edge , used run azure services artificial intelligence iot devices . november 20 , 2018 , microsoft launched open \n",
      "Cleaned Token After Stem =  microsoft launch azur iot edg , use run azur servic artifici intellig iot devic . novemb 20 , 2018 , microsoft launch open \n",
      "Cleaned Token Before =  checker symbolic-numeric computation symbolic simulation symbolic artificial intelligence \"acm association in computer algebra\". watt, stephen m. (2006)\n",
      "Cleaned Token After =  checker symbolic-numeric computation symbolic simulation symbolic artificial intelligence `` acm association computer algebra '' . watt , stephen m. ( 2006 ) \n",
      "Cleaned Token After Stem =  checker symbolic-numer comput symbol simul symbol artifici intellig `` acm associ comput algebra `` . watt , stephen m. ( 2006 ) \n",
      "Cleaned Token Before =  wheatley is a fictional artificial intelligence from the portal franchise first introduced in the 2011 video game portal 2. he is voiced by british comedian\n",
      "Cleaned Token After =  wheatley fictional artificial intelligence portal franchise first introduced 2011 video game portal 2. voiced british comedian \n",
      "Cleaned Token After Stem =  wheatley fiction artifici intellig portal franchis first introduc 2011 video game portal 2. voic british comedian \n",
      "Cleaned Token Before =  a wide variety of areas, particularly scientific computing and artificial intelligence. most differentiable programming frameworks work by constructing\n",
      "Cleaned Token After =  wide variety areas , particularly scientific computing artificial intelligence . differentiable programming frameworks work constructing \n",
      "Cleaned Token After Stem =  wide varieti area , particularli scientif comput artifici intellig . differenti program framework work construct \n",
      "Cleaned Token Before =  recognition when they were featured on warp's 1992 compilation artificial intelligence. influenced by styles such as 1980s synth-pop and hip hop, the\n",
      "Cleaned Token After =  recognition featured warp 's 1992 compilation artificial intelligence . influenced styles 1980s synth-pop hip hop , \n",
      "Cleaned Token After Stem =  recognit featur warp 's 1992 compil artifici intellig . influenc style 1980 synth-pop hip hop , \n",
      "Cleaned Token Before =  command. echelon information awareness office list of notable artificial intelligence projects multi-agent system nsa warrantless surveillance controversy\n",
      "Cleaned Token After =  command . echelon information awareness office list notable artificial intelligence projects multi-agent system nsa warrantless surveillance controversy \n",
      "Cleaned Token After Stem =  command . echelon inform awar offic list notabl artifici intellig project multi-ag system nsa warrantless surveil controversi \n",
      "Cleaned Token Before =  versions of the software. in 2020, f5 acquired shape security, an artificial intelligence-based bot detection company, for $1 billion. it also sells products\n",
      "Cleaned Token After =  versions software . 2020 , f5 acquired shape security , artificial intelligence-based bot detection company , $ 1 billion . also sells products \n",
      "Cleaned Token After Stem =  version softwar . 2020 , f5 acquir shape secur , artifici intelligence-bas bot detect compani , $ 1 billion . also sell product \n",
      "Cleaned Token Before =  specializing in computer vision/artificial intelligence. she spent a year at stanford university artificial intelligence lab with her ph.d. advisor, who\n",
      "Cleaned Token After =  specializing computer vision/artificial intelligence . spent year stanford university artificial intelligence lab ph.d. advisor , \n",
      "Cleaned Token After Stem =  special comput vision/artifici intellig . spent year stanford univers artifici intellig lab ph.d. advisor , \n",
      "Cleaned Token Before =  melee button, rebalanced weapons, and smarter enemy and squad artificial intelligence. certain boss encounters have received adjustments in order to\n",
      "Cleaned Token After =  melee button , rebalanced weapons , smarter enemy squad artificial intelligence . certain boss encounters received adjustments order \n",
      "Cleaned Token After Stem =  mele button , rebalanc weapon , smarter enemi squad artifici intellig . certain boss encount receiv adjust order \n",
      "Cleaned Token Before =  francisco where they partnered with anonymous hackers to build an artificial intelligence capable of analyzing and reproducing art styles of iconic artists\n",
      "Cleaned Token After =  francisco partnered anonymous hackers build artificial intelligence capable analyzing reproducing art styles iconic artists \n",
      "Cleaned Token After Stem =  francisco partner anonym hacker build artifici intellig capabl analyz reproduc art style icon artist \n",
      "Cleaned Token Before =  representation can be used for tasks, such as those related to artificial intelligence or machine learning. semantic decomposition is common in natural\n",
      "Cleaned Token After =  representation used tasks , related artificial intelligence machine learning . semantic decomposition common natural \n",
      "Cleaned Token After Stem =  represent use task , relat artifici intellig machin learn . semant decomposit common natur \n",
      "Cleaned Token Before =  center for digital agriculture and leads aifarms, a $20m national artificial intelligence research institute funded by nifa and nsf. he served as interim\n",
      "Cleaned Token After =  center digital agriculture leads aifarms , $ 20m national artificial intelligence research institute funded nifa nsf . served interim \n",
      "Cleaned Token After Stem =  center digit agricultur lead aifarm , $ 20m nation artifici intellig research institut fund nifa nsf . serv interim \n",
      "Cleaned Token Before =  anthropologists is artificial intelligence. cyber anthropologists study the co-evolutionary relationship between humans and artificial intelligence. this includes\n",
      "Cleaned Token After =  anthropologists artificial intelligence . cyber anthropologists study co-evolutionary relationship humans artificial intelligence . includes \n",
      "Cleaned Token After Stem =  anthropologist artifici intellig . cyber anthropologist studi co-evolutionari relationship human artifici intellig . includ \n",
      "Cleaned Token Before =  subjects are \"staples of cyberpunk and related genres, such as the artificial intelligence\". the novel is representative of dukaj's prose, posing philosophical\n",
      "Cleaned Token After =  subjects `` staples cyberpunk related genres , artificial intelligence '' . novel representative dukaj 's prose , posing philosophical \n",
      "Cleaned Token After Stem =  subject `` stapl cyberpunk relat genr , artifici intellig `` . novel repres dukaj 's prose , pose philosoph \n",
      "Cleaned Token Before =  city's population; the collective intelligence of the city's institutions and social capital; and the artificial intelligence of public and citywide smart\n",
      "Cleaned Token After =  city 's population ; collective intelligence city 's institutions social capital ; artificial intelligence public citywide smart \n",
      "Cleaned Token After Stem =  citi 's popul ; collect intellig citi 's institut social capit ; artifici intellig public citywid smart \n",
      "Cleaned Token Before =  controversial: what does it take for a physical system (such as a mind, or an artificial computer) to perform computations? in other words, under what conditions\n",
      "Cleaned Token After =  controversial : take physical system ( mind , artificial computer ) perform computations ? words , conditions \n",
      "Cleaned Token After Stem =  controversi : take physic system ( mind , artifici comput ) perform comput ? word , condit \n",
      "Cleaned Token Before =  harrison wells's particle accelerator to power it in order to increase his intelligence. while it was a success and he became the smartest man alive, devoe learned\n",
      "Cleaned Token After =  harrison wells 's particle accelerator power order increase intelligence . success became smartest man alive , devoe learned \n",
      "Cleaned Token After Stem =  harrison well 's particl acceler power order increas intellig . success becam smartest man aliv , devo learn \n",
      "Cleaned Token Before =  (automation), the automobile, the computer, the internet, medicine, and artificial intelligence. initially adopting a new gpt within an economy may, before improving\n",
      "Cleaned Token After =  ( automation ) , automobile , computer , internet , medicine , artificial intelligence . initially adopting new gpt within economy may , improving \n",
      "Cleaned Token After Stem =  ( autom ) , automobil , comput , internet , medicin , artifici intellig . initi adopt new gpt within economi may , improv \n",
      "Cleaned Token Before =  generation: core tasks, applications and evaluation\". journal of artificial intelligence research (61): 65–170. goldberg e, driedger n, kittredge r (1994)\n",
      "Cleaned Token After =  generation : core tasks , applications evaluation '' . journal artificial intelligence research ( 61 ) : 65–170 . goldberg e , driedger n , kittredge r ( 1994 ) \n",
      "Cleaned Token After Stem =  gener : core task , applic evalu `` . journal artifici intellig research ( 61 ) : 65–170 . goldberg e , driedger n , kittredg r ( 1994 ) \n",
      "Cleaned Token Before =  named xiaotu was developed by tsinghua university. xiaotu is an artificial intelligence library that allows users to interact with it by talking or chatting\n",
      "Cleaned Token After =  named xiaotu developed tsinghua university . xiaotu artificial intelligence library allows users interact talking chatting \n",
      "Cleaned Token After Stem =  name xiaotu develop tsinghua univers . xiaotu artifici intellig librari allow user interact talk chat \n",
      "Cleaned Token Before =  according to its official website, the game is \"a simulation of an artificial intelligence based on your memories and interaction with the game.\" players\n",
      "Cleaned Token After =  according official website , game `` simulation artificial intelligence based memories interaction game . '' players \n",
      "Cleaned Token After Stem =  accord offici websit , game `` simul artifici intellig base memori interact game . `` player \n",
      "Cleaned Token Before =  science fiction drama real humans, the series explores the themes of artificial intelligence and robotics, focusing on the social, cultural, and psychological\n",
      "Cleaned Token After =  science fiction drama real humans , series explores themes artificial intelligence robotics , focusing social , cultural , psychological \n",
      "Cleaned Token After Stem =  scienc fiction drama real human , seri explor theme artifici intellig robot , focus social , cultur , psycholog \n",
      "Cleaned Token Before =  titled computer power and human reason, which talked about how artificial intelligence is good for the world; however it should never be allowed to make\n",
      "Cleaned Token After =  titled computer power human reason , talked artificial intelligence good world ; however never allowed make \n",
      "Cleaned Token After Stem =  titl comput power human reason , talk artifici intellig good world ; howev never allow make \n",
      "Cleaned Token Before =  machine translation applications statistical machine translation artificial intelligence cache language model computational linguistics computer-assisted\n",
      "Cleaned Token After =  machine translation applications statistical machine translation artificial intelligence cache language model computational linguistics computer-assisted \n",
      "Cleaned Token After Stem =  machin translat applic statist machin translat artifici intellig cach languag model comput linguist computer-assist \n",
      "Cleaned Token Before =  pattern matcher, and is mostly used for research and teaching in artificial intelligence, although it has features sufficient for many other classes of\n",
      "Cleaned Token After =  pattern matcher , mostly used research teaching artificial intelligence , although features sufficient many classes \n",
      "Cleaned Token After Stem =  pattern matcher , mostli use research teach artifici intellig , although featur suffici mani class \n",
      "Cleaned Token Before =  is an internet of things start-up from munich. the company uses artificial intelligence (ai) to develop sensor-based systems that enable predictive maintenance\n",
      "Cleaned Token After =  internet things start-up munich . company uses artificial intelligence ( ai ) develop sensor-based systems enable predictive maintenance \n",
      "Cleaned Token After Stem =  internet thing start-up munich . compani use artifici intellig ( ai ) develop sensor-bas system enabl predict mainten \n",
      "Cleaned Token Before =  engineer. he created metaweb and freebase, led google search and artificial intelligence, was co-founder and cto of the speech recognition company tellme\n",
      "Cleaned Token After =  engineer . created metaweb freebase , led google search artificial intelligence , co-founder cto speech recognition company tellme \n",
      "Cleaned Token After Stem =  engin . creat metaweb freebas , led googl search artifici intellig , co-found cto speech recognit compani tellm \n",
      "Cleaned Token Before =  february 2018, and headed by ceo ben lamm. the company develops artificial intelligence (ai) products, and invests in other ai technologies and ai companies\n",
      "Cleaned Token After =  february 2018 , headed ceo ben lamm . company develops artificial intelligence ( ai ) products , invests ai technologies ai companies \n",
      "Cleaned Token After Stem =  februari 2018 , head ceo ben lamm . compani develop artifici intellig ( ai ) product , invest ai technolog ai compani \n",
      "Cleaned Token Before =  large and varied data sets, or big data. artificial intelligence and machine learning: artificial intelligence (ai) is a field within computer science\n",
      "Cleaned Token After =  large varied data sets , big data . artificial intelligence machine learning : artificial intelligence ( ai ) field within computer science \n",
      "Cleaned Token After Stem =  larg vari data set , big data . artifici intellig machin learn : artifici intellig ( ai ) field within comput scienc \n",
      "Cleaned Token Before =  meanings: biological neural networks interacting with artificial neuronal models, and artificial neural networks with a symbolic part (or, conversely,\n",
      "Cleaned Token After =  meanings : biological neural networks interacting artificial neuronal models , artificial neural networks symbolic part ( , conversely , \n",
      "Cleaned Token After Stem =  mean : biolog neural network interact artifici neuron model , artifici neural network symbol part ( , convers , \n",
      "Cleaned Token Before =  was cited by chinese leader xi jinping as recommended reading on artificial intelligence. his book bank 4.0 was awarded top book by a foreign author in\n",
      "Cleaned Token After =  cited chinese leader xi jinping recommended reading artificial intelligence . book bank 4.0 awarded top book foreign author \n",
      "Cleaned Token After Stem =  cite chines leader xi jinp recommend read artifici intellig . book bank 4.0 award top book foreign author \n",
      "Cleaned Token Before =  real person in order to continue the movie production. modern artificial intelligence, has allowed for the creation of deepfakes. this involves manipulation\n",
      "Cleaned Token After =  real person order continue movie production . modern artificial intelligence , allowed creation deepfakes . involves manipulation \n",
      "Cleaned Token After Stem =  real person order continu movi product . modern artifici intellig , allow creation deepfak . involv manipul \n",
      "Cleaned Token Before =  allen institute for brain science and the allen institute for artificial intelligence were incubated at vulcan inc. started at vulcan inc. in 2001, the\n",
      "Cleaned Token After =  allen institute brain science allen institute artificial intelligence incubated vulcan inc. started vulcan inc. 2001 , \n",
      "Cleaned Token After Stem =  allen institut brain scienc allen institut artifici intellig incub vulcan inc. start vulcan inc. 2001 , \n",
      "Cleaned Token Before =  contexts in online advertising campaigns. dmps may use big data and artificial intelligence algorithms to process and analyze large data sets about users from\n",
      "Cleaned Token After =  contexts online advertising campaigns . dmps may use big data artificial intelligence algorithms process analyze large data sets users \n",
      "Cleaned Token After Stem =  context onlin advertis campaign . dmp may use big data artifici intellig algorithm process analyz larg data set user \n",
      "Cleaned Token Before =  caity lotz and toby stephens as computer scientists who create an artificial intelligence for the british military. in the future, at an underground base\n",
      "Cleaned Token After =  caity lotz toby stephens computer scientists create artificial intelligence british military . future , underground base \n",
      "Cleaned Token After Stem =  caiti lotz tobi stephen comput scientist creat artifici intellig british militari . futur , underground base \n",
      "Cleaned Token Before =  sensors autonomous systems computer science, cognitive science, and artificial intelligence directed energy technology electronic electro-optical device technology\n",
      "Cleaned Token After =  sensors autonomous systems computer science , cognitive science , artificial intelligence directed energy technology electronic electro-optical device technology \n",
      "Cleaned Token After Stem =  sensor autonom system comput scienc , cognit scienc , artifici intellig direct energi technolog electron electro-opt devic technolog \n",
      "Cleaned Token Before =  helen chan wolf is an artificial intelligence pioneer who worked on facial recognition technology at the sri international. wolf worked on the shakey\n",
      "Cleaned Token After =  helen chan wolf artificial intelligence pioneer worked facial recognition technology sri international . wolf worked shakey \n",
      "Cleaned Token After Stem =  helen chan wolf artifici intellig pioneer work facial recognit technolog sri intern . wolf work shakey \n",
      "Cleaned Token Before =   artificial intelligence center. retrieved 2012-03-16. \"david h.d. warren\". alumnus of the artificial intelligence center. artificial intelligence center\n",
      "Cleaned Token After =  artificial intelligence center . retrieved 2012-03-16 . `` david h.d . warren '' . alumnus artificial intelligence center . artificial intelligence center \n",
      "Cleaned Token After Stem =  artifici intellig center . retriev 2012-03-16 . `` david h.d . warren `` . alumnu artifici intellig center . artifici intellig center \n",
      "Cleaned Token Before =  \"depth-first iterative-deepening: an optimal admissible tree search\". artificial intelligence. 27: 97–109. doi:10.1016/0004-3702(85)90084-0. david poole; alan\n",
      "Cleaned Token After =  `` depth-first iterative-deepening : optimal admissible tree search '' . artificial intelligence . 27 : 97–109 . doi:10.1016/0004-3702 ( 85 ) 90084-0. david poole ; alan \n",
      "Cleaned Token After Stem =  `` depth-first iterative-deepen : optim admiss tree search `` . artifici intellig . 27 : 97–109 . doi:10.1016/0004-3702 ( 85 ) 90084-0. david pool ; alan \n",
      "Cleaned Token Before =  checking, automated planning and scheduling, and diagnosis in artificial intelligence. as such, it has been a hot topic in research for many years, and\n",
      "Cleaned Token After =  checking , automated planning scheduling , diagnosis artificial intelligence . , hot topic research many years , \n",
      "Cleaned Token After Stem =  check , autom plan schedul , diagnosi artifici intellig . , hot topic research mani year , \n",
      "Cleaned Token Before =   proc. iasted, artificial intelligence and applications, innsbruck, austria, 2007, 384–389 pdf code infer: computational intelligence platform for evolving\n",
      "Cleaned Token After =  proc . iasted , artificial intelligence applications , innsbruck , austria , 2007 , 384–389 pdf code infer : computational intelligence platform evolving \n",
      "Cleaned Token After Stem =  proc . iast , artifici intellig applic , innsbruck , austria , 2007 , 384–389 pdf code infer : comput intellig platform evolv \n",
      "Cleaned Token Before =  tech fields included advanced materials, advanced manufacturing, artificial intelligence, biotechnology, blockchain, robotics, photonics, electronics, and\n",
      "Cleaned Token After =  tech fields included advanced materials , advanced manufacturing , artificial intelligence , biotechnology , blockchain , robotics , photonics , electronics , \n",
      "Cleaned Token After Stem =  tech field includ advanc materi , advanc manufactur , artifici intellig , biotechnolog , blockchain , robot , photon , electron , \n",
      "Cleaned Token Before =  creating an artificial intelligence through human interaction. the stated purpose of the project is to create an artificial intelligence that is capable\n",
      "Cleaned Token After =  creating artificial intelligence human interaction . stated purpose project create artificial intelligence capable \n",
      "Cleaned Token After Stem =  creat artifici intellig human interact . state purpos project creat artifici intellig capabl \n",
      "Cleaned Token Before =  institutions, medical informatics research focus on applications of artificial intelligence in healthcare and designing medical devices based on embedded systems\n",
      "Cleaned Token After =  institutions , medical informatics research focus applications artificial intelligence healthcare designing medical devices based embedded systems \n",
      "Cleaned Token After Stem =  institut , medic informat research focu applic artifici intellig healthcar design medic devic base embed system \n",
      "Cleaned Token Before =  tromp's work in compiling an 8-ply database (february 4, 1995). the artificial intelligence algorithms able to strongly solve connect four are minimax or negamax\n",
      "Cleaned Token After =  tromp 's work compiling 8-ply database ( february 4 , 1995 ) . artificial intelligence algorithms able strongly solve connect four minimax negamax \n",
      "Cleaned Token After Stem =  tromp 's work compil 8-pli databas ( februari 4 , 1995 ) . artifici intellig algorithm abl strongli solv connect four minimax negamax \n",
      "Cleaned Token Before =  a picture of an object or idea and then uses a neural network artificial intelligence to guess what the drawings represent. the ai learns from each drawing\n",
      "Cleaned Token After =  picture object idea uses neural network artificial intelligence guess drawings represent . ai learns drawing \n",
      "Cleaned Token After Stem =  pictur object idea use neural network artifici intellig guess draw repres . ai learn draw \n",
      "Cleaned Token Before =  entrepreneur and venture capitalist. he is the founder and ceo of artificial intelligence company 42.cx and a judge and business angel on the austrian television\n",
      "Cleaned Token After =  entrepreneur venture capitalist . founder ceo artificial intelligence company 42.cx judge business angel austrian television \n",
      "Cleaned Token After Stem =  entrepreneur ventur capitalist . founder ceo artifici intellig compani 42.cx judg busi angel austrian televis \n",
      "Cleaned Token Before =  cross-platform (linux, mac os x) program written by larry yaeger to evolve artificial intelligence through natural selection and evolutionary algorithms. it uses\n",
      "Cleaned Token After =  cross-platform ( linux , mac os x ) program written larry yaeger evolve artificial intelligence natural selection evolutionary algorithms . uses \n",
      "Cleaned Token After Stem =  cross-platform ( linux , mac os x ) program written larri yaeger evolv artifici intellig natur select evolutionari algorithm . use \n",
      "Cleaned Token Before =  behavior of a given system and is widely used in the fields of artificial intelligence and game theory. for instance, the toy problem vacuum world has\n",
      "Cleaned Token After =  behavior given system widely used fields artificial intelligence game theory . instance , toy problem vacuum world \n",
      "Cleaned Token After Stem =  behavior given system wide use field artifici intellig game theori . instanc , toy problem vacuum world \n",
      "Cleaned Token Before =  lectures, entitled the rise of robots. warwick performs research in artificial intelligence, biomedical engineering, control systems and robotics. much of\n",
      "Cleaned Token After =  lectures , entitled rise robots . warwick performs research artificial intelligence , biomedical engineering , control systems robotics . much \n",
      "Cleaned Token After Stem =  lectur , entitl rise robot . warwick perform research artifici intellig , biomed engin , control system robot . much \n",
      "Cleaned Token Before =  mechatronics. subsumption architecture is a methodology for developing artificial intelligence that is heavily associated with behavior based robotics. this architecture\n",
      "Cleaned Token After =  mechatronics . subsumption architecture methodology developing artificial intelligence heavily associated behavior based robotics . architecture \n",
      "Cleaned Token After Stem =  mechatron . subsumpt architectur methodolog develop artifici intellig heavili associ behavior base robot . architectur \n",
      "Cleaned Token Before =  gestures. it employs a mix off-the-shelf software and customized artificial intelligence algorithms, using a microphone to hear, voice recognition software\n",
      "Cleaned Token After =  gestures . employs mix off-the-shelf software customized artificial intelligence algorithms , using microphone hear , voice recognition software \n",
      "Cleaned Token After Stem =  gestur . employ mix off-the-shelf softwar custom artifici intellig algorithm , use microphon hear , voic recognit softwar \n",
      "Cleaned Token Before =  study of decision-making, including the disciplines of psychology, artificial intelligence, and management science, a fast-and-frugal tree is a type of classification\n",
      "Cleaned Token After =  study decision-making , including disciplines psychology , artificial intelligence , management science , fast-and-frugal tree type classification \n",
      "Cleaned Token After Stem =  studi decision-mak , includ disciplin psycholog , artifici intellig , manag scienc , fast-and-frug tree type classif \n",
      "Cleaned Token Before =  science and artificial intelligence laboratory. massachusetts institute of technology. jaffer, aubrey. \"scm mac\". mit computer science and artificial intelligence\n",
      "Cleaned Token After =  science artificial intelligence laboratory . massachusetts institute technology . jaffer , aubrey . `` scm mac '' . mit computer science artificial intelligence \n",
      "Cleaned Token After Stem =  scienc artifici intellig laboratori . massachusett institut technolog . jaffer , aubrey . `` scm mac `` . mit comput scienc artifici intellig \n",
      "Cleaned Token Before =  sustainability, infrastructural resilience and homeland security, and artificial intelligence and nonlinear dynamics. ganguly has done his schooling from st\n",
      "Cleaned Token After =  sustainability , infrastructural resilience homeland security , artificial intelligence nonlinear dynamics . ganguly done schooling st \n",
      "Cleaned Token After Stem =  sustain , infrastructur resili homeland secur , artifici intellig nonlinear dynam . ganguli done school st \n",
      "Cleaned Token Before =  utilizes \"data mining, statistical methods and artificial intelligence\". deep learning and artificial intelligence are used as tools to help with small-scale\n",
      "Cleaned Token After =  utilizes `` data mining , statistical methods artificial intelligence '' . deep learning artificial intelligence used tools help small-scale \n",
      "Cleaned Token After Stem =  util `` data mine , statist method artifici intellig `` . deep learn artifici intellig use tool help small-scal \n",
      "Cleaned Token Before =  the galaxy is ruled by a benevolent central body of humans and artificial intelligences called the core (a contraction of \"consciousness repository\").\n",
      "Cleaned Token After =  galaxy ruled benevolent central body humans artificial intelligences called core ( contraction `` consciousness repository '' ) . \n",
      "Cleaned Token After Stem =  galaxi rule benevol central bodi human artifici intellig call core ( contract `` conscious repositori `` ) . \n",
      "Cleaned Token Before =  morgan to a world she cannot be allowed to enter. psychologist and artificial intelligence expert dr. alan shapiro arrives to assess morgan and quickly defies\n",
      "Cleaned Token After =  morgan world allowed enter . psychologist artificial intelligence expert dr. alan shapiro arrives assess morgan quickly defies \n",
      "Cleaned Token After Stem =  morgan world allow enter . psychologist artifici intellig expert dr. alan shapiro arriv assess morgan quickli defi \n",
      "Cleaned Token Before =  a committee machine is a type of artificial neural network using a divide and conquer strategy in which the responses of multiple neural networks (experts)\n",
      "Cleaned Token After =  committee machine type artificial neural network using divide conquer strategy responses multiple neural networks ( experts ) \n",
      "Cleaned Token After Stem =  committe machin type artifici neural network use divid conquer strategi respons multipl neural network ( expert ) \n",
      "Cleaned Token Before =  2019.07.809. https://www.machinelearning.ai/artificial-intelligence/presenting-erica-an-artificial-intelligence-clinical-assistant-for-embryo-ranking/\n",
      "Cleaned Token After =  2019.07.809. https : //www.machinelearning.ai/artificial-intelligence/presenting-erica-an-artificial-intelligence-clinical-assistant-for-embryo-ranking/ \n",
      "Cleaned Token After Stem =  2019.07.809. http : //www.machinelearning.ai/artificial-intelligence/presenting-erica-an-artificial-intelligence-clinical-assistant-for-embryo-ranking/ \n",
      "Cleaned Token Before =  is a scientist who researches the nature of sapience, including artificial intelligence. he and his team work to create a sentient computer; he predicts\n",
      "Cleaned Token After =  scientist researches nature sapience , including artificial intelligence . team work create sentient computer ; predicts \n",
      "Cleaned Token After Stem =  scientist research natur sapienc , includ artifici intellig . team work creat sentient comput ; predict \n",
      "Cleaned Token Before =  artificial intelligence in germany and europe and has been named as one of the ten most important researchers in the german artificial intelligence history\n",
      "Cleaned Token After =  artificial intelligence germany europe named one ten important researchers german artificial intelligence history \n",
      "Cleaned Token After Stem =  artifici intellig germani europ name one ten import research german artifici intellig histori \n",
      "Cleaned Token Before =  is a developer kit and pc peripheral which employs the use of artificial intelligence (ai) sensors for computer vision and speech models. it is the successor\n",
      "Cleaned Token After =  developer kit pc peripheral employs use artificial intelligence ( ai ) sensors computer vision speech models . successor \n",
      "Cleaned Token After Stem =  develop kit pc peripher employ use artifici intellig ( ai ) sensor comput vision speech model . successor \n",
      "Cleaned Token Before =  subject to calculations of quality constraints, time, cost, etc.. artificial intelligence or knowledge engineering such as pattern recognition or neural\n",
      "Cleaned Token After =  subject calculations quality constraints , time , cost , etc .. artificial intelligence knowledge engineering pattern recognition neural \n",
      "Cleaned Token After Stem =  subject calcul qualiti constraint , time , cost , etc .. artifici intellig knowledg engin pattern recognit neural \n",
      "Cleaned Token Before =  including predator 2, backdraft, independence day, fight club and a.i. artificial intelligence. he was a second unit director for poetic justice, higher learning\n",
      "Cleaned Token After =  including predator 2 , backdraft , independence day , fight club a.i . artificial intelligence . second unit director poetic justice , higher learning \n",
      "Cleaned Token After Stem =  includ predat 2 , backdraft , independ day , fight club a.i . artifici intellig . second unit director poetic justic , higher learn \n",
      "Cleaned Token Before =  drones to hyper-intelligent minds. artificial intelligences with capabilities measured as a fraction of human intelligence also perform a variety of tasks\n",
      "Cleaned Token After =  drones hyper-intelligent minds . artificial intelligences capabilities measured fraction human intelligence also perform variety tasks \n",
      "Cleaned Token After Stem =  drone hyper-intellig mind . artifici intellig capabl measur fraction human intellig also perform varieti task \n",
      "Cleaned Token Before =  after irwin sobel and gary feldman, colleagues at the stanford artificial intelligence laboratory (sail). sobel and feldman presented the idea of an \"isotropic\n",
      "Cleaned Token After =  irwin sobel gary feldman , colleagues stanford artificial intelligence laboratory ( sail ) . sobel feldman presented idea `` isotropic \n",
      "Cleaned Token After Stem =  irwin sobel gari feldman , colleagu stanford artifici intellig laboratori ( sail ) . sobel feldman present idea `` isotrop \n",
      "Cleaned Token Before =  (sometimes minmax, mm or saddle point) is a decision rule used in artificial intelligence, decision theory, game theory, statistics, and philosophy for minimizing\n",
      "Cleaned Token After =  ( sometimes minmax , mm saddle point ) decision rule used artificial intelligence , decision theory , game theory , statistics , philosophy minimizing \n",
      "Cleaned Token After Stem =  ( sometim minmax , mm saddl point ) decis rule use artifici intellig , decis theori , game theori , statist , philosophi minim \n",
      "Cleaned Token Before =  analysis) methods has been considered as critical advantages. artificial intelligence has also been used to predict msi from the appearance of tumors\n",
      "Cleaned Token After =  analysis ) methods considered critical advantages . artificial intelligence also used predict msi appearance tumors \n",
      "Cleaned Token After Stem =  analysi ) method consid critic advantag . artifici intellig also use predict msi appear tumor \n",
      "Cleaned Token Before =  participated in the 1956 dartmouth summer research project on artificial intelligence. at the 50th year meeting of the dartmouth conference with marvin\n",
      "Cleaned Token After =  participated 1956 dartmouth summer research project artificial intelligence . 50th year meeting dartmouth conference marvin \n",
      "Cleaned Token After Stem =  particip 1956 dartmouth summer research project artifici intellig . 50th year meet dartmouth confer marvin \n",
      "Cleaned Token Before =  machine learning (ml) is the study of computer algorithms that improve automatically through experience and by the use of data. it is seen as a part of\n",
      "Cleaned Token After =  machine learning ( ml ) study computer algorithms improve automatically experience use data . seen part \n",
      "Cleaned Token After Stem =  machin learn ( ml ) studi comput algorithm improv automat experi use data . seen part \n",
      "Cleaned Token Before =  active learning is a special case of machine learning in which a learning algorithm can interactively query a user (or some other information source) to\n",
      "Cleaned Token After =  active learning special case machine learning learning algorithm interactively query user ( information source ) \n",
      "Cleaned Token After Stem =  activ learn special case machin learn learn algorithm interact queri user ( inform sourc ) \n",
      "Cleaned Token Before =  in machine learning, a hyperparameter is a parameter whose value is used to control the learning process. by contrast, the values of other parameters\n",
      "Cleaned Token After =  machine learning , hyperparameter parameter whose value used control learning process . contrast , values parameters \n",
      "Cleaned Token After Stem =  machin learn , hyperparamet paramet whose valu use control learn process . contrast , valu paramet \n",
      "Cleaned Token Before =  automated machine learning (automl) is the process of automating the tasks of applying machine learning to real-world problems. automl covers the complete\n",
      "Cleaned Token After =  automated machine learning ( automl ) process automating tasks applying machine learning real-world problems . automl covers complete \n",
      "Cleaned Token After Stem =  autom machin learn ( automl ) process autom task appli machin learn real-world problem . automl cover complet \n",
      "Cleaned Token Before =  deep learning (also known as deep structured learning) is part of a broader family of machine learning methods based on artificial neural networks with\n",
      "Cleaned Token After =  deep learning ( also known deep structured learning ) part broader family machine learning methods based artificial neural networks \n",
      "Cleaned Token After Stem =  deep learn ( also known deep structur learn ) part broader famili machin learn method base artifici neural network \n",
      "Cleaned Token Before =  quantum machine learning is the integration of quantum algorithms within machine learning programs. the most common use of the term refers to machine learning\n",
      "Cleaned Token After =  quantum machine learning integration quantum algorithms within machine learning programs . common use term refers machine learning \n",
      "Cleaned Token After Stem =  quantum machin learn integr quantum algorithm within machin learn program . common use term refer machin learn \n",
      "Cleaned Token Before =  for machine-learning research and have been cited in peer-reviewed academic journals. datasets are an integral part of the field of machine learning. major\n",
      "Cleaned Token After =  machine-learning research cited peer-reviewed academic journals . datasets integral part field machine learning . major \n",
      "Cleaned Token After Stem =  machine-learn research cite peer-review academ journal . dataset integr part field machin learn . major \n",
      "Cleaned Token Before =  in machine learning, boosting is an ensemble meta-algorithm for primarily reducing bias, and also variance in supervised learning, and a family of machine\n",
      "Cleaned Token After =  machine learning , boosting ensemble meta-algorithm primarily reducing bias , also variance supervised learning , family machine \n",
      "Cleaned Token After Stem =  machin learn , boost ensembl meta-algorithm primarili reduc bia , also varianc supervis learn , famili machin \n",
      "Cleaned Token Before =  adversarial machine learning is a machine learning technique that attempts to fool models by supplying deceptive input. the most common reason is to cause\n",
      "Cleaned Token After =  adversarial machine learning machine learning technique attempts fool models supplying deceptive input . common reason cause \n",
      "Cleaned Token After Stem =  adversari machin learn machin learn techniqu attempt fool model suppli decept input . common reason caus \n",
      "Cleaned Token Before =  supervised learning (sl) is the machine learning task of learning a function that maps an input to an output based on example input-output pairs. it infers\n",
      "Cleaned Token After =  supervised learning ( sl ) machine learning task learning function maps input output based example input-output pairs . infers \n",
      "Cleaned Token After Stem =  supervis learn ( sl ) machin learn task learn function map input output base exampl input-output pair . infer \n",
      "Cleaned Token Before =  in computer science, online machine learning is a method of machine learning in which data becomes available in a sequential order and is used to update\n",
      "Cleaned Token After =  computer science , online machine learning method machine learning data becomes available sequential order used update \n",
      "Cleaned Token After Stem =  comput scienc , onlin machin learn method machin learn data becom avail sequenti order use updat \n",
      "Cleaned Token Before =  in machine learning, support-vector machines (svms, also support-vector networks) are supervised learning models with associated learning algorithms that\n",
      "Cleaned Token After =  machine learning , support-vector machines ( svms , also support-vector networks ) supervised learning models associated learning algorithms \n",
      "Cleaned Token After Stem =  machin learn , support-vector machin ( svm , also support-vector network ) supervis learn model associ learn algorithm \n",
      "Cleaned Token Before =  the transformer is a deep learning model introduced in 2017 that utilizes the mechanism of attention, weighing the influence of different parts of the\n",
      "Cleaned Token After =  transformer deep learning model introduced 2017 utilizes mechanism attention , weighing influence different parts \n",
      "Cleaned Token After Stem =  transform deep learn model introduc 2017 util mechan attent , weigh influenc differ part \n",
      "Cleaned Token Before =  license, and the companion software to the book \"data mining: practical machine learning tools and techniques\". weka contains a collection of visualization\n",
      "Cleaned Token After =  license , companion software book `` data mining : practical machine learning tools techniques '' . weka contains collection visualization \n",
      "Cleaned Token After Stem =  licens , companion softwar book `` data mine : practic machin learn tool techniqu `` . weka contain collect visual \n",
      "Cleaned Token Before =  in machine learning and pattern recognition, a feature is an individual measurable property or characteristic of a phenomenon being observed. choosing\n",
      "Cleaned Token After =  machine learning pattern recognition , feature individual measurable property characteristic phenomenon observed . choosing \n",
      "Cleaned Token After Stem =  machin learn pattern recognit , featur individu measur properti characterist phenomenon observ . choos \n",
      "Cleaned Token Before =  learning machines are feedforward neural networks for classification, regression, clustering, sparse approximation, compression and feature learning with\n",
      "Cleaned Token After =  learning machines feedforward neural networks classification , regression , clustering , sparse approximation , compression feature learning \n",
      "Cleaned Token After Stem =  learn machin feedforward neural network classif , regress , cluster , spars approxim , compress featur learn \n",
      "Cleaned Token Before =  of machine learning. major discoveries, achievements, milestones and other major events are included. history of artificial intelligence machine learning\n",
      "Cleaned Token After =  machine learning . major discoveries , achievements , milestones major events included . history artificial intelligence machine learning \n",
      "Cleaned Token After Stem =  machin learn . major discoveri , achiev , mileston major event includ . histori artifici intellig machin learn \n",
      "Cleaned Token Before =  outline is provided as an overview of and topical guide to machine learning. machine learning is a subfield of soft computing within computer science that\n",
      "Cleaned Token After =  outline provided overview topical guide machine learning . machine learning subfield soft computing within computer science \n",
      "Cleaned Token After Stem =  outlin provid overview topic guid machin learn . machin learn subfield soft comput within comput scienc \n",
      "Cleaned Token Before =  training data by gradient descent. they are used in a wide variety of machine learning models, including in natural language processing and computer vision\n",
      "Cleaned Token After =  training data gradient descent . used wide variety machine learning models , including natural language processing computer vision \n",
      "Cleaned Token After Stem =  train data gradient descent . use wide varieti machin learn model , includ natur languag process comput vision \n",
      "Cleaned Token Before =  performance on various tasks, initially in pattern recognition and machine learning. for example, the bi-directional and multi-dimensional long short-term\n",
      "Cleaned Token After =  performance various tasks , initially pattern recognition machine learning . example , bi-directional multi-dimensional long short-term \n",
      "Cleaned Token After Stem =  perform variou task , initi pattern recognit machin learn . exampl , bi-direct multi-dimension long short-term \n",
      "Cleaned Token Before =  decision tree learning is one of the predictive modelling approaches used in statistics, data mining and machine learning. it uses a decision tree (as\n",
      "Cleaned Token After =  decision tree learning one predictive modelling approaches used statistics , data mining machine learning . uses decision tree ( \n",
      "Cleaned Token After Stem =  decis tree learn one predict model approach use statist , data mine machin learn . use decis tree ( \n",
      "Cleaned Token Before =  generation (pcg). machine learning is a subset of artificial intelligence that focuses on using algorithms and statistical models to make machines act without\n",
      "Cleaned Token After =  generation ( pcg ) . machine learning subset artificial intelligence focuses using algorithms statistical models make machines act without \n",
      "Cleaned Token After Stem =  gener ( pcg ) . machin learn subset artifici intellig focus use algorithm statist model make machin act without \n",
      "Cleaned Token Before =  speed, scale, and resource allocation when training a machine learning model comparison of deep learning software differentiable programming all-reduce alex\n",
      "Cleaned Token After =  speed , scale , resource allocation training machine learning model comparison deep learning software differentiable programming all-reduce alex \n",
      "Cleaned Token After Stem =  speed , scale , resourc alloc train machin learn model comparison deep learn softwar differenti program all-reduc alex \n",
      "Cleaned Token Before =  in statistics and machine learning, ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from\n",
      "Cleaned Token After =  statistics machine learning , ensemble methods use multiple learning algorithms obtain better predictive performance could obtained \n",
      "Cleaned Token After Stem =  statist machin learn , ensembl method use multipl learn algorithm obtain better predict perform could obtain \n",
      "Cleaned Token Before =  applying classical methods of machine learning to the study of quantum systems (sometimes called quantum machine learning) is the focus of an emergent\n",
      "Cleaned Token After =  applying classical methods machine learning study quantum systems ( sometimes called quantum machine learning ) focus emergent \n",
      "Cleaned Token After Stem =  appli classic method machin learn studi quantum system ( sometim call quantum machin learn ) focu emerg \n",
      "Cleaned Token Before =  reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning. reinforcement learning differs\n",
      "Cleaned Token After =  reinforcement learning one three basic machine learning paradigms , alongside supervised learning unsupervised learning . reinforcement learning differs \n",
      "Cleaned Token After Stem =  reinforc learn one three basic machin learn paradigm , alongsid supervis learn unsupervis learn . reinforc learn differ \n",
      "Cleaned Token Before =  semi-supervised learning is an approach to machine learning that combines a small amount of labeled data with a large amount of unlabeled data during\n",
      "Cleaned Token After =  semi-supervised learning approach machine learning combines small amount labeled data large amount unlabeled data \n",
      "Cleaned Token After Stem =  semi-supervis learn approach machin learn combin small amount label data larg amount unlabel data \n",
      "Cleaned Token Before =  in machine learning, a learning curve (or training curve) plots the optimal value of a model's loss function for a training set against this loss function\n",
      "Cleaned Token After =  machine learning , learning curve ( training curve ) plots optimal value model 's loss function training set loss function \n",
      "Cleaned Token After Stem =  machin learn , learn curv ( train curv ) plot optim valu model 's loss function train set loss function \n",
      "Cleaned Token Before =  rule-based machine learning (rbml) is a term in computer science intended to encompass any machine learning method that identifies, learns, or evolves\n",
      "Cleaned Token After =  rule-based machine learning ( rbml ) term computer science intended encompass machine learning method identifies , learns , evolves \n",
      "Cleaned Token After Stem =  rule-bas machin learn ( rbml ) term comput scienc intend encompass machin learn method identifi , learn , evolv \n",
      "Cleaned Token Before =  unsupervised learning (ul) is a type of algorithm that learns patterns from untagged data. the hope is that through mimicry, the machine is forced to\n",
      "Cleaned Token After =  unsupervised learning ( ul ) type algorithm learns patterns untagged data . hope mimicry , machine forced \n",
      "Cleaned Token After Stem =  unsupervis learn ( ul ) type algorithm learn pattern untag data . hope mimicri , machin forc \n",
      "Cleaned Token Before =  by humans, animals, and some machines; there is also evidence for some kind of learning in certain plants. some learning is immediate, induced by a single\n",
      "Cleaned Token After =  humans , animals , machines ; also evidence kind learning certain plants . learning immediate , induced single \n",
      "Cleaned Token After Stem =  human , anim , machin ; also evid kind learn certain plant . learn immedi , induc singl \n",
      "Cleaned Token Before =  international conference on machine learning (icml) is the leading international academic conference in machine learning. along with neurips and iclr\n",
      "Cleaned Token After =  international conference machine learning ( icml ) leading international academic conference machine learning . along neurips iclr \n",
      "Cleaned Token After Stem =  intern confer machin learn ( icml ) lead intern academ confer machin learn . along neurip iclr \n",
      "Cleaned Token Before =  in machine learning, a given algorithm is said to be fair, or to have fairness, if its results are independent of given variables, especially those considered\n",
      "Cleaned Token After =  machine learning , given algorithm said fair , fairness , results independent given variables , especially considered \n",
      "Cleaned Token After Stem =  machin learn , given algorithm said fair , fair , result independ given variabl , especi consid \n",
      "Cleaned Token Before =  microsoft azure machine learning (azure ml) provides a set of modern tools and ml frameworks for developers to create their own machine learning and ai services\n",
      "Cleaned Token After =  microsoft azure machine learning ( azure ml ) provides set modern tools ml frameworks developers create machine learning ai services \n",
      "Cleaned Token After Stem =  microsoft azur machin learn ( azur ml ) provid set modern tool ml framework develop creat machin learn ai servic \n",
      "Cleaned Token Before =  machine learning control (mlc) is a subfield of machine learning, intelligent control and control theory which solves optimal control problems with methods\n",
      "Cleaned Token After =  machine learning control ( mlc ) subfield machine learning , intelligent control control theory solves optimal control problems methods \n",
      "Cleaned Token After Stem =  machin learn control ( mlc ) subfield machin learn , intellig control control theori solv optim control problem method \n",
      "Cleaned Token Before =  describe machines that mimic \"cognitive\" functions that humans associate with the human mind, such as \"learning\" and \"problem solving\". as machines become\n",
      "Cleaned Token After =  describe machines mimic `` cognitive '' functions humans associate human mind , `` learning '' `` problem solving '' . machines become \n",
      "Cleaned Token After Stem =  describ machin mimic `` cognit `` function human associ human mind , `` learn `` `` problem solv `` . machin becom \n",
      "Cleaned Token Before =  federated learning (also known as collaborative learning) is a machine learning technique that trains an algorithm across multiple decentralized edge\n",
      "Cleaned Token After =  federated learning ( also known collaborative learning ) machine learning technique trains algorithm across multiple decentralized edge \n",
      "Cleaned Token After Stem =  feder learn ( also known collabor learn ) machin learn techniqu train algorithm across multipl decentr edg \n",
      "Cleaned Token Before =  forecasting, where its use has substantial overlap with the field of machine learning. second, in some situations regression analysis can be used to infer\n",
      "Cleaned Token After =  forecasting , use substantial overlap field machine learning . second , situations regression analysis used infer \n",
      "Cleaned Token After Stem =  forecast , use substanti overlap field machin learn . second , situat regress analysi use infer \n",
      "Cleaned Token Before =  semi-supervised learning, since vapnik's motivation is quite different. an example of an algorithm in this category is the transductive support vector machine (tsvm)\n",
      "Cleaned Token After =  semi-supervised learning , since vapnik 's motivation quite different . example algorithm category transductive support vector machine ( tsvm ) \n",
      "Cleaned Token After Stem =  semi-supervis learn , sinc vapnik 's motiv quit differ . exampl algorithm categori transduct support vector machin ( tsvm ) \n",
      "Cleaned Token Before =  mathematics, statistics, finance, computer science, particularly in machine learning and inverse problems, regularization is the process of adding information\n",
      "Cleaned Token After =  mathematics , statistics , finance , computer science , particularly machine learning inverse problems , regularization process adding information \n",
      "Cleaned Token After Stem =  mathemat , statist , financ , comput scienc , particularli machin learn invers problem , regular process ad inform \n",
      "Cleaned Token Before =  in machine learning and statistics, the learning rate is a tuning parameter in an optimization algorithm that determines the step size at each iteration\n",
      "Cleaned Token After =  machine learning statistics , learning rate tuning parameter optimization algorithm determines step size iteration \n",
      "Cleaned Token After Stem =  machin learn statist , learn rate tune paramet optim algorithm determin step size iter \n",
      "Cleaned Token Before =  understood by humans. it contrasts with the concept of the \"black box\" in machine learning where even its designers cannot explain why an ai arrived at a specific\n",
      "Cleaned Token After =  understood humans . contrasts concept `` black box '' machine learning even designers explain ai arrived specific \n",
      "Cleaned Token After Stem =  understood human . contrast concept `` black box `` machin learn even design explain ai arriv specif \n",
      "Cleaned Token Before =  torch is an open-source machine learning library, a scientific computing framework, and a script language based on the lua programming language. it provides\n",
      "Cleaned Token After =  torch open-source machine learning library , scientific computing framework , script language based lua programming language . provides \n",
      "Cleaned Token After Stem =  torch open-sourc machin learn librari , scientif comput framework , script languag base lua program languag . provid \n",
      "Cleaned Token Before =  association rule learning is a rule-based machine learning method for discovering interesting relations between variables in large databases. it is intended\n",
      "Cleaned Token After =  association rule learning rule-based machine learning method discovering interesting relations variables large databases . intended \n",
      "Cleaned Token After Stem =  associ rule learn rule-bas machin learn method discov interest relat variabl larg databas . intend \n",
      "Cleaned Token Before =  machine learning, a subfield of computer science involving the development of algorithms that learn how to make predictions based on data, has a number\n",
      "Cleaned Token After =  machine learning , subfield computer science involving development algorithms learn make predictions based data , number \n",
      "Cleaned Token After Stem =  machin learn , subfield comput scienc involv develop algorithm learn make predict base data , number \n",
      "Cleaned Token Before =  transfer learning (tl) is a research problem in machine learning (ml) that focuses on storing knowledge gained while solving one problem and applying\n",
      "Cleaned Token After =  transfer learning ( tl ) research problem machine learning ( ml ) focuses storing knowledge gained solving one problem applying \n",
      "Cleaned Token After Stem =  transfer learn ( tl ) research problem machin learn ( ml ) focus store knowledg gain solv one problem appli \n",
      "Cleaned Token Before =  learning to rank or machine-learned ranking (mlr) is the application of machine learning, typically supervised, semi-supervised or reinforcement learning\n",
      "Cleaned Token After =  learning rank machine-learned ranking ( mlr ) application machine learning , typically supervised , semi-supervised reinforcement learning \n",
      "Cleaned Token After Stem =  learn rank machine-learn rank ( mlr ) applic machin learn , typic supervis , semi-supervis reinforc learn \n",
      "Cleaned Token Before =  model for distributed word representation. the model is an unsupervised learning algorithm for obtaining vector representations for words. this is achieved\n",
      "Cleaned Token After =  model distributed word representation . model unsupervised learning algorithm obtaining vector representations words . achieved \n",
      "Cleaned Token After Stem =  model distribut word represent . model unsupervis learn algorithm obtain vector represent word . achiev \n",
      "Cleaned Token Before =  in statistics and machine learning, leakage (also known as data leakage or target leakage) is the use of information in the model training process which\n",
      "Cleaned Token After =  statistics machine learning , leakage ( also known data leakage target leakage ) use information model training process \n",
      "Cleaned Token After Stem =  statist machin learn , leakag ( also known data leakag target leakag ) use inform model train process \n",
      "Cleaned Token Before =  in machine learning, a common task is the study and construction of algorithms that can learn from and make predictions on data. such algorithms function\n",
      "Cleaned Token After =  machine learning , common task study construction algorithms learn make predictions data . algorithms function \n",
      "Cleaned Token After Stem =  machin learn , common task studi construct algorithm learn make predict data . algorithm function \n",
      "Cleaned Token Before =  zest automated machine learning (zaml) platform specifically for credit underwriting as well. this platform utilizes machine learning to analyze tens\n",
      "Cleaned Token After =  zest automated machine learning ( zaml ) platform specifically credit underwriting well . platform utilizes machine learning analyze tens \n",
      "Cleaned Token After Stem =  zest autom machin learn ( zaml ) platform specif credit underwrit well . platform util machin learn analyz ten \n",
      "Cleaned Token Before =  in machine learning, pattern recognition, and image processing, feature extraction starts from an initial set of measured data and builds derived values\n",
      "Cleaned Token After =  machine learning , pattern recognition , image processing , feature extraction starts initial set measured data builds derived values \n",
      "Cleaned Token After Stem =  machin learn , pattern recognit , imag process , featur extract start initi set measur data build deriv valu \n",
      "Cleaned Token Before =  become an important optimization method in machine learning. both statistical estimation and machine learning consider the problem of minimizing an objective\n",
      "Cleaned Token After =  become important optimization method machine learning . statistical estimation machine learning consider problem minimizing objective \n",
      "Cleaned Token After Stem =  becom import optim method machin learn . statist estim machin learn consid problem minim object \n",
      "Cleaned Token Before =  in machine learning, feature learning or representation learning is a set of techniques that allows a system to automatically discover the representations\n",
      "Cleaned Token After =  machine learning , feature learning representation learning set techniques allows system automatically discover representations \n",
      "Cleaned Token After Stem =  machin learn , featur learn represent learn set techniqu allow system automat discov represent \n",
      "Cleaned Token Before =  machine learning is a peer-reviewed scientific journal, published since 1986. in 2001, forty editors and members of the editorial board of machine learning\n",
      "Cleaned Token After =  machine learning peer-reviewed scientific journal , published since 1986. 2001 , forty editors members editorial board machine learning \n",
      "Cleaned Token After Stem =  machin learn peer-review scientif journal , publish sinc 1986 . 2001 , forti editor member editori board machin learn \n",
      "Cleaned Token Before =  in machine learning, the perceptron is an algorithm for supervised learning of binary classifiers. a binary classifier is a function which can decide whether\n",
      "Cleaned Token After =  machine learning , perceptron algorithm supervised learning binary classifiers . binary classifier function decide whether \n",
      "Cleaned Token After Stem =  machin learn , perceptron algorithm supervis learn binari classifi . binari classifi function decid whether \n",
      "Cleaned Token Before =  theoretical results in machine learning mainly deal with a type of inductive learning called supervised learning. in supervised learning, an algorithm is given\n",
      "Cleaned Token After =  theoretical results machine learning mainly deal type inductive learning called supervised learning . supervised learning , algorithm given \n",
      "Cleaned Token After Stem =  theoret result machin learn mainli deal type induct learn call supervis learn . supervis learn , algorithm given \n",
      "Cleaned Token Before =  processes. boltzmann machines with unconstrained connectivity have not proven useful for practical problems in machine learning or inference, but if the\n",
      "Cleaned Token After =  processes . boltzmann machines unconstrained connectivity proven useful practical problems machine learning inference , \n",
      "Cleaned Token After Stem =  process . boltzmann machin unconstrain connect proven use practic problem machin learn infer , \n",
      "Cleaned Token Before =  in machine learning, multiclass or multinomial classification is the problem of classifying instances into one of three or more classes (classifying instances\n",
      "Cleaned Token After =  machine learning , multiclass multinomial classification problem classifying instances one three classes ( classifying instances \n",
      "Cleaned Token After Stem =  machin learn , multiclass multinomi classif problem classifi instanc one three class ( classifi instanc \n",
      "Cleaned Token Before =  (1997). machine learning (1st ed.). new york: wcb/mcgraw-hill corporation. isbn 978-0-07-042807-2. booth, taylor l. (1967). sequential machines and automata\n",
      "Cleaned Token After =  ( 1997 ) . machine learning ( 1st ed. ) . new york : wcb/mcgraw-hill corporation . isbn 978-0-07-042807-2. booth , taylor l. ( 1967 ) . sequential machines automata \n",
      "Cleaned Token After Stem =  ( 1997 ) . machin learn ( 1st ed . ) . new york : wcb/mcgraw-hil corpor . isbn 978-0-07-042807-2. booth , taylor l. ( 1967 ) . sequenti machin automata \n",
      "Cleaned Token Before =  deep reinforcement learning (deep rl) is a subfield of machine learning that combines reinforcement learning (rl) and deep learning. rl considers the problem\n",
      "Cleaned Token After =  deep reinforcement learning ( deep rl ) subfield machine learning combines reinforcement learning ( rl ) deep learning . rl considers problem \n",
      "Cleaned Token After Stem =  deep reinforc learn ( deep rl ) subfield machin learn combin reinforc learn ( rl ) deep learn . rl consid problem \n",
      "Cleaned Token Before =  variables are visualized. underfitting occurs when a statistical model or machine learning algorithm cannot adequately capture the underlying structure of the\n",
      "Cleaned Token After =  variables visualized . underfitting occurs statistical model machine learning algorithm adequately capture underlying structure \n",
      "Cleaned Token After Stem =  variabl visual . underfit occur statist model machin learn algorithm adequ captur underli structur \n",
      "Cleaned Token Before =  similarity learning is an area of supervised machine learning in artificial intelligence. it is closely related to regression and classification, but the\n",
      "Cleaned Token After =  similarity learning area supervised machine learning artificial intelligence . closely related regression classification , \n",
      "Cleaned Token After Stem =  similar learn area supervis machin learn artifici intellig . close relat regress classif , \n",
      "Cleaned Token Before =  are considered to be possible values of the dependent variable. in machine learning, the observations are often known as instances, the explanatory variables\n",
      "Cleaned Token After =  considered possible values dependent variable . machine learning , observations often known instances , explanatory variables \n",
      "Cleaned Token After Stem =  consid possibl valu depend variabl . machin learn , observ often known instanc , explanatori variabl \n",
      "Cleaned Token Before =  retrieval, bioinformatics, data compression, computer graphics and machine learning. pattern recognition has its origins in statistics and engineering;\n",
      "Cleaned Token After =  retrieval , bioinformatics , data compression , computer graphics machine learning . pattern recognition origins statistics engineering ; \n",
      "Cleaned Token After Stem =  retriev , bioinformat , data compress , comput graphic machin learn . pattern recognit origin statist engin ; \n",
      "Cleaned Token Before =  recurrent neural network (rnn) architecture used in the field of deep learning. unlike standard feedforward neural networks, lstm has feedback connections\n",
      "Cleaned Token After =  recurrent neural network ( rnn ) architecture used field deep learning . unlike standard feedforward neural networks , lstm feedback connections \n",
      "Cleaned Token After Stem =  recurr neural network ( rnn ) architectur use field deep learn . unlik standard feedforward neural network , lstm feedback connect \n",
      "Cleaned Token Before =  in digital circuits and machine learning, a one-hot is a group of bits among which the legal combinations of values are only those with a single high (1)\n",
      "Cleaned Token After =  digital circuits machine learning , one-hot group bits among legal combinations values single high ( 1 ) \n",
      "Cleaned Token After Stem =  digit circuit machin learn , one-hot group bit among legal combin valu singl high ( 1 ) \n",
      "Cleaned Token Before =  a learning curve is a graphical representation of the relationship between how proficient someone is at a task and the amount of experience they have.\n",
      "Cleaned Token After =  learning curve graphical representation relationship proficient someone task amount experience . \n",
      "Cleaned Token After Stem =  learn curv graphic represent relationship profici someon task amount experi . \n",
      "Cleaned Token Before =  the ibm machine learning hub hosts businesses wanting to collaborate with ibm’s machine learning experts. its mission is to close the gap between available\n",
      "Cleaned Token After =  ibm machine learning hub hosts businesses wanting collaborate ibm ’ machine learning experts . mission close gap available \n",
      "Cleaned Token After Stem =  ibm machin learn hub host busi want collabor ibm ’ machin learn expert . mission close gap avail \n",
      "Cleaned Token Before =  in machine learning, particularly in the creation of artificial neural networks, ensemble averaging is the process of creating multiple models and combining\n",
      "Cleaned Token After =  machine learning , particularly creation artificial neural networks , ensemble averaging process creating multiple models combining \n",
      "Cleaned Token After Stem =  machin learn , particularli creation artifici neural network , ensembl averag process creat multipl model combin \n",
      "Cleaned Token Before =  database, analytics, application services, deployment, management, machine learning, mobile, developer tools, and tools for the internet of things. the\n",
      "Cleaned Token After =  database , analytics , application services , deployment , management , machine learning , mobile , developer tools , tools internet things . \n",
      "Cleaned Token After Stem =  databas , analyt , applic servic , deploy , manag , machin learn , mobil , develop tool , tool internet thing . \n",
      "Cleaned Token Before =  intelligence applications, especially artificial neural networks, machine vision and machine learning. typical applications include algorithms for robotics, internet\n",
      "Cleaned Token After =  intelligence applications , especially artificial neural networks , machine vision machine learning . typical applications include algorithms robotics , internet \n",
      "Cleaned Token After Stem =  intellig applic , especi artifici neural network , machin vision machin learn . typic applic includ algorithm robot , internet \n",
      "Cleaned Token Before =  in probability theory and machine learning, the multi-armed bandit problem (sometimes called the k- or n-armed bandit problem) is a problem in which a\n",
      "Cleaned Token After =  probability theory machine learning , multi-armed bandit problem ( sometimes called k- n-armed bandit problem ) problem \n",
      "Cleaned Token After Stem =  probabl theori machin learn , multi-arm bandit problem ( sometim call k- n-arm bandit problem ) problem \n",
      "Cleaned Token Before =  to be practical. in the 2010s, representation learning and deep neural network-style machine learning methods became widespread in natural language processing\n",
      "Cleaned Token After =  practical . 2010s , representation learning deep neural network-style machine learning methods became widespread natural language processing \n",
      "Cleaned Token After Stem =  practic . 2010 , represent learn deep neural network-styl machin learn method becam widespread natur languag process \n",
      "Cleaned Token Before =  statistical learning theory is a framework for machine learning drawing from the fields of statistics and functional analysis. statistical learning theory\n",
      "Cleaned Token After =  statistical learning theory framework machine learning drawing fields statistics functional analysis . statistical learning theory \n",
      "Cleaned Token After Stem =  statist learn theori framework machin learn draw field statist function analysi . statist learn theori \n",
      "Cleaned Token Before =  q-learning is a model-free reinforcement learning algorithm to learn the value of an action in a particular state. it does not require a model of the\n",
      "Cleaned Token After =  q-learning model-free reinforcement learning algorithm learn value action particular state . require model \n",
      "Cleaned Token After Stem =  q-learn model-fre reinforc learn algorithm learn valu action particular state . requir model \n",
      "Cleaned Token Before =  deep medicine, is an overarching term used to describe the use of machine-learning algorithms and software, or artificial intelligence (ai), to mimic\n",
      "Cleaned Token After =  deep medicine , overarching term used describe use machine-learning algorithms software , artificial intelligence ( ai ) , mimic \n",
      "Cleaned Token After Stem =  deep medicin , overarch term use describ use machine-learn algorithm softwar , artifici intellig ( ai ) , mimic \n",
      "Cleaned Token Before =  patterns in large data sets involving methods at the intersection of machine learning, statistics, and database systems. data mining is an interdisciplinary\n",
      "Cleaned Token After =  patterns large data sets involving methods intersection machine learning , statistics , database systems . data mining interdisciplinary \n",
      "Cleaned Token After Stem =  pattern larg data set involv method intersect machin learn , statist , databas system . data mine interdisciplinari \n",
      "Cleaned Token Before =  zero-shot learning (zsl) is a problem setup in machine learning, where at test time, a learner observes samples from classes that were not observed during\n",
      "Cleaned Token After =  zero-shot learning ( zsl ) problem setup machine learning , test time , learner observes samples classes observed \n",
      "Cleaned Token After Stem =  zero-shot learn ( zsl ) problem setup machin learn , test time , learner observ sampl class observ \n",
      "Cleaned Token Before =  ; schmidhuber, jürgen (2002). \"learning precise timing with lstm recurrent networks\" (pdf). journal of machine learning research. 3: 115–143. retrieved\n",
      "Cleaned Token After =  ; schmidhuber , jürgen ( 2002 ) . `` learning precise timing lstm recurrent networks '' ( pdf ) . journal machine learning research . 3 : 115–143 . retrieved \n",
      "Cleaned Token After Stem =  ; schmidhub , jürgen ( 2002 ) . `` learn precis time lstm recurr network `` ( pdf ) . journal machin learn research . 3 : 115–143 . retriev \n",
      "Cleaned Token Before =  bootstrap aggregating), is a machine learning ensemble meta-algorithm designed to improve the stability and accuracy of machine learning algorithms used in statistical\n",
      "Cleaned Token After =  bootstrap aggregating ) , machine learning ensemble meta-algorithm designed improve stability accuracy machine learning algorithms used statistical \n",
      "Cleaned Token After Stem =  bootstrap aggreg ) , machin learn ensembl meta-algorithm design improv stabil accuraci machin learn algorithm use statist \n",
      "Cleaned Token Before =  information theory, cryptography, program semantics and verification, machine learning, computational biology, computational economics, computational geometry\n",
      "Cleaned Token After =  information theory , cryptography , program semantics verification , machine learning , computational biology , computational economics , computational geometry \n",
      "Cleaned Token After Stem =  inform theori , cryptographi , program semant verif , machin learn , comput biolog , comput econom , comput geometri \n",
      "Cleaned Token Before =  in machine learning the margin of a single data point is defined to be the distance from the data point to a decision boundary. note that there are many\n",
      "Cleaned Token After =  machine learning margin single data point defined distance data point decision boundary . note many \n",
      "Cleaned Token After Stem =  machin learn margin singl data point defin distanc data point decis boundari . note mani \n",
      "Cleaned Token Before =  the journal of machine learning research is a peer-reviewed open access scientific journal covering machine learning. it was established in 2000 and the\n",
      "Cleaned Token After =  journal machine learning research peer-reviewed open access scientific journal covering machine learning . established 2000 \n",
      "Cleaned Token After Stem =  journal machin learn research peer-review open access scientif journal cover machin learn . establish 2000 \n",
      "Cleaned Token Before =  range of application domains. data science is related to data mining, machine learning and big data. data science is a \"concept to unify statistics, data\n",
      "Cleaned Token After =  range application domains . data science related data mining , machine learning big data . data science `` concept unify statistics , data \n",
      "Cleaned Token After Stem =  rang applic domain . data scienc relat data mine , machin learn big data . data scienc `` concept unifi statist , data \n",
      "Cleaned Token Before =  in computer science, incremental learning is a method of machine learning in which input data is continuously used to extend the existing model's knowledge\n",
      "Cleaned Token After =  computer science , incremental learning method machine learning input data continuously used extend existing model 's knowledge \n",
      "Cleaned Token After Stem =  comput scienc , increment learn method machin learn input data continu use extend exist model 's knowledg \n",
      "Cleaned Token Before =  differentiation in machine learning: a survey\". arxiv:1502.05767 [cs.lg]. \"microsoft/caffe\". github. \"caffe: a fast open framework for deep learning\". july 19\n",
      "Cleaned Token After =  differentiation machine learning : survey '' . arxiv:1502.05767 [ cs.lg ] . `` microsoft/caffe '' . github . `` caffe : fast open framework deep learning '' . july 19 \n",
      "Cleaned Token After Stem =  differenti machin learn : survey `` . arxiv:1502.05767 [ cs.lg ] . `` microsoft/caff `` . github . `` caff : fast open framework deep learn `` . juli 19 \n",
      "Cleaned Token Before =  modality given the observed ones. the multimodal learning model combines two deep boltzmann machines each corresponds to one modality. an additional hidden\n",
      "Cleaned Token After =  modality given observed ones . multimodal learning model combines two deep boltzmann machines corresponds one modality . additional hidden \n",
      "Cleaned Token After Stem =  modal given observ one . multimod learn model combin two deep boltzmann machin correspond one modal . addit hidden \n",
      "Cleaned Token Before =  many areas of computer science, such as robust programming, robust machine learning, and robust security network. formal techniques, such as fuzz testing\n",
      "Cleaned Token After =  many areas computer science , robust programming , robust machine learning , robust security network . formal techniques , fuzz testing \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Token After Stem =  mani area comput scienc , robust program , robust machin learn , robust secur network . formal techniqu , fuzz test \n",
      "Cleaned Token Before =  computational learning theory, probably approximately correct (pac) learning is a framework for mathematical analysis of machine learning. it was proposed\n",
      "Cleaned Token After =  computational learning theory , probably approximately correct ( pac ) learning framework mathematical analysis machine learning . proposed \n",
      "Cleaned Token After Stem =  comput learn theori , probabl approxim correct ( pac ) learn framework mathemat analysi machin learn . propos \n",
      "Cleaned Token Before =  2020-02-14. retrieved 2020-04-05. deep learning super sampling uses artificial intelligence and machine learning to produce an image that looks like a\n",
      "Cleaned Token After =  2020-02-14. retrieved 2020-04-05. deep learning super sampling uses artificial intelligence machine learning produce image looks like \n",
      "Cleaned Token After Stem =  2020-02-14. retriev 2020-04-05. deep learn super sampl use artifici intellig machin learn produc imag look like \n",
      "Cleaned Token Before =  gradient boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble\n",
      "Cleaned Token After =  gradient boosting machine learning technique regression classification problems , produces prediction model form ensemble \n",
      "Cleaned Token After Stem =  gradient boost machin learn techniqu regress classif problem , produc predict model form ensembl \n",
      "Cleaned Token Before =  of them. constructivism has also informed the design of interactive machine learning systems, whereas radical constructivism has been explored as a paradigm\n",
      "Cleaned Token After =  . constructivism also informed design interactive machine learning systems , whereas radical constructivism explored paradigm \n",
      "Cleaned Token After Stem =  . constructiv also inform design interact machin learn system , wherea radic constructiv explor paradigm \n",
      "Cleaned Token Before =  in machine learning, instance-based learning (sometimes called memory-based learning) is a family of learning algorithms that, instead of performing explicit\n",
      "Cleaned Token After =  machine learning , instance-based learning ( sometimes called memory-based learning ) family learning algorithms , instead performing explicit \n",
      "Cleaned Token After Stem =  machin learn , instance-bas learn ( sometim call memory-bas learn ) famili learn algorithm , instead perform explicit \n",
      "Cleaned Token Before =  allow the attacker to completely bypass the captcha, and finally using machine learning to build an automated solver. according to former google \"click fraud\n",
      "Cleaned Token After =  allow attacker completely bypass captcha , finally using machine learning build automated solver . according former google `` click fraud \n",
      "Cleaned Token After Stem =  allow attack complet bypass captcha , final use machin learn build autom solver . accord former googl `` click fraud \n",
      "Cleaned Token Before =  flux is an open-source machine-learning software library and ecosystem written in julia. its current stable release is v0.10.3. it has a layer-stacking-based\n",
      "Cleaned Token After =  flux open-source machine-learning software library ecosystem written julia . current stable release v0.10.3 . layer-stacking-based \n",
      "Cleaned Token After Stem =  flux open-sourc machine-learn softwar librari ecosystem written julia . current stabl releas v0.10.3 . layer-stacking-bas \n",
      "Cleaned Token Before =  popular machine learning solution in the 1980s, finding applications in diverse fields such as speech recognition, image recognition, and machine translation\n",
      "Cleaned Token After =  popular machine learning solution 1980s , finding applications diverse fields speech recognition , image recognition , machine translation \n",
      "Cleaned Token After Stem =  popular machin learn solut 1980 , find applic divers field speech recognit , imag recognit , machin translat \n",
      "Cleaned Token Before =  in artificial intelligence (ai), particularly machine learning (ml), ablation is the removal of a component of an ai system. an ablation study studies\n",
      "Cleaned Token After =  artificial intelligence ( ai ) , particularly machine learning ( ml ) , ablation removal component ai system . ablation study studies \n",
      "Cleaned Token After Stem =  artifici intellig ( ai ) , particularli machin learn ( ml ) , ablat remov compon ai system . ablat studi studi \n",
      "Cleaned Token Before =  in machine learning, semantic analysis of a corpus is the task of building structures that approximate concepts from a large set of documents. it generally\n",
      "Cleaned Token After =  machine learning , semantic analysis corpus task building structures approximate concepts large set documents . generally \n",
      "Cleaned Token After Stem =  machin learn , semant analysi corpu task build structur approxim concept larg set document . gener \n",
      "Cleaned Token Before =  nature machine intelligence is a transformative (offering optional open access) scientific journal dedicated to covering machine learning and artificial\n",
      "Cleaned Token After =  nature machine intelligence transformative ( offering optional open access ) scientific journal dedicated covering machine learning artificial \n",
      "Cleaned Token After Stem =  natur machin intellig transform ( offer option open access ) scientif journal dedic cover machin learn artifici \n",
      "Cleaned Token Before =  some express hope in developing quantum algorithms that can speed up machine learning tasks. for example, the quantum algorithm for linear systems of equations\n",
      "Cleaned Token After =  express hope developing quantum algorithms speed machine learning tasks . example , quantum algorithm linear systems equations \n",
      "Cleaned Token After Stem =  express hope develop quantum algorithm speed machin learn task . exampl , quantum algorithm linear system equat \n",
      "Cleaned Token Before =  has in turn boosted the design and adoption of technologies such as machine learning and artificial intelligence. by analyzing and processing data, algorithms\n",
      "Cleaned Token After =  turn boosted design adoption technologies machine learning artificial intelligence . analyzing processing data , algorithms \n",
      "Cleaned Token After Stem =  turn boost design adopt technolog machin learn artifici intellig . analyz process data , algorithm \n",
      "Cleaned Token Before =  features of a deep network. international conference on machine learning workshop on learning feature hierarchies. s2cid 15127402. simonyan, karen; vedaldi\n",
      "Cleaned Token After =  features deep network . international conference machine learning workshop learning feature hierarchies . s2cid 15127402. simonyan , karen ; vedaldi \n",
      "Cleaned Token After Stem =  featur deep network . intern confer machin learn workshop learn featur hierarchi . s2cid 15127402. simonyan , karen ; vedaldi \n",
      "Cleaned Token Before =  (formerly known as dolores lab, crowdflower) is a human-in-the-loop machine learning and artificial intelligence company based in san francisco. the company\n",
      "Cleaned Token After =  ( formerly known dolores lab , crowdflower ) human-in-the-loop machine learning artificial intelligence company based san francisco . company \n",
      "Cleaned Token After Stem =  ( formerli known dolor lab , crowdflow ) human-in-the-loop machin learn artifici intellig compani base san francisco . compani \n",
      "Cleaned Token Before =  learning express toys, incorporated in 1987 as learning express, inc., is a specialty toy, game and book retailer and franchisor headquartered in devens\n",
      "Cleaned Token After =  learning express toys , incorporated 1987 learning express , inc. , specialty toy , game book retailer franchisor headquartered devens \n",
      "Cleaned Token After Stem =  learn express toy , incorpor 1987 learn express , inc. , specialti toy , game book retail franchisor headquart deven \n",
      "Cleaned Token Before =  correlation. decision trees are a popular method for various machine learning tasks. tree learning \"come[s] closest to meeting the requirements for serving\n",
      "Cleaned Token After =  correlation . decision trees popular method various machine learning tasks . tree learning `` come [ ] closest meeting requirements serving \n",
      "Cleaned Token After Stem =  correl . decis tree popular method variou machin learn task . tree learn `` come [ ] closest meet requir serv \n",
      "Cleaned Token Before =  boltzmann machines, in particular the gradient-based contrastive divergence algorithm. restricted boltzmann machines can also be used in deep learning networks\n",
      "Cleaned Token After =  boltzmann machines , particular gradient-based contrastive divergence algorithm . restricted boltzmann machines also used deep learning networks \n",
      "Cleaned Token After Stem =  boltzmann machin , particular gradient-bas contrast diverg algorithm . restrict boltzmann machin also use deep learn network \n",
      "Cleaned Token Before =  database is also widely used for training and testing in the field of machine learning. it was created by \"re-mixing\" the samples from nist's original datasets\n",
      "Cleaned Token After =  database also widely used training testing field machine learning . created `` re-mixing '' samples nist 's original datasets \n",
      "Cleaned Token After Stem =  databas also wide use train test field machin learn . creat `` re-mix `` sampl nist 's origin dataset \n",
      "Cleaned Token Before =  role being takenover by artificial intelligence (ai) systems based on machine learning and artificial neural networks. it is important to realize why pa technology\n",
      "Cleaned Token After =  role takenover artificial intelligence ( ai ) systems based machine learning artificial neural networks . important realize pa technology \n",
      "Cleaned Token After Stem =  role takenov artifici intellig ( ai ) system base machin learn artifici neural network . import realiz pa technolog \n",
      "Cleaned Token Before =  probability theory, statistics—particularly bayesian statistics—and machine learning. generally, probabilistic graphical models use a graph-based representation\n",
      "Cleaned Token After =  probability theory , statistics—particularly bayesian statistics—and machine learning . generally , probabilistic graphical models use graph-based representation \n",
      "Cleaned Token After Stem =  probabl theori , statistics—particularli bayesian statistics—and machin learn . gener , probabilist graphic model use graph-bas represent \n",
      "Cleaned Token Before =  in machine learning, a deep belief network (dbn) is a generative graphical model, or alternatively a class of deep neural network, composed of multiple\n",
      "Cleaned Token After =  machine learning , deep belief network ( dbn ) generative graphical model , alternatively class deep neural network , composed multiple \n",
      "Cleaned Token After Stem =  machin learn , deep belief network ( dbn ) gener graphic model , altern class deep neural network , compos multipl \n",
      "Cleaned Token Before =  on machine learning and principles and practice of knowledge discovery in databases, is one of the leading academic conferences on machine learning and\n",
      "Cleaned Token After =  machine learning principles practice knowledge discovery databases , one leading academic conferences machine learning \n",
      "Cleaned Token After Stem =  machin learn principl practic knowledg discoveri databas , one lead academ confer machin learn \n",
      "Cleaned Token Before =  structured prediction or structured (output) learning is an umbrella term for supervised machine learning techniques that involves predicting structured\n",
      "Cleaned Token After =  structured prediction structured ( output ) learning umbrella term supervised machine learning techniques involves predicting structured \n",
      "Cleaned Token After Stem =  structur predict structur ( output ) learn umbrella term supervis machin learn techniqu involv predict structur \n",
      "Cleaned Token Before =  in machine learning, lazy learning is a learning method in which generalization of the training data is, in theory, delayed until a query is made to the\n",
      "Cleaned Token After =  machine learning , lazy learning learning method generalization training data , theory , delayed query made \n",
      "Cleaned Token After Stem =  machin learn , lazi learn learn method gener train data , theori , delay queri made \n",
      "Cleaned Token Before =  american-canadian-iranian computer scientist and technology executive working on machine learning. he is adjunct professor at stanford university and ceo of matroid\n",
      "Cleaned Token After =  american-canadian-iranian computer scientist technology executive working machine learning . adjunct professor stanford university ceo matroid \n",
      "Cleaned Token After Stem =  american-canadian-iranian comput scientist technolog execut work machin learn . adjunct professor stanford univers ceo matroid \n",
      "Cleaned Token Before =  interest in ai boomed in the first decades of the 21st century when machine learning was successfully applied to many problems in academia and industry\n",
      "Cleaned Token After =  interest ai boomed first decades 21st century machine learning successfully applied many problems academia industry \n",
      "Cleaned Token After Stem =  interest ai boom first decad 21st centuri machin learn success appli mani problem academia industri \n",
      "Cleaned Token Before =  is also known as sensitivity, recall or probability of detection in machine learning. the false-positive rate is also known as probability of false alarm\n",
      "Cleaned Token After =  also known sensitivity , recall probability detection machine learning . false-positive rate also known probability false alarm \n",
      "Cleaned Token After Stem =  also known sensit , recal probabl detect machin learn . false-posit rate also known probabl fals alarm \n",
      "Cleaned Token Before =  tensorflow is a free and open-source software library for machine learning. it can be used across a range of tasks but has a particular focus on training\n",
      "Cleaned Token After =  tensorflow free open-source software library machine learning . used across range tasks particular focus training \n",
      "Cleaned Token After Stem =  tensorflow free open-sourc softwar librari machin learn . use across rang task particular focu train \n",
      "Cleaned Token Before =  seq2seq is a family of machine learning approaches used for language processing. applications include language translation, image captioning, conversational\n",
      "Cleaned Token After =  seq2seq family machine learning approaches used language processing . applications include language translation , image captioning , conversational \n",
      "Cleaned Token After Stem =  seq2seq famili machin learn approach use languag process . applic includ languag translat , imag caption , convers \n",
      "Cleaned Token Before =  in machine learning and statistics, feature selection, also known as variable selection, attribute selection or variable subset selection, is the process\n",
      "Cleaned Token After =  machine learning statistics , feature selection , also known variable selection , attribute selection variable subset selection , process \n",
      "Cleaned Token After Stem =  machin learn statist , featur select , also known variabl select , attribut select variabl subset select , process \n",
      "Cleaned Token Before =  document's topics. lda is an example of a topic model and belongs to the machine learning toolbox and in wider sense to the artificial intelligence toolbox.\n",
      "Cleaned Token After =  document 's topics . lda example topic model belongs machine learning toolbox wider sense artificial intelligence toolbox . \n",
      "Cleaned Token After Stem =  document 's topic . lda exampl topic model belong machin learn toolbox wider sens artifici intellig toolbox . \n",
      "Cleaned Token Before =  marc g. (2001). \"classes of kernels for machine learning: a statistics perspective\". journal of machine learning research. 2: 299–312. doi:10.1162/15324430260185646\n",
      "Cleaned Token After =  marc g. ( 2001 ) . `` classes kernels machine learning : statistics perspective '' . journal machine learning research . 2 : 299–312 . doi:10.1162/15324430260185646 \n",
      "Cleaned Token After Stem =  marc g. ( 2001 ) . `` class kernel machin learn : statist perspect `` . journal machin learn research . 2 : 299–312 . doi:10.1162/15324430260185646 \n",
      "Cleaned Token Before =  smalltalk has been used extensively for simulations, neural networks, machine learning and genetic algorithms. it implements the purest and most elegant form\n",
      "Cleaned Token After =  smalltalk used extensively simulations , neural networks , machine learning genetic algorithms . implements purest elegant form \n",
      "Cleaned Token After Stem =  smalltalk use extens simul , neural network , machin learn genet algorithm . implement purest eleg form \n",
      "Cleaned Token Before =  in machine learning, hyperparameter optimization or tuning is the problem of choosing a set of optimal hyperparameters for a learning algorithm. a hyperparameter\n",
      "Cleaned Token After =  machine learning , hyperparameter optimization tuning problem choosing set optimal hyperparameters learning algorithm . hyperparameter \n",
      "Cleaned Token After Stem =  machin learn , hyperparamet optim tune problem choos set optim hyperparamet learn algorithm . hyperparamet \n",
      "Cleaned Token Before =  in machine learning, platt scaling or platt calibration is a way of transforming the outputs of a classification model into a probability distribution\n",
      "Cleaned Token After =  machine learning , platt scaling platt calibration way transforming outputs classification model probability distribution \n",
      "Cleaned Token After Stem =  machin learn , platt scale platt calibr way transform output classif model probabl distribut \n",
      "Cleaned Token Before =  processing systems (abbreviated as neurips and formerly nips) is a machine learning and computational neuroscience conference held every december. the\n",
      "Cleaned Token After =  processing systems ( abbreviated neurips formerly nips ) machine learning computational neuroscience conference held every december . \n",
      "Cleaned Token After Stem =  process system ( abbrevi neurip formerli nip ) machin learn comput neurosci confer held everi decemb . \n",
      "Cleaned Token Before =  online learning may refer to e-learning, in education e-learning (theory) online learning in higher education massive open online courses online machine learning\n",
      "Cleaned Token After =  online learning may refer e-learning , education e-learning ( theory ) online learning higher education massive open online courses online machine learning \n",
      "Cleaned Token After Stem =  onlin learn may refer e-learn , educ e-learn ( theori ) onlin learn higher educ massiv open onlin cours onlin machin learn \n",
      "Cleaned Token Before =  the areas of knowledge discovery in databases (kdd), data mining, machine learning and statistics. they offer applicable and successful solutions in different\n",
      "Cleaned Token After =  areas knowledge discovery databases ( kdd ) , data mining , machine learning statistics . offer applicable successful solutions different \n",
      "Cleaned Token After Stem =  area knowledg discoveri databas ( kdd ) , data mine , machin learn statist . offer applic success solut differ \n",
      "Cleaned Token Before =  logic learning machine (llm) is a machine learning method based on the generation of intelligible rules. llm is an efficient implementation of the switching\n",
      "Cleaned Token After =  logic learning machine ( llm ) machine learning method based generation intelligible rules . llm efficient implementation switching \n",
      "Cleaned Token After Stem =  logic learn machin ( llm ) machin learn method base gener intellig rule . llm effici implement switch \n",
      "Cleaned Token Before =  one-shot learning is an object categorization problem, found mostly in computer vision. whereas most machine learning based object categorization algorithms\n",
      "Cleaned Token After =  one-shot learning object categorization problem , found mostly computer vision . whereas machine learning based object categorization algorithms \n",
      "Cleaned Token After Stem =  one-shot learn object categor problem , found mostli comput vision . wherea machin learn base object categor algorithm \n",
      "Cleaned Token Before =  statistical mdl learning, such a description is frequently called a two-part code. mdl applies in machine learning when algorithms (machines) generate descriptions\n",
      "Cleaned Token After =  statistical mdl learning , description frequently called two-part code . mdl applies machine learning algorithms ( machines ) generate descriptions \n",
      "Cleaned Token After Stem =  statist mdl learn , descript frequent call two-part code . mdl appli machin learn algorithm ( machin ) gener descript \n",
      "Cleaned Token Before =   motivated entire branches of information theory, statistics, and machine learning. maximum entropy is the state of a physical system at greatest disorder\n",
      "Cleaned Token After =  motivated entire branches information theory , statistics , machine learning . maximum entropy state physical system greatest disorder \n",
      "Cleaned Token After Stem =  motiv entir branch inform theori , statist , machin learn . maximum entropi state physic system greatest disord \n",
      "Cleaned Token Before =  meta learning is a subfield of machine learning where automatic learning algorithms are applied to metadata about machine learning experiments. as of\n",
      "Cleaned Token After =  meta learning subfield machine learning automatic learning algorithms applied metadata machine learning experiments . \n",
      "Cleaned Token After Stem =  meta learn subfield machin learn automat learn algorithm appli metadata machin learn experi . \n",
      "Cleaned Token Before =  learning classifier systems, or lcs, are a paradigm of rule-based machine learning methods that combine a discovery component (e.g. typically a genetic\n",
      "Cleaned Token After =  learning classifier systems , lcs , paradigm rule-based machine learning methods combine discovery component ( e.g . typically genetic \n",
      "Cleaned Token After Stem =  learn classifi system , lc , paradigm rule-bas machin learn method combin discoveri compon ( e.g . typic genet \n",
      "Cleaned Token Before =  cloud services including computing, data storage, data analytics and machine learning. registration requires a credit card or bank account details. google\n",
      "Cleaned Token After =  cloud services including computing , data storage , data analytics machine learning . registration requires credit card bank account details . google \n",
      "Cleaned Token After Stem =  cloud servic includ comput , data storag , data analyt machin learn . registr requir credit card bank account detail . googl \n",
      "Cleaned Token Before =  a generative adversarial network (gan) is a class of machine learning frameworks designed by ian goodfellow and his colleagues in 2014. two neural networks\n",
      "Cleaned Token After =  generative adversarial network ( gan ) class machine learning frameworks designed ian goodfellow colleagues 2014. two neural networks \n",
      "Cleaned Token After Stem =  gener adversari network ( gan ) class machin learn framework design ian goodfellow colleagu 2014. two neural network \n",
      "Cleaned Token Before =  in machine learning, weighted majority algorithm (wma) is a meta learning algorithm used to construct a compound algorithm from a pool of prediction algorithms\n",
      "Cleaned Token After =  machine learning , weighted majority algorithm ( wma ) meta learning algorithm used construct compound algorithm pool prediction algorithms \n",
      "Cleaned Token After Stem =  machin learn , weight major algorithm ( wma ) meta learn algorithm use construct compound algorithm pool predict algorithm \n",
      "Cleaned Token Before =  artificial neural networks (ann), a widely used model in the field of machine learning. nas has been used to design networks that are on par or outperform\n",
      "Cleaned Token After =  artificial neural networks ( ann ) , widely used model field machine learning . nas used design networks par outperform \n",
      "Cleaned Token After Stem =  artifici neural network ( ann ) , wide use model field machin learn . na use design network par outperform \n",
      "Cleaned Token Before =  encoder representations from transformers (bert) is a transformer-based machine learning technique for natural language processing (nlp) pre-training developed\n",
      "Cleaned Token After =  encoder representations transformers ( bert ) transformer-based machine learning technique natural language processing ( nlp ) pre-training developed \n",
      "Cleaned Token After Stem =  encod represent transform ( bert ) transformer-bas machin learn techniqu natur languag process ( nlp ) pre-train develop \n",
      "Cleaned Token Before =  temporal difference (td) learning refers to a class of model-free reinforcement learning methods which learn by bootstrapping from the current estimate\n",
      "Cleaned Token After =  temporal difference ( td ) learning refers class model-free reinforcement learning methods learn bootstrapping current estimate \n",
      "Cleaned Token After Stem =  tempor differ ( td ) learn refer class model-fre reinforc learn method learn bootstrap current estim \n",
      "Cleaned Token Before =  acts as a regularizer and helps reduce overfitting when training a machine learning model. it is closely related to oversampling in data analysis. geometric\n",
      "Cleaned Token After =  acts regularizer helps reduce overfitting training machine learning model . closely related oversampling data analysis . geometric \n",
      "Cleaned Token After Stem =  act regular help reduc overfit train machin learn model . close relat oversampl data analysi . geometr \n",
      "Cleaned Token Before =   some of the alternatives to rote learning include meaningful learning, associative learning, and active learning. rote methods are routinely used when\n",
      "Cleaned Token After =  alternatives rote learning include meaningful learning , associative learning , active learning . rote methods routinely used \n",
      "Cleaned Token After Stem =  altern rote learn includ meaning learn , associ learn , activ learn . rote method routin use \n",
      "Cleaned Token Before =  technique. the project uses a combination of machine learning, natural language processing, and machine vision to add a layer of semantic analysis to\n",
      "Cleaned Token After =  technique . project uses combination machine learning , natural language processing , machine vision add layer semantic analysis \n",
      "Cleaned Token After Stem =  techniqu . project use combin machin learn , natur languag process , machin vision add layer semant analysi \n",
      "Cleaned Token Before =  circuit (asic) developed by google specifically for neural network machine learning, particularly using google's own tensorflow software. google began\n",
      "Cleaned Token After =  circuit ( asic ) developed google specifically neural network machine learning , particularly using google 's tensorflow software . google began \n",
      "Cleaned Token After Stem =  circuit ( asic ) develop googl specif neural network machin learn , particularli use googl 's tensorflow softwar . googl began \n",
      "Cleaned Token Before =  in machine learning, a probabilistic classifier is a classifier that is able to predict, given an observation of an input, a probability distribution over\n",
      "Cleaned Token After =  machine learning , probabilistic classifier classifier able predict , given observation input , probability distribution \n",
      "Cleaned Token After Stem =  machin learn , probabilist classifi classifi abl predict , given observ input , probabl distribut \n",
      "Cleaned Token Before =  of taking an experimental machine learning model into a production web system. the word is a compound of “machine learning” and the continuous development\n",
      "Cleaned Token After =  taking experimental machine learning model production web system . word compound “ machine learning ” continuous development \n",
      "Cleaned Token After Stem =  take experiment machin learn model product web system . word compound “ machin learn ” continu develop \n",
      "Cleaned Token Before =  was named a leader in the 2018 magic quadrant for data science and machine learning platforms. as of july 2020, alteryx offered the following products\n",
      "Cleaned Token After =  named leader 2018 magic quadrant data science machine learning platforms . july 2020 , alteryx offered following products \n",
      "Cleaned Token After Stem =  name leader 2018 magic quadrant data scienc machin learn platform . juli 2020 , alteryx offer follow product \n",
      "Cleaned Token Before =  instance, the wiener process is the limit of the bernoulli process. in machine learning theory, i.i.d. assumption is often made for training datasets to imply\n",
      "Cleaned Token After =  instance , wiener process limit bernoulli process . machine learning theory , i.i.d . assumption often made training datasets imply \n",
      "Cleaned Token After Stem =  instanc , wiener process limit bernoulli process . machin learn theori , i.i.d . assumpt often made train dataset impli \n",
      "Cleaned Token Before =  problems in machine learning and control engineering. symbolic ai was intended to produce general, human-like intelligence in a machine, whereas most\n",
      "Cleaned Token After =  problems machine learning control engineering . symbolic ai intended produce general , human-like intelligence machine , whereas \n",
      "Cleaned Token After Stem =  problem machin learn control engin . symbol ai intend produc gener , human-lik intellig machin , wherea \n",
      "Cleaned Token Before =  supervised learning, taking advantage of similar mathematical structure in variational studies in quantum mechanics and large-scale machine learning. this\n",
      "Cleaned Token After =  supervised learning , taking advantage similar mathematical structure variational studies quantum mechanics large-scale machine learning . \n",
      "Cleaned Token After Stem =  supervis learn , take advantag similar mathemat structur variat studi quantum mechan large-scal machin learn . \n",
      "Cleaned Token Before =  tanagra is a free suite of machine learning software for research and academic purposes developed by ricco rakotomalala at the lumière university lyon\n",
      "Cleaned Token After =  tanagra free suite machine learning software research academic purposes developed ricco rakotomalala lumière university lyon \n",
      "Cleaned Token After Stem =  tanagra free suit machin learn softwar research academ purpos develop ricco rakotomalala lumièr univers lyon \n",
      "Cleaned Token Before =  in computing, a virtual machine (vm) is the virtualization/emulation of a computer system. virtual machines are based on computer architectures and provide\n",
      "Cleaned Token After =  computing , virtual machine ( vm ) virtualization/emulation computer system . virtual machines based computer architectures provide \n",
      "Cleaned Token After Stem =  comput , virtual machin ( vm ) virtualization/emul comput system . virtual machin base comput architectur provid \n",
      "Cleaned Token Before =   in machine learning, one aims to construct algorithms that are able to learn to predict a certain target output. to achieve this, the learning algorithm\n",
      "Cleaned Token After =  machine learning , one aims construct algorithms able learn predict certain target output . achieve , learning algorithm \n",
      "Cleaned Token After Stem =  machin learn , one aim construct algorithm abl learn predict certain target output . achiev , learn algorithm \n",
      "Cleaned Token Before =  the company dessa in support for new deep-learning techniques. many of his numerous papers on machine learning and computer vision are frequently cited\n",
      "Cleaned Token After =  company dessa support new deep-learning techniques . many numerous papers machine learning computer vision frequently cited \n",
      "Cleaned Token After Stem =  compani dessa support new deep-learn techniqu . mani numer paper machin learn comput vision frequent cite \n",
      "Cleaned Token Before =  library written in java for the java virtual machine (jvm). it is a framework with wide support for deep learning algorithms. deeplearning4j includes implementations\n",
      "Cleaned Token After =  library written java java virtual machine ( jvm ) . framework wide support deep learning algorithms . deeplearning4j includes implementations \n",
      "Cleaned Token After Stem =  librari written java java virtual machin ( jvm ) . framework wide support deep learn algorithm . deeplearning4j includ implement \n",
      "Cleaned Token Before =  (2007). \"euclidean embedding of co-occurrence data\" (pdf). journal of machine learning research. qureshi, m. atif; greene, derek (2018-06-04). \"eve: explainable\n",
      "Cleaned Token After =  ( 2007 ) . `` euclidean embedding co-occurrence data '' ( pdf ) . journal machine learning research . qureshi , m. atif ; greene , derek ( 2018-06-04 ) . `` eve : explainable \n",
      "Cleaned Token After Stem =  ( 2007 ) . `` euclidean embed co-occurr data `` ( pdf ) . journal machin learn research . qureshi , m. atif ; green , derek ( 2018-06-04 ) . `` eve : explain \n",
      "Cleaned Token Before =  mixture of experts (moe) refers to a machine learning technique where multiple experts (learners) are used to divide the problem space into homogeneous\n",
      "Cleaned Token After =  mixture experts ( moe ) refers machine learning technique multiple experts ( learners ) used divide problem space homogeneous \n",
      "Cleaned Token After Stem =  mixtur expert ( moe ) refer machin learn techniqu multipl expert ( learner ) use divid problem space homogen \n",
      "Cleaned Token Before =  in machine learning, knowledge distillation is the process of transferring knowledge from a large model to a smaller one. while large models (such as very\n",
      "Cleaned Token After =  machine learning , knowledge distillation process transferring knowledge large model smaller one . large models ( \n",
      "Cleaned Token After Stem =  machin learn , knowledg distil process transfer knowledg larg model smaller one . larg model ( \n",
      "Cleaned Token Before =  of machine learning to extract knowledge from data. subfields of machine learning include deep learning, supervised learning, unsupervised learning, reinforcement\n",
      "Cleaned Token After =  machine learning extract knowledge data . subfields machine learning include deep learning , supervised learning , unsupervised learning , reinforcement \n",
      "Cleaned Token After Stem =  machin learn extract knowledg data . subfield machin learn includ deep learn , supervis learn , unsupervis learn , reinforc \n",
      "Cleaned Token Before =  the international conference on learning representations (iclr) is a machine learning conference held every spring. the conference includes invited talks\n",
      "Cleaned Token After =  international conference learning representations ( iclr ) machine learning conference held every spring . conference includes invited talks \n",
      "Cleaned Token After Stem =  intern confer learn represent ( iclr ) machin learn confer held everi spring . confer includ invit talk \n",
      "Cleaned Token Before =  pytorch is an open source machine learning library based on the torch library, used for applications such as computer vision and natural language processing\n",
      "Cleaned Token After =  pytorch open source machine learning library based torch library , used applications computer vision natural language processing \n",
      "Cleaned Token After Stem =  pytorch open sourc machin learn librari base torch librari , use applic comput vision natur languag process \n",
      "Cleaned Token Before =  in pattern recognition, information retrieval and classification (machine learning), precision (also called positive predictive value) is the fraction\n",
      "Cleaned Token After =  pattern recognition , information retrieval classification ( machine learning ) , precision ( also called positive predictive value ) fraction \n",
      "Cleaned Token After Stem =  pattern recognit , inform retriev classif ( machin learn ) , precis ( also call posit predict valu ) fraction \n",
      "Cleaned Token Before =  faster than the a12. it also includes a 16-core neural engine and new machine learning matrix accelerators that perform twice and ten times as fast, respectively\n",
      "Cleaned Token After =  faster a12 . also includes 16-core neural engine new machine learning matrix accelerators perform twice ten times fast , respectively \n",
      "Cleaned Token After Stem =  faster a12 . also includ 16-core neural engin new machin learn matrix acceler perform twice ten time fast , respect \n",
      "Cleaned Token Before =  learning with errors (lwe) is the computational problem of inferring a linear n {\\displaystyle n} -ary function f {\\displaystyle f} over a finite ring\n",
      "Cleaned Token After =  learning errors ( lwe ) computational problem inferring linear n { \\displaystyle n } -ary function f { \\displaystyle f } finite ring \n",
      "Cleaned Token After Stem =  learn error ( lwe ) comput problem infer linear n { \\displaystyl n } -ari function f { \\displaystyl f } finit ring \n",
      "Cleaned Token Before =  on open source technology, cloudera’s platform uses analytics and machine learning to yield insights from data through a secure connection. cloudera’s\n",
      "Cleaned Token After =  open source technology , cloudera ’ platform uses analytics machine learning yield insights data secure connection . cloudera ’ \n",
      "Cleaned Token After Stem =  open sourc technolog , cloudera ’ platform use analyt machin learn yield insight data secur connect . cloudera ’ \n",
      "Cleaned Token Before =  in computational learning theory of how a machine learning algorithm is perturbed by small changes to its inputs. a stable learning algorithm is one for\n",
      "Cleaned Token After =  computational learning theory machine learning algorithm perturbed small changes inputs . stable learning algorithm one \n",
      "Cleaned Token After Stem =  comput learn theori machin learn algorithm perturb small chang input . stabl learn algorithm one \n",
      "Cleaned Token Before =  strategy most likely to reach a goal, but are also a popular tool in machine learning. a decision tree is a flowchart-like structure in which each internal\n",
      "Cleaned Token After =  strategy likely reach goal , also popular tool machine learning . decision tree flowchart-like structure internal \n",
      "Cleaned Token After Stem =  strategi like reach goal , also popular tool machin learn . decis tree flowchart-lik structur intern \n",
      "Cleaned Token Before =  attacks, such as buffer overflows. traditional machine learning systems have a fixed, pre-programmed learning algorithm to adjust their parameters. however\n",
      "Cleaned Token After =  attacks , buffer overflows . traditional machine learning systems fixed , pre-programmed learning algorithm adjust parameters . however \n",
      "Cleaned Token After Stem =  attack , buffer overflow . tradit machin learn system fix , pre-program learn algorithm adjust paramet . howev \n",
      "Cleaned Token Before =  in machine learning, the radial basis function kernel, or rbf kernel, is a popular kernel function used in various kernelized learning algorithms. in\n",
      "Cleaned Token After =  machine learning , radial basis function kernel , rbf kernel , popular kernel function used various kernelized learning algorithms . \n",
      "Cleaned Token After Stem =  machin learn , radial basi function kernel , rbf kernel , popular kernel function use variou kernel learn algorithm . \n",
      "Cleaned Token Before =  relationship to the k-nearest neighbor classifier, a popular supervised machine learning technique for classification that is often confused with k-means due\n",
      "Cleaned Token After =  relationship k-nearest neighbor classifier , popular supervised machine learning technique classification often confused k-means due \n",
      "Cleaned Token After Stem =  relationship k-nearest neighbor classifi , popular supervis machin learn techniqu classif often confus k-mean due \n",
      "Cleaned Token Before =  and r programming languages for scientific computing (data science, machine learning applications, large-scale data processing, predictive analytics, etc\n",
      "Cleaned Token After =  r programming languages scientific computing ( data science , machine learning applications , large-scale data processing , predictive analytics , etc \n",
      "Cleaned Token After Stem =  r program languag scientif comput ( data scienc , machin learn applic , large-scal data process , predict analyt , etc \n",
      "Cleaned Token Before =  conference on machine learning. the 33rd international conference on machine learning. new york, new york, usa: proceedings of machine learning research.\n",
      "Cleaned Token After =  conference machine learning . 33rd international conference machine learning . new york , new york , usa : proceedings machine learning research . \n",
      "Cleaned Token After Stem =  confer machin learn . 33rd intern confer machin learn . new york , new york , usa : proceed machin learn research . \n",
      "Cleaned Token Before =  ml.net is a free software machine learning library for the c# and f# programming languages. it also supports python models when used together with nimbusml\n",
      "Cleaned Token After =  ml.net free software machine learning library c # f # programming languages . also supports python models used together nimbusml \n",
      "Cleaned Token After Stem =  ml.net free softwar machin learn librari c # f # program languag . also support python model use togeth nimbusml \n",
      "Cleaned Token Before =  sparse coding is a representation learning method which aims at finding a sparse representation of the input data (also known as sparse coding) in the\n",
      "Cleaned Token After =  sparse coding representation learning method aims finding sparse representation input data ( also known sparse coding ) \n",
      "Cleaned Token After Stem =  spars code represent learn method aim find spars represent input data ( also known spars code ) \n",
      "Cleaned Token Before =  models of machine learning: unsupervised learning supervised learning reinforcement learning a lot of the learning methods in machine learning work similar\n",
      "Cleaned Token After =  models machine learning : unsupervised learning supervised learning reinforcement learning lot learning methods machine learning work similar \n",
      "Cleaned Token After Stem =  model machin learn : unsupervis learn supervis learn reinforc learn lot learn method machin learn work similar \n",
      "Cleaned Token Before =  popularized the term \"machine learning\" in 1959. the samuel checkers-playing program was among the world's first successful self-learning programs, and as\n",
      "Cleaned Token After =  popularized term `` machine learning '' 1959. samuel checkers-playing program among world 's first successful self-learning programs , \n",
      "Cleaned Token After Stem =  popular term `` machin learn `` 1959. samuel checkers-play program among world 's first success self-learn program , \n",
      "Cleaned Token Before =  communication of the nodes subsamples of large data sets and online machine learning there are many reasons for wanting to distribute intelligence or cope\n",
      "Cleaned Token After =  communication nodes subsamples large data sets online machine learning many reasons wanting distribute intelligence cope \n",
      "Cleaned Token After Stem =  commun node subsampl larg data set onlin machin learn mani reason want distribut intellig cope \n",
      "Cleaned Token Before =  for supervised learning applications in machine learning and statistical learning theory, generalization error (also known as the out-of-sample error or\n",
      "Cleaned Token After =  supervised learning applications machine learning statistical learning theory , generalization error ( also known out-of-sample error \n",
      "Cleaned Token After Stem =  supervis learn applic machin learn statist learn theori , gener error ( also known out-of-sampl error \n",
      "Cleaned Token Before =  waffles is a collection of command-line tools for performing machine learning operations developed at brigham young university. these tools are written\n",
      "Cleaned Token After =  waffles collection command-line tools performing machine learning operations developed brigham young university . tools written \n",
      "Cleaned Token After Stem =  waffl collect command-lin tool perform machin learn oper develop brigham young univers . tool written \n",
      "Cleaned Token Before =  features learning in 2005. at the moment, automated learning methods can further separate into supervised and unsupervised machine learning. patterns\n",
      "Cleaned Token After =  features learning 2005. moment , automated learning methods separate supervised unsupervised machine learning . patterns \n",
      "Cleaned Token After Stem =  featur learn 2005. moment , autom learn method separ supervis unsupervis machin learn . pattern \n",
      "Cleaned Token Before =  technologies that will change your world\" concerning the topic of bayesian machine learning. koller received a bachelor's degree from the hebrew university of\n",
      "Cleaned Token After =  technologies change world '' concerning topic bayesian machine learning . koller received bachelor 's degree hebrew university \n",
      "Cleaned Token After Stem =  technolog chang world `` concern topic bayesian machin learn . koller receiv bachelor 's degre hebrew univers \n",
      "Cleaned Token Before =  pipeline workflows libsvm – c++ support vector machine libraries mlpack – open-source library for machine learning, exploits c++ language features to provide\n",
      "Cleaned Token After =  pipeline workflows libsvm – c++ support vector machine libraries mlpack – open-source library machine learning , exploits c++ language features provide \n",
      "Cleaned Token After Stem =  pipelin workflow libsvm – c++ support vector machin librari mlpack – open-sourc librari machin learn , exploit c++ languag featur provid \n",
      "Cleaned Token Before =  multi-agent learning is the use of machine learning in a multi-agent system. typically, agents improve their decisions via experience. in particular,\n",
      "Cleaned Token After =  multi-agent learning use machine learning multi-agent system . typically , agents improve decisions via experience . particular , \n",
      "Cleaned Token After Stem =  multi-ag learn use machin learn multi-ag system . typic , agent improv decis via experi . particular , \n",
      "Cleaned Token Before =  multiple kernel learning refers to a set of machine learning methods that use a predefined set of kernels and learn an optimal linear or non-linear combination\n",
      "Cleaned Token After =  multiple kernel learning refers set machine learning methods use predefined set kernels learn optimal linear non-linear combination \n",
      "Cleaned Token After Stem =  multipl kernel learn refer set machin learn method use predefin set kernel learn optim linear non-linear combin \n",
      "Cleaned Token Before =  statistical techniques from data mining, predictive modelling, and machine learning that analyze current and historical facts to make predictions about\n",
      "Cleaned Token After =  statistical techniques data mining , predictive modelling , machine learning analyze current historical facts make predictions \n",
      "Cleaned Token After Stem =  statist techniqu data mine , predict model , machin learn analyz current histor fact make predict \n",
      "Cleaned Token Before =  american computer scientist, and technology entrepreneur focusing on machine learning and ai. ng was a co-founder and head of google brain and was the former\n",
      "Cleaned Token After =  american computer scientist , technology entrepreneur focusing machine learning ai . ng co-founder head google brain former \n",
      "Cleaned Token After Stem =  american comput scientist , technolog entrepreneur focus machin learn ai . ng co-found head googl brain former \n",
      "Cleaned Token Before =  android), on the web, or on the java virtual machine. it also allows use of distributed training of deep-learning models on clusters of graphics processing\n",
      "Cleaned Token After =  android ) , web , java virtual machine . also allows use distributed training deep-learning models clusters graphics processing \n",
      "Cleaned Token After Stem =  android ) , web , java virtual machin . also allow use distribut train deep-learn model cluster graphic process \n",
      "Cleaned Token Before =  used both in statistical sampling, survey design methodology and in machine learning. oversampling and undersampling are opposite and roughly equivalent\n",
      "Cleaned Token After =  used statistical sampling , survey design methodology machine learning . oversampling undersampling opposite roughly equivalent \n",
      "Cleaned Token After Stem =  use statist sampl , survey design methodolog machin learn . oversampl undersampl opposit roughli equival \n",
      "Cleaned Token Before =  weak supervision is a branch of machine learning where noisy, limited, or imprecise sources are used to provide supervision signal for labeling large amounts\n",
      "Cleaned Token After =  weak supervision branch machine learning noisy , limited , imprecise sources used provide supervision signal labeling large amounts \n",
      "Cleaned Token After Stem =  weak supervis branch machin learn noisi , limit , imprecis sourc use provid supervis signal label larg amount \n",
      "Cleaned Token Before =  a learning automaton is one type of machine learning algorithm studied since 1970s. learning automata select their current action based on past experiences\n",
      "Cleaned Token After =  learning automaton one type machine learning algorithm studied since 1970s . learning automata select current action based past experiences \n",
      "Cleaned Token After Stem =  learn automaton one type machin learn algorithm studi sinc 1970 . learn automata select current action base past experi \n",
      "Cleaned Token Before =  ultimate learning machine will remake our world. basic books. \"deeper into the brain\" subsection. isbn 978-046506192-1. bengio, y. (2009). \"learning deep\n",
      "Cleaned Token After =  ultimate learning machine remake world . basic books . `` deeper brain '' subsection . isbn 978-046506192-1. bengio , . ( 2009 ) . `` learning deep \n",
      "Cleaned Token After Stem =  ultim learn machin remak world . basic book . `` deeper brain `` subsect . isbn 978-046506192-1. bengio , . ( 2009 ) . `` learn deep \n",
      "Cleaned Token Before =  statistical relational learning (srl) is a subdiscipline of artificial intelligence and machine learning that is concerned with domain models that exhibit\n",
      "Cleaned Token After =  statistical relational learning ( srl ) subdiscipline artificial intelligence machine learning concerned domain models exhibit \n",
      "Cleaned Token After Stem =  statist relat learn ( srl ) subdisciplin artifici intellig machin learn concern domain model exhibit \n",
      "Cleaned Token Before =  in machine learning, kernel machines are a class of algorithms for pattern analysis, whose best known member is the support-vector machine (svm). the\n",
      "Cleaned Token After =  machine learning , kernel machines class algorithms pattern analysis , whose best known member support-vector machine ( svm ) . \n",
      "Cleaned Token After Stem =  machin learn , kernel machin class algorithm pattern analysi , whose best known member support-vector machin ( svm ) . \n",
      "Cleaned Token Before =  marketing leveraging artificial intelligence concept and model such as machine learning and bayesian network to achieve marketing goals. the main difference\n",
      "Cleaned Token After =  marketing leveraging artificial intelligence concept model machine learning bayesian network achieve marketing goals . main difference \n",
      "Cleaned Token After Stem =  market leverag artifici intellig concept model machin learn bayesian network achiev market goal . main differ \n",
      "Cleaned Token Before =  ability to distinguish its behavior from that of a human. the term \"machine learning\" was first used to describe a possible approach to artificial intelligence\n",
      "Cleaned Token After =  ability distinguish behavior human . term `` machine learning '' first used describe possible approach artificial intelligence \n",
      "Cleaned Token After Stem =  abil distinguish behavior human . term `` machin learn `` first use describ possibl approach artifici intellig \n",
      "Cleaned Token Before =  codechef long challenges - held every month - lasts upto 10 days kaggle – machine learning competitions. codecup – board game ai competition held annually since\n",
      "Cleaned Token After =  codechef long challenges - held every month - lasts upto 10 days kaggle – machine learning competitions . codecup – board game ai competition held annually since \n",
      "Cleaned Token After Stem =  codechef long challeng - held everi month - last upto 10 day kaggl – machin learn competit . codecup – board game ai competit held annual sinc \n",
      "Cleaned Token Before =  california irvine hosts the uci machine learning repository, a data resource which is very popular among machine learning researchers and data mining practitioners\n",
      "Cleaned Token After =  california irvine hosts uci machine learning repository , data resource popular among machine learning researchers data mining practitioners \n",
      "Cleaned Token After Stem =  california irvin host uci machin learn repositori , data resourc popular among machin learn research data mine practition \n",
      "Cleaned Token Before =  for his cutting-edge research in robotics and machine learning, particularly in deep reinforcement learning. abbeel was born in antwerp, belgium in 1977\n",
      "Cleaned Token After =  cutting-edge research robotics machine learning , particularly deep reinforcement learning . abbeel born antwerp , belgium 1977 \n",
      "Cleaned Token After Stem =  cutting-edg research robot machin learn , particularli deep reinforc learn . abbeel born antwerp , belgium 1977 \n",
      "Cleaned Token Before =  in mathematics, a relevance vector machine (rvm) is a machine learning technique that uses bayesian inference to obtain parsimonious solutions for regression\n",
      "Cleaned Token After =  mathematics , relevance vector machine ( rvm ) machine learning technique uses bayesian inference obtain parsimonious solutions regression \n",
      "Cleaned Token After Stem =  mathemat , relev vector machin ( rvm ) machin learn techniqu use bayesian infer obtain parsimoni solut regress \n",
      "Cleaned Token Before =  open source projects that span data engineering, data science and machine learning. databricks develops a web-based platform for working with spark, that\n",
      "Cleaned Token After =  open source projects span data engineering , data science machine learning . databricks develops web-based platform working spark , \n",
      "Cleaned Token After Stem =  open sourc project span data engin , data scienc machin learn . databrick develop web-bas platform work spark , \n",
      "Cleaned Token Before =  artificial intelligence. formed in 2011, google brain combines open-ended machine learning research with information systems and large-scale computing resources\n",
      "Cleaned Token After =  artificial intelligence . formed 2011 , google brain combines open-ended machine learning research information systems large-scale computing resources \n",
      "Cleaned Token After Stem =  artifici intellig . form 2011 , googl brain combin open-end machin learn research inform system large-scal comput resourc \n",
      "Cleaned Token Before =  commonly used to train machine learning and computer vision algorithms. it is one of the most widely used datasets for machine learning research. the cifar-10\n",
      "Cleaned Token After =  commonly used train machine learning computer vision algorithms . one widely used datasets machine learning research . cifar-10 \n",
      "Cleaned Token After Stem =  commonli use train machin learn comput vision algorithm . one wide use dataset machin learn research . cifar-10 \n",
      "Cleaned Token Before =  in deep learning, a convolutional neural network (cnn, or convnet) is a class of deep neural network, most commonly applied to analyze visual imagery.\n",
      "Cleaned Token After =  deep learning , convolutional neural network ( cnn , convnet ) class deep neural network , commonly applied analyze visual imagery . \n",
      "Cleaned Token After Stem =  deep learn , convolut neural network ( cnn , convnet ) class deep neural network , commonli appli analyz visual imageri . \n",
      "Cleaned Token Before =  problem with a wide range of applications from finance and economics to machine learning. qubo is an np hard problem, and for many classical problems from theoretical\n",
      "Cleaned Token After =  problem wide range applications finance economics machine learning . qubo np hard problem , many classical problems theoretical \n",
      "Cleaned Token After Stem =  problem wide rang applic financ econom machin learn . qubo np hard problem , mani classic problem theoret \n",
      "Cleaned Token Before =  business and web analytics. recently, splunk has also begun developing machine learning and data solutions for bizops. michael baum, rob das and erik swan\n",
      "Cleaned Token After =  business web analytics . recently , splunk also begun developing machine learning data solutions bizops . michael baum , rob das erik swan \n",
      "Cleaned Token After Stem =  busi web analyt . recent , splunk also begun develop machin learn data solut bizop . michael baum , rob da erik swan \n",
      "Cleaned Token Before =  preference learning is a subfield in machine learning, which is a classification method based on observed preference information. in the view of supervised\n",
      "Cleaned Token After =  preference learning subfield machine learning , classification method based observed preference information . view supervised \n",
      "Cleaned Token After Stem =  prefer learn subfield machin learn , classif method base observ prefer inform . view supervis \n",
      "Cleaned Token Before =  uncertainty in a model's predictions. deep learning and artificial neural networks are approaches used in machine learning to build computational models which\n",
      "Cleaned Token After =  uncertainty model 's predictions . deep learning artificial neural networks approaches used machine learning build computational models \n",
      "Cleaned Token After Stem =  uncertainti model 's predict . deep learn artifici neural network approach use machin learn build comput model \n",
      "Cleaned Token Before =  birthdays, buildings, animals, food, and more. different forms of machine learning in the photos service allow recognition of photo contents, automatically\n",
      "Cleaned Token After =  birthdays , buildings , animals , food , . different forms machine learning photos service allow recognition photo contents , automatically \n",
      "Cleaned Token After Stem =  birthday , build , anim , food , . differ form machin learn photo servic allow recognit photo content , automat \n",
      "Cleaned Token Before =  the university of washington. her research investigates the use of machine learning to understand high-dimensional data. witten studied mathematics and\n",
      "Cleaned Token After =  university washington . research investigates use machine learning understand high-dimensional data . witten studied mathematics \n",
      "Cleaned Token After Stem =  univers washington . research investig use machin learn understand high-dimension data . witten studi mathemat \n",
      "Cleaned Token Before =  regulates what users can do. updates have introduced features using machine learning, including \"explore\", offering answers based on natural language questions\n",
      "Cleaned Token After =  regulates users . updates introduced features using machine learning , including `` explore '' , offering answers based natural language questions \n",
      "Cleaned Token After Stem =  regul user . updat introduc featur use machin learn , includ `` explor `` , offer answer base natur languag question \n",
      "Cleaned Token Before =   deep learning applications appeared first in speech recognition in the 1990s. the first scientific paper on using neural networks in machine translation\n",
      "Cleaned Token After =  deep learning applications appeared first speech recognition 1990s . first scientific paper using neural networks machine translation \n",
      "Cleaned Token After Stem =  deep learn applic appear first speech recognit 1990 . first scientif paper use neural network machin translat \n",
      "Cleaned Token Before =  in computational learning theory (machine learning and theory of computation), rademacher complexity, named after hans rademacher, measures richness of\n",
      "Cleaned Token After =  computational learning theory ( machine learning theory computation ) , rademacher complexity , named hans rademacher , measures richness \n",
      "Cleaned Token After Stem =  comput learn theori ( machin learn theori comput ) , rademach complex , name han rademach , measur rich \n",
      "Cleaned Token Before =  combine \"the best techniques from machine learning and systems neuroscience to build powerful general-purpose learning algorithms\". google research released\n",
      "Cleaned Token After =  combine `` best techniques machine learning systems neuroscience build powerful general-purpose learning algorithms '' . google research released \n",
      "Cleaned Token After Stem =  combin `` best techniqu machin learn system neurosci build power general-purpos learn algorithm `` . googl research releas \n",
      "Cleaned Token Before =  in machine learning. the world economic forum's recommendations are as follows: active inclusion: the development and design of machine learning applications\n",
      "Cleaned Token After =  machine learning . world economic forum 's recommendations follows : active inclusion : development design machine learning applications \n",
      "Cleaned Token After Stem =  machin learn . world econom forum 's recommend follow : activ inclus : develop design machin learn applic \n",
      "Cleaned Token Before =  in predictive analytics and machine learning, the concept drift means that the statistical properties of the target variable, which the model is trying\n",
      "Cleaned Token After =  predictive analytics machine learning , concept drift means statistical properties target variable , model trying \n",
      "Cleaned Token After Stem =  predict analyt machin learn , concept drift mean statist properti target variabl , model tri \n",
      "Cleaned Token Before =  wage. supervised machine learning algorithms require large amounts of human-annotated data to be trained successfully. machine learning researchers have\n",
      "Cleaned Token After =  wage . supervised machine learning algorithms require large amounts human-annotated data trained successfully . machine learning researchers \n",
      "Cleaned Token After Stem =  wage . supervis machin learn algorithm requir larg amount human-annot data train success . machin learn research \n",
      "Cleaned Token Before =  linguistics that underlies the machine-learning approach to language processing. some of the earliest-used machine learning algorithms, such as decision\n",
      "Cleaned Token After =  linguistics underlies machine-learning approach language processing . earliest-used machine learning algorithms , decision \n",
      "Cleaned Token After Stem =  linguist underli machine-learn approach languag process . earliest-us machin learn algorithm , decis \n",
      "Cleaned Token Before =  multi-task learning (mtl) is a subfield of machine learning in which multiple learning tasks are solved at the same time, while exploiting commonalities\n",
      "Cleaned Token After =  multi-task learning ( mtl ) subfield machine learning multiple learning tasks solved time , exploiting commonalities \n",
      "Cleaned Token After Stem =  multi-task learn ( mtl ) subfield machin learn multipl learn task solv time , exploit common \n",
      "Cleaned Token Before =  sommerschield, thea; prag, jonathan (2019). \"restoring ancient text using deep learning: a case study on greek epigraphy\". proceedings of the 2019 conference on\n",
      "Cleaned Token After =  sommerschield , thea ; prag , jonathan ( 2019 ) . `` restoring ancient text using deep learning : case study greek epigraphy '' . proceedings 2019 conference \n",
      "Cleaned Token After Stem =  sommerschield , thea ; prag , jonathan ( 2019 ) . `` restor ancient text use deep learn : case studi greek epigraphi `` . proceed 2019 confer \n",
      "Cleaned Token Before =  self-learning wi-fi-enabled thermostat that optimizes heating and cooling of homes and businesses to conserve energy. the device is based on a machine learning\n",
      "Cleaned Token After =  self-learning wi-fi-enabled thermostat optimizes heating cooling homes businesses conserve energy . device based machine learning \n",
      "Cleaned Token After Stem =  self-learn wi-fi-en thermostat optim heat cool home busi conserv energi . devic base machin learn \n",
      "Cleaned Token Before =  simulation data. to this extent, it can be associated with the field of machine learning. the main use of pod is to decompose a physical field (like pressure\n",
      "Cleaned Token After =  simulation data . extent , associated field machine learning . main use pod decompose physical field ( like pressure \n",
      "Cleaned Token After Stem =  simul data . extent , associ field machin learn . main use pod decompos physic field ( like pressur \n",
      "Cleaned Token Before =  \"garbage in, garbage out\" is particularly applicable to data mining and machine learning projects. data-gathering methods are often loosely controlled, resulting\n",
      "Cleaned Token After =  `` garbage , garbage '' particularly applicable data mining machine learning projects . data-gathering methods often loosely controlled , resulting \n",
      "Cleaned Token After Stem =  `` garbag , garbag `` particularli applic data mine machin learn project . data-gath method often loos control , result \n",
      "Cleaned Token Before =  in machine learning, the polynomial kernel is a kernel function commonly used with support vector machines (svms) and other kernelized models, that represents\n",
      "Cleaned Token After =  machine learning , polynomial kernel kernel function commonly used support vector machines ( svms ) kernelized models , represents \n",
      "Cleaned Token After Stem =  machin learn , polynomi kernel kernel function commonli use support vector machin ( svm ) kernel model , repres \n",
      "Cleaned Token Before =  in the field of machine learning and specifically the problem of statistical classification, a confusion matrix, also known as an error matrix, is a specific\n",
      "Cleaned Token After =  field machine learning specifically problem statistical classification , confusion matrix , also known error matrix , specific \n",
      "Cleaned Token After Stem =  field machin learn specif problem statist classif , confus matrix , also known error matrix , specif \n",
      "Cleaned Token Before =  in machine learning and currently serving as the chief scientist of openai. he has made several major contributions to the field of deep learning. he\n",
      "Cleaned Token After =  machine learning currently serving chief scientist openai . made several major contributions field deep learning . \n",
      "Cleaned Token After Stem =  machin learn current serv chief scientist openai . made sever major contribut field deep learn . \n",
      "Cleaned Token Before =  equations, boundary-value problems for partial differential equations, machine learning, embedding problem, information theory, and other areas. this article\n",
      "Cleaned Token After =  equations , boundary-value problems partial differential equations , machine learning , embedding problem , information theory , areas . article \n",
      "Cleaned Token After Stem =  equat , boundary-valu problem partial differenti equat , machin learn , embed problem , inform theori , area . articl \n",
      "Cleaned Token Before =   its enterprise immune system technology uses ai and unsupervised machine learning to autonomously detect and take action against cyber-threats across\n",
      "Cleaned Token After =  enterprise immune system technology uses ai unsupervised machine learning autonomously detect take action cyber-threats across \n",
      "Cleaned Token After Stem =  enterpris immun system technolog use ai unsupervis machin learn autonom detect take action cyber-threat across \n",
      "Cleaned Token Before =  as well as a milestone in machine learning as it uses monte carlo tree search with artificial neural networks (a deep learning method) for policy (move\n",
      "Cleaned Token After =  well milestone machine learning uses monte carlo tree search artificial neural networks ( deep learning method ) policy ( move \n",
      "Cleaned Token After Stem =  well mileston machin learn use mont carlo tree search artifici neural network ( deep learn method ) polici ( move \n",
      "Cleaned Token Before =  empirical likelihood. beyond simple linear regression, there are several machine learning methods that can be extended to quantile regression. a switch from\n",
      "Cleaned Token After =  empirical likelihood . beyond simple linear regression , several machine learning methods extended quantile regression . switch \n",
      "Cleaned Token After Stem =  empir likelihood . beyond simpl linear regress , sever machin learn method extend quantil regress . switch \n",
      "Cleaned Token Before =  in machine learning, multi-label classification and the strongly related problem of multi-output classification are variants of the classification problem\n",
      "Cleaned Token After =  machine learning , multi-label classification strongly related problem multi-output classification variants classification problem \n",
      "Cleaned Token After Stem =  machin learn , multi-label classif strongli relat problem multi-output classif variant classif problem \n",
      "Cleaned Token Before =  montreal institute for learning algorithms) is a research institute in montreal, quebec, focusing mainly on machine learning research. approximately\n",
      "Cleaned Token After =  montreal institute learning algorithms ) research institute montreal , quebec , focusing mainly machine learning research . approximately \n",
      "Cleaned Token After Stem =  montreal institut learn algorithm ) research institut montreal , quebec , focus mainli machin learn research . approxim \n",
      "Cleaned Token Before =  out of the page in mathematics, especially in literature related to machine learning, it is used to denote element-wise multiplication the lost symbol -\n",
      "Cleaned Token After =  page mathematics , especially literature related machine learning , used denote element-wise multiplication lost symbol - \n",
      "Cleaned Token After Stem =  page mathemat , especi literatur relat machin learn , use denot element-wis multipl lost symbol - \n",
      "Cleaned Token Before =  the fields of artificial intelligence (ai), statistical analysis, machine learning, and business intelligence offer an additional narrative, the main\n",
      "Cleaned Token After =  fields artificial intelligence ( ai ) , statistical analysis , machine learning , business intelligence offer additional narrative , main \n",
      "Cleaned Token After Stem =  field artifici intellig ( ai ) , statist analysi , machin learn , busi intellig offer addit narr , main \n",
      "Cleaned Token Before =  tool for advancing life sciences) was a board management software machine learning proprietary software developed by aging analytics, a company registered\n",
      "Cleaned Token After =  tool advancing life sciences ) board management software machine learning proprietary software developed aging analytics , company registered \n",
      "Cleaned Token After Stem =  tool advanc life scienc ) board manag softwar machin learn proprietari softwar develop age analyt , compani regist \n",
      "Cleaned Token Before =  (aiops) is a term coined by gartner in 2016 as an industry category for machine learning analytics technology that enhances it operations analytics. aiops is\n",
      "Cleaned Token After =  ( aiops ) term coined gartner 2016 industry category machine learning analytics technology enhances operations analytics . aiops \n",
      "Cleaned Token After Stem =  ( aiop ) term coin gartner 2016 industri categori machin learn analyt technolog enhanc oper analyt . aiop \n",
      "Cleaned Token Before =  code apx. appen provides or improves data used for the development of machine learning and artificial intelligence products. data types include speech and\n",
      "Cleaned Token After =  code apx . appen provides improves data used development machine learning artificial intelligence products . data types include speech \n",
      "Cleaned Token After Stem =  code apx . appen provid improv data use develop machin learn artifici intellig product . data type includ speech \n",
      "Cleaned Token Before =  for tasks such as reporting, visualization, advanced analytics and machine learning. a data lake can include structured data from relational databases\n",
      "Cleaned Token After =  tasks reporting , visualization , advanced analytics machine learning . data lake include structured data relational databases \n",
      "Cleaned Token After Stem =  task report , visual , advanc analyt machin learn . data lake includ structur data relat databas \n",
      "Cleaned Token Before =  databases documentation graphical user interfaces image processing machine learning mobile app multimedia computer networking scientific computing system\n",
      "Cleaned Token After =  databases documentation graphical user interfaces image processing machine learning mobile app multimedia computer networking scientific computing system \n",
      "Cleaned Token After Stem =  databas document graphic user interfac imag process machin learn mobil app multimedia comput network scientif comput system \n",
      "Cleaned Token Before =  them. the sql server machine learning services operates within the sql server instance, allowing people to do machine learning and data analytics without\n",
      "Cleaned Token After =  . sql server machine learning services operates within sql server instance , allowing people machine learning data analytics without \n",
      "Cleaned Token After Stem =  . sql server machin learn servic oper within sql server instanc , allow peopl machin learn data analyt without \n",
      "Cleaned Token Before =  including learning to rank, computer graphics and visual design, robotics, sensor networks, automatic algorithm configuration, automatic machine learning toolboxes\n",
      "Cleaned Token After =  including learning rank , computer graphics visual design , robotics , sensor networks , automatic algorithm configuration , automatic machine learning toolboxes \n",
      "Cleaned Token After Stem =  includ learn rank , comput graphic visual design , robot , sensor network , automat algorithm configur , automat machin learn toolbox \n",
      "Cleaned Token Before =  as well as in information retrieval. in machine learning, ordinal regression may also be called ranking learning. ordinal regression can be performed using\n",
      "Cleaned Token After =  well information retrieval . machine learning , ordinal regression may also called ranking learning . ordinal regression performed using \n",
      "Cleaned Token After Stem =  well inform retriev . machin learn , ordin regress may also call rank learn . ordin regress perform use \n",
      "Cleaned Token Before =  proprietary software; for example, see scikit-learn – python library for machine learning which contains pca, probabilistic pca, kernel pca, sparse pca and other\n",
      "Cleaned Token After =  proprietary software ; example , see scikit-learn – python library machine learning contains pca , probabilistic pca , kernel pca , sparse pca \n",
      "Cleaned Token After Stem =  proprietari softwar ; exampl , see scikit-learn – python librari machin learn contain pca , probabilist pca , kernel pca , spars pca \n",
      "Cleaned Token Before =  example-based (ebmt) machine translation method in which the system \"learns from millions of examples\". gnmt's proposed architecture of system learning was first\n",
      "Cleaned Token After =  example-based ( ebmt ) machine translation method system `` learns millions examples '' . gnmt 's proposed architecture system learning first \n",
      "Cleaned Token After Stem =  example-bas ( ebmt ) machin translat method system `` learn million exampl `` . gnmt 's propos architectur system learn first \n",
      "Cleaned Token Before =  for many statistical classification techniques in machine learning such as support vector machines. the use of this data set in cluster analysis however\n",
      "Cleaned Token After =  many statistical classification techniques machine learning support vector machines . use data set cluster analysis however \n",
      "Cleaned Token After Stem =  mani statist classif techniqu machin learn support vector machin . use data set cluster analysi howev \n",
      "Cleaned Token Before =  that do not contain concept-relevant features. in a concept learning task, a human or machine learner is trained to classify objects by being shown a set\n",
      "Cleaned Token After =  contain concept-relevant features . concept learning task , human machine learner trained classify objects shown set \n",
      "Cleaned Token After Stem =  contain concept-relev featur . concept learn task , human machin learner train classifi object shown set \n",
      "Cleaned Token Before =  analytics is an approach of data analytics that employs the use of machine learning and natural language processing to automate analysis processes normally\n",
      "Cleaned Token After =  analytics approach data analytics employs use machine learning natural language processing automate analysis processes normally \n",
      "Cleaned Token After Stem =  analyt approach data analyt employ use machin learn natur languag process autom analysi process normal \n",
      "Cleaned Token Before =   studies in human-computer interaction through the application of machine learning with statistical temporal features extracted from the frontal lobe\n",
      "Cleaned Token After =  studies human-computer interaction application machine learning statistical temporal features extracted frontal lobe \n",
      "Cleaned Token After Stem =  studi human-comput interact applic machin learn statist tempor featur extract frontal lobe \n",
      "Cleaned Token Before =  training programs, or learning and development programs. the learning management system concept emerged directly from e-learning. although the first lms\n",
      "Cleaned Token After =  training programs , learning development programs . learning management system concept emerged directly e-learning . although first lms \n",
      "Cleaned Token After Stem =  train program , learn develop program . learn manag system concept emerg directli e-learn . although first lm \n",
      "Cleaned Token Before =  for ai and machine learning. it aims to make a massively parallel intelligence processing unit (ipu) that holds the complete machine learning model inside\n",
      "Cleaned Token After =  ai machine learning . aims make massively parallel intelligence processing unit ( ipu ) holds complete machine learning model inside \n",
      "Cleaned Token After Stem =  ai machin learn . aim make massiv parallel intellig process unit ( ipu ) hold complet machin learn model insid \n",
      "Cleaned Token Before =  and chairman of machine learning consultants llc. he is known for his research and educational activities in the area of machine learning. abu-mostafa studied\n",
      "Cleaned Token After =  chairman machine learning consultants llc . known research educational activities area machine learning . abu-mostafa studied \n",
      "Cleaned Token After Stem =  chairman machin learn consult llc . known research educ activ area machin learn . abu-mostafa studi \n",
      "Cleaned Token Before =  madlib: scalable, big data, sql-driven machine learning framework for data scientists mahout: machine learning and data mining solution. mahout manifoldcf:\n",
      "Cleaned Token After =  madlib : scalable , big data , sql-driven machine learning framework data scientists mahout : machine learning data mining solution . mahout manifoldcf : \n",
      "Cleaned Token After Stem =  madlib : scalabl , big data , sql-driven machin learn framework data scientist mahout : machin learn data mine solut . mahout manifoldcf : \n",
      "Cleaned Token Before =  suchi saria is an associate professor of machine learning and healthcare at johns hopkins university, where she uses big data to improve patient outcomes\n",
      "Cleaned Token After =  suchi saria associate professor machine learning healthcare johns hopkins university , uses big data improve patient outcomes \n",
      "Cleaned Token After Stem =  suchi saria associ professor machin learn healthcar john hopkin univers , use big data improv patient outcom \n",
      "Cleaned Token Before =  triplet loss is a loss function for machine learning algorithms where a baseline (anchor) input is compared to a positive (truthy) input and a negative\n",
      "Cleaned Token After =  triplet loss loss function machine learning algorithms baseline ( anchor ) input compared positive ( truthy ) input negative \n",
      "Cleaned Token After Stem =  triplet loss loss function machin learn algorithm baselin ( anchor ) input compar posit ( truthi ) input neg \n",
      "Cleaned Token Before =  optimization\". wolpert had previously derived no free lunch theorems for machine learning (statistical inference). in 2005, wolpert and macready themselves indicated\n",
      "Cleaned Token After =  optimization '' . wolpert previously derived free lunch theorems machine learning ( statistical inference ) . 2005 , wolpert macready indicated \n",
      "Cleaned Token After Stem =  optim `` . wolpert previous deriv free lunch theorem machin learn ( statist infer ) . 2005 , wolpert macreadi indic \n",
      "Cleaned Token Before =  self-learning can refer to: autodidacticism learning theory (education) night self-learning unsupervised learning, a kind of machine learning this disambiguation\n",
      "Cleaned Token After =  self-learning refer : autodidacticism learning theory ( education ) night self-learning unsupervised learning , kind machine learning disambiguation \n",
      "Cleaned Token After Stem =  self-learn refer : autodidactic learn theori ( educ ) night self-learn unsupervis learn , kind machin learn disambigu \n",
      "Cleaned Token Before =  max welling (born 1968) is a dutch computer scientist in machine learning at the university of amsterdam. in august 2017, the university spin-off, “scyfer\n",
      "Cleaned Token After =  max welling ( born 1968 ) dutch computer scientist machine learning university amsterdam . august 2017 , university spin-off , “ scyfer \n",
      "Cleaned Token After Stem =  max well ( born 1968 ) dutch comput scientist machin learn univers amsterdam . august 2017 , univers spin-off , “ scyfer \n",
      "Cleaned Token Before =  reality business\". unity machine learning agents is open-source software whereby the unity platform connects to machine learning programs, including google's\n",
      "Cleaned Token After =  reality business '' . unity machine learning agents open-source software whereby unity platform connects machine learning programs , including google 's \n",
      "Cleaned Token After Stem =  realiti busi `` . uniti machin learn agent open-sourc softwar wherebi uniti platform connect machin learn program , includ googl 's \n",
      "Cleaned Token Before =  eu/resources/publications/cerbah-learning-highly-structured-semantic-repositories-from-relational-databases.pdf archived 2011-07-20 at the wayback machine wimalasuriya,\n",
      "Cleaned Token After =  eu/resources/publications/cerbah-learning-highly-structured-semantic-repositories-from-relational-databases.pdf archived 2011-07-20 wayback machine wimalasuriya , \n",
      "Cleaned Token After Stem =  eu/resources/publications/cerbah-learning-highly-structured-semantic-repositories-from-relational-databases.pdf archiv 2011-07-20 wayback machin wimalasuriya , \n",
      "Cleaned Token Before =  of machine learning competitions. xgboost initially started as a research project by tianqi chen as part of the distributed (deep) machine learning community\n",
      "Cleaned Token After =  machine learning competitions . xgboost initially started research project tianqi chen part distributed ( deep ) machine learning community \n",
      "Cleaned Token After Stem =  machin learn competit . xgboost initi start research project tianqi chen part distribut ( deep ) machin learn commun \n",
      "Cleaned Token Before =  list of open-source machine learning software see data mining below see r programming language – packages of statistical learning and analysis tools trex\n",
      "Cleaned Token After =  list open-source machine learning software see data mining see r programming language – packages statistical learning analysis tools trex \n",
      "Cleaned Token After Stem =  list open-sourc machin learn softwar see data mine see r program languag – packag statist learn analysi tool trex \n",
      "Cleaned Token Before =  version space learning is a logical approach to machine learning, specifically binary classification. version space learning algorithms search a predefined\n",
      "Cleaned Token After =  version space learning logical approach machine learning , specifically binary classification . version space learning algorithms search predefined \n",
      "Cleaned Token After Stem =  version space learn logic approach machin learn , specif binari classif . version space learn algorithm search predefin \n",
      "Cleaned Token Before =  using adaptive window size. variants of the algorithm can be found in machine learning and image processing packages: elki. java data mining tool with many\n",
      "Cleaned Token After =  using adaptive window size . variants algorithm found machine learning image processing packages : elki . java data mining tool many \n",
      "Cleaned Token After Stem =  use adapt window size . variant algorithm found machin learn imag process packag : elki . java data mine tool mani \n",
      "Cleaned Token Before =  label propagation is a semi-supervised machine learning algorithm that assigns labels to previously unlabeled data points. at the start of the algorithm\n",
      "Cleaned Token After =  label propagation semi-supervised machine learning algorithm assigns labels previously unlabeled data points . start algorithm \n",
      "Cleaned Token After Stem =  label propag semi-supervis machin learn algorithm assign label previous unlabel data point . start algorithm \n",
      "Cleaned Token Before =  in machine learning, the vanishing gradient problem is encountered when training artificial neural networks with gradient-based learning methods and backpropagation\n",
      "Cleaned Token After =  machine learning , vanishing gradient problem encountered training artificial neural networks gradient-based learning methods backpropagation \n",
      "Cleaned Token After Stem =  machin learn , vanish gradient problem encount train artifici neural network gradient-bas learn method backpropag \n",
      "Cleaned Token Before =  in reinforcement learning (rl), a model-free algorithm (as opposed to a model-based one) is an algorithm which does not use the transition probability\n",
      "Cleaned Token After =  reinforcement learning ( rl ) , model-free algorithm ( opposed model-based one ) algorithm use transition probability \n",
      "Cleaned Token After Stem =  reinforc learn ( rl ) , model-fre algorithm ( oppos model-bas one ) algorithm use transit probabl \n",
      "Cleaned Token Before =  to the convergence of multiple technologies, real-time analytics, machine learning, commodity sensors, and embedded systems. traditional fields of embedded\n",
      "Cleaned Token After =  convergence multiple technologies , real-time analytics , machine learning , commodity sensors , embedded systems . traditional fields embedded \n",
      "Cleaned Token After Stem =  converg multipl technolog , real-tim analyt , machin learn , commod sensor , embed system . tradit field embed \n",
      "Cleaned Token Before =  bigo technology has developed proprietary artificial intelligence and machine learning that is integrated into the application. the ai features are used to\n",
      "Cleaned Token After =  bigo technology developed proprietary artificial intelligence machine learning integrated application . ai features used \n",
      "Cleaned Token After Stem =  bigo technolog develop proprietari artifici intellig machin learn integr applic . ai featur use \n",
      "Cleaned Token Before =  (pdf), proceedings of the 26th annual international conference on machine learning (published june 2009), pp. 1–8, doi:10.1145/1553374.1553494, isbn 9781605585161\n",
      "Cleaned Token After =  ( pdf ) , proceedings 26th annual international conference machine learning ( published june 2009 ) , pp . 1–8 , doi:10.1145/1553374.1553494 , isbn 9781605585161 \n",
      "Cleaned Token After Stem =  ( pdf ) , proceed 26th annual intern confer machin learn ( publish june 2009 ) , pp . 1–8 , doi:10.1145/1553374.1553494 , isbn 9781605585161 \n",
      "Cleaned Token Before =  boosting machine learning library\". techcrunch. retrieved 2020-08-30. yegulalp, serdar (2017-07-18). \"yandex open sources catboost machine learning library\"\n",
      "Cleaned Token After =  boosting machine learning library '' . techcrunch . retrieved 2020-08-30. yegulalp , serdar ( 2017-07-18 ) . `` yandex open sources catboost machine learning library '' \n",
      "Cleaned Token After Stem =  boost machin learn librari `` . techcrunch . retriev 2020-08-30. yegulalp , serdar ( 2017-07-18 ) . `` yandex open sourc catboost machin learn librari `` \n",
      "Cleaned Token Before =  openmp, in order to increase computer performance. opennn contains machine learning algorithms as a bundle of functions. these can be embedded in other\n",
      "Cleaned Token After =  openmp , order increase computer performance . opennn contains machine learning algorithms bundle functions . embedded \n",
      "Cleaned Token After Stem =  openmp , order increas comput perform . opennn contain machin learn algorithm bundl function . embed \n",
      "Cleaned Token Before =  the precursor to the c4.5 algorithm, and is typically used in the machine learning and natural language processing domains. the id3 algorithm begins with\n",
      "Cleaned Token After =  precursor c4.5 algorithm , typically used machine learning natural language processing domains . id3 algorithm begins \n",
      "Cleaned Token After Stem =  precursor c4.5 algorithm , typic use machin learn natur languag process domain . id3 algorithm begin \n",
      "Cleaned Token Before =  on statistical machine translation. language acquisition can be modeled as a machine learning process, which may be based on learning semantic parsers\n",
      "Cleaned Token After =  statistical machine translation . language acquisition modeled machine learning process , may based learning semantic parsers \n",
      "Cleaned Token After Stem =  statist machin translat . languag acquisit model machin learn process , may base learn semant parser \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Token Before =  in machine learning and bioinformatics. professor greiner is one of the principal investigators at the alberta innovates centre for machine learning (aicml)\n",
      "Cleaned Token After =  machine learning bioinformatics . professor greiner one principal investigators alberta innovates centre machine learning ( aicml ) \n",
      "Cleaned Token After Stem =  machin learn bioinformat . professor greiner one princip investig alberta innov centr machin learn ( aicml ) \n",
      "Cleaned Token Before =  improve the performance of machine learning algorithms. feature engineering can be considered as applied machine learning itself. a feature is an attribute\n",
      "Cleaned Token After =  improve performance machine learning algorithms . feature engineering considered applied machine learning . feature attribute \n",
      "Cleaned Token After Stem =  improv perform machin learn algorithm . featur engin consid appli machin learn . featur attribut \n",
      "Cleaned Token Before =  (paas) that supports querying using ansi sql. it also has built-in machine learning capabilities. bigquery was announced in may 2010 and made generally\n",
      "Cleaned Token After =  ( paas ) supports querying using ansi sql . also built-in machine learning capabilities . bigquery announced may 2010 made generally \n",
      "Cleaned Token After Stem =  ( paa ) support queri use ansi sql . also built-in machin learn capabl . bigqueri announc may 2010 made gener \n",
      "Cleaned Token Before =  1986) is a researcher working in machine learning, currently employed at apple inc. as its director of machine learning in the special projects group. he\n",
      "Cleaned Token After =  1986 ) researcher working machine learning , currently employed apple inc. director machine learning special projects group . \n",
      "Cleaned Token After Stem =  1986 ) research work machin learn , current employ appl inc. director machin learn special project group . \n",
      "Cleaned Token Before =  processing, speech recognition, machine vision, probabilistic logic, planning, reasoning, many forms of machine learning) into an ai assistant that learns\n",
      "Cleaned Token After =  processing , speech recognition , machine vision , probabilistic logic , planning , reasoning , many forms machine learning ) ai assistant learns \n",
      "Cleaned Token After Stem =  process , speech recognit , machin vision , probabilist logic , plan , reason , mani form machin learn ) ai assist learn \n",
      "Cleaned Token Before =  regulates what users can do. updates have introduced features using machine learning, including \"explore\", offering suggested layouts and images for presentations\n",
      "Cleaned Token After =  regulates users . updates introduced features using machine learning , including `` explore '' , offering suggested layouts images presentations \n",
      "Cleaned Token After Stem =  regul user . updat introduc featur use machin learn , includ `` explor `` , offer suggest layout imag present \n",
      "Cleaned Token Before =  and researcher in machine learning, statistics, and artificial intelligence. he is one of the leading figures in machine learning, and in 2016 science\n",
      "Cleaned Token After =  researcher machine learning , statistics , artificial intelligence . one leading figures machine learning , 2016 science \n",
      "Cleaned Token After Stem =  research machin learn , statist , artifici intellig . one lead figur machin learn , 2016 scienc \n",
      "Cleaned Token Before =  by machine learning, traditionally using statistical methods, since the mid-2010s by neural networks: socher et al. (2012) was an early deep learning tutorial\n",
      "Cleaned Token After =  machine learning , traditionally using statistical methods , since mid-2010s neural networks : socher et al . ( 2012 ) early deep learning tutorial \n",
      "Cleaned Token After Stem =  machin learn , tradit use statist method , sinc mid-2010 neural network : socher et al . ( 2012 ) earli deep learn tutori \n",
      "Cleaned Token Before =  the class of iterative algorithms are the training algorithms for machine learning systems, which formed the initial impetus for developing apache spark\n",
      "Cleaned Token After =  class iterative algorithms training algorithms machine learning systems , formed initial impetus developing apache spark \n",
      "Cleaned Token After Stem =  class iter algorithm train algorithm machin learn system , form initi impetu develop apach spark \n",
      "Cleaned Token Before =  (formerly scikits.learn and also known as sklearn) is a free software machine learning library for the python programming language. it features various classification\n",
      "Cleaned Token After =  ( formerly scikits.learn also known sklearn ) free software machine learning library python programming language . features various classification \n",
      "Cleaned Token After Stem =  ( formerli scikits.learn also known sklearn ) free softwar machin learn librari python program languag . featur variou classif \n",
      "Cleaned Token Before =  error-driven learning is a sub-area of machine learning concerned with how an agent ought to take actions in an environment so as to minimize some error\n",
      "Cleaned Token After =  error-driven learning sub-area machine learning concerned agent ought take actions environment minimize error \n",
      "Cleaned Token After Stem =  error-driven learn sub-area machin learn concern agent ought take action environ minim error \n",
      "Cleaned Token Before =  2018 book by safiya umoja noble in the fields of information science, machine learning, and human-computer interaction. algorithms of oppression is a text\n",
      "Cleaned Token After =  2018 book safiya umoja noble fields information science , machine learning , human-computer interaction . algorithms oppression text \n",
      "Cleaned Token After Stem =  2018 book safiya umoja nobl field inform scienc , machin learn , human-comput interact . algorithm oppress text \n",
      "Cleaned Token Before =  occasions. over time, google has added functionality that makes use of machine learning, including \"events from gmail\", where event information from a user's\n",
      "Cleaned Token After =  occasions . time , google added functionality makes use machine learning , including `` events gmail '' , event information user 's \n",
      "Cleaned Token After Stem =  occas . time , googl ad function make use machin learn , includ `` event gmail `` , event inform user 's \n",
      "Cleaned Token Before =  knowledge representation – semantic web – machine learning – constrained conditional models – deep learning – neural modeling fields – natural language\n",
      "Cleaned Token After =  knowledge representation – semantic web – machine learning – constrained conditional models – deep learning – neural modeling fields – natural language \n",
      "Cleaned Token After Stem =  knowledg represent – semant web – machin learn – constrain condit model – deep learn – neural model field – natur languag \n",
      "Cleaned Token Before =  in the field of machine learning. this is a relatively new field and is still evolving. as its most basic level, a machine-learning algorithm can be\n",
      "Cleaned Token After =  field machine learning . relatively new field still evolving . basic level , machine-learning algorithm \n",
      "Cleaned Token After Stem =  field machin learn . rel new field still evolv . basic level , machine-learn algorithm \n",
      "Cleaned Token Before =  occur in domains such as numerical analysis, sampling, combinatorics, machine learning, data mining and databases. the common theme of these problems is that\n",
      "Cleaned Token After =  occur domains numerical analysis , sampling , combinatorics , machine learning , data mining databases . common theme problems \n",
      "Cleaned Token After Stem =  occur domain numer analysi , sampl , combinator , machin learn , data mine databas . common theme problem \n",
      "Cleaned Token Before =  neil david lawrence is the deepmind professor of machine learning at the university of cambridge in the department of computer science and technology,\n",
      "Cleaned Token After =  neil david lawrence deepmind professor machine learning university cambridge department computer science technology , \n",
      "Cleaned Token After Stem =  neil david lawrenc deepmind professor machin learn univers cambridg depart comput scienc technolog , \n",
      "Cleaned Token Before =  data as follows: techniques for analyzing data, such as a/b testing, machine learning, and natural language processing big data technologies, like business\n",
      "Cleaned Token After =  data follows : techniques analyzing data , a/b testing , machine learning , natural language processing big data technologies , like business \n",
      "Cleaned Token After Stem =  data follow : techniqu analyz data , a/b test , machin learn , natur languag process big data technolog , like busi \n",
      "Cleaned Token Before =  where the elastic net method has been applied are: support vector machine metric learning portfolio optimization cancer prognosis in late 2014, it was proven\n",
      "Cleaned Token After =  elastic net method applied : support vector machine metric learning portfolio optimization cancer prognosis late 2014 , proven \n",
      "Cleaned Token After Stem =  elast net method appli : support vector machin metric learn portfolio optim cancer prognosi late 2014 , proven \n",
      "Cleaned Token Before =  the study of empirical processes as well as in statistical computational learning theory. suppose a is a set and c is a class of sets. the class c shatters\n",
      "Cleaned Token After =  study empirical processes well statistical computational learning theory . suppose set c class sets . class c shatters \n",
      "Cleaned Token After Stem =  studi empir process well statist comput learn theori . suppos set c class set . class c shatter \n",
      "Cleaned Token Before =  observational learning is learning that occurs through observing the behavior of others. it is a form of social learning which takes various forms, based\n",
      "Cleaned Token After =  observational learning learning occurs observing behavior others . form social learning takes various forms , based \n",
      "Cleaned Token After Stem =  observ learn learn occur observ behavior other . form social learn take variou form , base \n",
      "Cleaned Token Before =  (2018). \"a convergence theory for deep learning via overparameterization\". international conference on machine learning. du, simon s; zhai, xiyu; poczos, barnabas;\n",
      "Cleaned Token After =  ( 2018 ) . `` convergence theory deep learning via overparameterization '' . international conference machine learning . du , simon ; zhai , xiyu ; poczos , barnabas ; \n",
      "Cleaned Token After Stem =  ( 2018 ) . `` converg theori deep learn via overparameter `` . intern confer machin learn . du , simon ; zhai , xiyu ; poczo , barnaba ; \n",
      "Cleaned Token Before =  langford (born january 2, 1975) is a computer scientist working in machine learning and learning theory, a field that he says \"is shifting from an academic discipline\n",
      "Cleaned Token After =  langford ( born january 2 , 1975 ) computer scientist working machine learning learning theory , field says `` shifting academic discipline \n",
      "Cleaned Token After Stem =  langford ( born januari 2 , 1975 ) comput scientist work machin learn learn theori , field say `` shift academ disciplin \n",
      "Cleaned Token Before =  artificial intelligence. the unity platform is used to help machines through reinforced learning. according to fast company, deepmind uses unity software\n",
      "Cleaned Token After =  artificial intelligence . unity platform used help machines reinforced learning . according fast company , deepmind uses unity software \n",
      "Cleaned Token After Stem =  artifici intellig . uniti platform use help machin reinforc learn . accord fast compani , deepmind use uniti softwar \n",
      "Cleaned Token Before =  in machine learning, one-class classification (occ), also known as unary classification or class-modelling, tries to identify objects of a specific class\n",
      "Cleaned Token After =  machine learning , one-class classification ( occ ) , also known unary classification class-modelling , tries identify objects specific class \n",
      "Cleaned Token After Stem =  machin learn , one-class classif ( occ ) , also known unari classif class-model , tri identifi object specif class \n",
      "Cleaned Token Before =  furthermore, in 2017, it was listed by kdnuggets in top 10 open source machine learning python projects. in december 2019, preferred networks announced the\n",
      "Cleaned Token After =  furthermore , 2017 , listed kdnuggets top 10 open source machine learning python projects . december 2019 , preferred networks announced \n",
      "Cleaned Token After Stem =  furthermor , 2017 , list kdnugget top 10 open sourc machin learn python project . decemb 2019 , prefer network announc \n",
      "Cleaned Token Before =  in machine learning, the hinge loss is a loss function used for training classifiers. the hinge loss is used for \"maximum-margin\" classification, most\n",
      "Cleaned Token After =  machine learning , hinge loss loss function used training classifiers . hinge loss used `` maximum-margin '' classification , \n",
      "Cleaned Token After Stem =  machin learn , hing loss loss function use train classifi . hing loss use `` maximum-margin `` classif , \n",
      "Cleaned Token Before =  step. since the range of values of raw data varies widely, in some machine learning algorithms, objective functions will not work properly without normalization\n",
      "Cleaned Token After =  step . since range values raw data varies widely , machine learning algorithms , objective functions work properly without normalization \n",
      "Cleaned Token After Stem =  step . sinc rang valu raw data vari wide , machin learn algorithm , object function work properli without normal \n",
      "Cleaned Token Before =  accurate term \"softargmax\", but the term \"softmax\" is conventional in machine learning. this section uses the term \"softargmax\" to emphasize this interpretation\n",
      "Cleaned Token After =  accurate term `` softargmax '' , term `` softmax '' conventional machine learning . section uses term `` softargmax '' emphasize interpretation \n",
      "Cleaned Token After Stem =  accur term `` softargmax `` , term `` softmax `` convent machin learn . section use term `` softargmax `` emphas interpret \n",
      "Cleaned Token Before =  engine was provided by nuance communications, and siri uses advanced machine learning technologies to function. its original american, british, and australian\n",
      "Cleaned Token After =  engine provided nuance communications , siri uses advanced machine learning technologies function . original american , british , australian \n",
      "Cleaned Token After Stem =  engin provid nuanc commun , siri use advanc machin learn technolog function . origin american , british , australian \n",
      "Cleaned Token Before =  matthews correlation coefficient (mcc) or phi coefficient is used in machine learning as a measure of the quality of binary (two-class) classifications,\n",
      "Cleaned Token After =  matthews correlation coefficient ( mcc ) phi coefficient used machine learning measure quality binary ( two-class ) classifications , \n",
      "Cleaned Token After Stem =  matthew correl coeffici ( mcc ) phi coeffici use machin learn measur qualiti binari ( two-class ) classif , \n",
      "Cleaned Token Before =  robot learning is a research field at the intersection of machine learning and robotics. it studies techniques allowing a robot to acquire novel skills\n",
      "Cleaned Token After =  robot learning research field intersection machine learning robotics . studies techniques allowing robot acquire novel skills \n",
      "Cleaned Token After Stem =  robot learn research field intersect machin learn robot . studi techniqu allow robot acquir novel skill \n",
      "Cleaned Token Before =  inc., pp. 10201–10212, retrieved 2019-02-13 innes, mike (2018). \"on machine learning and programming languages\" (pdf). sysml conference 2018. archived from\n",
      "Cleaned Token After =  inc. , pp . 10201–10212 , retrieved 2019-02-13 innes , mike ( 2018 ) . `` machine learning programming languages '' ( pdf ) . sysml conference 2018. archived \n",
      "Cleaned Token After Stem =  inc. , pp . 10201–10212 , retriev 2019-02-13 inn , mike ( 2018 ) . `` machin learn program languag `` ( pdf ) . sysml confer 2018. archiv \n",
      "Cleaned Token Before =  in machine learning, feature hashing, also known as the hashing trick (by analogy to the kernel trick), is a fast and space-efficient way of vectorizing\n",
      "Cleaned Token After =  machine learning , feature hashing , also known hashing trick ( analogy kernel trick ) , fast space-efficient way vectorizing \n",
      "Cleaned Token After Stem =  machin learn , featur hash , also known hash trick ( analog kernel trick ) , fast space-effici way vector \n",
      "Cleaned Token Before =  caffe2 (april 18, 2017). \"caffe2 open source brings cross platform machine learning tools to developers\". caffe2. \"caffe2 merges with pytorch\". medium\n",
      "Cleaned Token After =  caffe2 ( april 18 , 2017 ) . `` caffe2 open source brings cross platform machine learning tools developers '' . caffe2 . `` caffe2 merges pytorch '' . medium \n",
      "Cleaned Token After Stem =  caffe2 ( april 18 , 2017 ) . `` caffe2 open sourc bring cross platform machin learn tool develop `` . caffe2 . `` caffe2 merg pytorch `` . medium \n",
      "Cleaned Token Before =  rule induction is an area of machine learning in which formal rules are extracted from a set of observations. the rules extracted may represent a full\n",
      "Cleaned Token After =  rule induction area machine learning formal rules extracted set observations . rules extracted may represent full \n",
      "Cleaned Token After Stem =  rule induct area machin learn formal rule extract set observ . rule extract may repres full \n",
      "Cleaned Token Before =  refers to these three classes as generative learning, conditional learning, and discriminative learning, but ng & jordan (2002) only distinguish two\n",
      "Cleaned Token After =  refers three classes generative learning , conditional learning , discriminative learning , ng & jordan ( 2002 ) distinguish two \n",
      "Cleaned Token After Stem =  refer three class gener learn , condit learn , discrimin learn , ng & jordan ( 2002 ) distinguish two \n",
      "Cleaned Token Before =  maximum – a smooth approximation to the maximum function, mainly used by machine learning algorithms. it is defined as the logarithm of the sum of the exponentials\n",
      "Cleaned Token After =  maximum – smooth approximation maximum function , mainly used machine learning algorithms . defined logarithm sum exponentials \n",
      "Cleaned Token After Stem =  maximum – smooth approxim maximum function , mainli use machin learn algorithm . defin logarithm sum exponenti \n",
      "Cleaned Token Before =  the weka machine learning software described the c4.5 algorithm as \"a landmark decision tree program that is probably the machine learning workhorse\n",
      "Cleaned Token After =  weka machine learning software described c4.5 algorithm `` landmark decision tree program probably machine learning workhorse \n",
      "Cleaned Token After Stem =  weka machin learn softwar describ c4.5 algorithm `` landmark decis tree program probabl machin learn workhors \n",
      "Cleaned Token Before =  is often used in combination with machine learning. eeg data are pre-processed to be passed on to machine learning algorithms. these algorithms are then\n",
      "Cleaned Token After =  often used combination machine learning . eeg data pre-processed passed machine learning algorithms . algorithms \n",
      "Cleaned Token After Stem =  often use combin machin learn . eeg data pre-process pass machin learn algorithm . algorithm \n",
      "Cleaned Token Before =  in information theory and machine learning, information gain is a synonym for kullback–leibler divergence; the amount of information gained about a random\n",
      "Cleaned Token After =  information theory machine learning , information gain synonym kullback–leibler divergence ; amount information gained random \n",
      "Cleaned Token After Stem =  inform theori machin learn , inform gain synonym kullback–leibl diverg ; amount inform gain random \n",
      "Cleaned Token Before =  high-dimensional data tend to have a very high time complexity. many machine learning algorithms, for example, struggle with high-dimensional data. reducing\n",
      "Cleaned Token After =  high-dimensional data tend high time complexity . many machine learning algorithms , example , struggle high-dimensional data . reducing \n",
      "Cleaned Token After Stem =  high-dimension data tend high time complex . mani machin learn algorithm , exampl , struggl high-dimension data . reduc \n",
      "Cleaned Token Before =  subsidiary of google llc, is an online community of data scientists and machine learning practitioners. kaggle allows users to find and publish data sets, explore\n",
      "Cleaned Token After =  subsidiary google llc , online community data scientists machine learning practitioners . kaggle allows users find publish data sets , explore \n",
      "Cleaned Token After Stem =  subsidiari googl llc , onlin commun data scientist machin learn practition . kaggl allow user find publish data set , explor \n",
      "Cleaned Token Before =  platforms of content creation, aggregation and distribution underpinned by machine learning techniques, with 120 million daily active users as of september 2017\n",
      "Cleaned Token After =  platforms content creation , aggregation distribution underpinned machine learning techniques , 120 million daily active users september 2017 \n",
      "Cleaned Token After Stem =  platform content creation , aggreg distribut underpin machin learn techniqu , 120 million daili activ user septemb 2017 \n",
      "Cleaned Token Before =  technology. she is a director of machine learning research at nvidia. her research considers tensor-algebraic methods, deep learning and non-convex problems.\n",
      "Cleaned Token After =  technology . director machine learning research nvidia . research considers tensor-algebraic methods , deep learning non-convex problems . \n",
      "Cleaned Token After Stem =  technolog . director machin learn research nvidia . research consid tensor-algebra method , deep learn non-convex problem . \n",
      "Cleaned Token Before =  (sarsa) is an algorithm for learning a markov decision process policy, used in the reinforcement learning area of machine learning. it was proposed by rummery\n",
      "Cleaned Token After =  ( sarsa ) algorithm learning markov decision process policy , used reinforcement learning area machine learning . proposed rummery \n",
      "Cleaned Token After Stem =  ( sarsa ) algorithm learn markov decis process polici , use reinforc learn area machin learn . propos rummeri \n",
      "Cleaned Token Before =  federated learning of cohorts (floc) is a type of web tracking through federated learning. it groups people into \"cohorts\" based on their browsing history\n",
      "Cleaned Token After =  federated learning cohorts ( floc ) type web tracking federated learning . groups people `` cohorts '' based browsing history \n",
      "Cleaned Token After Stem =  feder learn cohort ( floc ) type web track feder learn . group peopl `` cohort `` base brows histori \n",
      "Cleaned Token Before =  pruning is a data compression technique in machine learning and search algorithms that reduces the size of decision trees by removing sections of the tree\n",
      "Cleaned Token After =  pruning data compression technique machine learning search algorithms reduces size decision trees removing sections tree \n",
      "Cleaned Token After Stem =  prune data compress techniqu machin learn search algorithm reduc size decis tree remov section tree \n",
      "Cleaned Token Before =  adds neural network-based machine learning to the team. \"sophos to acquire invincea to add industry leading machine learning to its next generation endpoint\n",
      "Cleaned Token After =  adds neural network-based machine learning team . `` sophos acquire invincea add industry leading machine learning next generation endpoint \n",
      "Cleaned Token After Stem =  add neural network-bas machin learn team . `` sopho acquir invincea add industri lead machin learn next gener endpoint \n",
      "Cleaned Token Before =  in statistics and machine learning, the bias–variance tradeoff is the property of a model that the variance of the parameter estimates across samples can\n",
      "Cleaned Token After =  statistics machine learning , bias–variance tradeoff property model variance parameter estimates across samples \n",
      "Cleaned Token After Stem =  statist machin learn , bias–vari tradeoff properti model varianc paramet estim across sampl \n",
      "Cleaned Token Before =  manipulated. in data mining tools (for multivariate statistics and machine learning), the dependent variable is assigned a role as target variable (or\n",
      "Cleaned Token After =  manipulated . data mining tools ( multivariate statistics machine learning ) , dependent variable assigned role target variable ( \n",
      "Cleaned Token After Stem =  manipul . data mine tool ( multivari statist machin learn ) , depend variabl assign role target variabl ( \n",
      "Cleaned Token Before =  time, and may be used for automated planning. action model learning an area of machine learning concerned with creation and modification of software agent's\n",
      "Cleaned Token After =  time , may used automated planning . action model learning area machine learning concerned creation modification software agent 's \n",
      "Cleaned Token After Stem =  time , may use autom plan . action model learn area machin learn concern creation modif softwar agent 's \n",
      "Cleaned Token Before =  in statistics and in machine learning, a linear predictor function is a linear function (linear combination) of a set of coefficients and explanatory variables\n",
      "Cleaned Token After =  statistics machine learning , linear predictor function linear function ( linear combination ) set coefficients explanatory variables \n",
      "Cleaned Token After Stem =  statist machin learn , linear predictor function linear function ( linear combin ) set coeffici explanatori variabl \n",
      "Cleaned Token Before =  for light gradient boosting machine, is a free and open source distributed gradient boosting framework for machine learning originally developed by microsoft\n",
      "Cleaned Token After =  light gradient boosting machine , free open source distributed gradient boosting framework machine learning originally developed microsoft \n",
      "Cleaned Token After Stem =  light gradient boost machin , free open sourc distribut gradient boost framework machin learn origin develop microsoft \n",
      "Cleaned Token Before =  in statistics and machine learning, lasso (least absolute shrinkage and selection operator; also lasso or lasso) is a regression analysis method that performs\n",
      "Cleaned Token After =  statistics machine learning , lasso ( least absolute shrinkage selection operator ; also lasso lasso ) regression analysis method performs \n",
      "Cleaned Token After Stem =  statist machin learn , lasso ( least absolut shrinkag select oper ; also lasso lasso ) regress analysi method perform \n",
      "Cleaned Token Before =  (detecting deviations from a model of \"good\" traffic, which often relies on machine learning). another common variant is reputation-based detection (recognizing\n",
      "Cleaned Token After =  ( detecting deviations model `` good '' traffic , often relies machine learning ) . another common variant reputation-based detection ( recognizing \n",
      "Cleaned Token After Stem =  ( detect deviat model `` good `` traffic , often reli machin learn ) . anoth common variant reputation-bas detect ( recogn \n",
      "Cleaned Token Before =  an empirical comparison of supervised learning algorithms. proc. 23rd international conference on machine learning. citeseerx 10.1.1.122.5901. narasimha\n",
      "Cleaned Token After =  empirical comparison supervised learning algorithms . proc . 23rd international conference machine learning . citeseerx 10.1.1.122.5901. narasimha \n",
      "Cleaned Token After Stem =  empir comparison supervis learn algorithm . proc . 23rd intern confer machin learn . citeseerx 10.1.1.122.5901. narasimha \n",
      "Cleaned Token Before =  scientist at google and leading a large group of researchers working in machine learning including adversarial settings. among others, samy bengio supervised\n",
      "Cleaned Token After =  scientist google leading large group researchers working machine learning including adversarial settings . among others , samy bengio supervised \n",
      "Cleaned Token After Stem =  scientist googl lead larg group research work machin learn includ adversari set . among other , sami bengio supervis \n",
      "Cleaned Token Before =  in machine learning, multiple-instance learning (mil) is a type of supervised learning. instead of receiving a set of instances which are individually\n",
      "Cleaned Token After =  machine learning , multiple-instance learning ( mil ) type supervised learning . instead receiving set instances individually \n",
      "Cleaned Token After Stem =  machin learn , multiple-inst learn ( mil ) type supervis learn . instead receiv set instanc individu \n",
      "Cleaned Token Before =  artbreeder, formerly known as ganbreeder, is a collaborative, machine learning-based art website. using the models stylegan and biggan, the app allows\n",
      "Cleaned Token After =  artbreeder , formerly known ganbreeder , collaborative , machine learning-based art website . using models stylegan biggan , app allows \n",
      "Cleaned Token After Stem =  artbreed , formerli known ganbreed , collabor , machin learning-bas art websit . use model stylegan biggan , app allow \n",
      "Cleaned Token Before =  in machine learning and computational learning theory, logitboost is a boosting algorithm formulated by jerome friedman, trevor hastie, and robert tibshirani\n",
      "Cleaned Token After =  machine learning computational learning theory , logitboost boosting algorithm formulated jerome friedman , trevor hastie , robert tibshirani \n",
      "Cleaned Token After Stem =  machin learn comput learn theori , logitboost boost algorithm formul jerom friedman , trevor hasti , robert tibshirani \n",
      "Cleaned Token Before =  regulates what users can do. updates have introduced features using machine learning, including \"explore\", offering search results based on the contents\n",
      "Cleaned Token After =  regulates users . updates introduced features using machine learning , including `` explore '' , offering search results based contents \n",
      "Cleaned Token After Stem =  regul user . updat introduc featur use machin learn , includ `` explor `` , offer search result base content \n",
      "Cleaned Token Before =  \"apple acquires turi, a machine learning company\". techcrunch. retrieved august 5, 2016. clover, juli. \"apple acquires machine learning and ai startup turi\"\n",
      "Cleaned Token After =  `` apple acquires turi , machine learning company '' . techcrunch . retrieved august 5 , 2016. clover , juli . `` apple acquires machine learning ai startup turi '' \n",
      "Cleaned Token After Stem =  `` appl acquir turi , machin learn compani `` . techcrunch . retriev august 5 , 2016. clover , juli . `` appl acquir machin learn ai startup turi `` \n",
      "Cleaned Token Before =  being used for machine learning applications: a model is trained on a synthetically generated dataset with the intention of transfer learning to real data\n",
      "Cleaned Token After =  used machine learning applications : model trained synthetically generated dataset intention transfer learning real data \n",
      "Cleaned Token After Stem =  use machin learn applic : model train synthet gener dataset intent transfer learn real data \n",
      "Cleaned Token Before =  regression using u-net and its application on pansharpening; 3d u-net: learning dense volumetric segmentation from sparse annotation; ternausnet: u-net\n",
      "Cleaned Token After =  regression using u-net application pansharpening ; 3d u-net : learning dense volumetric segmentation sparse annotation ; ternausnet : u-net \n",
      "Cleaned Token After Stem =  regress use u-net applic pansharpen ; 3d u-net : learn dens volumetr segment spars annot ; ternausnet : u-net \n",
      "Cleaned Token Before =  c, c++, java, r, matlab, mathematica, and python. data science and machine learning analysis and modelling methods are being increasingly employed in portfolio\n",
      "Cleaned Token After =  c , c++ , java , r , matlab , mathematica , python . data science machine learning analysis modelling methods increasingly employed portfolio \n",
      "Cleaned Token After Stem =  c , c++ , java , r , matlab , mathematica , python . data scienc machin learn analysi model method increasingli employ portfolio \n",
      "Cleaned Token Before =  developing the ability in computers to do natural language processing and machine learning. a lot of techniques have been researched, including dictionary-based\n",
      "Cleaned Token After =  developing ability computers natural language processing machine learning . lot techniques researched , including dictionary-based \n",
      "Cleaned Token After Stem =  develop abil comput natur languag process machin learn . lot techniqu research , includ dictionary-bas \n",
      "Cleaned Token Before =  \"tutorial on learning with bayesian networks\". in jordan, michael irwin (ed.). learning in graphical models. adaptive computation and machine learning. cambridge\n",
      "Cleaned Token After =  `` tutorial learning bayesian networks '' . jordan , michael irwin ( ed. ) . learning graphical models . adaptive computation machine learning . cambridge \n",
      "Cleaned Token After Stem =  `` tutori learn bayesian network `` . jordan , michael irwin ( ed . ) . learn graphic model . adapt comput machin learn . cambridg \n",
      "Cleaned Token Before =  mode. models prioritize compounds for lead discovery. in order to use machine learning for this model of virtual screening there must be a training set with\n",
      "Cleaned Token After =  mode . models prioritize compounds lead discovery . order use machine learning model virtual screening must training set \n",
      "Cleaned Token After Stem =  mode . model priorit compound lead discoveri . order use machin learn model virtual screen must train set \n",
      "Cleaned Token Before =  in images using machine vision. it is often used in preprocessing to remove anomalous data from the dataset. in supervised learning, removing the anomalous\n",
      "Cleaned Token After =  images using machine vision . often used preprocessing remove anomalous data dataset . supervised learning , removing anomalous \n",
      "Cleaned Token After Stem =  imag use machin vision . often use preprocess remov anomal data dataset . supervis learn , remov anomal \n",
      "Cleaned Token Before =  discriminant, a method used in statistics, pattern recognition and machine learning to find a linear combination of features that characterizes or separates\n",
      "Cleaned Token After =  discriminant , method used statistics , pattern recognition machine learning find linear combination features characterizes separates \n",
      "Cleaned Token After Stem =  discrimin , method use statist , pattern recognit machin learn find linear combin featur character separ \n",
      "Cleaned Token Before =  in machine learning of learning a formal grammar (usually as a collection of re-write rules or productions or alternatively as a finite state machine or\n",
      "Cleaned Token After =  machine learning learning formal grammar ( usually collection re-write rules productions alternatively finite state machine \n",
      "Cleaned Token After Stem =  machin learn learn formal grammar ( usual collect re-writ rule product altern finit state machin \n",
      "Cleaned Token Before =  research laboratory. gpt-3's full version has a capacity of 175 billion machine learning parameters. gpt-3, which was introduced in may 2020, and was in beta\n",
      "Cleaned Token After =  research laboratory . gpt-3 's full version capacity 175 billion machine learning parameters . gpt-3 , introduced may 2020 , beta \n",
      "Cleaned Token After Stem =  research laboratori . gpt-3 's full version capac 175 billion machin learn paramet . gpt-3 , introduc may 2020 , beta \n",
      "Cleaned Token Before =  modeling and natural language processing, using modern statistical machine learning. gensim is implemented in python and cython for performance. gensim\n",
      "Cleaned Token After =  modeling natural language processing , using modern statistical machine learning . gensim implemented python cython performance . gensim \n",
      "Cleaned Token After Stem =  model natur languag process , use modern statist machin learn . gensim implement python cython perform . gensim \n",
      "Cleaned Token Before =  a timeline of artificial intelligence. timeline of machine translation timeline of machine learning mccorduck 2004, pp. 4–5 mccorduck (2004, pp. 5–9) needham\n",
      "Cleaned Token After =  timeline artificial intelligence . timeline machine translation timeline machine learning mccorduck 2004 , pp . 4–5 mccorduck ( 2004 , pp . 5–9 ) needham \n",
      "Cleaned Token After Stem =  timelin artifici intellig . timelin machin translat timelin machin learn mccorduck 2004 , pp . 4–5 mccorduck ( 2004 , pp . 5–9 ) needham \n",
      "Cleaned Token Before =  in machine learning, a highway network is an approach to optimizing networks and increasing their depth. highway networks use learned gating mechanisms\n",
      "Cleaned Token After =  machine learning , highway network approach optimizing networks increasing depth . highway networks use learned gating mechanisms \n",
      "Cleaned Token After Stem =  machin learn , highway network approach optim network increas depth . highway network use learn gate mechan \n",
      "Cleaned Token Before =  alchemyapi was a software company in the field of machine learning. its technology employed deep learning for various applications in natural language processing\n",
      "Cleaned Token After =  alchemyapi software company field machine learning . technology employed deep learning various applications natural language processing \n",
      "Cleaned Token After Stem =  alchemyapi softwar compani field machin learn . technolog employ deep learn variou applic natur languag process \n",
      "Cleaned Token Before =  number shalev-shwartz, shai; ben-david, shai (2014). understanding machine learning – from theory to algorithms. cambridge university press. isbn 9781107057135\n",
      "Cleaned Token After =  number shalev-shwartz , shai ; ben-david , shai ( 2014 ) . understanding machine learning – theory algorithms . cambridge university press . isbn 9781107057135 \n",
      "Cleaned Token After Stem =  number shalev-shwartz , shai ; ben-david , shai ( 2014 ) . understand machin learn – theori algorithm . cambridg univers press . isbn 9781107057135 \n",
      "Cleaned Token Before =  jeffrey (2018). \"automatic differentiation in machine learning: a survey\". journal of machine learning research. 18: 1–43. wang, fei; decker, james; wu\n",
      "Cleaned Token After =  jeffrey ( 2018 ) . `` automatic differentiation machine learning : survey '' . journal machine learning research . 18 : 1–43 . wang , fei ; decker , james ; wu \n",
      "Cleaned Token After Stem =  jeffrey ( 2018 ) . `` automat differenti machin learn : survey `` . journal machin learn research . 18 : 1–43 . wang , fei ; decker , jame ; wu \n",
      "Cleaned Token Before =  co-training is a machine learning algorithm used when there are only small amounts of labeled data and large amounts of unlabeled data. one of its uses\n",
      "Cleaned Token After =  co-training machine learning algorithm used small amounts labeled data large amounts unlabeled data . one uses \n",
      "Cleaned Token After Stem =  co-train machin learn algorithm use small amount label data larg amount unlabel data . one use \n",
      "Cleaned Token Before =  in order to prepare a consistent result set. apache ignite provides machine learning training and inference functionality as well as data preprocessing\n",
      "Cleaned Token After =  order prepare consistent result set . apache ignite provides machine learning training inference functionality well data preprocessing \n",
      "Cleaned Token After Stem =  order prepar consist result set . apach ignit provid machin learn train infer function well data preprocess \n",
      "Cleaned Token Before =  kubeflow is a free and open-source machine learning platform designed to enable using machine learning pipelines to orchestrate complicated workflows\n",
      "Cleaned Token After =  kubeflow free open-source machine learning platform designed enable using machine learning pipelines orchestrate complicated workflows \n",
      "Cleaned Token After Stem =  kubeflow free open-sourc machin learn platform design enabl use machin learn pipelin orchestr complic workflow \n",
      "Cleaned Token Before =  programming constraint satisfaction knowledge engineering learning classifier system rule-based machine learning jackson, peter (1998). introduction to expert systems\n",
      "Cleaned Token After =  programming constraint satisfaction knowledge engineering learning classifier system rule-based machine learning jackson , peter ( 1998 ) . introduction expert systems \n",
      "Cleaned Token After Stem =  program constraint satisfact knowledg engin learn classifi system rule-bas machin learn jackson , peter ( 1998 ) . introduct expert system \n",
      "Cleaned Token Before =  specifying an architecture for machine learning in future networks including 5g (imt-2020). the architecture describes a machine learning pipeline in the context\n",
      "Cleaned Token After =  specifying architecture machine learning future networks including 5g ( imt-2020 ) . architecture describes machine learning pipeline context \n",
      "Cleaned Token After Stem =  specifi architectur machin learn futur network includ 5g ( imt-2020 ) . architectur describ machin learn pipelin context \n",
      "Cleaned Token Before =  hyperplane if they are, arises in several areas. in statistics and machine learning, classifying certain types of data is a problem for which good algorithms\n",
      "Cleaned Token After =  hyperplane , arises several areas . statistics machine learning , classifying certain types data problem good algorithms \n",
      "Cleaned Token After Stem =  hyperplan , aris sever area . statist machin learn , classifi certain type data problem good algorithm \n",
      "Cleaned Token Before =  neuroscience and machine learning with new developments in computing hardware to unlock increasingly powerful general-purpose learning algorithms that\n",
      "Cleaned Token After =  neuroscience machine learning new developments computing hardware unlock increasingly powerful general-purpose learning algorithms \n",
      "Cleaned Token After Stem =  neurosci machin learn new develop comput hardwar unlock increasingli power general-purpos learn algorithm \n",
      "Cleaned Token Before =  in machine learning, backpropagation (backprop, bp) is a widely used algorithm for training feedforward neural networks. generalizations of backpropagation\n",
      "Cleaned Token After =  machine learning , backpropagation ( backprop , bp ) widely used algorithm training feedforward neural networks . generalizations backpropagation \n",
      "Cleaned Token After Stem =  machin learn , backpropag ( backprop , bp ) wide use algorithm train feedforward neural network . gener backpropag \n",
      "Cleaned Token Before =  in machine learning, the kernel embedding of distributions (also called the kernel mean or mean map) comprises a class of nonparametric methods in which\n",
      "Cleaned Token After =  machine learning , kernel embedding distributions ( also called kernel mean mean map ) comprises class nonparametric methods \n",
      "Cleaned Token After Stem =  machin learn , kernel embed distribut ( also call kernel mean mean map ) compris class nonparametr method \n",
      "Cleaned Token Before =  prediction error of random forests, boosted decision trees, and other machine learning models utilizing bootstrap aggregating (bagging). bagging uses subsampling\n",
      "Cleaned Token After =  prediction error random forests , boosted decision trees , machine learning models utilizing bootstrap aggregating ( bagging ) . bagging uses subsampling \n",
      "Cleaned Token After Stem =  predict error random forest , boost decis tree , machin learn model util bootstrap aggreg ( bag ) . bag use subsampl \n",
      "Cleaned Token Before =  the master algorithm: how the quest for the ultimate learning machine will remake our world is a book by pedro domingos released in 2015. domingos wrote\n",
      "Cleaned Token After =  master algorithm : quest ultimate learning machine remake world book pedro domingos released 2015. domingos wrote \n",
      "Cleaned Token After Stem =  master algorithm : quest ultim learn machin remak world book pedro domingo releas 2015. domingo wrote \n",
      "Cleaned Token Before =   queries that may involve user feedback, systems that may include machine learning, and systems that may understand user satisfaction levels. many cbir\n",
      "Cleaned Token After =  queries may involve user feedback , systems may include machine learning , systems may understand user satisfaction levels . many cbir \n",
      "Cleaned Token After Stem =  queri may involv user feedback , system may includ machin learn , system may understand user satisfact level . mani cbir \n",
      "Cleaned Token Before =  the knowledge engineering and machine learning group (kemlg) is a research group belonging to the technical university of catalonia (upc) – barcelonatech\n",
      "Cleaned Token After =  knowledge engineering machine learning group ( kemlg ) research group belonging technical university catalonia ( upc ) – barcelonatech \n",
      "Cleaned Token After Stem =  knowledg engin machin learn group ( kemlg ) research group belong technic univers catalonia ( upc ) – barcelonatech \n",
      "Cleaned Token Before =  from machine learning and artificial intelligence to manipulate or generate visual and audio content with a high potential to deceive. the main machine learning\n",
      "Cleaned Token After =  machine learning artificial intelligence manipulate generate visual audio content high potential deceive . main machine learning \n",
      "Cleaned Token After Stem =  machin learn artifici intellig manipul gener visual audio content high potenti deceiv . main machin learn \n",
      "Cleaned Token Before =  meta-analysis results. boosting (machine learning) bootstrap aggregating (bagging) bootstrapping (statistics) leakage (machine learning) model selection resampling\n",
      "Cleaned Token After =  meta-analysis results . boosting ( machine learning ) bootstrap aggregating ( bagging ) bootstrapping ( statistics ) leakage ( machine learning ) model selection resampling \n",
      "Cleaned Token After Stem =  meta-analysi result . boost ( machin learn ) bootstrap aggreg ( bag ) bootstrap ( statist ) leakag ( machin learn ) model select resampl \n",
      "Cleaned Token Before =  computational neuroscience. he is known for applying bayesian methods from machine learning and artificial intelligence to understand neural function and is particularly\n",
      "Cleaned Token After =  computational neuroscience . known applying bayesian methods machine learning artificial intelligence understand neural function particularly \n",
      "Cleaned Token After Stem =  comput neurosci . known appli bayesian method machin learn artifici intellig understand neural function particularli \n",
      "Cleaned Token Before =  is also frequently used for data clustering, computer vision and in machine learning. in natural language processing, two prominent instances of the algorithm\n",
      "Cleaned Token After =  also frequently used data clustering , computer vision machine learning . natural language processing , two prominent instances algorithm \n",
      "Cleaned Token After Stem =  also frequent use data cluster , comput vision machin learn . natur languag process , two promin instanc algorithm \n",
      "Cleaned Token Before =  contribute favorably to binding affinity. machine-learning – unlike these classical scoring functions, machine-learning scoring functions are characterized\n",
      "Cleaned Token After =  contribute favorably binding affinity . machine-learning – unlike classical scoring functions , machine-learning scoring functions characterized \n",
      "Cleaned Token After Stem =  contribut favor bind affin . machine-learn – unlik classic score function , machine-learn score function character \n",
      "Cleaned Token Before =  for the weka machine learning workbench. gmlvq toolbox: an easy-to-use implementation of generalized matrix lvq (matrix relevance learning) in (c) matlab\n",
      "Cleaned Token After =  weka machine learning workbench . gmlvq toolbox : easy-to-use implementation generalized matrix lvq ( matrix relevance learning ) ( c ) matlab \n",
      "Cleaned Token After Stem =  weka machin learn workbench . gmlvq toolbox : easy-to-us implement gener matrix lvq ( matrix relev learn ) ( c ) matlab \n",
      "Cleaned Token Before =  elmo was given 64 threads and a hash size of 1 gb. after 34 hours of self-learning of go and against alphago zero, alphazero won 60 games and lost 40. deepmind\n",
      "Cleaned Token After =  elmo given 64 threads hash size 1 gb . 34 hours self-learning go alphago zero , alphazero 60 games lost 40. deepmind \n",
      "Cleaned Token After Stem =  elmo given 64 thread hash size 1 gb . 34 hour self-learn go alphago zero , alphazero 60 game lost 40. deepmind \n",
      "Cleaned Token Before =  portfolio algorithm is a portfolio selection algorithm from the field of machine learning and information theory. the algorithm learns adaptively from historical\n",
      "Cleaned Token After =  portfolio algorithm portfolio selection algorithm field machine learning information theory . algorithm learns adaptively historical \n",
      "Cleaned Token After Stem =  portfolio algorithm portfolio select algorithm field machin learn inform theori . algorithm learn adapt histor \n",
      "Cleaned Token Before =  apache license. data driven applications, such as data analytics, machine learning, and ai, use apis (such as hadoop hdfs api, s3 api, fuse api) provided\n",
      "Cleaned Token After =  apache license . data driven applications , data analytics , machine learning , ai , use apis ( hadoop hdfs api , s3 api , fuse api ) provided \n",
      "Cleaned Token After Stem =  apach licens . data driven applic , data analyt , machin learn , ai , use api ( hadoop hdf api , s3 api , fuse api ) provid \n",
      "Cleaned Token Before =  based on an example in christopher m. bishop, pattern recognition and machine learning. imagine that we are given an n×n black-and-white image that is known\n",
      "Cleaned Token After =  based example christopher m. bishop , pattern recognition machine learning . imagine given n×n black-and-white image known \n",
      "Cleaned Token After Stem =  base exampl christoph m. bishop , pattern recognit machin learn . imagin given n×n black-and-whit imag known \n",
      "Cleaned Token Before =  cloud machine-learning platform that was launched in november 2017. sagemaker enables developers to create, train, and deploy machine-learning (ml) models\n",
      "Cleaned Token After =  cloud machine-learning platform launched november 2017. sagemaker enables developers create , train , deploy machine-learning ( ml ) models \n",
      "Cleaned Token After Stem =  cloud machine-learn platform launch novemb 2017. sagemak enabl develop creat , train , deploy machine-learn ( ml ) model \n",
      "Cleaned Token Before =  non-formal learning includes various structured learning situations which do not either have the level of curriculum, syllabus, accreditation and certification\n",
      "Cleaned Token After =  non-formal learning includes various structured learning situations either level curriculum , syllabus , accreditation certification \n",
      "Cleaned Token After Stem =  non-form learn includ variou structur learn situat either level curriculum , syllabu , accredit certif \n",
      "Cleaned Token Before =  since september 2015, he has been working on his vehicle automation machine learning company comma.ai. he attended the academy for engineering and design\n",
      "Cleaned Token After =  since september 2015 , working vehicle automation machine learning company comma.ai . attended academy engineering design \n",
      "Cleaned Token After Stem =  sinc septemb 2015 , work vehicl autom machin learn compani comma.ai . attend academi engin design \n",
      "Cleaned Token Before =  (game theory), dale schuurmans (machine learning), csaba szepesvari (reinforcement learning), martha white (machine learning), among others. the computing\n",
      "Cleaned Token After =  ( game theory ) , dale schuurmans ( machine learning ) , csaba szepesvari ( reinforcement learning ) , martha white ( machine learning ) , among others . computing \n",
      "Cleaned Token After Stem =  ( game theori ) , dale schuurman ( machin learn ) , csaba szepesvari ( reinforc learn ) , martha white ( machin learn ) , among other . comput \n",
      "Cleaned Token Before =  of machine learning technologies. 2 (1): 37–63. ting, kai ming (2011). sammut, claude; webb, geoffrey i. (eds.). encyclopedia of machine learning. springer\n",
      "Cleaned Token After =  machine learning technologies . 2 ( 1 ) : 37–63 . ting , kai ming ( 2011 ) . sammut , claude ; webb , geoffrey . ( eds. ) . encyclopedia machine learning . springer \n",
      "Cleaned Token After Stem =  machin learn technolog . 2 ( 1 ) : 37–63 . ting , kai ming ( 2011 ) . sammut , claud ; webb , geoffrey . ( ed . ) . encyclopedia machin learn . springer \n",
      "Cleaned Token Before =  this article is the unit ramp function (slope 1, starting at 0). in machine learning, it is commonly known as a relu activation function or a rectifier\n",
      "Cleaned Token After =  article unit ramp function ( slope 1 , starting 0 ) . machine learning , commonly known relu activation function rectifier \n",
      "Cleaned Token After Stem =  articl unit ramp function ( slope 1 , start 0 ) . machin learn , commonli known relu activ function rectifi \n",
      "Cleaned Token Before =  messages containing \"replica\" in the messages identified as spam during the learning phase. similarly, pr ( w | h ) {\\displaystyle \\pr(w|h)} is approximated\n",
      "Cleaned Token After =  messages containing `` replica '' messages identified spam learning phase . similarly , pr ( w | h ) { \\displaystyle \\pr ( w|h ) } approximated \n",
      "Cleaned Token After Stem =  messag contain `` replica `` messag identifi spam learn phase . similarli , pr ( w | h ) { \\displaystyl \\pr ( w|h ) } approxim \n",
      "Cleaned Token Before =  communities. the stochastic block model is important in statistics, machine learning, and network science, where it serves as a useful benchmark for the\n",
      "Cleaned Token After =  communities . stochastic block model important statistics , machine learning , network science , serves useful benchmark \n",
      "Cleaned Token After Stem =  commun . stochast block model import statist , machin learn , network scienc , serv use benchmark \n",
      "Cleaned Token Before =  systems constructed using automatic rule inference, such as rule-based machine learning, are normally excluded from this system type. a classic example of\n",
      "Cleaned Token After =  systems constructed using automatic rule inference , rule-based machine learning , normally excluded system type . classic example \n",
      "Cleaned Token After Stem =  system construct use automat rule infer , rule-bas machin learn , normal exclud system type . classic exampl \n",
      "Cleaned Token Before =  (forward backward splitting) methods for learning is an area of research in optimization and statistical learning theory which studies algorithms for a general\n",
      "Cleaned Token After =  ( forward backward splitting ) methods learning area research optimization statistical learning theory studies algorithms general \n",
      "Cleaned Token After Stem =  ( forward backward split ) method learn area research optim statist learn theori studi algorithm gener \n",
      "Cleaned Token Before =  moving targets through its real-time image processing capabilities and machine learning algorithms embedded on the platform. kargu can rapidly and effectively\n",
      "Cleaned Token After =  moving targets real-time image processing capabilities machine learning algorithms embedded platform . kargu rapidly effectively \n",
      "Cleaned Token After Stem =  move target real-tim imag process capabl machin learn algorithm embed platform . kargu rapidli effect \n",
      "Cleaned Token Before =  for many record linkage applications. since the late 1990s, various machine learning techniques have been developed that can, under favorable conditions\n",
      "Cleaned Token After =  many record linkage applications . since late 1990s , various machine learning techniques developed , favorable conditions \n",
      "Cleaned Token After Stem =  mani record linkag applic . sinc late 1990 , variou machin learn techniqu develop , favor condit \n",
      "Cleaned Token Before =  university of toronto, where he holds a research chair in statistics and machine learning. he studied computer science at the university of calgary (b.sc. 1977\n",
      "Cleaned Token After =  university toronto , holds research chair statistics machine learning . studied computer science university calgary ( b.sc . 1977 \n",
      "Cleaned Token After Stem =  univers toronto , hold research chair statist machin learn . studi comput scienc univers calgari ( b.sc . 1977 \n",
      "Cleaned Token Before =  to make deep learning more accessible.[citation needed] previously, he was the ceo and founder at enlitic, an advanced machine learning company in san\n",
      "Cleaned Token After =  make deep learning accessible . [ citation needed ] previously , ceo founder enlitic , advanced machine learning company san \n",
      "Cleaned Token After Stem =  make deep learn access . [ citat need ] previous , ceo founder enlit , advanc machin learn compani san \n",
      "Cleaned Token Before =  offices in mountain view, boston, tokyo, and tel aviv. the company uses machine learning for monitoring personal computers, iot devices, and cloud workloads\n",
      "Cleaned Token After =  offices mountain view , boston , tokyo , tel aviv . company uses machine learning monitoring personal computers , iot devices , cloud workloads \n",
      "Cleaned Token After Stem =  offic mountain view , boston , tokyo , tel aviv . compani use machin learn monitor person comput , iot devic , cloud workload \n",
      "Cleaned Token Before =  exploiting these learning opportunities the learning agent is able to learn beyond the explicit content of the new information. the machine learning program ki\n",
      "Cleaned Token After =  exploiting learning opportunities learning agent able learn beyond explicit content new information . machine learning program ki \n",
      "Cleaned Token After Stem =  exploit learn opportun learn agent abl learn beyond explicit content new inform . machin learn program ki \n",
      "Cleaned Token Before =  the randomized weighted majority algorithm is an algorithm in machine learning theory. it improves the mistake bound of the weighted majority algorithm\n",
      "Cleaned Token After =  randomized weighted majority algorithm algorithm machine learning theory . improves mistake bound weighted majority algorithm \n",
      "Cleaned Token After Stem =  random weight major algorithm algorithm machin learn theori . improv mistak bound weight major algorithm \n",
      "Cleaned Token Before =  from smaller components, a systems-level development more than a pure machine-learning development. while only pseudocode was released by the development\n",
      "Cleaned Token After =  smaller components , systems-level development pure machine-learning development . pseudocode released development \n",
      "Cleaned Token After Stem =  smaller compon , systems-level develop pure machine-learn develop . pseudocod releas develop \n",
      "Cleaned Token Before =  adaptation is a field associated with machine learning and transfer learning. this scenario arises when we aim at learning from a source data distribution a\n",
      "Cleaned Token After =  adaptation field associated machine learning transfer learning . scenario arises aim learning source data distribution \n",
      "Cleaned Token After Stem =  adapt field associ machin learn transfer learn . scenario aris aim learn sourc data distribut \n",
      "Cleaned Token Before =  and markov chain monte carlo capabilities. ml.net is a free-software machine-learning library for the c# programming language. nag library is an extensive\n",
      "Cleaned Token After =  markov chain monte carlo capabilities . ml.net free-software machine-learning library c # programming language . nag library extensive \n",
      "Cleaned Token After Stem =  markov chain mont carlo capabl . ml.net free-softwar machine-learn librari c # program languag . nag librari extens \n",
      "Cleaned Token Before =  company based in california that uses artificial intelligence and machine learning to understand consumer intent. it helps companies create a personalized\n",
      "Cleaned Token After =  company based california uses artificial intelligence machine learning understand consumer intent . helps companies create personalized \n",
      "Cleaned Token After Stem =  compani base california use artifici intellig machin learn understand consum intent . help compani creat person \n",
      "Cleaned Token Before =  difference learning relevance-vector machine (rvm): similar to svm, but provides probabilistic classification supervised learning: learning by examples\n",
      "Cleaned Token After =  difference learning relevance-vector machine ( rvm ) : similar svm , provides probabilistic classification supervised learning : learning examples \n",
      "Cleaned Token After Stem =  differ learn relevance-vector machin ( rvm ) : similar svm , provid probabilist classif supervis learn : learn exampl \n",
      "Cleaned Token Before =  whose research investigates machine learning, algorithmic game theory, theoretical computer science, including active learning, kernel methods, random-sampling\n",
      "Cleaned Token After =  whose research investigates machine learning , algorithmic game theory , theoretical computer science , including active learning , kernel methods , random-sampling \n",
      "Cleaned Token After Stem =  whose research investig machin learn , algorithm game theori , theoret comput scienc , includ activ learn , kernel method , random-sampl \n",
      "Cleaned Token Before =  in the fields of machine learning, the theory of computation, and random matrix theory, a probability distribution over vectors is said to be in isotropic\n",
      "Cleaned Token After =  fields machine learning , theory computation , random matrix theory , probability distribution vectors said isotropic \n",
      "Cleaned Token After Stem =  field machin learn , theori comput , random matrix theori , probabl distribut vector said isotrop \n",
      "Cleaned Token Before =  offering legal services and fundraising advice for startups powered by machine learning. kan raised $10.5 million in an initial \"party\" round of investment\n",
      "Cleaned Token After =  offering legal services fundraising advice startups powered machine learning . kan raised $ 10.5 million initial `` party '' round investment \n",
      "Cleaned Token After Stem =  offer legal servic fundrais advic startup power machin learn . kan rais $ 10.5 million initi `` parti `` round invest \n",
      "Cleaned Token Before =  transitioned its translating method to a system called neural machine translation. it uses deep learning techniques to translate whole sentences at a time, which\n",
      "Cleaned Token After =  transitioned translating method system called neural machine translation . uses deep learning techniques translate whole sentences time , \n",
      "Cleaned Token After Stem =  transit translat method system call neural machin translat . use deep learn techniqu translat whole sentenc time , \n",
      "Cleaned Token Before =  report the speed of learning of their implementation. differentiable neural computers are an outgrowth of neural turing machines, with attention mechanisms\n",
      "Cleaned Token After =  report speed learning implementation . differentiable neural computers outgrowth neural turing machines , attention mechanisms \n",
      "Cleaned Token After Stem =  report speed learn implement . differenti neural comput outgrowth neural ture machin , attent mechan \n",
      "Cleaned Token Before =  (born 5 may 1967) is a swedish-american physicist, cosmologist and machine learning researcher. he is a professor at the massachusetts institute of technology\n",
      "Cleaned Token After =  ( born 5 may 1967 ) swedish-american physicist , cosmologist machine learning researcher . professor massachusetts institute technology \n",
      "Cleaned Token After Stem =  ( born 5 may 1967 ) swedish-american physicist , cosmologist machin learn research . professor massachusett institut technolog \n",
      "Cleaned Token Before =  learning is a generalization of active learning designed to relax unrealistic assumptions and thereby reach practical applications. \"active learning seeks\n",
      "Cleaned Token After =  learning generalization active learning designed relax unrealistic assumptions thereby reach practical applications . `` active learning seeks \n",
      "Cleaned Token After Stem =  learn gener activ learn design relax unrealist assumpt therebi reach practic applic . `` activ learn seek \n",
      "Cleaned Token Before =  air. he is best known for his seminal work in facial recognition and machine learning. he is the co-inventor of the viola–jones object detection framework\n",
      "Cleaned Token After =  air . best known seminal work facial recognition machine learning . co-inventor viola–jones object detection framework \n",
      "Cleaned Token After Stem =  air . best known semin work facial recognit machin learn . co-inventor viola–jon object detect framework \n",
      "Cleaned Token Before =  workloads. built-in machine learning and geospatial capabilities: db2 warehouse on cloud comes with in-database machine learning capabilities that allow\n",
      "Cleaned Token After =  workloads . built-in machine learning geospatial capabilities : db2 warehouse cloud comes in-database machine learning capabilities allow \n",
      "Cleaned Token After Stem =  workload . built-in machin learn geospati capabl : db2 warehous cloud come in-databas machin learn capabl allow \n",
      "Cleaned Token Before =  small. the midas can also be used for machine learning time series and panel data nowcasting. the machine learning midas regressions involve legendre polynomials\n",
      "Cleaned Token After =  small . midas also used machine learning time series panel data nowcasting . machine learning midas regressions involve legendre polynomials \n",
      "Cleaned Token After Stem =  small . mida also use machin learn time seri panel data nowcast . machin learn mida regress involv legendr polynomi \n",
      "Cleaned Token Before =  sometimes referred to as “machine ethics\". collaborating with professor jodi forlizzi, mclaren developed a digital learning game called decimal point\n",
      "Cleaned Token After =  sometimes referred “ machine ethics '' . collaborating professor jodi forlizzi , mclaren developed digital learning game called decimal point \n",
      "Cleaned Token After Stem =  sometim refer “ machin ethic `` . collabor professor jodi forlizzi , mclaren develop digit learn game call decim point \n",
      "Cleaned Token Before =  id, animoji and other machine learning tasks. the neural engine allows apple to implement neural network and machine learning in a more energy-efficient\n",
      "Cleaned Token After =  id , animoji machine learning tasks . neural engine allows apple implement neural network machine learning energy-efficient \n",
      "Cleaned Token After Stem =  id , animoji machin learn task . neural engin allow appl implement neural network machin learn energy-effici \n",
      "Cleaned Token Before =  otherwise. it was discovered repeatedly in very diverse fields such as machine learning (adaboost, winnow, hedge), optimization (solving linear programs),\n",
      "Cleaned Token After =  otherwise . discovered repeatedly diverse fields machine learning ( adaboost , winnow , hedge ) , optimization ( solving linear programs ) , \n",
      "Cleaned Token After Stem =  otherwis . discov repeatedli divers field machin learn ( adaboost , winnow , hedg ) , optim ( solv linear program ) , \n",
      "Cleaned Token Before =  detection. other application are in data mining, pattern recognition and machine learning, where time series analysis can be used for clustering, classification\n",
      "Cleaned Token After =  detection . application data mining , pattern recognition machine learning , time series analysis used clustering , classification \n",
      "Cleaned Token After Stem =  detect . applic data mine , pattern recognit machin learn , time seri analysi use cluster , classif \n",
      "Cleaned Token Before =  skynet is a program by the u.s. national security agency that performs machine learning analysis on communications data to extract information about possible\n",
      "Cleaned Token After =  skynet program u.s. national security agency performs machine learning analysis communications data extract information possible \n",
      "Cleaned Token After Stem =  skynet program u.s. nation secur agenc perform machin learn analysi commun data extract inform possibl \n",
      "Cleaned Token Before =  solvers (ipopt, apopt, bpopt, snopt, minos). modes of operation include machine learning, data reconciliation, real-time optimization, dynamic simulation, and\n",
      "Cleaned Token After =  solvers ( ipopt , apopt , bpopt , snopt , minos ) . modes operation include machine learning , data reconciliation , real-time optimization , dynamic simulation , \n",
      "Cleaned Token After Stem =  solver ( ipopt , apopt , bpopt , snopt , mino ) . mode oper includ machin learn , data reconcili , real-tim optim , dynam simul , \n",
      "Cleaned Token Before =  geometric feature learning is a technique combining machine learning and computer vision to solve visual tasks. the main goal of this method is to find\n",
      "Cleaned Token After =  geometric feature learning technique combining machine learning computer vision solve visual tasks . main goal method find \n",
      "Cleaned Token After Stem =  geometr featur learn techniqu combin machin learn comput vision solv visual task . main goal method find \n",
      "Cleaned Token Before =  holds a conference, scaled machine learning, where technical speakers lead discussions about running and scaling machine learning algorithms, artificial intelligence\n",
      "Cleaned Token After =  holds conference , scaled machine learning , technical speakers lead discussions running scaling machine learning algorithms , artificial intelligence \n",
      "Cleaned Token After Stem =  hold confer , scale machin learn , technic speaker lead discuss run scale machin learn algorithm , artifici intellig \n",
      "Cleaned Token Before =  optimization) is a free toolkit facilitating the optimization of a deep learning model from a framework and deployment using an inference engine onto intel\n",
      "Cleaned Token After =  optimization ) free toolkit facilitating optimization deep learning model framework deployment using inference engine onto intel \n",
      "Cleaned Token After Stem =  optim ) free toolkit facilit optim deep learn model framework deploy use infer engin onto intel \n",
      "Cleaned Token Before =  action learning, adventure learning, free-choice learning, cooperative learning, service-learning, and situated learning. experiential learning is often\n",
      "Cleaned Token After =  action learning , adventure learning , free-choice learning , cooperative learning , service-learning , situated learning . experiential learning often \n",
      "Cleaned Token After Stem =  action learn , adventur learn , free-choic learn , cooper learn , service-learn , situat learn . experienti learn often \n",
      "Cleaned Token Before =  of the robot learning group at the max planck institute for intelligent systems. peters is renowned for his research in machine learning and robotics\n",
      "Cleaned Token After =  robot learning group max planck institute intelligent systems . peters renowned research machine learning robotics \n",
      "Cleaned Token After Stem =  robot learn group max planck institut intellig system . peter renown research machin learn robot \n",
      "Cleaned Token Before =  of applied psychologists and educators. the learning material is in a kind of textbook or teaching machine or computer. the medium presents the material\n",
      "Cleaned Token After =  applied psychologists educators . learning material kind textbook teaching machine computer . medium presents material \n",
      "Cleaned Token After Stem =  appli psychologist educ . learn materi kind textbook teach machin comput . medium present materi \n",
      "Cleaned Token Before =  neighbors. for example, in a text about machine learning, the unigram \"learning\" might co-occur with \"machine\", \"supervised\", \"un-supervised\", and \"semi-supervised\"\n",
      "Cleaned Token After =  neighbors . example , text machine learning , unigram `` learning '' might co-occur `` machine '' , `` supervised '' , `` un-supervised '' , `` semi-supervised '' \n",
      "Cleaned Token After Stem =  neighbor . exampl , text machin learn , unigram `` learn `` might co-occur `` machin `` , `` supervis `` , `` un-supervis `` , `` semi-supervis `` \n",
      "Cleaned Token Before =   spacy also supports deep learning workflows that allow connecting statistical models trained by popular machine learning libraries like tensorflow,\n",
      "Cleaned Token After =  spacy also supports deep learning workflows allow connecting statistical models trained popular machine learning libraries like tensorflow , \n",
      "Cleaned Token After Stem =  spaci also support deep learn workflow allow connect statist model train popular machin learn librari like tensorflow , \n",
      "Cleaned Token Before =   he holds a canada research chair in machine learning, and is currently an advisor for the learning in machines & brains program at the canadian institute\n",
      "Cleaned Token After =  holds canada research chair machine learning , currently advisor learning machines & brains program canadian institute \n",
      "Cleaned Token After Stem =  hold canada research chair machin learn , current advisor learn machin & brain program canadian institut \n",
      "Cleaned Token Before =  reduction). the following learning method can be any of the already mentioned machine learning methods, e.g. support vector machines. an alternative approach\n",
      "Cleaned Token After =  reduction ) . following learning method already mentioned machine learning methods , e.g . support vector machines . alternative approach \n",
      "Cleaned Token After Stem =  reduct ) . follow learn method alreadi mention machin learn method , e.g . support vector machin . altern approach \n",
      "Cleaned Token Before =  continuous domain, e.g. time or space. a machine-learning algorithm that involves a gaussian process uses lazy learning and a measure of the similarity between\n",
      "Cleaned Token After =  continuous domain , e.g . time space . machine-learning algorithm involves gaussian process uses lazy learning measure similarity \n",
      "Cleaned Token After Stem =  continu domain , e.g . time space . machine-learn algorithm involv gaussian process use lazi learn measur similar \n",
      "Cleaned Token Before =  in the near future, transaction monitoring systems will be based on machine learning rather than on rules and scenarios. anti-money laundering bank regulation\n",
      "Cleaned Token After =  near future , transaction monitoring systems based machine learning rather rules scenarios . anti-money laundering bank regulation \n",
      "Cleaned Token After Stem =  near futur , transact monitor system base machin learn rather rule scenario . anti-money launder bank regul \n",
      "Cleaned Token Before =  combinator ilya sutskever, research director, a former google expert on machine learning cto: greg brockman, former cto, 3rd employee of stripe other backers\n",
      "Cleaned Token After =  combinator ilya sutskever , research director , former google expert machine learning cto : greg brockman , former cto , 3rd employee stripe backers \n",
      "Cleaned Token After Stem =  combin ilya sutskev , research director , former googl expert machin learn cto : greg brockman , former cto , 3rd employe stripe backer \n",
      "Cleaned Token Before =  platform is designed to alert clients to disruptions and outages through machine learning and automation. the software operates as a standalone service or can\n",
      "Cleaned Token After =  platform designed alert clients disruptions outages machine learning automation . software operates standalone service \n",
      "Cleaned Token After Stem =  platform design alert client disrupt outag machin learn autom . softwar oper standalon servic \n",
      "Cleaned Token Before =  neural networks\". in proceedings of the international conference on machine learning, icml 2006: 369–376. citeseerx 10.1.1.75.6306. hannun, awni (27 november\n",
      "Cleaned Token After =  neural networks '' . proceedings international conference machine learning , icml 2006 : 369–376 . citeseerx 10.1.1.75.6306. hannun , awni ( 27 november \n",
      "Cleaned Token After Stem =  neural network `` . proceed intern confer machin learn , icml 2006 : 369–376 . citeseerx 10.1.1.75.6306. hannun , awni ( 27 novemb \n",
      "Cleaned Token Before =  creating a broad set of statistical machine learning tools and in 2009 dlib was published in the journal of machine learning research. since then it has been\n",
      "Cleaned Token After =  creating broad set statistical machine learning tools 2009 dlib published journal machine learning research . since \n",
      "Cleaned Token After Stem =  creat broad set statist machin learn tool 2009 dlib publish journal machin learn research . sinc \n",
      "Cleaned Token Before =  parity learning is a problem in machine learning. an algorithm that solves this problem must find a function ƒ, given some samples (x, ƒ(x)) and the assurance\n",
      "Cleaned Token After =  parity learning problem machine learning . algorithm solves problem must find function ƒ , given samples ( x , ƒ ( x ) ) assurance \n",
      "Cleaned Token After Stem =  pariti learn problem machin learn . algorithm solv problem must find function ƒ , given sampl ( x , ƒ ( x ) ) assur \n",
      "Cleaned Token Before =  single-precision floating-point format (binary32) with the intent of accelerating machine learning and near-sensor computing. it preserves the approximate dynamic range\n",
      "Cleaned Token After =  single-precision floating-point format ( binary32 ) intent accelerating machine learning near-sensor computing . preserves approximate dynamic range \n",
      "Cleaned Token After Stem =  single-precis floating-point format ( binary32 ) intent acceler machin learn near-sensor comput . preserv approxim dynam rang \n",
      "Cleaned Token Before =  similarity of pairs of graphs. they allow kernelized learning algorithms such as support vector machines to work directly on graphs, without having to do\n",
      "Cleaned Token After =  similarity pairs graphs . allow kernelized learning algorithms support vector machines work directly graphs , without \n",
      "Cleaned Token After Stem =  similar pair graph . allow kernel learn algorithm support vector machin work directli graph , without \n",
      "Cleaned Token Before =  self-learn and play chess at above human level is reinforcement learning. this is a machine-learning algorithm, mirrored from alphazero used by the leela chess\n",
      "Cleaned Token After =  self-learn play chess human level reinforcement learning . machine-learning algorithm , mirrored alphazero used leela chess \n",
      "Cleaned Token After Stem =  self-learn play chess human level reinforc learn . machine-learn algorithm , mirror alphazero use leela chess \n",
      "Cleaned Token Before =  classification is a problem studied in machine learning. it is a type of supervised learning, a method of machine learning where the categories are predefined\n",
      "Cleaned Token After =  classification problem studied machine learning . type supervised learning , method machine learning categories predefined \n",
      "Cleaned Token After Stem =  classif problem studi machin learn . type supervis learn , method machin learn categori predefin \n",
      "Cleaned Token Before =  smartphone technology for taking vehicle photos with 3d computer vision, machine learning, and augmented reality. in december 2020, carvana donated 21 vehicles\n",
      "Cleaned Token After =  smartphone technology taking vehicle photos 3d computer vision , machine learning , augmented reality . december 2020 , carvana donated 21 vehicles \n",
      "Cleaned Token After Stem =  smartphon technolog take vehicl photo 3d comput vision , machin learn , augment realiti . decemb 2020 , carvana donat 21 vehicl \n",
      "Cleaned Token Before =  capital. brynjolfsson erik and mitchell, tom (december, 2017) what can machine learning do? workforce implications science. brynjolfsson erik, syverson, chad\n",
      "Cleaned Token After =  capital . brynjolfsson erik mitchell , tom ( december , 2017 ) machine learning ? workforce implications science . brynjolfsson erik , syverson , chad \n",
      "Cleaned Token After Stem =  capit . brynjolfsson erik mitchel , tom ( decemb , 2017 ) machin learn ? workforc implic scienc . brynjolfsson erik , syverson , chad \n",
      "Cleaned Token Before =  divergences\". proceedings of the 25th international conference on machine learning: 112–119. doi:10.1145/1390156.1390171. isbn 9781605582054. bewley,\n",
      "Cleaned Token After =  divergences '' . proceedings 25th international conference machine learning : 112–119 . doi:10.1145/1390156.1390171 . isbn 9781605582054. bewley , \n",
      "Cleaned Token After Stem =  diverg `` . proceed 25th intern confer machin learn : 112–119 . doi:10.1145/1390156.1390171 . isbn 9781605582054. bewley , \n",
      "Cleaned Token Before =  administered to humans to measure intelligence) was reported on by machine learning engineer dale markowitz in a piece for thenextweb. nature introduced\n",
      "Cleaned Token After =  administered humans measure intelligence ) reported machine learning engineer dale markowitz piece thenextweb . nature introduced \n",
      "Cleaned Token After Stem =  administ human measur intellig ) report machin learn engin dale markowitz piec thenextweb . natur introduc \n",
      "Cleaned Token Before =  never-ending language learning system (nell) is a semantic machine learning system developed by a research team at carnegie mellon university, and supported\n",
      "Cleaned Token After =  never-ending language learning system ( nell ) semantic machine learning system developed research team carnegie mellon university , supported \n",
      "Cleaned Token After Stem =  never-end languag learn system ( nell ) semant machin learn system develop research team carnegi mellon univers , support \n",
      "Cleaned Token Before =  transforms, and vector math. mlpack is an open-source library for machine learning, exploiting c++ language features to provide maximum performance and\n",
      "Cleaned Token After =  transforms , vector math . mlpack open-source library machine learning , exploiting c++ language features provide maximum performance \n",
      "Cleaned Token After Stem =  transform , vector math . mlpack open-sourc librari machin learn , exploit c++ languag featur provid maximum perform \n",
      "Cleaned Token Before =  publication of machine learning research by marvin minsky and seymour papert (1969). they discovered two key issues with the computational machines that processed\n",
      "Cleaned Token After =  publication machine learning research marvin minsky seymour papert ( 1969 ) . discovered two key issues computational machines processed \n",
      "Cleaned Token After Stem =  public machin learn research marvin minski seymour papert ( 1969 ) . discov two key issu comput machin process \n",
      "Cleaned Token Before =  scientist and youtuber who works on neuroengineering, brain-machine interfaces, and machine learning for medicine. a current graduate student at harvard and\n",
      "Cleaned Token After =  scientist youtuber works neuroengineering , brain-machine interfaces , machine learning medicine . current graduate student harvard \n",
      "Cleaned Token After Stem =  scientist youtub work neuroengin , brain-machin interfac , machin learn medicin . current graduat student harvard \n",
      "Cleaned Token Before =  products of the basis functions of the finite dimensional subspace. in machine learning, kernel functions are often represented as gram matrices. since the\n",
      "Cleaned Token After =  products basis functions finite dimensional subspace . machine learning , kernel functions often represented gram matrices . since \n",
      "Cleaned Token After Stem =  product basi function finit dimension subspac . machin learn , kernel function often repres gram matric . sinc \n",
      "Cleaned Token Before =  for reactive search include machine learning and statistics, in particular reinforcement learning, active or query learning, neural networks, and metaheuristics\n",
      "Cleaned Token After =  reactive search include machine learning statistics , particular reinforcement learning , active query learning , neural networks , metaheuristics \n",
      "Cleaned Token After Stem =  reactiv search includ machin learn statist , particular reinforc learn , activ queri learn , neural network , metaheurist \n",
      "Cleaned Token Before =  \"end-to-end\" machine learning to build a system, without having separate stages as above. in other words, we build an nlg system by training a machine learning algorithm\n",
      "Cleaned Token After =  `` end-to-end '' machine learning build system , without separate stages . words , build nlg system training machine learning algorithm \n",
      "Cleaned Token After Stem =  `` end-to-end `` machin learn build system , without separ stage . word , build nlg system train machin learn algorithm \n",
      "Cleaned Token Before =  skinner was responsible for a different type of machine called glider, which used his ideas on how learning should be directed with positive reinforcement\n",
      "Cleaned Token After =  skinner responsible different type machine called glider , used ideas learning directed positive reinforcement \n",
      "Cleaned Token After Stem =  skinner respons differ type machin call glider , use idea learn direct posit reinforc \n",
      "Cleaned Token Before =  (dog) used by the sift, susan and harris detectors. moreover, when machine learning techniques are applied, superior performance in terms of computation\n",
      "Cleaned Token After =  ( dog ) used sift , susan harris detectors . moreover , machine learning techniques applied , superior performance terms computation \n",
      "Cleaned Token After Stem =  ( dog ) use sift , susan harri detector . moreov , machin learn techniqu appli , superior perform term comput \n",
      "Cleaned Token Before =  variety of technological methods, including artificial intelligence, machine learning, and distributed computing, for its trading strategies. the firm is\n",
      "Cleaned Token After =  variety technological methods , including artificial intelligence , machine learning , distributed computing , trading strategies . firm \n",
      "Cleaned Token After Stem =  varieti technolog method , includ artifici intellig , machin learn , distribut comput , trade strategi . firm \n",
      "Cleaned Token Before =  construct low dimensional embeddings, which can be useful for a variety of machine learning applications. given a simple graph g {\\displaystyle g} with n {\\displaystyle\n",
      "Cleaned Token After =  construct low dimensional embeddings , useful variety machine learning applications . given simple graph g { \\displaystyle g } n { \\displaystyle \n",
      "Cleaned Token After Stem =  construct low dimension embed , use varieti machin learn applic . given simpl graph g { \\displaystyl g } n { \\displaystyl \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Token Before =  accuracy disparities in commercial gender classification\". proceedings of machine learning research. 81: 1–15. issn 1938-7288. gebru, timnit (9 july 2020). \"race\n",
      "Cleaned Token After =  accuracy disparities commercial gender classification '' . proceedings machine learning research . 81 : 1–15 . issn 1938-7288. gebru , timnit ( 9 july 2020 ) . `` race \n",
      "Cleaned Token After Stem =  accuraci dispar commerci gender classif `` . proceed machin learn research . 81 : 1–15 . issn 1938-7288. gebru , timnit ( 9 juli 2020 ) . `` race \n",
      "Cleaned Token Before =  (october 2005). \"hybrid algorithms with instance-based classification\". machine learning: ecml2005. springer. pp. 158–169. introduction to knowledge processing\n",
      "Cleaned Token After =  ( october 2005 ) . `` hybrid algorithms instance-based classification '' . machine learning : ecml2005 . springer . pp . 158–169 . introduction knowledge processing \n",
      "Cleaned Token After Stem =  ( octob 2005 ) . `` hybrid algorithm instance-bas classif `` . machin learn : ecml2005 . springer . pp . 158–169 . introduct knowledg process \n",
      "Cleaned Token Before =  applied to fields such as cognitive science, pattern recognition and machine learning. alphago defeated european champion fan hui, a 2 dan professional,\n",
      "Cleaned Token After =  applied fields cognitive science , pattern recognition machine learning . alphago defeated european champion fan hui , 2 dan professional , \n",
      "Cleaned Token After Stem =  appli field cognit scienc , pattern recognit machin learn . alphago defeat european champion fan hui , 2 dan profession , \n",
      "Cleaned Token Before =  engineering at the university of washington. he is a researcher in machine learning known for markov logic network enabling uncertain inference. domingos\n",
      "Cleaned Token After =  engineering university washington . researcher machine learning known markov logic network enabling uncertain inference . domingos \n",
      "Cleaned Token After Stem =  engin univers washington . research machin learn known markov logic network enabl uncertain infer . domingo \n",
      "Cleaned Token Before =  documentation for the data used to train ai systems. the problem of bias in machine learning is likely to become more significant as the technology spreads to critical\n",
      "Cleaned Token After =  documentation data used train ai systems . problem bias machine learning likely become significant technology spreads critical \n",
      "Cleaned Token After Stem =  document data use train ai system . problem bia machin learn like becom signific technolog spread critic \n",
      "Cleaned Token Before =  there is a large expansion of this, using deep learning and machine learning to significantly expand machine vision capabilities. pattern recognition including\n",
      "Cleaned Token After =  large expansion , using deep learning machine learning significantly expand machine vision capabilities . pattern recognition including \n",
      "Cleaned Token After Stem =  larg expans , use deep learn machin learn significantli expand machin vision capabl . pattern recognit includ \n",
      "Cleaned Token Before =  2018-01-23. gagliordi, natalie. \"workday buys skipflag to bolster machine learning capabilities | zdnet\". zdnet. retrieved 2018-01-21. official website\n",
      "Cleaned Token After =  2018-01-23. gagliordi , natalie . `` workday buys skipflag bolster machine learning capabilities | zdnet '' . zdnet . retrieved 2018-01-21. official website \n",
      "Cleaned Token After Stem =  2018-01-23. gagliordi , natali . `` workday buy skipflag bolster machin learn capabl | zdnet `` . zdnet . retriev 2018-01-21. offici websit \n",
      "Cleaned Token Before =  contains tsne, also with barnes-hut approximation scikit-learn, a popular machine learning toolkit in python implements t-sne with both exact solutions and the\n",
      "Cleaned Token After =  contains tsne , also barnes-hut approximation scikit-learn , popular machine learning toolkit python implements t-sne exact solutions \n",
      "Cleaned Token After Stem =  contain tsne , also barnes-hut approxim scikit-learn , popular machin learn toolkit python implement t-sne exact solut \n",
      "Cleaned Token Before =  the vapnik–chervonenkis theory of statistical learning, and the co-inventor of the support-vector machine method, and support-vector clustering algorithm\n",
      "Cleaned Token After =  vapnik–chervonenkis theory statistical learning , co-inventor support-vector machine method , support-vector clustering algorithm \n",
      "Cleaned Token After Stem =  vapnik–chervonenki theori statist learn , co-inventor support-vector machin method , support-vector cluster algorithm \n",
      "Cleaned Token Before =  frequencies for some problems (e.g., this option is implemented in the weka machine learning software system). the bag-of-words model is an orderless document representation\n",
      "Cleaned Token After =  frequencies problems ( e.g. , option implemented weka machine learning software system ) . bag-of-words model orderless document representation \n",
      "Cleaned Token After Stem =  frequenc problem ( e.g . , option implement weka machin learn softwar system ) . bag-of-word model orderless document represent \n",
      "Cleaned Token Before =  succeeded in generating their own knowledge from scratch, many other machine learning projects require large training datasets. researcher andrew ng has\n",
      "Cleaned Token After =  succeeded generating knowledge scratch , many machine learning projects require large training datasets . researcher andrew ng \n",
      "Cleaned Token After Stem =  succeed gener knowledg scratch , mani machin learn project requir larg train dataset . research andrew ng \n",
      "Cleaned Token Before =  into itsm systems, terminal services and even some types of ai (e.g. machine learning) services such as image recognition. it is considered to be a significant\n",
      "Cleaned Token After =  itsm systems , terminal services even types ai ( e.g . machine learning ) services image recognition . considered significant \n",
      "Cleaned Token After Stem =  itsm system , termin servic even type ai ( e.g . machin learn ) servic imag recognit . consid signific \n",
      "Cleaned Token Before =  shane legg cbe is a machine learning researcher and cofounder of deepmind technologies, acquired by google in 2014. legg attended rotorua lakes high school\n",
      "Cleaned Token After =  shane legg cbe machine learning researcher cofounder deepmind technologies , acquired google 2014. legg attended rotorua lakes high school \n",
      "Cleaned Token After Stem =  shane legg cbe machin learn research cofound deepmind technolog , acquir googl 2014. legg attend rotorua lake high school \n",
      "Cleaned Token Before =  republic that researches and develops computer security software, machine learning and artificial intelligence. avast has more than 435 million monthly\n",
      "Cleaned Token After =  republic researches develops computer security software , machine learning artificial intelligence . avast 435 million monthly \n",
      "Cleaned Token After Stem =  republ research develop comput secur softwar , machin learn artifici intellig . avast 435 million monthli \n",
      "Cleaned Token Before =  statistics, to predict when maintenance will be required. typically, machine learning approaches are adopted for the definition of the actual condition of\n",
      "Cleaned Token After =  statistics , predict maintenance required . typically , machine learning approaches adopted definition actual condition \n",
      "Cleaned Token After Stem =  statist , predict mainten requir . typic , machin learn approach adopt definit actual condit \n",
      "Cleaned Token Before =  the university of toronto. frey is a pioneer in the development of machine learning and artificial intelligence methods, their use in accurately determining\n",
      "Cleaned Token After =  university toronto . frey pioneer development machine learning artificial intelligence methods , use accurately determining \n",
      "Cleaned Token After Stem =  univers toronto . frey pioneer develop machin learn artifici intellig method , use accur determin \n",
      "Cleaned Token Before =  in machine learning, early stopping is a form of regularization used to avoid overfitting when training a learner with an iterative method, such as gradient\n",
      "Cleaned Token After =  machine learning , early stopping form regularization used avoid overfitting training learner iterative method , gradient \n",
      "Cleaned Token After Stem =  machin learn , earli stop form regular use avoid overfit train learner iter method , gradient \n",
      "Cleaned Token Before =  through a graph starting at a target node. it is useful for a variety of machine learning applications. besides reducing the engineering effort, representations\n",
      "Cleaned Token After =  graph starting target node . useful variety machine learning applications . besides reducing engineering effort , representations \n",
      "Cleaned Token After Stem =  graph start target node . use varieti machin learn applic . besid reduc engin effort , represent \n",
      "Cleaned Token Before =  possibilities of machine learning. it is all about the behaviour of users over network. adaptive authentication depends on machine learning to model a baseline\n",
      "Cleaned Token After =  possibilities machine learning . behaviour users network . adaptive authentication depends machine learning model baseline \n",
      "Cleaned Token After Stem =  possibl machin learn . behaviour user network . adapt authent depend machin learn model baselin \n",
      "Cleaned Token Before =  cyber security market report by zion market research, the role of machine learning and artificial intelligence will create a $30.9 billion cyber security\n",
      "Cleaned Token After =  cyber security market report zion market research , role machine learning artificial intelligence create $ 30.9 billion cyber security \n",
      "Cleaned Token After Stem =  cyber secur market report zion market research , role machin learn artifici intellig creat $ 30.9 billion cyber secur \n",
      "Cleaned Token Before =  than typical players. developments in monte carlo tree search and machine learning brought the best programs to high dan level on the small 9x9 board\n",
      "Cleaned Token After =  typical players . developments monte carlo tree search machine learning brought best programs high dan level small 9x9 board \n",
      "Cleaned Token After Stem =  typic player . develop mont carlo tree search machin learn brought best program high dan level small 9x9 board \n",
      "Cleaned Token Before =  classification (business intelligence) classification (machine learning), classification of data using machine learning algorithms assigning a level of sensitivity\n",
      "Cleaned Token After =  classification ( business intelligence ) classification ( machine learning ) , classification data using machine learning algorithms assigning level sensitivity \n",
      "Cleaned Token After Stem =  classif ( busi intellig ) classif ( machin learn ) , classif data use machin learn algorithm assign level sensit \n",
      "Cleaned Token Before =  explanation-based learning (ebl) is a form of machine learning that exploits a very strong, or even perfect, domain theory (i.e. a formal theory of an\n",
      "Cleaned Token After =  explanation-based learning ( ebl ) form machine learning exploits strong , even perfect , domain theory ( i.e . formal theory \n",
      "Cleaned Token After Stem =  explanation-bas learn ( ebl ) form machin learn exploit strong , even perfect , domain theori ( i.e . formal theori \n",
      "Cleaned Token Before =  analytics and machine learning”. the firm provides services in the area of predictive analytics, artificial intelligence, big data and machine learning. affine\n",
      "Cleaned Token After =  analytics machine learning ” . firm provides services area predictive analytics , artificial intelligence , big data machine learning . affine \n",
      "Cleaned Token After Stem =  analyt machin learn ” . firm provid servic area predict analyt , artifici intellig , big data machin learn . affin \n",
      "Cleaned Token Before =  in the field of machine learning, the goal of statistical classification is to use an object's characteristics to identify which class (or group) it belongs\n",
      "Cleaned Token After =  field machine learning , goal statistical classification use object 's characteristics identify class ( group ) belongs \n",
      "Cleaned Token After Stem =  field machin learn , goal statist classif use object 's characterist identifi class ( group ) belong \n",
      "Cleaned Token Before =  in machine learning, systems which employ offline learning do not change their approximation of the target function when the initial training phase has\n",
      "Cleaned Token After =  machine learning , systems employ offline learning change approximation target function initial training phase \n",
      "Cleaned Token After Stem =  machin learn , system employ offlin learn chang approxim target function initi train phase \n",
      "Cleaned Token Before =  rule them out. these research areas are active focuses of work in the machine learning community, although that work is not normally aimed towards solving\n",
      "Cleaned Token After =  rule . research areas active focuses work machine learning community , although work normally aimed towards solving \n",
      "Cleaned Token After Stem =  rule . research area activ focus work machin learn commun , although work normal aim toward solv \n",
      "Cleaned Token Before =  intent in order to make the results more reliable and comprehensive. machine learning is extremely important for resume parsing. each block of information\n",
      "Cleaned Token After =  intent order make results reliable comprehensive . machine learning extremely important resume parsing . block information \n",
      "Cleaned Token After Stem =  intent order make result reliabl comprehens . machin learn extrem import resum pars . block inform \n",
      "Cleaned Token Before =  describe and exchange predictive models produced by data mining and machine learning algorithms. it supports common models such as logistic regression and\n",
      "Cleaned Token After =  describe exchange predictive models produced data mining machine learning algorithms . supports common models logistic regression \n",
      "Cleaned Token After Stem =  describ exchang predict model produc data mine machin learn algorithm . support common model logist regress \n",
      "Cleaned Token Before =  computer memory. it is a popular algorithm for parameter estimation in machine learning. the algorithm's target problem is to minimize f ( x ) {\\displaystyle\n",
      "Cleaned Token After =  computer memory . popular algorithm parameter estimation machine learning . algorithm 's target problem minimize f ( x ) { \\displaystyle \n",
      "Cleaned Token After Stem =  comput memori . popular algorithm paramet estim machin learn . algorithm 's target problem minim f ( x ) { \\displaystyl \n",
      "Cleaned Token Before =  recognition including the google phd fellowship in machine learning and a rising star in machine learning nomination by the university of maryland. dieng\n",
      "Cleaned Token After =  recognition including google phd fellowship machine learning rising star machine learning nomination university maryland . dieng \n",
      "Cleaned Token After Stem =  recognit includ googl phd fellowship machin learn rise star machin learn nomin univers maryland . dieng \n",
      "Cleaned Token Before =  stats, inverted index construction, document clustering, machine learning, and statistical machine translation. moreover, the mapreduce model has been adapted\n",
      "Cleaned Token After =  stats , inverted index construction , document clustering , machine learning , statistical machine translation . moreover , mapreduce model adapted \n",
      "Cleaned Token After Stem =  stat , invert index construct , document cluster , machin learn , statist machin translat . moreov , mapreduc model adapt \n",
      "Cleaned Token Before =  (cto) of twitter. he is responsible for twitter's technical strategy, machine learning, artificial intelligence, consumer, revenue and science teams. agrawal\n",
      "Cleaned Token After =  ( cto ) twitter . responsible twitter 's technical strategy , machine learning , artificial intelligence , consumer , revenue science teams . agrawal \n",
      "Cleaned Token After Stem =  ( cto ) twitter . respons twitter 's technic strategi , machin learn , artifici intellig , consum , revenu scienc team . agraw \n",
      "Cleaned Token Before =  in statistics and machine learning, when one wants to infer a random variable with a set of variables, usually a subset is enough, and other variables\n",
      "Cleaned Token After =  statistics machine learning , one wants infer random variable set variables , usually subset enough , variables \n",
      "Cleaned Token After Stem =  statist machin learn , one want infer random variabl set variabl , usual subset enough , variabl \n",
      "Cleaned Token Before =  applications for quantum cryptography, quantum chemistry, quantum machine learning and quantum artificial intelligence. cqc was established in 2014, and\n",
      "Cleaned Token After =  applications quantum cryptography , quantum chemistry , quantum machine learning quantum artificial intelligence . cqc established 2014 , \n",
      "Cleaned Token After Stem =  applic quantum cryptographi , quantum chemistri , quantum machin learn quantum artifici intellig . cqc establish 2014 , \n",
      "Cleaned Token Before =  popular for particular kinds of applications: for example, python for machine learning, java for backend server development, c in embedded applications and\n",
      "Cleaned Token After =  popular particular kinds applications : example , python machine learning , java backend server development , c embedded applications \n",
      "Cleaned Token After Stem =  popular particular kind applic : exampl , python machin learn , java backend server develop , c embed applic \n",
      "Cleaned Token Before =  development in areas as sequencing technologies, bioinformatics and machine learning (machine learning in bioinformatics). new biomedical technologies like microarrays\n",
      "Cleaned Token After =  development areas sequencing technologies , bioinformatics machine learning ( machine learning bioinformatics ) . new biomedical technologies like microarrays \n",
      "Cleaned Token After Stem =  develop area sequenc technolog , bioinformat machin learn ( machin learn bioinformat ) . new biomed technolog like microarray \n",
      "Cleaned Token Before =  optimization than to traditional learning approaches. however, process mining can be used to generate machine learning, data mining, and artificial intelligence\n",
      "Cleaned Token After =  optimization traditional learning approaches . however , process mining used generate machine learning , data mining , artificial intelligence \n",
      "Cleaned Token After Stem =  optim tradit learn approach . howev , process mine use gener machin learn , data mine , artifici intellig \n",
      "Cleaned Token Before =  book's authors. the bupa liver data – used in several papers in the machine learning (data mining) literature. anscombe's quartet – small data set illustrating\n",
      "Cleaned Token After =  book 's authors . bupa liver data – used several papers machine learning ( data mining ) literature . anscombe 's quartet – small data set illustrating \n",
      "Cleaned Token After Stem =  book 's author . bupa liver data – use sever paper machin learn ( data mine ) literatur . anscomb 's quartet – small data set illustr \n",
      "Cleaned Token Before =  prominent scientist in the application of artificial intelligence, machine learning and intelligent agents in the design of smart markets, including demand\n",
      "Cleaned Token After =  prominent scientist application artificial intelligence , machine learning intelligent agents design smart markets , including demand \n",
      "Cleaned Token After Stem =  promin scientist applic artifici intellig , machin learn intellig agent design smart market , includ demand \n",
      "Cleaned Token Before =  is the original author of the scikit-learn package, an open source machine learning library in the python programming language. cournapeau graduated with\n",
      "Cleaned Token After =  original author scikit-learn package , open source machine learning library python programming language . cournapeau graduated \n",
      "Cleaned Token After Stem =  origin author scikit-learn packag , open sourc machin learn librari python program languag . cournapeau graduat \n",
      "Cleaned Token Before =  scientist at facebook ai research (fair). she works on computer vision and machine learning. grauman studied computer science at boston college, graduating summa\n",
      "Cleaned Token After =  scientist facebook ai research ( fair ) . works computer vision machine learning . grauman studied computer science boston college , graduating summa \n",
      "Cleaned Token After Stem =  scientist facebook ai research ( fair ) . work comput vision machin learn . grauman studi comput scienc boston colleg , graduat summa \n",
      "Cleaned Token Before =  in machine learning and mathematical optimization, loss functions for classification are computationally feasible loss functions representing the price\n",
      "Cleaned Token After =  machine learning mathematical optimization , loss functions classification computationally feasible loss functions representing price \n",
      "Cleaned Token After Stem =  machin learn mathemat optim , loss function classif comput feasibl loss function repres price \n",
      "Cleaned Token Before =  november 2016). \"how does google \"quick, draw!\" work? this game makes learning about artificial intelligence fun\". bustle.com. retrieved 24 november 2016\n",
      "Cleaned Token After =  november 2016 ) . `` google `` quick , draw ! '' work ? game makes learning artificial intelligence fun '' . bustle.com . retrieved 24 november 2016 \n",
      "Cleaned Token After Stem =  novemb 2016 ) . `` googl `` quick , draw ! `` work ? game make learn artifici intellig fun `` . bustle.com . retriev 24 novemb 2016 \n",
      "Cleaned Token Before =  of machine learning technologies. 2 (1): 37–63. ting, kai ming (2011). sammut, claude; webb, geoffrey i. (eds.). encyclopedia of machine learning. springer\n",
      "Cleaned Token After =  machine learning technologies . 2 ( 1 ) : 37–63 . ting , kai ming ( 2011 ) . sammut , claude ; webb , geoffrey . ( eds. ) . encyclopedia machine learning . springer \n",
      "Cleaned Token After Stem =  machin learn technolog . 2 ( 1 ) : 37–63 . ting , kai ming ( 2011 ) . sammut , claud ; webb , geoffrey . ( ed . ) . encyclopedia machin learn . springer \n",
      "Cleaned Token Before =  university of toronto, “machine learning and the market for intelligence.” agrawal is a co-author of the book ‘prediction machines: the simple economics\n",
      "Cleaned Token After =  university toronto , “ machine learning market intelligence. ” agrawal co-author book ‘ prediction machines : simple economics \n",
      "Cleaned Token After Stem =  univers toronto , “ machin learn market intellig . ” agraw co-author book ‘ predict machin : simpl econom \n",
      "Cleaned Token Before =  lifelong learning is the \"ongoing, voluntary, and self-motivated\" pursuit of knowledge for either personal or professional reasons. therefore, it not only\n",
      "Cleaned Token After =  lifelong learning `` ongoing , voluntary , self-motivated '' pursuit knowledge either personal professional reasons . therefore , \n",
      "Cleaned Token After Stem =  lifelong learn `` ongo , voluntari , self-motiv `` pursuit knowledg either person profession reason . therefor , \n",
      "Cleaned Token Before =  statistical modeling method often applied in pattern recognition and machine learning and used for structured prediction. whereas a classifier predicts a\n",
      "Cleaned Token After =  statistical modeling method often applied pattern recognition machine learning used structured prediction . whereas classifier predicts \n",
      "Cleaned Token After Stem =  statist model method often appli pattern recognit machin learn use structur predict . wherea classifi predict \n",
      "Cleaned Token Before =  available (such as the pixel 2 and pixel 3), and the application of machine learning to identify what should be kept in focus and what should be blurred\n",
      "Cleaned Token After =  available ( pixel 2 pixel 3 ) , application machine learning identify kept focus blurred \n",
      "Cleaned Token After Stem =  avail ( pixel 2 pixel 3 ) , applic machin learn identifi kept focu blur \n",
      "Cleaned Token Before =  being submitted to the facial recognition system utilise example-based machine learning with pixel substitution or nearest neighbour distribution indexes that\n",
      "Cleaned Token After =  submitted facial recognition system utilise example-based machine learning pixel substitution nearest neighbour distribution indexes \n",
      "Cleaned Token After Stem =  submit facial recognit system utilis example-bas machin learn pixel substitut nearest neighbour distribut index \n",
      "Cleaned Token Before =  data in each group is normally distributed. [circular reference] in machine learning, the latent variable z {\\displaystyle z} is considered as a latent\n",
      "Cleaned Token After =  data group normally distributed . [ circular reference ] machine learning , latent variable z { \\displaystyle z } considered latent \n",
      "Cleaned Token After Stem =  data group normal distribut . [ circular refer ] machin learn , latent variabl z { \\displaystyl z } consid latent \n",
      "Cleaned Token Before =  one or more languages that are intelligible to programmers, rather than machine code, which is directly executed by the central processing unit. the purpose\n",
      "Cleaned Token After =  one languages intelligible programmers , rather machine code , directly executed central processing unit . purpose \n",
      "Cleaned Token After Stem =  one languag intellig programm , rather machin code , directli execut central process unit . purpos \n",
      "Cleaned Token Before =  interest in artificial intelligence (and especially the sub-field of machine learning) from the research and corporate communities led to a dramatic increase\n",
      "Cleaned Token After =  interest artificial intelligence ( especially sub-field machine learning ) research corporate communities led dramatic increase \n",
      "Cleaned Token After Stem =  interest artifici intellig ( especi sub-field machin learn ) research corpor commun led dramat increas \n",
      "Cleaned Token Before =   isbn 978-3-540-66490-1. alpaydin, ethem (2020). introduction to machine learning (fourth ed.). cambridge, massachusetts. isbn 978-0-262-04379-3. oclc 1108782604\n",
      "Cleaned Token After =  isbn 978-3-540-66490-1. alpaydin , ethem ( 2020 ) . introduction machine learning ( fourth ed. ) . cambridge , massachusetts . isbn 978-0-262-04379-3. oclc 1108782604 \n",
      "Cleaned Token After Stem =  isbn 978-3-540-66490-1. alpaydin , ethem ( 2020 ) . introduct machin learn ( fourth ed . ) . cambridg , massachusett . isbn 978-0-262-04379-3. oclc 1108782604 \n",
      "Cleaned Token Before =  international conference on machine learning. arxiv:1212.4777. bibcode:2012arxiv1212.4777a. lee, daniel d and seung, h sebastian (1999). \"learning the parts of objects\n",
      "Cleaned Token After =  international conference machine learning . arxiv:1212.4777. bibcode:2012arxiv1212.4777a . lee , daniel seung , h sebastian ( 1999 ) . `` learning parts objects \n",
      "Cleaned Token After Stem =  intern confer machin learn . arxiv:1212.4777. bibcode:2012arxiv1212.4777a . lee , daniel seung , h sebastian ( 1999 ) . `` learn part object \n",
      "Cleaned Token Before =  openai five is the name of a machine learning project that performs as a team of video game bots playing against human players in the competitive five-on-five\n",
      "Cleaned Token After =  openai five name machine learning project performs team video game bots playing human players competitive five-on-five \n",
      "Cleaned Token After Stem =  openai five name machin learn project perform team video game bot play human player competit five-on-f \n",
      "Cleaned Token Before =  wave of bans. in february 2017, valve announced plans to introduce a machine-learning approach to detecting cheats in counter-strike: global offensive, and\n",
      "Cleaned Token After =  wave bans . february 2017 , valve announced plans introduce machine-learning approach detecting cheats counter-strike : global offensive , \n",
      "Cleaned Token After Stem =  wave ban . februari 2017 , valv announc plan introduc machine-learn approach detect cheat counter-strik : global offens , \n",
      "Cleaned Token Before =  softmax are used in machine learning. exponential linear units try to make the mean activations closer to zero, which speeds up learning. it has been shown\n",
      "Cleaned Token After =  softmax used machine learning . exponential linear units try make mean activations closer zero , speeds learning . shown \n",
      "Cleaned Token After Stem =  softmax use machin learn . exponenti linear unit tri make mean activ closer zero , speed learn . shown \n",
      "Cleaned Token Before =  artificial intelligence and machine learning: artificial intelligence (ai) is a field within computer science in which intelligent machines are created that work\n",
      "Cleaned Token After =  artificial intelligence machine learning : artificial intelligence ( ai ) field within computer science intelligent machines created work \n",
      "Cleaned Token After Stem =  artifici intellig machin learn : artifici intellig ( ai ) field within comput scienc intellig machin creat work \n",
      "Cleaned Token Before =  accuracy equality and disparate mistreatment, is a measure of fairness in machine learning. a classifier satisfies this definition if the subjects in the protected\n",
      "Cleaned Token After =  accuracy equality disparate mistreatment , measure fairness machine learning . classifier satisfies definition subjects protected \n",
      "Cleaned Token After Stem =  accuraci equal dispar mistreat , measur fair machin learn . classifi satisfi definit subject protect \n",
      "Cleaned Token Before =  core of htm are learning algorithms that can store, learn, infer, and recall high-order sequences. unlike most other machine learning methods, htm constantly\n",
      "Cleaned Token After =  core htm learning algorithms store , learn , infer , recall high-order sequences . unlike machine learning methods , htm constantly \n",
      "Cleaned Token After Stem =  core htm learn algorithm store , learn , infer , recal high-ord sequenc . unlik machin learn method , htm constantli \n",
      "Cleaned Token Before =  august 15, 1961) is a french-born researcher in machine learning known for her work on support-vector machines, artificial neural networks and bioinformatics\n",
      "Cleaned Token After =  august 15 , 1961 ) french-born researcher machine learning known work support-vector machines , artificial neural networks bioinformatics \n",
      "Cleaned Token After Stem =  august 15 , 1961 ) french-born research machin learn known work support-vector machin , artifici neural network bioinformat \n",
      "Cleaned Token Before =  \"joy buolamwini wins national contest for her work fighting bias in machine learning\". mit news. retrieved march 24, 2018. \"rhodes scholar shows 'compassion\n",
      "Cleaned Token After =  `` joy buolamwini wins national contest work fighting bias machine learning '' . mit news . retrieved march 24 , 2018 . `` rhodes scholar shows 'compassion \n",
      "Cleaned Token After Stem =  `` joy buolamwini win nation contest work fight bia machin learn `` . mit news . retriev march 24 , 2018 . `` rhode scholar show 'compass \n",
      "Cleaned Token Before =  in machine learning, sequence labeling is a type of pattern recognition task that involves the algorithmic assignment of a categorical label to each member\n",
      "Cleaned Token After =  machine learning , sequence labeling type pattern recognition task involves algorithmic assignment categorical label member \n",
      "Cleaned Token After Stem =  machin learn , sequenc label type pattern recognit task involv algorithm assign categor label member \n",
      "Cleaned Token Before =  is a covariance function used in spatial statistics, geostatistics, machine learning, image analysis, and other applications of multivariate statistical\n",
      "Cleaned Token After =  covariance function used spatial statistics , geostatistics , machine learning , image analysis , applications multivariate statistical \n",
      "Cleaned Token After Stem =  covari function use spatial statist , geostatist , machin learn , imag analysi , applic multivari statist \n",
      "Cleaned Token Before =  api, has been updated to metal 2. it includes virtual-reality and machine-learning features, as well as support for external gpus. the system's windowing\n",
      "Cleaned Token After =  api , updated metal 2. includes virtual-reality machine-learning features , well support external gpus . system 's windowing \n",
      "Cleaned Token After Stem =  api , updat metal 2. includ virtual-r machine-learn featur , well support extern gpu . system 's window \n",
      "Cleaned Token Before =  adapt are part of the emerging field of artificial intelligence and machine learning. artificial intelligence based products generally fall into two major\n",
      "Cleaned Token After =  adapt part emerging field artificial intelligence machine learning . artificial intelligence based products generally fall two major \n",
      "Cleaned Token After Stem =  adapt part emerg field artifici intellig machin learn . artifici intellig base product gener fall two major \n",
      "Cleaned Token Before =  research organizations that establish open standards for representing machine learning algorithms and software tools to promote innovation and collaboration\n",
      "Cleaned Token After =  research organizations establish open standards representing machine learning algorithms software tools promote innovation collaboration \n",
      "Cleaned Token After Stem =  research organ establish open standard repres machin learn algorithm softwar tool promot innov collabor \n",
      "Cleaned Token Before =  provides it operations analytics, cloud computing, cybersecurity, machine learning, artificial intelligence (ai), big data intelligence, internet of things\n",
      "Cleaned Token After =  provides operations analytics , cloud computing , cybersecurity , machine learning , artificial intelligence ( ai ) , big data intelligence , internet things \n",
      "Cleaned Token After Stem =  provid oper analyt , cloud comput , cybersecur , machin learn , artifici intellig ( ai ) , big data intellig , internet thing \n",
      "Cleaned Token Before =  a decision stump is a machine learning model consisting of a one-level decision tree. that is, it is a decision tree with one internal node (the root)\n",
      "Cleaned Token After =  decision stump machine learning model consisting one-level decision tree . , decision tree one internal node ( root ) \n",
      "Cleaned Token After Stem =  decis stump machin learn model consist one-level decis tree . , decis tree one intern node ( root ) \n",
      "Cleaned Token Before =  energy-efficient cores called thunder. the lightning cores feature machine learning accelerators called amx blocks. apple claims the amx blocks are six\n",
      "Cleaned Token After =  energy-efficient cores called thunder . lightning cores feature machine learning accelerators called amx blocks . apple claims amx blocks six \n",
      "Cleaned Token After Stem =  energy-effici core call thunder . lightn core featur machin learn acceler call amx block . appl claim amx block six \n",
      "Cleaned Token Before =  maint: discouraged parameter (link) \"next generation machine learning - training deep learning models in a browser: andrej karpathy interview | datascienceweekly\n",
      "Cleaned Token After =  maint : discouraged parameter ( link ) `` next generation machine learning - training deep learning models browser : andrej karpathy interview | datascienceweekly \n",
      "Cleaned Token After Stem =  maint : discourag paramet ( link ) `` next gener machin learn - train deep learn model browser : andrej karpathi interview | datascienceweekli \n",
      "Cleaned Token Before =  indicates physiognomy works, but the rise of artificial intelligence and machine learning for facial recognition has brought a revival of interest, and some\n",
      "Cleaned Token After =  indicates physiognomy works , rise artificial intelligence machine learning facial recognition brought revival interest , \n",
      "Cleaned Token After Stem =  indic physiognomi work , rise artifici intellig machin learn facial recognit brought reviv interest , \n",
      "Cleaned Token Before =  mathematics, science, finance, gambling, artificial intelligence, machine learning, computer science, game theory, and philosophy to, for example, draw\n",
      "Cleaned Token After =  mathematics , science , finance , gambling , artificial intelligence , machine learning , computer science , game theory , philosophy , example , draw \n",
      "Cleaned Token After Stem =  mathemat , scienc , financ , gambl , artifici intellig , machin learn , comput scienc , game theori , philosophi , exampl , draw \n",
      "Cleaned Token Before =  extraction, networking, program analysis, security, cloud computing and machine learning. its origins date back to the beginning of logic programming, but it\n",
      "Cleaned Token After =  extraction , networking , program analysis , security , cloud computing machine learning . origins date back beginning logic programming , \n",
      "Cleaned Token After Stem =  extract , network , program analysi , secur , cloud comput machin learn . origin date back begin logic program , \n",
      "Cleaned Token Before =  danny b. lange is a danish computer scientist who has worked on machine learning for ibm, microsoft, amazon web services, uber, and unity technologies\n",
      "Cleaned Token After =  danny b. lange danish computer scientist worked machine learning ibm , microsoft , amazon web services , uber , unity technologies \n",
      "Cleaned Token After Stem =  danni b. lang danish comput scientist work machin learn ibm , microsoft , amazon web servic , uber , uniti technolog \n",
      "Cleaned Token Before =  and the number field sieve. tree growth step of the random forest machine learning technique. discrete fourier transform where each harmonic is independently\n",
      "Cleaned Token After =  number field sieve . tree growth step random forest machine learning technique . discrete fourier transform harmonic independently \n",
      "Cleaned Token After Stem =  number field siev . tree growth step random forest machin learn techniqu . discret fourier transform harmon independ \n",
      "Cleaned Token Before =  appeared, including behavioral detection, artificial intelligence, machine learning, and cloud-based file detonation. according to gartner, it is expected\n",
      "Cleaned Token After =  appeared , including behavioral detection , artificial intelligence , machine learning , cloud-based file detonation . according gartner , expected \n",
      "Cleaned Token After Stem =  appear , includ behavior detect , artifici intellig , machin learn , cloud-bas file deton . accord gartner , expect \n",
      "Cleaned Token Before =  nupic is to build and support a community that is interested in machine learning and machine intelligence based on modeling the neocortex and its principles\n",
      "Cleaned Token After =  nupic build support community interested machine learning machine intelligence based modeling neocortex principles \n",
      "Cleaned Token After Stem =  nupic build support commun interest machin learn machin intellig base model neocortex principl \n",
      "Cleaned Token Before =  research communities ranging from statistics and network science to machine learning and data mining. in statistics, generative random graph models such\n",
      "Cleaned Token After =  research communities ranging statistics network science machine learning data mining . statistics , generative random graph models \n",
      "Cleaned Token After Stem =  research commun rang statist network scienc machin learn data mine . statist , gener random graph model \n",
      "Cleaned Token Before =  organization knowledge organization system library classification machine learning native language identification string metrics subject (documents) subject\n",
      "Cleaned Token After =  organization knowledge organization system library classification machine learning native language identification string metrics subject ( documents ) subject \n",
      "Cleaned Token After Stem =  organ knowledg organ system librari classif machin learn nativ languag identif string metric subject ( document ) subject \n",
      "Cleaned Token Before =  watermarking seymour cray – cray research, supercomputer nello cristianini – machine learning, pattern analysis, artificial intelligence jon crowcroft – networking\n",
      "Cleaned Token After =  watermarking seymour cray – cray research , supercomputer nello cristianini – machine learning , pattern analysis , artificial intelligence jon crowcroft – networking \n",
      "Cleaned Token After Stem =  watermark seymour cray – cray research , supercomput nello cristianini – machin learn , pattern analysi , artifici intellig jon crowcroft – network \n",
      "Cleaned Token Before =  distributions but to a general class of distributions. in some fields, such as machine learning and natural language processing, the categorical and multinomial distributions\n",
      "Cleaned Token After =  distributions general class distributions . fields , machine learning natural language processing , categorical multinomial distributions \n",
      "Cleaned Token After Stem =  distribut gener class distribut . field , machin learn natur languag process , categor multinomi distribut \n",
      "Cleaned Token Before =  address various sources of bias. computer vision list of datasets for machine learning research wordnet \"new computer vision challenge wants to teach robots\n",
      "Cleaned Token After =  address various sources bias . computer vision list datasets machine learning research wordnet `` new computer vision challenge wants teach robots \n",
      "Cleaned Token After Stem =  address variou sourc bia . comput vision list dataset machin learn research wordnet `` new comput vision challeng want teach robot \n",
      "Cleaned Token Before =  (cpu). jetson is a low-power system and is designed for accelerating machine learning applications. the jetson family includes the following boards: in late\n",
      "Cleaned Token After =  ( cpu ) . jetson low-power system designed accelerating machine learning applications . jetson family includes following boards : late \n",
      "Cleaned Token After Stem =  ( cpu ) . jetson low-pow system design acceler machin learn applic . jetson famili includ follow board : late \n",
      "Cleaned Token Before =  the target data set, runs many different unsupervised and supervised machine learning algorithms on the data, automatically finds and ranks best fits, and\n",
      "Cleaned Token After =  target data set , runs many different unsupervised supervised machine learning algorithms data , automatically finds ranks best fits , \n",
      "Cleaned Token After Stem =  target data set , run mani differ unsupervis supervis machin learn algorithm data , automat find rank best fit , \n",
      "Cleaned Token Before =  linguistic grammar-based techniques as well as statistical models such as machine learning. hand-crafted grammar-based systems typically obtain better precision\n",
      "Cleaned Token After =  linguistic grammar-based techniques well statistical models machine learning . hand-crafted grammar-based systems typically obtain better precision \n",
      "Cleaned Token After Stem =  linguist grammar-bas techniqu well statist model machin learn . hand-craft grammar-bas system typic obtain better precis \n",
      "Cleaned Token Before =  computer scientist. he is professor of artificial intelligence and machine learning at the department of computer science of the technische universität\n",
      "Cleaned Token After =  computer scientist . professor artificial intelligence machine learning department computer science technische universität \n",
      "Cleaned Token After Stem =  comput scientist . professor artifici intellig machin learn depart comput scienc technisch universität \n",
      "Cleaned Token Before =  cited expert in cosmology, machine learning applications in astrophysics and data science, her interest are using deep learning accelerated simulations to\n",
      "Cleaned Token After =  cited expert cosmology , machine learning applications astrophysics data science , interest using deep learning accelerated simulations \n",
      "Cleaned Token After Stem =  cite expert cosmolog , machin learn applic astrophys data scienc , interest use deep learn acceler simul \n",
      "Cleaned Token Before =  orange is an open-source data visualization, machine learning and data mining toolkit. it features a visual programming front-end for explorative rapid\n",
      "Cleaned Token After =  orange open-source data visualization , machine learning data mining toolkit . features visual programming front-end explorative rapid \n",
      "Cleaned Token After Stem =  orang open-sourc data visual , machin learn data mine toolkit . featur visual program front-end explor rapid \n",
      "Cleaned Token Before =  spark’s distributed machine learning library. together with sparklyr’s dplyr interface, you can easily create and tune machine learning workflows on spark\n",
      "Cleaned Token After =  spark ’ distributed machine learning library . together sparklyr ’ dplyr interface , easily create tune machine learning workflows spark \n",
      "Cleaned Token After Stem =  spark ’ distribut machin learn librari . togeth sparklyr ’ dplyr interfac , easili creat tune machin learn workflow spark \n",
      "Cleaned Token Before =  fasttext is a library for learning of word embeddings and text classification created by facebook's ai research (fair) lab. the model allows one to create\n",
      "Cleaned Token After =  fasttext library learning word embeddings text classification created facebook 's ai research ( fair ) lab . model allows one create \n",
      "Cleaned Token After Stem =  fasttext librari learn word embed text classif creat facebook 's ai research ( fair ) lab . model allow one creat \n",
      "Cleaned Token Before =  source-available license. in addition, elasticsearch now offers siem and machine learning as part of its offered services. developed from the found acquisition\n",
      "Cleaned Token After =  source-available license . addition , elasticsearch offers siem machine learning part offered services . developed found acquisition \n",
      "Cleaned Token After Stem =  source-avail licens . addit , elasticsearch offer siem machin learn part offer servic . develop found acquisit \n",
      "Cleaned Token Before =  api to interact with the platform. it makes a form of machine learning known as deep learning available to mobile devices. it is used for image and sound\n",
      "Cleaned Token After =  api interact platform . makes form machine learning known deep learning available mobile devices . used image sound \n",
      "Cleaned Token After Stem =  api interact platform . make form machin learn known deep learn avail mobil devic . use imag sound \n",
      "Cleaned Token Before =  classification to calibrate the predicted probabilities of supervised machine learning models. isotonic regression for the simply ordered case with univariate\n",
      "Cleaned Token After =  classification calibrate predicted probabilities supervised machine learning models . isotonic regression simply ordered case univariate \n",
      "Cleaned Token After Stem =  classif calibr predict probabl supervis machin learn model . isoton regress simpli order case univari \n",
      "Cleaned Token Before =  sequences, this representation can be widely used in applications of machine learning in proteomics and genomics. the results suggest that biovectors can\n",
      "Cleaned Token After =  sequences , representation widely used applications machine learning proteomics genomics . results suggest biovectors \n",
      "Cleaned Token After Stem =  sequenc , represent wide use applic machin learn proteom genom . result suggest biovector \n",
      "Cleaned Token Before =  journal big data. and the founder of sct capital, one of the first machine-learning-based hedge funds in new york city in the 90s. his research focuses\n",
      "Cleaned Token After =  journal big data . founder sct capital , one first machine-learning-based hedge funds new york city 90s . research focuses \n",
      "Cleaned Token After Stem =  journal big data . founder sct capit , one first machine-learning-bas hedg fund new york citi 90 . research focus \n",
      "Cleaned Token Before =  in statistical learning theory, a representer theorem is any of several related results stating that a minimizer f ∗ {\\displaystyle f^{*}} of a regularized\n",
      "Cleaned Token After =  statistical learning theory , representer theorem several related results stating minimizer f ∗ { \\displaystyle f^ { * } } regularized \n",
      "Cleaned Token After Stem =  statist learn theori , represent theorem sever relat result state minim f ∗ { \\displaystyl f^ { * } } regular \n",
      "Cleaned Token Before =  conference on machine learning. fowlkes, c (2004). \"spectral grouping using the nystrom method\". ieee transactions on pattern analysis and machine intelligence\n",
      "Cleaned Token After =  conference machine learning . fowlkes , c ( 2004 ) . `` spectral grouping using nystrom method '' . ieee transactions pattern analysis machine intelligence \n",
      "Cleaned Token After Stem =  confer machin learn . fowlk , c ( 2004 ) . `` spectral group use nystrom method `` . ieee transact pattern analysi machin intellig \n",
      "Cleaned Token Before =  to score the similarity of documents in the vector space model. in machine learning, common kernel functions such as the rbf kernel can be viewed as similarity\n",
      "Cleaned Token After =  score similarity documents vector space model . machine learning , common kernel functions rbf kernel viewed similarity \n",
      "Cleaned Token After Stem =  score similar document vector space model . machin learn , common kernel function rbf kernel view similar \n",
      "Cleaned Token Before =  transcription and translation applications using artificial intelligence and machine learning. its software, called otter, shows captions for live speakers, and\n",
      "Cleaned Token After =  transcription translation applications using artificial intelligence machine learning . software , called otter , shows captions live speakers , \n",
      "Cleaned Token After Stem =  transcript translat applic use artifici intellig machin learn . softwar , call otter , show caption live speaker , \n",
      "Cleaned Token Before =  enterprise tag management, an api hub, a customer data platform with machine learning, and data management products. tealium was founded in 2008 in san diego\n",
      "Cleaned Token After =  enterprise tag management , api hub , customer data platform machine learning , data management products . tealium founded 2008 san diego \n",
      "Cleaned Token After Stem =  enterpris tag manag , api hub , custom data platform machin learn , data manag product . tealium found 2008 san diego \n",
      "Cleaned Token Before =  in machine learning, the kernel perceptron is a variant of the popular perceptron learning algorithm that can learn kernel machines, i.e. non-linear classifiers\n",
      "Cleaned Token After =  machine learning , kernel perceptron variant popular perceptron learning algorithm learn kernel machines , i.e . non-linear classifiers \n",
      "Cleaned Token After Stem =  machin learn , kernel perceptron variant popular perceptron learn algorithm learn kernel machin , i.e . non-linear classifi \n",
      "Cleaned Token Before =  organization for the promotion of artificial intelligence with a focus on machine learning. the organization's goal is to establish top ai research institutes\n",
      "Cleaned Token After =  organization promotion artificial intelligence focus machine learning . organization 's goal establish top ai research institutes \n",
      "Cleaned Token After Stem =  organ promot artifici intellig focu machin learn . organ 's goal establish top ai research institut \n",
      "Cleaned Token Before =  higher learning is a 1995 american drama film written and directed by john singleton and starring an ensemble cast. the film follows the changing lives\n",
      "Cleaned Token After =  higher learning 1995 american drama film written directed john singleton starring ensemble cast . film follows changing lives \n",
      "Cleaned Token After Stem =  higher learn 1995 american drama film written direct john singleton star ensembl cast . film follow chang live \n",
      "Cleaned Token Before =  of models used in machine learning, and inspired by biological neural networks. they are the core component of modern deep learning algorithms. computation\n",
      "Cleaned Token After =  models used machine learning , inspired biological neural networks . core component modern deep learning algorithms . computation \n",
      "Cleaned Token After Stem =  model use machin learn , inspir biolog neural network . core compon modern deep learn algorithm . comput \n",
      "Cleaned Token Before =  automated semantic knowledge extraction using machine learning algorithms is used to \"extract machine-processable information at a relatively low complexity\n",
      "Cleaned Token After =  automated semantic knowledge extraction using machine learning algorithms used `` extract machine-processable information relatively low complexity \n",
      "Cleaned Token After Stem =  autom semant knowledg extract use machin learn algorithm use `` extract machine-process inform rel low complex \n",
      "Cleaned Token Before =  is a technology platform that uses natural language processing and machine learning to reveal insights from large amounts of unstructured data. watson\n",
      "Cleaned Token After =  technology platform uses natural language processing machine learning reveal insights large amounts unstructured data . watson \n",
      "Cleaned Token After Stem =  technolog platform use natur languag process machin learn reveal insight larg amount unstructur data . watson \n",
      "Cleaned Token Before =  earth – multivariate adaptive regression splines in orange (python machine learning library) friedman, j. h. (1993) fast mars, stanford university department\n",
      "Cleaned Token After =  earth – multivariate adaptive regression splines orange ( python machine learning library ) friedman , j. h. ( 1993 ) fast mars , stanford university department \n",
      "Cleaned Token After Stem =  earth – multivari adapt regress spline orang ( python machin learn librari ) friedman , j. h. ( 1993 ) fast mar , stanford univers depart \n",
      "Cleaned Token Before =  information retrieval information theory logic in computer science machine learning mathematical software multiagent systems multimedia networking and\n",
      "Cleaned Token After =  information retrieval information theory logic computer science machine learning mathematical software multiagent systems multimedia networking \n",
      "Cleaned Token After Stem =  inform retriev inform theori logic comput scienc machin learn mathemat softwar multiag system multimedia network \n",
      "Cleaned Token Before =  reaxff) and machine learning models. it should first be noted that non-parametric potentials are often referred to as \"machine learning\" potentials.\n",
      "Cleaned Token After =  reaxff ) machine learning models . first noted non-parametric potentials often referred `` machine learning '' potentials . \n",
      "Cleaned Token After Stem =  reaxff ) machin learn model . first note non-parametr potenti often refer `` machin learn `` potenti . \n",
      "Cleaned Token Before =  artificial intelligence and signal processing. these platforms encompass machine learning, reasoning, natural language processing, speech recognition and vision\n",
      "Cleaned Token After =  artificial intelligence signal processing . platforms encompass machine learning , reasoning , natural language processing , speech recognition vision \n",
      "Cleaned Token After Stem =  artifici intellig signal process . platform encompass machin learn , reason , natur languag process , speech recognit vision \n",
      "Cleaned Token Before =  in computational learning theory, occam learning is a model of algorithmic learning where the objective of the learner is to output a succinct representation\n",
      "Cleaned Token After =  computational learning theory , occam learning model algorithmic learning objective learner output succinct representation \n",
      "Cleaned Token After Stem =  comput learn theori , occam learn model algorithm learn object learner output succinct represent \n",
      "Cleaned Token Before =  in machine learning and natural language processing, a topic model is a type of statistical model for discovering the abstract \"topics\" that occur in a\n",
      "Cleaned Token After =  machine learning natural language processing , topic model type statistical model discovering abstract `` topics '' occur \n",
      "Cleaned Token After Stem =  machin learn natur languag process , topic model type statist model discov abstract `` topic `` occur \n",
      "Cleaned Token Before =  minimization (erm) is a principle in statistical learning theory which defines a family of learning algorithms and is used to give theoretical bounds\n",
      "Cleaned Token After =  minimization ( erm ) principle statistical learning theory defines family learning algorithms used give theoretical bounds \n",
      "Cleaned Token After Stem =  minim ( erm ) principl statist learn theori defin famili learn algorithm use give theoret bound \n",
      "Cleaned Token Before =  autonomous learning may refer to: autonomous learning in homeschooling learner autonomy machine learning self-paced instruction this disambiguation page\n",
      "Cleaned Token After =  autonomous learning may refer : autonomous learning homeschooling learner autonomy machine learning self-paced instruction disambiguation page \n",
      "Cleaned Token After Stem =  autonom learn may refer : autonom learn homeschool learner autonomi machin learn self-pac instruct disambigu page \n",
      "Cleaned Token Before =  process. advances in artificial intelligence, such as the advent of machine learning and the growth of big data, enable ai to be utilized to recruit, screen\n",
      "Cleaned Token After =  process . advances artificial intelligence , advent machine learning growth big data , enable ai utilized recruit , screen \n",
      "Cleaned Token After Stem =  process . advanc artifici intellig , advent machin learn growth big data , enabl ai util recruit , screen \n",
      "Cleaned Token Before =  dataiku is an artificial intelligence (ai) and machine learning company which was founded in 2013. in december 2019, dataiku announced that capitalg -\n",
      "Cleaned Token After =  dataiku artificial intelligence ( ai ) machine learning company founded 2013. december 2019 , dataiku announced capitalg - \n",
      "Cleaned Token After Stem =  dataiku artifici intellig ( ai ) machin learn compani found 2013. decemb 2019 , dataiku announc capitalg - \n",
      "Cleaned Token Before =  is a french computer scientist working primarily in the fields of machine learning, computer vision, mobile robotics, and computational neuroscience.\n",
      "Cleaned Token After =  french computer scientist working primarily fields machine learning , computer vision , mobile robotics , computational neuroscience . \n",
      "Cleaned Token After Stem =  french comput scientist work primarili field machin learn , comput vision , mobil robot , comput neurosci . \n",
      "Cleaned Token Before =  research expertise includes artificial intelligence (ai), machine learning, deep learning, computer vision and cognitive neuroscience. she was the leading\n",
      "Cleaned Token After =  research expertise includes artificial intelligence ( ai ) , machine learning , deep learning , computer vision cognitive neuroscience . leading \n",
      "Cleaned Token After Stem =  research expertis includ artifici intellig ( ai ) , machin learn , deep learn , comput vision cognit neurosci . lead \n",
      "Cleaned Token Before =  in machine learning, a margin classifier is a classifier which is able to give an associated distance from the decision boundary for each example. for\n",
      "Cleaned Token After =  machine learning , margin classifier classifier able give associated distance decision boundary example . \n",
      "Cleaned Token After Stem =  machin learn , margin classifi classifi abl give associ distanc decis boundari exampl . \n",
      "Cleaned Token Before =  google in a full-time position to \"work on new projects involving machine learning and language processing\". he was personally hired by google co-founder\n",
      "Cleaned Token After =  google full-time position `` work new projects involving machine learning language processing '' . personally hired google co-founder \n",
      "Cleaned Token After Stem =  googl full-tim posit `` work new project involv machin learn languag process `` . person hire googl co-found \n",
      "Cleaned Token Before =  alphafold: machine learning for protein structure prediction, foldit, 31 january 2020 torrisi, mirko et al. (22 jan. 2020), deep learning methods in protein\n",
      "Cleaned Token After =  alphafold : machine learning protein structure prediction , foldit , 31 january 2020 torrisi , mirko et al . ( 22 jan. 2020 ) , deep learning methods protein \n",
      "Cleaned Token After Stem =  alphafold : machin learn protein structur predict , foldit , 31 januari 2020 torrisi , mirko et al . ( 22 jan. 2020 ) , deep learn method protein \n",
      "Cleaned Token Before =  apprenticeship learning (or learning from demonstration) is the process of learning by observing an expert. it can be viewed as a form of supervised learning, where\n",
      "Cleaned Token After =  apprenticeship learning ( learning demonstration ) process learning observing expert . viewed form supervised learning , \n",
      "Cleaned Token After Stem =  apprenticeship learn ( learn demonstr ) process learn observ expert . view form supervis learn , \n",
      "Cleaned Token Before =  f_{\\beta }} is seen in wide application. the f-score is also used in machine learning. however, the f-measures do not take true negatives into account, hence\n",
      "Cleaned Token After =  f_ { \\beta } } seen wide application . f-score also used machine learning . however , f-measures take true negatives account , hence \n",
      "Cleaned Token After Stem =  f_ { \\beta } } seen wide applic . f-score also use machin learn . howev , f-measur take true neg account , henc \n",
      "Cleaned Token Before =  used in conjunction with machine learning techniques and complex optimization frameworks. the advancement of deep learning techniques has brought further\n",
      "Cleaned Token After =  used conjunction machine learning techniques complex optimization frameworks . advancement deep learning techniques brought \n",
      "Cleaned Token After Stem =  use conjunct machin learn techniqu complex optim framework . advanc deep learn techniqu brought \n",
      "Cleaned Token Before =  provide descriptive data such as word frequencies and document lengths. machine learning classifiers can greatly increase the number of texts that can be labeled\n",
      "Cleaned Token After =  provide descriptive data word frequencies document lengths . machine learning classifiers greatly increase number texts labeled \n",
      "Cleaned Token After Stem =  provid descript data word frequenc document length . machin learn classifi greatli increas number text label \n",
      "Cleaned Token Before =  the first neural networks to demonstrate learning of latent variables (hidden units). boltzmann machine learning was at first slow to simulate, but the\n",
      "Cleaned Token After =  first neural networks demonstrate learning latent variables ( hidden units ) . boltzmann machine learning first slow simulate , \n",
      "Cleaned Token After Stem =  first neural network demonstr learn latent variabl ( hidden unit ) . boltzmann machin learn first slow simul , \n",
      "Cleaned Token Before =  most commonly used machine learning algorithms include support vector machines (svm), naive bayes, and maximum entropy. deep learning, which is under the\n",
      "Cleaned Token After =  commonly used machine learning algorithms include support vector machines ( svm ) , naive bayes , maximum entropy . deep learning , \n",
      "Cleaned Token After Stem =  commonli use machin learn algorithm includ support vector machin ( svm ) , naiv bay , maximum entropi . deep learn , \n",
      "Cleaned Token Before =  on the development of self-driving cars and cleaning robots, these machine learning systems continue to struggle with their low adaptability and interpretability\n",
      "Cleaned Token After =  development self-driving cars cleaning robots , machine learning systems continue struggle low adaptability interpretability \n",
      "Cleaned Token After Stem =  develop self-driv car clean robot , machin learn system continu struggl low adapt interpret \n",
      "Cleaned Token Before =  where it is known as the laplace filter, and in machine learning for clustering and semi-supervised learning on neighborhood graphs. there are various definitions\n",
      "Cleaned Token After =  known laplace filter , machine learning clustering semi-supervised learning neighborhood graphs . various definitions \n",
      "Cleaned Token After Stem =  known laplac filter , machin learn cluster semi-supervis learn neighborhood graph . variou definit \n",
      "Cleaned Token Before =  schmidhuber and other early machine learning pioneers including alexey grigorevich ivakhnenko who published the first deep learning networks already in 1965\n",
      "Cleaned Token After =  schmidhuber early machine learning pioneers including alexey grigorevich ivakhnenko published first deep learning networks already 1965 \n",
      "Cleaned Token After Stem =  schmidhub earli machin learn pioneer includ alexey grigorevich ivakhnenko publish first deep learn network alreadi 1965 \n",
      "Cleaned Token Before =  systems (ais) are a class of computationally intelligent, rule-based machine learning systems inspired by the principles and processes of the vertebrate\n",
      "Cleaned Token After =  systems ( ais ) class computationally intelligent , rule-based machine learning systems inspired principles processes vertebrate \n",
      "Cleaned Token After Stem =  system ( ai ) class comput intellig , rule-bas machin learn system inspir principl process vertebr \n",
      "Cleaned Token Before =  cooling of homes and businesses to conserve energy. it is based on a machine-learning algorithm: for the first weeks users have to regulate the thermostat\n",
      "Cleaned Token After =  cooling homes businesses conserve energy . based machine-learning algorithm : first weeks users regulate thermostat \n",
      "Cleaned Token After Stem =  cool home busi conserv energi . base machine-learn algorithm : first week user regul thermostat \n",
      "Cleaned Token Before =  in machine learning and artificial intelligence, including automatic summarization, multi-document summarization, feature selection, active learning, sensor\n",
      "Cleaned Token After =  machine learning artificial intelligence , including automatic summarization , multi-document summarization , feature selection , active learning , sensor \n",
      "Cleaned Token After Stem =  machin learn artifici intellig , includ automat summar , multi-docu summar , featur select , activ learn , sensor \n",
      "Cleaned Token Before =  characters in a segmented line of text. particularly they focus on machine learning techniques that are able to learn visual features, avoiding the limiting\n",
      "Cleaned Token After =  characters segmented line text . particularly focus machine learning techniques able learn visual features , avoiding limiting \n",
      "Cleaned Token After Stem =  charact segment line text . particularli focu machin learn techniqu abl learn visual featur , avoid limit \n",
      "Cleaned Token Before =  of pbd is the macro recorder. query by example automated machine learning example-based machine translation inductive programming lapis (text editor), which\n",
      "Cleaned Token After =  pbd macro recorder . query example automated machine learning example-based machine translation inductive programming lapis ( text editor ) , \n",
      "Cleaned Token After Stem =  pbd macro record . queri exampl autom machin learn example-bas machin translat induct program lapi ( text editor ) , \n",
      "Cleaned Token Before =  machine can be used for supervised machine learning, in which training set of already classified data is available, or unsupervised machine learning,\n",
      "Cleaned Token After =  machine used supervised machine learning , training set already classified data available , unsupervised machine learning , \n",
      "Cleaned Token After Stem =  machin use supervis machin learn , train set alreadi classifi data avail , unsupervis machin learn , \n",
      "Cleaned Token Before =  it is an artificial neural net trained by a form of temporal-difference learning, specifically td-lambda. td-gammon achieved a level of play just slightly\n",
      "Cleaned Token After =  artificial neural net trained form temporal-difference learning , specifically td-lambda . td-gammon achieved level play slightly \n",
      "Cleaned Token After Stem =  artifici neural net train form temporal-differ learn , specif td-lambda . td-gammon achiev level play slightli \n",
      "Cleaned Token Before =  in 2014, ian goodfellow and his colleagues developed a new class of machine learning systems: generative adversarial networks (gan). two neural networks\n",
      "Cleaned Token After =  2014 , ian goodfellow colleagues developed new class machine learning systems : generative adversarial networks ( gan ) . two neural networks \n",
      "Cleaned Token After Stem =  2014 , ian goodfellow colleagu develop new class machin learn system : gener adversari network ( gan ) . two neural network \n",
      "Cleaned Token Before =  tomáš mikolov is a czech computer scientist working in the field of machine learning. he is currently a research scientist at czech institute of informatics\n",
      "Cleaned Token After =  tomáš mikolov czech computer scientist working field machine learning . currently research scientist czech institute informatics \n",
      "Cleaned Token After Stem =  tomáš mikolov czech comput scientist work field machin learn . current research scientist czech institut informat \n",
      "Cleaned Token Before =  inquiry-based learning (also spelled as enquiry-based learning in british english) is a form of active learning that starts by posing questions, problems\n",
      "Cleaned Token After =  inquiry-based learning ( also spelled enquiry-based learning british english ) form active learning starts posing questions , problems \n",
      "Cleaned Token After Stem =  inquiry-bas learn ( also spell enquiry-bas learn british english ) form activ learn start pose question , problem \n",
      "Cleaned Token Before =  applications have found wide use in image processing, signal processing, machine learning, medical imaging, and more. consider a linear system of equations x\n",
      "Cleaned Token After =  applications found wide use image processing , signal processing , machine learning , medical imaging , . consider linear system equations x \n",
      "Cleaned Token After Stem =  applic found wide use imag process , signal process , machin learn , medic imag , . consid linear system equat x \n",
      "Cleaned Token Before =  contrastive hebbian learning was shown to be equivalent in power to the backpropagation algorithms commonly used in machine learning. qiu, yixuan; zhang\n",
      "Cleaned Token After =  contrastive hebbian learning shown equivalent power backpropagation algorithms commonly used machine learning . qiu , yixuan ; zhang \n",
      "Cleaned Token After Stem =  contrast hebbian learn shown equival power backpropag algorithm commonli use machin learn . qiu , yixuan ; zhang \n",
      "Cleaned Token Before =  goal is to pioneer research on how quantum computing might help with machine learning and other difficult computer science problems. the lab is hosted at\n",
      "Cleaned Token After =  goal pioneer research quantum computing might help machine learning difficult computer science problems . lab hosted \n",
      "Cleaned Token After Stem =  goal pioneer research quantum comput might help machin learn difficult comput scienc problem . lab host \n",
      "Cleaned Token Before =  at princeton university. her research considers computer vision and machine learning. she was one of the leaders of the imagenet large scale visual recognition\n",
      "Cleaned Token After =  princeton university . research considers computer vision machine learning . one leaders imagenet large scale visual recognition \n",
      "Cleaned Token After Stem =  princeton univers . research consid comput vision machin learn . one leader imagenet larg scale visual recognit \n",
      "Cleaned Token Before =  neural networks capable of machine learning, where andrew ng determined that gpus could increase the speed of deep-learning systems by about 100 times\n",
      "Cleaned Token After =  neural networks capable machine learning , andrew ng determined gpus could increase speed deep-learning systems 100 times \n",
      "Cleaned Token After Stem =  neural network capabl machin learn , andrew ng determin gpu could increas speed deep-learn system 100 time \n",
      "Cleaned Token Before =  ninth international workshop on machine learning, p249-256 kononenko, igor et al. overcoming the myopia of inductive learning algorithms with relieff (1997)\n",
      "Cleaned Token After =  ninth international workshop machine learning , p249-256 kononenko , igor et al . overcoming myopia inductive learning algorithms relieff ( 1997 ) \n",
      "Cleaned Token After Stem =  ninth intern workshop machin learn , p249-256 kononenko , igor et al . overcom myopia induct learn algorithm relieff ( 1997 ) \n",
      "Cleaned Token Before =  center for secure and trusted machine learning (trusted ai) and the director of the information theory and machine learning (vital) research lab. avestimehr's\n",
      "Cleaned Token After =  center secure trusted machine learning ( trusted ai ) director information theory machine learning ( vital ) research lab . avestimehr 's \n",
      "Cleaned Token After Stem =  center secur trust machin learn ( trust ai ) director inform theori machin learn ( vital ) research lab . avestimehr 's \n",
      "Cleaned Token Before =  field: \"every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate\n",
      "Cleaned Token After =  field : `` every aspect learning feature intelligence principle precisely described machine made simulate \n",
      "Cleaned Token After Stem =  field : `` everi aspect learn featur intellig principl precis describ machin made simul \n",
      "Cleaned Token Before =  programming, data streaming, and machine learning. packt publishing ltd. p. 87. isbn 978-1-78355-050-0. lex sheehan, 2017. learning functional programming in\n",
      "Cleaned Token After =  programming , data streaming , machine learning . packt publishing ltd. p. 87. isbn 978-1-78355-050-0. lex sheehan , 2017. learning functional programming \n",
      "Cleaned Token After Stem =  program , data stream , machin learn . packt publish ltd. p. 87. isbn 978-1-78355-050-0. lex sheehan , 2017. learn function program \n",
      "Cleaned Token Before =  scale. crunchbase sources its data in four ways: the venture program, machine learning, an in-house data team, and the crunchbase community. members of the\n",
      "Cleaned Token After =  scale . crunchbase sources data four ways : venture program , machine learning , in-house data team , crunchbase community . members \n",
      "Cleaned Token After Stem =  scale . crunchbas sourc data four way : ventur program , machin learn , in-hous data team , crunchbas commun . member \n",
      "Cleaned Token Before =  application of kernel methods to large-scale learning problems. kernel methods (for instance, support vector machines or gaussian processes) project data points\n",
      "Cleaned Token After =  application kernel methods large-scale learning problems . kernel methods ( instance , support vector machines gaussian processes ) project data points \n",
      "Cleaned Token After Stem =  applic kernel method large-scal learn problem . kernel method ( instanc , support vector machin gaussian process ) project data point \n",
      "Cleaned Token Before =  action model learning (sometimes abbreviated action learning) is an area of machine learning concerned with creation and modification of software agent's\n",
      "Cleaned Token After =  action model learning ( sometimes abbreviated action learning ) area machine learning concerned creation modification software agent 's \n",
      "Cleaned Token After Stem =  action model learn ( sometim abbrevi action learn ) area machin learn concern creation modif softwar agent 's \n",
      "Cleaned Token Before =  combine multiple sub-tasks of ie in order to achieve a wider goal. machine learning, statistical analysis and/or natural language processing are often\n",
      "Cleaned Token After =  combine multiple sub-tasks ie order achieve wider goal . machine learning , statistical analysis and/or natural language processing often \n",
      "Cleaned Token After Stem =  combin multipl sub-task ie order achiev wider goal . machin learn , statist analysi and/or natur languag process often \n",
      "Cleaned Token Before =   1023–1029. burgin, m.; klinger, a. experience, generations, and limits in machine learning, theoretical computer science, v. 317, no. 1/3, 2004, pp. 71–91 davis\n",
      "Cleaned Token After =  1023–1029 . burgin , m. ; klinger , a. experience , generations , limits machine learning , theoretical computer science , v. 317 , . 1/3 , 2004 , pp . 71–91 davis \n",
      "Cleaned Token After Stem =  1023–1029 . burgin , m. ; klinger , a. experi , gener , limit machin learn , theoret comput scienc , v. 317 , . 1/3 , 2004 , pp . 71–91 davi \n",
      "Cleaned Token Before =  encompasses several domains including learning theory, computer-based training, online learning, and m-learning, where mobile technologies are used. the\n",
      "Cleaned Token After =  encompasses several domains including learning theory , computer-based training , online learning , m-learning , mobile technologies used . \n",
      "Cleaned Token After Stem =  encompass sever domain includ learn theori , computer-bas train , onlin learn , m-learn , mobil technolog use . \n",
      "Cleaned Token Before =  practices in organizational decision-making and processes for applying machine learning at scale. the basic idea is that decisions are based on our understanding\n",
      "Cleaned Token After =  practices organizational decision-making processes applying machine learning scale . basic idea decisions based understanding \n",
      "Cleaned Token After Stem =  practic organiz decision-mak process appli machin learn scale . basic idea decis base understand \n",
      "Cleaned Token Before =  machine intelligence may refer to: artificial intelligence, intelligence exhibited by machines machine learning, giving computers the ability to learn\n",
      "Cleaned Token After =  machine intelligence may refer : artificial intelligence , intelligence exhibited machines machine learning , giving computers ability learn \n",
      "Cleaned Token After Stem =  machin intellig may refer : artifici intellig , intellig exhibit machin machin learn , give comput abil learn \n",
      "Cleaned Token Before =  proprietary machine-learning system for deep neural networks that was eventually refactored into tensorflow tensorflow, an open-source machine-learning software\n",
      "Cleaned Token After =  proprietary machine-learning system deep neural networks eventually refactored tensorflow tensorflow , open-source machine-learning software \n",
      "Cleaned Token After Stem =  proprietari machine-learn system deep neural network eventu refactor tensorflow tensorflow , open-sourc machine-learn softwar \n",
      "Cleaned Token Before =  org. archived 2016-01-10 at the wayback machine ghahramani, z (2015). \"probabilistic machine learning and artificial intelligence\". nature. 521 (7553):\n",
      "Cleaned Token After =  org . archived 2016-01-10 wayback machine ghahramani , z ( 2015 ) . `` probabilistic machine learning artificial intelligence '' . nature . 521 ( 7553 ) : \n",
      "Cleaned Token After Stem =  org . archiv 2016-01-10 wayback machin ghahramani , z ( 2015 ) . `` probabilist machin learn artifici intellig `` . natur . 521 ( 7553 ) : \n",
      "Cleaned Token Before =  academic ai. it serves to improve the game-player experience rather than machine learning or decision making. during the golden age of arcade video games the\n",
      "Cleaned Token After =  academic ai . serves improve game-player experience rather machine learning decision making . golden age arcade video games \n",
      "Cleaned Token After Stem =  academ ai . serv improv game-play experi rather machin learn decis make . golden age arcad video game \n",
      "Cleaned Token Before =  class membership or values of previous instances in the data stream. machine learning techniques can be used to learn this prediction task from labeled examples\n",
      "Cleaned Token After =  class membership values previous instances data stream . machine learning techniques used learn prediction task labeled examples \n",
      "Cleaned Token After Stem =  class membership valu previou instanc data stream . machin learn techniqu use learn predict task label exampl \n",
      "Cleaned Token Before =  stagnated after machine learning research by minsky and papert (1969), who discovered two key issues with the computational machines that processed neural\n",
      "Cleaned Token After =  stagnated machine learning research minsky papert ( 1969 ) , discovered two key issues computational machines processed neural \n",
      "Cleaned Token After Stem =  stagnat machin learn research minski papert ( 1969 ) , discov two key issu comput machin process neural \n",
      "Cleaned Token Before =  august 6, 1971) is a swiss physicist and pioneer in the fields of machine learning and human-robot interactions. as a full professor at the school of\n",
      "Cleaned Token After =  august 6 , 1971 ) swiss physicist pioneer fields machine learning human-robot interactions . full professor school \n",
      "Cleaned Token After Stem =  august 6 , 1971 ) swiss physicist pioneer field machin learn human-robot interact . full professor school \n",
      "Cleaned Token Before =  intelligence projects are currently better understood as types of machine-learning algorithms, that can be integrated with existing data to understand\n",
      "Cleaned Token After =  intelligence projects currently better understood types machine-learning algorithms , integrated existing data understand \n",
      "Cleaned Token After Stem =  intellig project current better understood type machine-learn algorithm , integr exist data understand \n",
      "Cleaned Token Before =  there are many statistical and machine learning approaches. the decision tree is perhaps the most widely used machine learning algorithm. other widely used\n",
      "Cleaned Token After =  many statistical machine learning approaches . decision tree perhaps widely used machine learning algorithm . widely used \n",
      "Cleaned Token After Stem =  mani statist machin learn approach . decis tree perhap wide use machin learn algorithm . wide use \n",
      "Cleaned Token Before =  the platform combines elk as a cloud service and machine learning to derive new insights from machine data. logz.io has offices in boston and tel aviv\n",
      "Cleaned Token After =  platform combines elk cloud service machine learning derive new insights machine data . logz.io offices boston tel aviv \n",
      "Cleaned Token After Stem =  platform combin elk cloud servic machin learn deriv new insight machin data . logz.io offic boston tel aviv \n",
      "Cleaned Token Before =  former chair of the machine learning department at cmu. mitchell is known for his contributions to the advancement of machine learning, artificial intelligence\n",
      "Cleaned Token After =  former chair machine learning department cmu . mitchell known contributions advancement machine learning , artificial intelligence \n",
      "Cleaned Token After Stem =  former chair machin learn depart cmu . mitchel known contribut advanc machin learn , artifici intellig \n",
      "Cleaned Token Before =  label large amounts of data. these data are then used for training machine learning and artificial intelligence algorithms that lie behind self-driving\n",
      "Cleaned Token After =  label large amounts data . data used training machine learning artificial intelligence algorithms lie behind self-driving \n",
      "Cleaned Token After Stem =  label larg amount data . data use train machin learn artifici intellig algorithm lie behind self-driv \n",
      "Cleaned Token Before =  algorithmic learning theory is a mathematical framework for analyzing machine learning problems and algorithms. synonyms include formal learning theory and\n",
      "Cleaned Token After =  algorithmic learning theory mathematical framework analyzing machine learning problems algorithms . synonyms include formal learning theory \n",
      "Cleaned Token After Stem =  algorithm learn theori mathemat framework analyz machin learn problem algorithm . synonym includ formal learn theori \n",
      "Cleaned Token Before =  feature selection, one of the basic problems in pattern recognition and machine learning, identifies subsets of data that are relevant to the parameters used\n",
      "Cleaned Token After =  feature selection , one basic problems pattern recognition machine learning , identifies subsets data relevant parameters used \n",
      "Cleaned Token After Stem =  featur select , one basic problem pattern recognit machin learn , identifi subset data relev paramet use \n",
      "Cleaned Token Before =  algorithms, particularly artificial intelligence and its subfield of machine learning, a right to explanation (or right to an explanation) is a right to\n",
      "Cleaned Token After =  algorithms , particularly artificial intelligence subfield machine learning , right explanation ( right explanation ) right \n",
      "Cleaned Token After Stem =  algorithm , particularli artifici intellig subfield machin learn , right explan ( right explan ) right \n",
      "Cleaned Token Before =  knowledge. in order to allow the use of knowledge graphs in various machine learning tasks, several methods for deriving latent feature representations\n",
      "Cleaned Token After =  knowledge . order allow use knowledge graphs various machine learning tasks , several methods deriving latent feature representations \n",
      "Cleaned Token After Stem =  knowledg . order allow use knowledg graph variou machin learn task , sever method deriv latent featur represent \n",
      "Cleaned Token Before =  diverse machine learning algorithms, like inductive logic programming, bayesian network, statistical relational learning, support vector machines, survival\n",
      "Cleaned Token After =  diverse machine learning algorithms , like inductive logic programming , bayesian network , statistical relational learning , support vector machines , survival \n",
      "Cleaned Token After Stem =  divers machin learn algorithm , like induct logic program , bayesian network , statist relat learn , support vector machin , surviv \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Token Before =  for network traffic solid-state lighting semi-supervised learning, a class of machine learning techniques single stuck line, a fault model for digital\n",
      "Cleaned Token After =  network traffic solid-state lighting semi-supervised learning , class machine learning techniques single stuck line , fault model digital \n",
      "Cleaned Token After Stem =  network traffic solid-st light semi-supervis learn , class machin learn techniqu singl stuck line , fault model digit \n",
      "Cleaned Token Before =  minimization (srm) is an inductive principle of use in machine learning. commonly in machine learning, a generalized model must be selected from a finite\n",
      "Cleaned Token After =  minimization ( srm ) inductive principle use machine learning . commonly machine learning , generalized model must selected finite \n",
      "Cleaned Token After Stem =  minim ( srm ) induct principl use machin learn . commonli machin learn , gener model must select finit \n",
      "Cleaned Token Before =  provides data analysis, data management, statistics, data mining, machine learning, text analytics and data visualization procedures. statistica is a\n",
      "Cleaned Token After =  provides data analysis , data management , statistics , data mining , machine learning , text analytics data visualization procedures . statistica \n",
      "Cleaned Token After Stem =  provid data analysi , data manag , statist , data mine , machin learn , text analyt data visual procedur . statistica \n",
      "Cleaned Token Before =  combine large amounts of data from things connected to the internet with machine learning and sap's real-time database s/4 hana.\" on 29 january 2019, sap announced\n",
      "Cleaned Token After =  combine large amounts data things connected internet machine learning sap 's real-time database s/4 hana . '' 29 january 2019 , sap announced \n",
      "Cleaned Token After Stem =  combin larg amount data thing connect internet machin learn sap 's real-tim databas s/4 hana . `` 29 januari 2019 , sap announc \n",
      "Cleaned Token Before =  to describe the clinical features of a patient and is suitable for machine learning approaches. publicly accessible databases that labs use to deposit\n",
      "Cleaned Token After =  describe clinical features patient suitable machine learning approaches . publicly accessible databases labs use deposit \n",
      "Cleaned Token After Stem =  describ clinic featur patient suitabl machin learn approach . publicli access databas lab use deposit \n",
      "Cleaned Token Before =  a professor in the department of statistics & data science and the machine learning department at carnegie mellon university. wasserman received his ph\n",
      "Cleaned Token After =  professor department statistics & data science machine learning department carnegie mellon university . wasserman received ph \n",
      "Cleaned Token After Stem =  professor depart statist & data scienc machin learn depart carnegi mellon univers . wasserman receiv ph \n",
      "Cleaned Token Before =  and integration platform. knime integrates various components for machine learning and data mining through its modular data pipelining \"lego of analytics\"\n",
      "Cleaned Token After =  integration platform . knime integrates various components machine learning data mining modular data pipelining `` lego analytics '' \n",
      "Cleaned Token After Stem =  integr platform . knime integr variou compon machin learn data mine modular data pipelin `` lego analyt `` \n",
      "Cleaned Token Before =  a branch of evolutionary computation, which is closely related to machine learning. wong provides a short survey, wherein the chapter of shir and the\n",
      "Cleaned Token After =  branch evolutionary computation , closely related machine learning . wong provides short survey , wherein chapter shir \n",
      "Cleaned Token After Stem =  branch evolutionari comput , close relat machin learn . wong provid short survey , wherein chapter shir \n",
      "Cleaned Token Before =  image understanding, pattern analysis and recognition, machine intelligence, machine learning, search techniques, document and handwriting analysis, medical\n",
      "Cleaned Token After =  image understanding , pattern analysis recognition , machine intelligence , machine learning , search techniques , document handwriting analysis , medical \n",
      "Cleaned Token After Stem =  imag understand , pattern analysi recognit , machin intellig , machin learn , search techniqu , document handwrit analysi , medic \n",
      "Cleaned Token Before =  recently, more complex methods based on simulation, markov models and machine learning models have been introduced. a well-known model to show the probability\n",
      "Cleaned Token After =  recently , complex methods based simulation , markov models machine learning models introduced . well-known model show probability \n",
      "Cleaned Token After Stem =  recent , complex method base simul , markov model machin learn model introduc . well-known model show probabl \n",
      "Cleaned Token Before =  in machine learning and data mining, a string kernel is a kernel function that operates on strings, i.e. finite sequences of symbols that need not be of\n",
      "Cleaned Token After =  machine learning data mining , string kernel kernel function operates strings , i.e . finite sequences symbols need \n",
      "Cleaned Token After Stem =  machin learn data mine , string kernel kernel function oper string , i.e . finit sequenc symbol need \n",
      "Cleaned Token Before =  computer scientist based at microsoft research, who uses statistics and machine learning to understand the progression of diseases. belgrave grew up in trinidad\n",
      "Cleaned Token After =  computer scientist based microsoft research , uses statistics machine learning understand progression diseases . belgrave grew trinidad \n",
      "Cleaned Token After Stem =  comput scientist base microsoft research , use statist machin learn understand progress diseas . belgrav grew trinidad \n",
      "Cleaned Token Before =  (29 may 2017). \"arm's new processors are designed to power the machine-learning machines\". the verge. retrieved 10 july 2017. frumusanu, andrei (6 december\n",
      "Cleaned Token After =  ( 29 may 2017 ) . `` arm 's new processors designed power machine-learning machines '' . verge . retrieved 10 july 2017. frumusanu , andrei ( 6 december \n",
      "Cleaned Token After Stem =  ( 29 may 2017 ) . `` arm 's new processor design power machine-learn machin `` . verg . retriev 10 juli 2017. frumusanu , andrei ( 6 decemb \n",
      "Cleaned Token Before =  technology company that builds intelligent products and services powered by machine learning; it is one of europe's largest internet companies, operating russia's\n",
      "Cleaned Token After =  technology company builds intelligent products services powered machine learning ; one europe 's largest internet companies , operating russia 's \n",
      "Cleaned Token After Stem =  technolog compani build intellig product servic power machin learn ; one europ 's largest internet compani , oper russia 's \n",
      "Cleaned Token Before =  linguistics portal lexical analysis discourse analysis semantic analysis (machine learning) literal and figurative language translation semantic structure analysis\n",
      "Cleaned Token After =  linguistics portal lexical analysis discourse analysis semantic analysis ( machine learning ) literal figurative language translation semantic structure analysis \n",
      "Cleaned Token After Stem =  linguist portal lexic analysi discours analysi semant analysi ( machin learn ) liter figur languag translat semant structur analysi \n",
      "Cleaned Token Before =  predictive learning is a technique of machine learning in which an agent tries to build a model of its environment by trying out different actions in\n",
      "Cleaned Token After =  predictive learning technique machine learning agent tries build model environment trying different actions \n",
      "Cleaned Token After Stem =  predict learn techniqu machin learn agent tri build model environ tri differ action \n",
      "Cleaned Token Before =  reinforcement learning with replacing eligibility traces. machine learning 22(1/2/3):123-158. [sutton and barto, 1998] reinforcement learning: an introduction\n",
      "Cleaned Token After =  reinforcement learning replacing eligibility traces . machine learning 22 ( 1/2/3 ) :123-158 . [ sutton barto , 1998 ] reinforcement learning : introduction \n",
      "Cleaned Token After Stem =  reinforc learn replac elig trace . machin learn 22 ( 1/2/3 ) :123-158 . [ sutton barto , 1998 ] reinforc learn : introduct \n",
      "Cleaned Token Before =  tool to aid in learning. this type of learning methodology is called blended learning. blended learning can also use machine learning and other such technologies\n",
      "Cleaned Token After =  tool aid learning . type learning methodology called blended learning . blended learning also use machine learning technologies \n",
      "Cleaned Token After Stem =  tool aid learn . type learn methodolog call blend learn . blend learn also use machin learn technolog \n",
      "Cleaned Token Before =  management services. its services use robotics, artificial intelligence and machine learning algorithms. headquartered in mumbai, the company has a presence across\n",
      "Cleaned Token After =  management services . services use robotics , artificial intelligence machine learning algorithms . headquartered mumbai , company presence across \n",
      "Cleaned Token After Stem =  manag servic . servic use robot , artifici intellig machin learn algorithm . headquart mumbai , compani presenc across \n",
      "Cleaned Token Before =  scikit-mutliflow (also known as skmultiflow) is a free and open source software machine learning library for multi-output/multi-label and stream data written in python\n",
      "Cleaned Token After =  scikit-mutliflow ( also known skmultiflow ) free open source software machine learning library multi-output/multi-label stream data written python \n",
      "Cleaned Token After Stem =  scikit-mutliflow ( also known skmultiflow ) free open sourc softwar machin learn librari multi-output/multi-label stream data written python \n",
      "Cleaned Token Before =  programs but on machine learning of symbolic hypotheses from logical representations. however, there were some encouraging results on learning recursive prolog\n",
      "Cleaned Token After =  programs machine learning symbolic hypotheses logical representations . however , encouraging results learning recursive prolog \n",
      "Cleaned Token After Stem =  program machin learn symbol hypothes logic represent . howev , encourag result learn recurs prolog \n",
      "Cleaned Token Before =  optimization and machine learning, known for his work on randomized coordinate descent algorithms, stochastic gradient descent and federated learning. he is currently\n",
      "Cleaned Token After =  optimization machine learning , known work randomized coordinate descent algorithms , stochastic gradient descent federated learning . currently \n",
      "Cleaned Token After Stem =  optim machin learn , known work random coordin descent algorithm , stochast gradient descent feder learn . current \n",
      "Cleaned Token Before =  a simple machine is a mechanical device that changes the direction or magnitude of a force. in general, they can be defined as the simplest mechanisms\n",
      "Cleaned Token After =  simple machine mechanical device changes direction magnitude force . general , defined simplest mechanisms \n",
      "Cleaned Token After Stem =  simpl machin mechan devic chang direct magnitud forc . gener , defin simplest mechan \n",
      "Cleaned Token Before =  remotely via online chat. it features a ranking algorithm that uses machine learning for classification and recommendation of tutors. the company was launched\n",
      "Cleaned Token After =  remotely via online chat . features ranking algorithm uses machine learning classification recommendation tutors . company launched \n",
      "Cleaned Token After Stem =  remot via onlin chat . featur rank algorithm use machin learn classif recommend tutor . compani launch \n",
      "Cleaned Token Before =  above areas, opencv includes a statistical machine learning library that contains: boosting decision tree learning gradient boosting trees expectation-maximization\n",
      "Cleaned Token After =  areas , opencv includes statistical machine learning library contains : boosting decision tree learning gradient boosting trees expectation-maximization \n",
      "Cleaned Token After Stem =  area , opencv includ statist machin learn librari contain : boost decis tree learn gradient boost tree expectation-maxim \n",
      "Cleaned Token Before =  julia offers a package for a comprehensive hpc ecosystem covering machine learning, data science, various scientific domains and visualization.\" additionally\n",
      "Cleaned Token After =  julia offers package comprehensive hpc ecosystem covering machine learning , data science , various scientific domains visualization . '' additionally \n",
      "Cleaned Token After Stem =  julia offer packag comprehens hpc ecosystem cover machin learn , data scienc , variou scientif domain visual . `` addit \n",
      "Cleaned Token Before =  discouraged parameter (link) natarajan, b.k. (1989). \"on learning sets and functions\". machine learning. 4: 67–97. doi:10.1007/bf00114804. ben-david, shai;\n",
      "Cleaned Token After =  discouraged parameter ( link ) natarajan , b.k . ( 1989 ) . `` learning sets functions '' . machine learning . 4 : 67–97 . doi:10.1007/bf00114804 . ben-david , shai ; \n",
      "Cleaned Token After Stem =  discourag paramet ( link ) natarajan , b.k . ( 1989 ) . `` learn set function `` . machin learn . 4 : 67–97 . doi:10.1007/bf00114804 . ben-david , shai ; \n",
      "Cleaned Token Before =  commercial applications, such as artificial neural networks and statistical machine learning. these \"applied ai\" systems are now used extensively throughout the\n",
      "Cleaned Token After =  commercial applications , artificial neural networks statistical machine learning . `` applied ai '' systems used extensively throughout \n",
      "Cleaned Token After Stem =  commerci applic , artifici neural network statist machin learn . `` appli ai `` system use extens throughout \n",
      "Cleaned Token Before =  convergence (the generalization ability) of the learning process? theory of constructing learning machines how can one construct algorithms that can control\n",
      "Cleaned Token After =  convergence ( generalization ability ) learning process ? theory constructing learning machines one construct algorithms control \n",
      "Cleaned Token After Stem =  converg ( gener abil ) learn process ? theori construct learn machin one construct algorithm control \n",
      "Cleaned Token Before =  related to a certain application. this is the same sense as feature in machine learning and pattern recognition generally, though image processing has a very\n",
      "Cleaned Token After =  related certain application . sense feature machine learning pattern recognition generally , though image processing \n",
      "Cleaned Token After Stem =  relat certain applic . sens featur machin learn pattern recognit gener , though imag process \n",
      "Cleaned Token Before =  hutter's 2005 book universal artificial intelligence. aixi is a reinforcement learning agent. it maximizes the expected total rewards received from the environment\n",
      "Cleaned Token After =  hutter 's 2005 book universal artificial intelligence . aixi reinforcement learning agent . maximizes expected total rewards received environment \n",
      "Cleaned Token After Stem =  hutter 's 2005 book univers artifici intellig . aixi reinforc learn agent . maxim expect total reward receiv environ \n",
      "Cleaned Token Before =  major benefit of teleradiology is that it can be automated with modern machine learning techniques. the benefits of artificial intelligence include efficiency\n",
      "Cleaned Token After =  major benefit teleradiology automated modern machine learning techniques . benefits artificial intelligence include efficiency \n",
      "Cleaned Token After Stem =  major benefit teleradiolog autom modern machin learn techniqu . benefit artifici intellig includ effici \n",
      "Cleaned Token Before =  region based convolutional neural networks (r-cnn) are a family of machine learning models for computer vision and specifically object detection. the original\n",
      "Cleaned Token After =  region based convolutional neural networks ( r-cnn ) family machine learning models computer vision specifically object detection . original \n",
      "Cleaned Token After Stem =  region base convolut neural network ( r-cnn ) famili machin learn model comput vision specif object detect . origin \n",
      "Cleaned Token Before =  labelbox is a cloud-based machine learning platform for image annotation and data labeling.<ref>\n",
      "Cleaned Token After =  labelbox cloud-based machine learning platform image annotation data labeling. < ref > \n",
      "Cleaned Token After Stem =  labelbox cloud-bas machin learn platform imag annot data label . < ref > \n",
      "Cleaned Token Before =  in machine learning: vol. 11: no. 1, pp 1-96. https://web.stanford.edu/~bvr/pubs/ts_tutorial.pdf j. wyatt. exploration and inference in learning from\n",
      "Cleaned Token After =  machine learning : vol . 11 : . 1 , pp 1-96. https : //web.stanford.edu/~bvr/pubs/ts_tutorial.pdf j. wyatt . exploration inference learning \n",
      "Cleaned Token After Stem =  machin learn : vol . 11 : . 1 , pp 1-96. http : //web.stanford.edu/~bvr/pubs/ts_tutorial.pdf j. wyatt . explor infer learn \n",
      "Cleaned Token Before =  photonic quantum computers and develops open-source software for quantum machine learning and simulating quantum photonic devices. xanadu was founded in 2016\n",
      "Cleaned Token After =  photonic quantum computers develops open-source software quantum machine learning simulating quantum photonic devices . xanadu founded 2016 \n",
      "Cleaned Token After Stem =  photon quantum comput develop open-sourc softwar quantum machin learn simul quantum photon devic . xanadu found 2016 \n",
      "Cleaned Token Before =  in probability theory, statistics, and machine learning, recursive bayesian estimation, also known as a bayes filter, is a general probabilistic approach\n",
      "Cleaned Token After =  probability theory , statistics , machine learning , recursive bayesian estimation , also known bayes filter , general probabilistic approach \n",
      "Cleaned Token After Stem =  probabl theori , statist , machin learn , recurs bayesian estim , also known bay filter , gener probabilist approach \n",
      "Cleaned Token Before =  random kitchen sink algorithm (also going by the name of extreme learning machines in some communities). in 2019, another possible implementation of\n",
      "Cleaned Token After =  random kitchen sink algorithm ( also going name extreme learning machines communities ) . 2019 , another possible implementation \n",
      "Cleaned Token After Stem =  random kitchen sink algorithm ( also go name extrem learn machin commun ) . 2019 , anoth possibl implement \n",
      "Cleaned Token Before =  stem research. inductive bias occurs within the field of machine learning. in machine learning one seeks to develop algorithms that are able to learn to\n",
      "Cleaned Token After =  stem research . inductive bias occurs within field machine learning . machine learning one seeks develop algorithms able learn \n",
      "Cleaned Token After Stem =  stem research . induct bia occur within field machin learn . machin learn one seek develop algorithm abl learn \n",
      "Cleaned Token Before =  the sample complexity of a machine learning algorithm represents the number of training-samples that it needs in order to successfully learn a target function\n",
      "Cleaned Token After =  sample complexity machine learning algorithm represents number training-samples needs order successfully learn target function \n",
      "Cleaned Token After Stem =  sampl complex machin learn algorithm repres number training-sampl need order success learn target function \n",
      "Cleaned Token Before =  tests\" (pdf). in sammut, claude; webb, geoff (eds.). encyclopedia of machine learning and data mining. springer. kohavi, ron; thomke, stefan (september 2017)\n",
      "Cleaned Token After =  tests '' ( pdf ) . sammut , claude ; webb , geoff ( eds. ) . encyclopedia machine learning data mining . springer . kohavi , ron ; thomke , stefan ( september 2017 ) \n",
      "Cleaned Token After Stem =  test `` ( pdf ) . sammut , claud ; webb , geoff ( ed . ) . encyclopedia machin learn data mine . springer . kohavi , ron ; thomk , stefan ( septemb 2017 ) \n",
      "Cleaned Token Before =  that provides an integrated environment for data preparation, machine learning, deep learning, text mining, and predictive analytics. it is used for business\n",
      "Cleaned Token After =  provides integrated environment data preparation , machine learning , deep learning , text mining , predictive analytics . used business \n",
      "Cleaned Token After Stem =  provid integr environ data prepar , machin learn , deep learn , text mine , predict analyt . use busi \n",
      "Cleaned Token Before =  psychology, academic music study, signal processing, informatics, machine learning, optical music recognition, computational intelligence or some combination\n",
      "Cleaned Token After =  psychology , academic music study , signal processing , informatics , machine learning , optical music recognition , computational intelligence combination \n",
      "Cleaned Token After Stem =  psycholog , academ music studi , signal process , informat , machin learn , optic music recognit , comput intellig combin \n",
      "Cleaned Token Before =  is a chinese technology company that designs image recognition and deep-learning software. based in beijing, the company develops artificial intelligence\n",
      "Cleaned Token After =  chinese technology company designs image recognition deep-learning software . based beijing , company develops artificial intelligence \n",
      "Cleaned Token After Stem =  chines technolog compani design imag recognit deep-learn softwar . base beij , compani develop artifici intellig \n",
      "Cleaned Token Before =  such as manufacturing, supply chains and logistics, analytics and machine learning, production systems, human factors and industrial design, and service\n",
      "Cleaned Token After =  manufacturing , supply chains logistics , analytics machine learning , production systems , human factors industrial design , service \n",
      "Cleaned Token After Stem =  manufactur , suppli chain logist , analyt machin learn , product system , human factor industri design , servic \n",
      "Cleaned Token Before =  the company uses data science and has combined personal stylists and machine learning (ai) for personalized recommendation. stitch fix was referenced in\n",
      "Cleaned Token After =  company uses data science combined personal stylists machine learning ( ai ) personalized recommendation . stitch fix referenced \n",
      "Cleaned Token After Stem =  compani use data scienc combin person stylist machin learn ( ai ) person recommend . stitch fix referenc \n",
      "Cleaned Token Before =  ml fairness, short for machine learning fairness, is an initiative by software companies, namely the google arm of the alphabet corporation, to implement\n",
      "Cleaned Token After =  ml fairness , short machine learning fairness , initiative software companies , namely google arm alphabet corporation , implement \n",
      "Cleaned Token After Stem =  ml fair , short machin learn fair , initi softwar compani , name googl arm alphabet corpor , implement \n",
      "Cleaned Token Before =  operationalized artificial intelligence (ai) and decision models, including machine learning, knowledge graphs, rules, optimization, linguistic and agent-based\n",
      "Cleaned Token After =  operationalized artificial intelligence ( ai ) decision models , including machine learning , knowledge graphs , rules , optimization , linguistic agent-based \n",
      "Cleaned Token After Stem =  operation artifici intellig ( ai ) decis model , includ machin learn , knowledg graph , rule , optim , linguist agent-bas \n",
      "Cleaned Token Before =  finds important use in the study of patterns and machine learning techniques. in terms of machine learning and pattern classification, the labels of a set\n",
      "Cleaned Token After =  finds important use study patterns machine learning techniques . terms machine learning pattern classification , labels set \n",
      "Cleaned Token After Stem =  find import use studi pattern machin learn techniqu . term machin learn pattern classif , label set \n",
      "Cleaned Token Before =  computer scientist. he works mainly in reinforcement learning, but has done work in machine learning, game theory, computer networking, partially observable\n",
      "Cleaned Token After =  computer scientist . works mainly reinforcement learning , done work machine learning , game theory , computer networking , partially observable \n",
      "Cleaned Token After Stem =  comput scientist . work mainli reinforc learn , done work machin learn , game theori , comput network , partial observ \n",
      "Cleaned Token Before =  of the plant. process data analytics: applying data analytics and machine learning methods for process manufacturing problems. various chemical techniques\n",
      "Cleaned Token After =  plant . process data analytics : applying data analytics machine learning methods process manufacturing problems . various chemical techniques \n",
      "Cleaned Token After Stem =  plant . process data analyt : appli data analyt machin learn method process manufactur problem . variou chemic techniqu \n",
      "Cleaned Token Before =  applications in several fields, including artificial intelligence, machine learning, auction theory, software engineering, applied mathematics and theoretical\n",
      "Cleaned Token After =  applications several fields , including artificial intelligence , machine learning , auction theory , software engineering , applied mathematics theoretical \n",
      "Cleaned Token After Stem =  applic sever field , includ artifici intellig , machin learn , auction theori , softwar engin , appli mathemat theoret \n",
      "Cleaned Token Before =  originally called the imitation game by alan turing in 1950, is a test of a machine's ability to exhibit intelligent behaviour equivalent to, or indistinguishable\n",
      "Cleaned Token After =  originally called imitation game alan turing 1950 , test machine 's ability exhibit intelligent behaviour equivalent , indistinguishable \n",
      "Cleaned Token After Stem =  origin call imit game alan ture 1950 , test machin 's abil exhibit intellig behaviour equival , indistinguish \n",
      "Cleaned Token Before =  use of node graphs has exploded. the fields of graphics, games, and machine learning are the main adopters of this software design with the majority of\n",
      "Cleaned Token After =  use node graphs exploded . fields graphics , games , machine learning main adopters software design majority \n",
      "Cleaned Token After Stem =  use node graph explod . field graphic , game , machin learn main adopt softwar design major \n",
      "Cleaned Token Before =  on knowledge previously acquired by machine learning, specifically by an artificial neural network (a deep learning method) by extensive training, both\n",
      "Cleaned Token After =  knowledge previously acquired machine learning , specifically artificial neural network ( deep learning method ) extensive training , \n",
      "Cleaned Token After Stem =  knowledg previous acquir machin learn , specif artifici neural network ( deep learn method ) extens train , \n",
      "Cleaned Token Before =  crowdflower) — an internet company that collects training data for machine learning — which he co-founded in december 2007 with chris van pelt. in 2019\n",
      "Cleaned Token After =  crowdflower ) — internet company collects training data machine learning — co-founded december 2007 chris van pelt . 2019 \n",
      "Cleaned Token After Stem =  crowdflow ) — internet compani collect train data machin learn — co-found decemb 2007 chri van pelt . 2019 \n",
      "Cleaned Token Before =  toward discovery of biomarkers. in this approach, a feature selection machine learning algorithm observes a large collection of health records and identifies\n",
      "Cleaned Token After =  toward discovery biomarkers . approach , feature selection machine learning algorithm observes large collection health records identifies \n",
      "Cleaned Token After Stem =  toward discoveri biomark . approach , featur select machin learn algorithm observ larg collect health record identifi \n",
      "Cleaned Token Before =  at google known for leading a large group of researchers working in machine learning including adversarial settings. he is also among the three authors\n",
      "Cleaned Token After =  google known leading large group researchers working machine learning including adversarial settings . also among three authors \n",
      "Cleaned Token After Stem =  googl known lead larg group research work machin learn includ adversari set . also among three author \n",
      "Cleaned Token Before =  an important data pre-processing step that can be applied in many machine learning (or data mining) tasks. approaches for instance selection can be applied\n",
      "Cleaned Token After =  important data pre-processing step applied many machine learning ( data mining ) tasks . approaches instance selection applied \n",
      "Cleaned Token After Stem =  import data pre-process step appli mani machin learn ( data mine ) task . approach instanc select appli \n",
      "Cleaned Token Before =  those regions. such annotations can for instance be used to train machine learning algorithms for computer vision applications. this is a list of computer\n",
      "Cleaned Token After =  regions . annotations instance used train machine learning algorithms computer vision applications . list computer \n",
      "Cleaned Token After Stem =  region . annot instanc use train machin learn algorithm comput vision applic . list comput \n",
      "Cleaned Token Before =  scientist and statistician specializing in machine learning and known for her work in interpretable machine learning. she is the director of the prediction\n",
      "Cleaned Token After =  scientist statistician specializing machine learning known work interpretable machine learning . director prediction \n",
      "Cleaned Token After Stem =  scientist statistician special machin learn known work interpret machin learn . director predict \n",
      "Cleaned Token Before =  paul john werbos (born 1947) is an american social scientist and machine learning pioneer. he is best known for his 1974 dissertation, which first described\n",
      "Cleaned Token After =  paul john werbos ( born 1947 ) american social scientist machine learning pioneer . best known 1974 dissertation , first described \n",
      "Cleaned Token After Stem =  paul john werbo ( born 1947 ) american social scientist machin learn pioneer . best known 1974 dissert , first describ \n",
      "Cleaned Token Before =  mapped to vectors of real numbers . sentence embedding is used by the deep learning software libraries pytorch and tensorflow a way of testing sentence encodings\n",
      "Cleaned Token After =  mapped vectors real numbers . sentence embedding used deep learning software libraries pytorch tensorflow way testing sentence encodings \n",
      "Cleaned Token After Stem =  map vector real number . sentenc embed use deep learn softwar librari pytorch tensorflow way test sentenc encod \n",
      "Cleaned Token Before =  various machine learning paradigms, notably including deep learning, in recent overview articles. one fundamental principle of deep learning is to do\n",
      "Cleaned Token After =  various machine learning paradigms , notably including deep learning , recent overview articles . one fundamental principle deep learning \n",
      "Cleaned Token After Stem =  variou machin learn paradigm , notabl includ deep learn , recent overview articl . one fundament principl deep learn \n",
      "Cleaned Token Before =  isbn 978-0-9745607-2-4. retrieved 28 march 2020. mitchell, tom m. (1997). machine learning. wcb–mcgraw–hill. isbn 978-0-07-042807-2.. in particular see \"chapter\n",
      "Cleaned Token After =  isbn 978-0-9745607-2-4. retrieved 28 march 2020. mitchell , tom m. ( 1997 ) . machine learning . wcb–mcgraw–hill . isbn 978-0-07-042807-2 .. particular see `` chapter \n",
      "Cleaned Token After Stem =  isbn 978-0-9745607-2-4. retriev 28 march 2020. mitchel , tom m. ( 1997 ) . machin learn . wcb–mcgraw–hil . isbn 978-0-07-042807-2 .. particular see `` chapter \n",
      "Cleaned Token Before =  mapreduce - google's fundamental data filtering algorithm apache mahout - machine learning algorithms implemented on hadoop apache cassandra - a column-oriented\n",
      "Cleaned Token After =  mapreduce - google 's fundamental data filtering algorithm apache mahout - machine learning algorithms implemented hadoop apache cassandra - column-oriented \n",
      "Cleaned Token After Stem =  mapreduc - googl 's fundament data filter algorithm apach mahout - machin learn algorithm implement hadoop apach cassandra - column-ori \n",
      "Cleaned Token Before =  <2\\varepsilon } . machine learning data mining probably approximately correct learning adversarial machine learning valiant, l. g. (august 1985). learning disjunction\n",
      "Cleaned Token After =  < 2\\varepsilon } . machine learning data mining probably approximately correct learning adversarial machine learning valiant , l. g. ( august 1985 ) . learning disjunction \n",
      "Cleaned Token After Stem =  < 2\\varepsilon } . machin learn data mine probabl approxim correct learn adversari machin learn valiant , l. g. ( august 1985 ) . learn disjunct \n",
      "Cleaned Token Before =  and machines occur. the goal of this interaction is to allow effective operation and control of the machine from the human end, whilst the machine simultaneously\n",
      "Cleaned Token After =  machines occur . goal interaction allow effective operation control machine human end , whilst machine simultaneously \n",
      "Cleaned Token After Stem =  machin occur . goal interact allow effect oper control machin human end , whilst machin simultan \n",
      "Cleaned Token Before =  indian-origin couple pranoti nagarkar and rishi israni in 2008. rotimatic uses machine learning to make bread and takes about a minute to make one roti. it was first\n",
      "Cleaned Token After =  indian-origin couple pranoti nagarkar rishi israni 2008. rotimatic uses machine learning make bread takes minute make one roti . first \n",
      "Cleaned Token After Stem =  indian-origin coupl pranoti nagarkar rishi israni 2008. rotimat use machin learn make bread take minut make one roti . first \n",
      "Cleaned Token Before =  machine learning. she is most well-known for her work on automatically removing undesired biases concerning demographic groups from machine learning models\n",
      "Cleaned Token After =  machine learning . well-known work automatically removing undesired biases concerning demographic groups machine learning models \n",
      "Cleaned Token After Stem =  machin learn . well-known work automat remov undesir bias concern demograph group machin learn model \n",
      "Cleaned Token Before =   ming published research on ai in education and created ”muse”, a machine learning-based tool for parents. it recommends research-based activities to\n",
      "Cleaned Token After =  ming published research ai education created ” muse ” , machine learning-based tool parents . recommends research-based activities \n",
      "Cleaned Token After Stem =  ming publish research ai educ creat ” muse ” , machin learning-bas tool parent . recommend research-bas activ \n",
      "Cleaned Token Before =  g. stork is a scientist and author, who has made contributions to machine learning, pattern recognition, computer vision, artificial intelligence, computational\n",
      "Cleaned Token After =  g. stork scientist author , made contributions machine learning , pattern recognition , computer vision , artificial intelligence , computational \n",
      "Cleaned Token After Stem =  g. stork scientist author , made contribut machin learn , pattern recognit , comput vision , artifici intellig , comput \n",
      "Cleaned Token Before =  use of inexact solutions for otherwise extremely difficult problems: machine learning - automated creation of a set of rules and axioms based on input. evolutionary\n",
      "Cleaned Token After =  use inexact solutions otherwise extremely difficult problems : machine learning - automated creation set rules axioms based input . evolutionary \n",
      "Cleaned Token After Stem =  use inexact solut otherwis extrem difficult problem : machin learn - autom creation set rule axiom base input . evolutionari \n",
      "Cleaned Token Before =  and john shawe-taylor. an introduction to support vector machines and other kernel-based learning methods. cambridge university press, 2000. isbn 0-521-78019-5\n",
      "Cleaned Token After =  john shawe-taylor . introduction support vector machines kernel-based learning methods . cambridge university press , 2000. isbn 0-521-78019-5 \n",
      "Cleaned Token After Stem =  john shawe-taylor . introduct support vector machin kernel-bas learn method . cambridg univers press , 2000. isbn 0-521-78019-5 \n",
      "Cleaned Token Before =  reverse\". \"mit shows off machine-learning script to make creepy heads\". \"mit's gen programming system flattens the learning curve for ai projects\". venturebeat\n",
      "Cleaned Token After =  reverse '' . `` mit shows machine-learning script make creepy heads '' . `` mit 's gen programming system flattens learning curve ai projects '' . venturebeat \n",
      "Cleaned Token After Stem =  revers `` . `` mit show machine-learn script make creepi head `` . `` mit 's gen program system flatten learn curv ai project `` . venturebeat \n",
      "Cleaned Token Before =  surprise, disgust. different kinds of machine learning regression and classification models can be used for having machines produce continuous or discrete labels\n",
      "Cleaned Token After =  surprise , disgust . different kinds machine learning regression classification models used machines produce continuous discrete labels \n",
      "Cleaned Token After Stem =  surpris , disgust . differ kind machin learn regress classif model use machin produc continu discret label \n",
      "Cleaned Token Before =  develop and deliver certificate programs in artificial intelligence & machine learning, blockchain, fintech, and emerging tech. talentsprint was started by\n",
      "Cleaned Token After =  develop deliver certificate programs artificial intelligence & machine learning , blockchain , fintech , emerging tech . talentsprint started \n",
      "Cleaned Token After Stem =  develop deliv certif program artifici intellig & machin learn , blockchain , fintech , emerg tech . talentsprint start \n",
      "Cleaned Token Before =  database of small connected graphs image gallery: graphs at the wayback machine (archived february 6, 2006) concise, annotated list of graph theory resources\n",
      "Cleaned Token After =  database small connected graphs image gallery : graphs wayback machine ( archived february 6 , 2006 ) concise , annotated list graph theory resources \n",
      "Cleaned Token After Stem =  databas small connect graph imag galleri : graph wayback machin ( archiv februari 6 , 2006 ) concis , annot list graph theori resourc \n",
      "Cleaned Token Before =  passive learning is a method of learning or instruction where students receive information from the instructor and internalize it. it is a method \"where\n",
      "Cleaned Token After =  passive learning method learning instruction students receive information instructor internalize . method `` \n",
      "Cleaned Token After Stem =  passiv learn method learn instruct student receiv inform instructor intern . method `` \n",
      "Cleaned Token Before =  describes a research field concerned with the application of data mining, machine learning and statistics to information generated from educational settings (e\n",
      "Cleaned Token After =  describes research field concerned application data mining , machine learning statistics information generated educational settings ( e \n",
      "Cleaned Token After Stem =  describ research field concern applic data mine , machin learn statist inform gener educ set ( e \n",
      "Cleaned Token Before =  applications. its creators distribute a python machine learning toolkit called divisi for performing machine learning based on text corpora, structured knowledge\n",
      "Cleaned Token After =  applications . creators distribute python machine learning toolkit called divisi performing machine learning based text corpora , structured knowledge \n",
      "Cleaned Token After Stem =  applic . creator distribut python machin learn toolkit call divisi perform machin learn base text corpora , structur knowledg \n",
      "Cleaned Token Before =  allow lifelong and open-ended learning of new skills and new knowledge in embodied machines. as in human children, learning is expected to be cumulative\n",
      "Cleaned Token After =  allow lifelong open-ended learning new skills new knowledge embodied machines . human children , learning expected cumulative \n",
      "Cleaned Token After Stem =  allow lifelong open-end learn new skill new knowledg embodi machin . human children , learn expect cumul \n",
      "Cleaned Token Before =  developing machine learning methods for protein structure prediction. king's research interests are in the automation of science, drug design, ai, machine learning\n",
      "Cleaned Token After =  developing machine learning methods protein structure prediction . king 's research interests automation science , drug design , ai , machine learning \n",
      "Cleaned Token After Stem =  develop machin learn method protein structur predict . king 's research interest autom scienc , drug design , ai , machin learn \n",
      "Cleaned Token Before =  probability has applications to statistics as well as machine learning as part of statistical learning theory. the law of large numbers says that, for each\n",
      "Cleaned Token After =  probability applications statistics well machine learning part statistical learning theory . law large numbers says , \n",
      "Cleaned Token After Stem =  probabl applic statist well machin learn part statist learn theori . law larg number say , \n",
      "Cleaned Token Before =  lamda group. his research interests include artificial intelligence, machine learning and data mining. zhou zhi-hua received his b.sc., m.sc. and ph.d. degrees\n",
      "Cleaned Token After =  lamda group . research interests include artificial intelligence , machine learning data mining . zhou zhi-hua received b.sc. , m.sc . ph.d. degrees \n",
      "Cleaned Token After Stem =  lamda group . research interest includ artifici intellig , machin learn data mine . zhou zhi-hua receiv b.sc . , m.sc . ph.d. degre \n",
      "Cleaned Token Before =  names: authors list (link) \"oppo announces bright coloros 6.0 with machine learning and new font\". gsmarena.com. retrieved 2018-11-29. delhinovember 5\n",
      "Cleaned Token After =  names : authors list ( link ) `` oppo announces bright coloros 6.0 machine learning new font '' . gsmarena.com . retrieved 2018-11-29. delhinovember 5 \n",
      "Cleaned Token After Stem =  name : author list ( link ) `` oppo announc bright coloro 6.0 machin learn new font `` . gsmarena.com . retriev 2018-11-29. delhinovemb 5 \n",
      "Cleaned Token Before =  (in performance, portability, or—especially—functionality) feature (machine learning), in statistics: individual measurable properties of the phenomena\n",
      "Cleaned Token After =  ( performance , portability , or—especially—functionality ) feature ( machine learning ) , statistics : individual measurable properties phenomena \n",
      "Cleaned Token After Stem =  ( perform , portabl , or—especially—function ) featur ( machin learn ) , statist : individu measur properti phenomena \n",
      "Cleaned Token Before =  and fail-safe n analysis. machine learning: machine learning module contains 13 analyses for supervised an unsupervised learning: regression boosting regression\n",
      "Cleaned Token After =  fail-safe n analysis . machine learning : machine learning module contains 13 analyses supervised unsupervised learning : regression boosting regression \n",
      "Cleaned Token After Stem =  fail-saf n analysi . machin learn : machin learn modul contain 13 analys supervis unsupervis learn : regress boost regress \n",
      "Cleaned Token Before =  the hyperplane separation theorem. in machine learning, hyperplanes are a key tool to create support vector machines for such tasks as computer vision and\n",
      "Cleaned Token After =  hyperplane separation theorem . machine learning , hyperplanes key tool create support vector machines tasks computer vision \n",
      "Cleaned Token After Stem =  hyperplan separ theorem . machin learn , hyperplan key tool creat support vector machin task comput vision \n",
      "Cleaned Token Before =  work in face and object recognition and his contributions to quantum machine learning. he is currently senior director of engineering and distinguished scientist\n",
      "Cleaned Token After =  work face object recognition contributions quantum machine learning . currently senior director engineering distinguished scientist \n",
      "Cleaned Token After Stem =  work face object recognit contribut quantum machin learn . current senior director engin distinguish scientist \n",
      "Cleaned Token Before =  science at the university of california san diego who mainly works on machine learning, probability theory and related fields and applications. he is best\n",
      "Cleaned Token After =  science university california san diego mainly works machine learning , probability theory related fields applications . best \n",
      "Cleaned Token After Stem =  scienc univers california san diego mainli work machin learn , probabl theori relat field applic . best \n",
      "Cleaned Token Before =   10% of patents pertain to machine-learning algorithms for detecting malware and other online threats, with deep learning and anomaly-based detection\n",
      "Cleaned Token After =  10 % patents pertain machine-learning algorithms detecting malware online threats , deep learning anomaly-based detection \n",
      "Cleaned Token After Stem =  10 % patent pertain machine-learn algorithm detect malwar onlin threat , deep learn anomaly-bas detect \n",
      "Cleaned Token Before =  was leading their ai efforts, left to pursue a venture in applying machine learning techniques to drug design. verily human longevity \"the brains behind\n",
      "Cleaned Token After =  leading ai efforts , left pursue venture applying machine learning techniques drug design . verily human longevity `` brains behind \n",
      "Cleaned Token After Stem =  lead ai effort , left pursu ventur appli machin learn techniqu drug design . verili human longev `` brain behind \n",
      "Cleaned Token Before =  technology such as x.509 for cybersecurity, y.3172 and y.3173 for machine learning, and h.264/mpeg-4 avc for video compression, between its member states\n",
      "Cleaned Token After =  technology x.509 cybersecurity , y.3172 y.3173 machine learning , h.264/mpeg-4 avc video compression , member states \n",
      "Cleaned Token After Stem =  technolog x.509 cybersecur , y.3172 y.3173 machin learn , h.264/mpeg-4 avc video compress , member state \n",
      "Cleaned Token Before =  identified undergo automatic quality evaluation by a human-trained machine learning algorithm that estimates the quality of translation. the user can set\n",
      "Cleaned Token After =  identified undergo automatic quality evaluation human-trained machine learning algorithm estimates quality translation . user set \n",
      "Cleaned Token After Stem =  identifi undergo automat qualiti evalu human-train machin learn algorithm estim qualiti translat . user set \n",
      "Cleaned Token Before =  on the assumption that the data come from a larger population. in machine learning, the term inference is sometimes used instead to mean \"make a prediction\n",
      "Cleaned Token After =  assumption data come larger population . machine learning , term inference sometimes used instead mean `` make prediction \n",
      "Cleaned Token After Stem =  assumpt data come larger popul . machin learn , term infer sometim use instead mean `` make predict \n",
      "Cleaned Token Before =  technology) and presagen (health technology). the australian institute for machine learning (aml), an artificial intelligence research institute created collaboratively\n",
      "Cleaned Token After =  technology ) presagen ( health technology ) . australian institute machine learning ( aml ) , artificial intelligence research institute created collaboratively \n",
      "Cleaned Token After Stem =  technolog ) presagen ( health technolog ) . australian institut machin learn ( aml ) , artifici intellig research institut creat collabor \n",
      "Cleaned Token Before =  and domain knowledge. they developed a density-based unsupervised machine learning model to detect anomalies within an enterprise application, based upon\n",
      "Cleaned Token After =  domain knowledge . developed density-based unsupervised machine learning model detect anomalies within enterprise application , based upon \n",
      "Cleaned Token After Stem =  domain knowledg . develop density-bas unsupervis machin learn model detect anomali within enterpris applic , base upon \n",
      "Cleaned Token Before =  is a computer scientist at ibm watson health with contributions to machine learning, data mining, and classification. ho is noted for introducing random\n",
      "Cleaned Token After =  computer scientist ibm watson health contributions machine learning , data mining , classification . ho noted introducing random \n",
      "Cleaned Token After Stem =  comput scientist ibm watson health contribut machin learn , data mine , classif . ho note introduc random \n",
      "Cleaned Token Before =  neural modeling field (nmf) is a mathematical framework for machine learning which combines ideas from neural networks, fuzzy logic, and model based recognition\n",
      "Cleaned Token After =  neural modeling field ( nmf ) mathematical framework machine learning combines ideas neural networks , fuzzy logic , model based recognition \n",
      "Cleaned Token After Stem =  neural model field ( nmf ) mathemat framework machin learn combin idea neural network , fuzzi logic , model base recognit \n",
      "Cleaned Token Before =  in education, authentic learning is an instructional approach that allows students to explore, discuss, and meaningfully construct concepts and relationships\n",
      "Cleaned Token After =  education , authentic learning instructional approach allows students explore , discuss , meaningfully construct concepts relationships \n",
      "Cleaned Token After Stem =  educ , authent learn instruct approach allow student explor , discuss , meaning construct concept relationship \n",
      "Cleaned Token Before =  university of waterloo. he is known for his research in theoretical machine learning. shai ben-david grew up in jerusalem, israel and received a ph.d. in\n",
      "Cleaned Token After =  university waterloo . known research theoretical machine learning . shai ben-david grew jerusalem , israel received ph.d. \n",
      "Cleaned Token After Stem =  univers waterloo . known research theoret machin learn . shai ben-david grew jerusalem , israel receiv ph.d . \n",
      "Cleaned Token Before =  are especially useful to derive statistical pattern recognition and machine learning algorithms. one popular example of an algorithm that assumes homoscedasticity\n",
      "Cleaned Token After =  especially useful derive statistical pattern recognition machine learning algorithms . one popular example algorithm assumes homoscedasticity \n",
      "Cleaned Token After Stem =  especi use deriv statist pattern recognit machin learn algorithm . one popular exampl algorithm assum homoscedast \n",
      "Cleaned Token Before =  professor of computer science at harvard university. she works on machine learning, computational statistics and healthcare. doshi-velez studied aerospace\n",
      "Cleaned Token After =  professor computer science harvard university . works machine learning , computational statistics healthcare . doshi-velez studied aerospace \n",
      "Cleaned Token After Stem =  professor comput scienc harvard univers . work machin learn , comput statist healthcar . doshi-velez studi aerospac \n",
      "Cleaned Token Before =  tool to use to also calculate churn. in recent years, using ai and machine-learning as a means to calculate customer churn has become increasingly common\n",
      "Cleaned Token After =  tool use also calculate churn . recent years , using ai machine-learning means calculate customer churn become increasingly common \n",
      "Cleaned Token After Stem =  tool use also calcul churn . recent year , use ai machine-learn mean calcul custom churn becom increasingli common \n",
      "Cleaned Token Before =  alexandre; cournapeau, david (2011). \"scikit-learn: machine learning in python\". journal of machine learning research. 12: 2825–2830. arxiv:1201.0490. \"is quora\n",
      "Cleaned Token After =  alexandre ; cournapeau , david ( 2011 ) . `` scikit-learn : machine learning python '' . journal machine learning research . 12 : 2825–2830 . arxiv:1201.0490 . `` quora \n",
      "Cleaned Token After Stem =  alexandr ; cournapeau , david ( 2011 ) . `` scikit-learn : machin learn python `` . journal machin learn research . 12 : 2825–2830 . arxiv:1201.0490 . `` quora \n",
      "Cleaned Token Before =  recording, google clips automatically captures video clips at moments its machine learning algorithms determine to be interesting or relevant. it has a built-in\n",
      "Cleaned Token After =  recording , google clips automatically captures video clips moments machine learning algorithms determine interesting relevant . built-in \n",
      "Cleaned Token After Stem =  record , googl clip automat captur video clip moment machin learn algorithm determin interest relev . built-in \n",
      "Cleaned Token Before =  functional programming language .ml, the top-level internet domain for mali machine learning, a field of computer science markup language, a system for annotating\n",
      "Cleaned Token After =  functional programming language .ml , top-level internet domain mali machine learning , field computer science markup language , system annotating \n",
      "Cleaned Token After Stem =  function program languag .ml , top-level internet domain mali machin learn , field comput scienc markup languag , system annot \n",
      "Cleaned Token Before =  for the competition are selected from the tptp library. automated machine learning (automl) automated theorem proving reasoning system semantic reasoner\n",
      "Cleaned Token After =  competition selected tptp library . automated machine learning ( automl ) automated theorem proving reasoning system semantic reasoner \n",
      "Cleaned Token After Stem =  competit select tptp librari . autom machin learn ( automl ) autom theorem prove reason system semant reason \n",
      "Cleaned Token Before =  a vending machine is an automated machine that provides items such as snacks, beverages, cigarettes and lottery tickets to consumers after cash, a credit\n",
      "Cleaned Token After =  vending machine automated machine provides items snacks , beverages , cigarettes lottery tickets consumers cash , credit \n",
      "Cleaned Token After Stem =  vend machin autom machin provid item snack , beverag , cigarett lotteri ticket consum cash , credit \n",
      "Cleaned Token Before =  can revert edits, often within minutes, if not seconds. the bot uses machine learning in lieu of heuristics. the amount of vandalism a wiki receives depends\n",
      "Cleaned Token After =  revert edits , often within minutes , seconds . bot uses machine learning lieu heuristics . amount vandalism wiki receives depends \n",
      "Cleaned Token After Stem =  revert edit , often within minut , second . bot use machin learn lieu heurist . amount vandal wiki receiv depend \n",
      "Cleaned Token Before =  merging, dna analysis, rna analysis, image analysis, evidence-based machine learning, database data deduplication, data mining, incremental search, data\n",
      "Cleaned Token After =  merging , dna analysis , rna analysis , image analysis , evidence-based machine learning , database data deduplication , data mining , incremental search , data \n",
      "Cleaned Token After Stem =  merg , dna analysi , rna analysi , imag analysi , evidence-bas machin learn , databas data dedupl , data mine , increment search , data \n",
      "Cleaned Token Before =  adaptive learning, also known as adaptive teaching, is an educational method which uses computer algorithms to orchestrate the interaction with the learner\n",
      "Cleaned Token After =  adaptive learning , also known adaptive teaching , educational method uses computer algorithms orchestrate interaction learner \n",
      "Cleaned Token After Stem =  adapt learn , also known adapt teach , educ method use comput algorithm orchestr interact learner \n",
      "Cleaned Token Before =  traditional machine learning approaches for text classification, a human expert is required to label phrases or entire notes, and then a supervised learning algorithm\n",
      "Cleaned Token After =  traditional machine learning approaches text classification , human expert required label phrases entire notes , supervised learning algorithm \n",
      "Cleaned Token After Stem =  tradit machin learn approach text classif , human expert requir label phrase entir note , supervis learn algorithm \n",
      "Cleaned Token Before =  friis and salesforce.com ceo marc benioff. vicarious is developing machine learning software based on the computational principles of the human brain.\n",
      "Cleaned Token After =  friis salesforce.com ceo marc benioff . vicarious developing machine learning software based computational principles human brain . \n",
      "Cleaned Token After Stem =  frii salesforce.com ceo marc benioff . vicari develop machin learn softwar base comput principl human brain . \n",
      "Cleaned Token Before =  purposes. for example, machine learning systems may use inductive reasoning to generate hypotheses for observed facts. learning systems search for generalised\n",
      "Cleaned Token After =  purposes . example , machine learning systems may use inductive reasoning generate hypotheses observed facts . learning systems search generalised \n",
      "Cleaned Token After Stem =  purpos . exampl , machin learn system may use induct reason gener hypothes observ fact . learn system search generalis \n",
      "Cleaned Token Before =  entries are then filtered from the candidate list using statistical and machine learning methods. once filtered, because of their low ambiguity and high specificity\n",
      "Cleaned Token After =  entries filtered candidate list using statistical machine learning methods . filtered , low ambiguity high specificity \n",
      "Cleaned Token After Stem =  entri filter candid list use statist machin learn method . filter , low ambigu high specif \n",
      "Cleaned Token Before =  theory an air classifier or similar machine for sorting materials classifier (machine learning) finite-state machine#classifiers classification (disambiguation)\n",
      "Cleaned Token After =  theory air classifier similar machine sorting materials classifier ( machine learning ) finite-state machine # classifiers classification ( disambiguation ) \n",
      "Cleaned Token After Stem =  theori air classifi similar machin sort materi classifi ( machin learn ) finite-st machin # classifi classif ( disambigu ) \n",
      "Cleaned Token Before =  inferential theory of learning (itl) is an area of machine learning which describes inferential processes performed by learning agents. itl has been continuously\n",
      "Cleaned Token After =  inferential theory learning ( itl ) area machine learning describes inferential processes performed learning agents . itl continuously \n",
      "Cleaned Token After Stem =  inferenti theori learn ( itl ) area machin learn describ inferenti process perform learn agent . itl continu \n",
      "Cleaned Token Before =  averaging (machine learning) distribution ensemble or probability ensemble (cryptography) ensemble learning (statistics and machine learning) neural ensemble\n",
      "Cleaned Token After =  averaging ( machine learning ) distribution ensemble probability ensemble ( cryptography ) ensemble learning ( statistics machine learning ) neural ensemble \n",
      "Cleaned Token After Stem =  averag ( machin learn ) distribut ensembl probabl ensembl ( cryptographi ) ensembl learn ( statist machin learn ) neural ensembl \n",
      "Cleaned Token Before =  free lunch. wolpert had previously derived no free lunch theorems for machine learning (statistical inference). before wolpert's article was published, cullen\n",
      "Cleaned Token After =  free lunch . wolpert previously derived free lunch theorems machine learning ( statistical inference ) . wolpert 's article published , cullen \n",
      "Cleaned Token After Stem =  free lunch . wolpert previous deriv free lunch theorem machin learn ( statist infer ) . wolpert 's articl publish , cullen \n",
      "Cleaned Token Before =  pieces them together to form words and sentences. wavenet instead uses machine learning to generate speech. it then waveforms from a database of human speech\n",
      "Cleaned Token After =  pieces together form words sentences . wavenet instead uses machine learning generate speech . waveforms database human speech \n",
      "Cleaned Token After Stem =  piec togeth form word sentenc . wavenet instead use machin learn gener speech . waveform databas human speech \n",
      "Cleaned Token Before =  individual sentences using rule/pattern-based information extraction and machine learning approaches. a wide variety of text mining applications for ppi extraction\n",
      "Cleaned Token After =  individual sentences using rule/pattern-based information extraction machine learning approaches . wide variety text mining applications ppi extraction \n",
      "Cleaned Token After Stem =  individu sentenc use rule/pattern-bas inform extract machin learn approach . wide varieti text mine applic ppi extract \n",
      "Cleaned Token Before =  of x (such as customer, risk, patient), and advanced analytics and machine learning (such as next best action and realtime cybersecurity). hortonworks\n",
      "Cleaned Token After =  x ( customer , risk , patient ) , advanced analytics machine learning ( next best action realtime cybersecurity ) . hortonworks \n",
      "Cleaned Token After Stem =  x ( custom , risk , patient ) , advanc analyt machin learn ( next best action realtim cybersecur ) . hortonwork \n",
      "Cleaned Token Before =  arm claims the cortex-x1 offers 30% faster integer and 100% faster machine learning performance than the arm cortex-a77. the cortex-x1 supports arm's dynamiq\n",
      "Cleaned Token After =  arm claims cortex-x1 offers 30 % faster integer 100 % faster machine learning performance arm cortex-a77 . cortex-x1 supports arm 's dynamiq \n",
      "Cleaned Token After Stem =  arm claim cortex-x1 offer 30 % faster integ 100 % faster machin learn perform arm cortex-a77 . cortex-x1 support arm 's dynamiq \n",
      "Cleaned Token Before =  power analysis (spa) and differential power analysis (dpa). example of machine learning approaches are in. fluctuations in current also generate radio waves\n",
      "Cleaned Token After =  power analysis ( spa ) differential power analysis ( dpa ) . example machine learning approaches . fluctuations current also generate radio waves \n",
      "Cleaned Token After Stem =  power analysi ( spa ) differenti power analysi ( dpa ) . exampl machin learn approach . fluctuat current also gener radio wave \n",
      "Cleaned Token Before =  natural language processing (specifically machine reading comprehension), deep learning and reinforcement learning. microsoft research silicon valley, located\n",
      "Cleaned Token After =  natural language processing ( specifically machine reading comprehension ) , deep learning reinforcement learning . microsoft research silicon valley , located \n",
      "Cleaned Token After Stem =  natur languag process ( specif machin read comprehens ) , deep learn reinforc learn . microsoft research silicon valley , locat \n",
      "Cleaned Token Before =  automated machine learning, or automl, technology, which extends the automation of model building towards automation of the full life cycle of a machine learning\n",
      "Cleaned Token After =  automated machine learning , automl , technology , extends automation model building towards automation full life cycle machine learning \n",
      "Cleaned Token After Stem =  autom machin learn , automl , technolog , extend autom model build toward autom full life cycl machin learn \n",
      "Cleaned Token Before =  zachary lipton (born 1985) is a machine learning researcher and jazz saxophonist from new rochelle, new york. he is currently an assistant professor of\n",
      "Cleaned Token After =  zachary lipton ( born 1985 ) machine learning researcher jazz saxophonist new rochelle , new york . currently assistant professor \n",
      "Cleaned Token After Stem =  zachari lipton ( born 1985 ) machin learn research jazz saxophonist new rochel , new york . current assist professor \n",
      "Cleaned Token Before =  perlis symposium in april 2001: \"from statistics to chat: trends in machine learning\". she is a member of the association for computing machinery and the\n",
      "Cleaned Token After =  perlis symposium april 2001 : `` statistics chat : trends machine learning '' . member association computing machinery \n",
      "Cleaned Token After Stem =  perli symposium april 2001 : `` statist chat : trend machin learn `` . member associ comput machineri \n",
      "Cleaned Token Before =  defined in many ways: the capacity for logic, understanding, self-awareness, learning, emotional knowledge, reasoning, planning, creativity, critical thinking\n",
      "Cleaned Token After =  defined many ways : capacity logic , understanding , self-awareness , learning , emotional knowledge , reasoning , planning , creativity , critical thinking \n",
      "Cleaned Token After Stem =  defin mani way : capac logic , understand , self-awar , learn , emot knowledg , reason , plan , creativ , critic think \n",
      "Cleaned Token Before =  from natural language processing and machine learning such as latent semantic analysis, support vector machines, \"bag of words\" among other techniques\n",
      "Cleaned Token After =  natural language processing machine learning latent semantic analysis , support vector machines , `` bag words '' among techniques \n",
      "Cleaned Token After Stem =  natur languag process machin learn latent semant analysi , support vector machin , `` bag word `` among techniqu \n",
      "Cleaned Token Before =   quantitative psychology, machine learning, artificial neural networks, artificial intelligence and computational learning theory; although mutual inspiration\n",
      "Cleaned Token After =  quantitative psychology , machine learning , artificial neural networks , artificial intelligence computational learning theory ; although mutual inspiration \n",
      "Cleaned Token After Stem =  quantit psycholog , machin learn , artifici neural network , artifici intellig comput learn theori ; although mutual inspir \n",
      "Cleaned Token Before =  in association with the call for papers for a aaai summer symposium machine learning of natural language and ontology, with an expanded version published\n",
      "Cleaned Token After =  association call papers aaai summer symposium machine learning natural language ontology , expanded version published \n",
      "Cleaned Token After Stem =  associ call paper aaai summer symposium machin learn natur languag ontolog , expand version publish \n",
      "Cleaned Token Before =  result in a positive bias towards randomness. global optimization machine learning scenario optimization gaussian process state space model model predictive\n",
      "Cleaned Token After =  result positive bias towards randomness . global optimization machine learning scenario optimization gaussian process state space model model predictive \n",
      "Cleaned Token After Stem =  result posit bia toward random . global optim machin learn scenario optim gaussian process state space model model predict \n",
      "Cleaned Token Before =  jurimetrics is the application of probability and statistics to law. machine learning is the subfield of computer science that formulates algorithms in order\n",
      "Cleaned Token After =  jurimetrics application probability statistics law . machine learning subfield computer science formulates algorithms order \n",
      "Cleaned Token After Stem =  jurimetr applic probabl statist law . machin learn subfield comput scienc formul algorithm order \n",
      "Cleaned Token Before =  parts of the above proposal. for instance, machine learning, beginning with turing's infamous child machine proposal essentially achieves the desired feature\n",
      "Cleaned Token After =  parts proposal . instance , machine learning , beginning turing 's infamous child machine proposal essentially achieves desired feature \n",
      "Cleaned Token After Stem =  part propos . instanc , machin learn , begin ture 's infam child machin propos essenti achiev desir featur \n",
      "Cleaned Token Before =  of computational medicine, where her research focuses on developing machine-learning algorithms to inform health-care decisions. she is currently an assistant\n",
      "Cleaned Token After =  computational medicine , research focuses developing machine-learning algorithms inform health-care decisions . currently assistant \n",
      "Cleaned Token After Stem =  comput medicin , research focus develop machine-learn algorithm inform health-car decis . current assist \n",
      "Cleaned Token Before =  openml may refer to: openml (open machine learning), an open science online platform for machine learning, which holds open data, open algorithms and\n",
      "Cleaned Token After =  openml may refer : openml ( open machine learning ) , open science online platform machine learning , holds open data , open algorithms \n",
      "Cleaned Token After Stem =  openml may refer : openml ( open machin learn ) , open scienc onlin platform machin learn , hold open data , open algorithm \n",
      "Cleaned Token Before =  a committee machine is a type of artificial neural network using a divide and conquer strategy in which the responses of multiple neural networks (experts)\n",
      "Cleaned Token After =  committee machine type artificial neural network using divide conquer strategy responses multiple neural networks ( experts ) \n",
      "Cleaned Token After Stem =  committe machin type artifici neural network use divid conquer strategi respons multipl neural network ( expert ) \n",
      "Cleaned Token Before =  action’ at record distance, science magazine physicists extend quantum machine learning to infinite dimensions, phys.org engineering physics, embry-riddle\n",
      "Cleaned Token After =  action ’ record distance , science magazine physicists extend quantum machine learning infinite dimensions , phys.org engineering physics , embry-riddle \n",
      "Cleaned Token After Stem =  action ’ record distanc , scienc magazin physicist extend quantum machin learn infinit dimens , phys.org engin physic , embry-riddl \n",
      "Cleaned Token Before =  computer science research. michie was honoured for his contribution to machine learning research, and was twice commissioned to program a menace simulation\n",
      "Cleaned Token After =  computer science research . michie honoured contribution machine learning research , twice commissioned program menace simulation \n",
      "Cleaned Token After Stem =  comput scienc research . michi honour contribut machin learn research , twice commiss program menac simul \n",
      "Cleaned Token Before =  studied us federal agencies have experimented with ai and related machine learning (ml) tools up to 2020. us federal agencies counted the following number\n",
      "Cleaned Token After =  studied us federal agencies experimented ai related machine learning ( ml ) tools 2020. us federal agencies counted following number \n",
      "Cleaned Token After Stem =  studi us feder agenc experi ai relat machin learn ( ml ) tool 2020. us feder agenc count follow number \n",
      "Cleaned Token Before =  servant. on april 10, 2020, muller released his debut soundtrack album, machine learning experiments (original soundtrack), which featured original scores composed\n",
      "Cleaned Token After =  servant . april 10 , 2020 , muller released debut soundtrack album , machine learning experiments ( original soundtrack ) , featured original scores composed \n",
      "Cleaned Token After Stem =  servant . april 10 , 2020 , muller releas debut soundtrack album , machin learn experi ( origin soundtrack ) , featur origin score compos \n",
      "Cleaned Token Before =  such as robotic process automation (rpa), artificial intelligence/machine learning (ai/ml), software defined networks/network function virtualization\n",
      "Cleaned Token After =  robotic process automation ( rpa ) , artificial intelligence/machine learning ( ai/ml ) , software defined networks/network function virtualization \n",
      "Cleaned Token After Stem =  robot process autom ( rpa ) , artifici intelligence/machin learn ( ai/ml ) , softwar defin networks/network function virtual \n",
      "Cleaned Token Before =  corpus was used as a standardized baseline. comparison of datasets in machine learning fisher, william m.; doddington, george r.; goudie-marshall, kathleen\n",
      "Cleaned Token After =  corpus used standardized baseline . comparison datasets machine learning fisher , william m. ; doddington , george r. ; goudie-marshall , kathleen \n",
      "Cleaned Token After Stem =  corpu use standard baselin . comparison dataset machin learn fisher , william m. ; doddington , georg r. ; goudie-marshal , kathleen \n",
      "Cleaned Token Before =  inc. in june 2018, it launched a seed fund for startups \"applying machine learning to health.\" in october 2018, the firm raised its largest fund, its\n",
      "Cleaned Token After =  inc. june 2018 , launched seed fund startups `` applying machine learning health . '' october 2018 , firm raised largest fund , \n",
      "Cleaned Token After Stem =  inc. june 2018 , launch seed fund startup `` appli machin learn health . `` octob 2018 , firm rais largest fund , \n",
      "Cleaned Token Before =  university of massachusetts amherst. his primary specialties are in machine learning, natural language processing, information extraction, information integration\n",
      "Cleaned Token After =  university massachusetts amherst . primary specialties machine learning , natural language processing , information extraction , information integration \n",
      "Cleaned Token After Stem =  univers massachusett amherst . primari specialti machin learn , natur languag process , inform extract , inform integr \n",
      "Cleaned Token Before =  at carnegie mellon university, where she was previously head of the machine learning department. she served as president of association for the advancement\n",
      "Cleaned Token After =  carnegie mellon university , previously head machine learning department . served president association advancement \n",
      "Cleaned Token After Stem =  carnegi mellon univers , previous head machin learn depart . serv presid associ advanc \n",
      "Cleaned Token Before =  artwork neural gas learning vector quantization liquid state machine hybrid kohonen som sparse coding sparse distributed memory deep learning neocognitron topological\n",
      "Cleaned Token After =  artwork neural gas learning vector quantization liquid state machine hybrid kohonen som sparse coding sparse distributed memory deep learning neocognitron topological \n",
      "Cleaned Token After Stem =  artwork neural ga learn vector quantiz liquid state machin hybrid kohonen som spars code spars distribut memori deep learn neocognitron topolog \n",
      "Cleaned Token Before =  company and laserlike inc., an interest search engine startup based on machine learning. at google, mountain view, he led a team developing google news, a\n",
      "Cleaned Token After =  company laserlike inc. , interest search engine startup based machine learning . google , mountain view , led team developing google news , \n",
      "Cleaned Token After Stem =  compani laserlik inc. , interest search engin startup base machin learn . googl , mountain view , led team develop googl news , \n",
      "Cleaned Token Before =  of learning; he concluded it was only possible to learn something one nearly already knows.[citation needed] his research interests included machine learning\n",
      "Cleaned Token After =  learning ; concluded possible learn something one nearly already knows . [ citation needed ] research interests included machine learning \n",
      "Cleaned Token After Stem =  learn ; conclud possibl learn someth one nearli alreadi know . [ citat need ] research interest includ machin learn \n",
      "Cleaned Token Before =  in machine learning, a nearest centroid classifier or nearest prototype classifier is a classification model that assigns to observations the label of\n",
      "Cleaned Token After =  machine learning , nearest centroid classifier nearest prototype classifier classification model assigns observations label \n",
      "Cleaned Token After Stem =  machin learn , nearest centroid classifi nearest prototyp classifi classif model assign observ label \n",
      "Cleaned Token Before =  german computer scientist. since 2018 he has led the institute for machine learning at the johannes kepler university of linz after having led the institute\n",
      "Cleaned Token After =  german computer scientist . since 2018 led institute machine learning johannes kepler university linz led institute \n",
      "Cleaned Token After Stem =  german comput scientist . sinc 2018 led institut machin learn johann kepler univers linz led institut \n",
      "Cleaned Token Before =  type of aircraft. today, the phenomenon plays an important role in machine learning and data science, where the corresponding methods are known as anomaly\n",
      "Cleaned Token After =  type aircraft . today , phenomenon plays important role machine learning data science , corresponding methods known anomaly \n",
      "Cleaned Token After Stem =  type aircraft . today , phenomenon play import role machin learn data scienc , correspond method known anomali \n",
      "Cleaned Token Before =  a tsetlin machine is an artificial intelligence algorithm based on propositional logic. a tsetlin machine is a form of learning automaton based upon algorithms\n",
      "Cleaned Token After =  tsetlin machine artificial intelligence algorithm based propositional logic . tsetlin machine form learning automaton based upon algorithms \n",
      "Cleaned Token After Stem =  tsetlin machin artifici intellig algorithm base proposit logic . tsetlin machin form learn automaton base upon algorithm \n",
      "Cleaned Token Before =  the possible techniques is to apply active learning (machine learning). the main goal of active learning is to guide the user in the preference elicitation\n",
      "Cleaned Token After =  possible techniques apply active learning ( machine learning ) . main goal active learning guide user preference elicitation \n",
      "Cleaned Token After Stem =  possibl techniqu appli activ learn ( machin learn ) . main goal activ learn guid user prefer elicit \n",
      "Cleaned Token Before =  hily is an online dating application that employs machine learning to match prospective partners. named as an acronym for \"hey, i like you\", the app is\n",
      "Cleaned Token After =  hily online dating application employs machine learning match prospective partners . named acronym `` hey , like '' , app \n",
      "Cleaned Token After Stem =  hili onlin date applic employ machin learn match prospect partner . name acronym `` hey , like `` , app \n",
      "Cleaned Token Before =  cognitive science, artificial intelligence, information retrieval, and machine learning. nltk has been used successfully as a teaching tool, as an individual\n",
      "Cleaned Token After =  cognitive science , artificial intelligence , information retrieval , machine learning . nltk used successfully teaching tool , individual \n",
      "Cleaned Token After Stem =  cognit scienc , artifici intellig , inform retriev , machin learn . nltk use success teach tool , individu \n",
      "Cleaned Token Before =  land languages laws life livers logistics lubricants machine learning and knowledge extraction machines magnetochemistry marine drugs materials mathematical\n",
      "Cleaned Token After =  land languages laws life livers logistics lubricants machine learning knowledge extraction machines magnetochemistry marine drugs materials mathematical \n",
      "Cleaned Token After Stem =  land languag law life liver logist lubric machin learn knowledg extract machin magnetochemistri marin drug materi mathemat \n",
      "Cleaned Token Before =  computer science such as theory of computation, numerical methods, machine learning, programming theory and paradigms. modern academic programs also cover\n",
      "Cleaned Token After =  computer science theory computation , numerical methods , machine learning , programming theory paradigms . modern academic programs also cover \n",
      "Cleaned Token After Stem =  comput scienc theori comput , numer method , machin learn , program theori paradigm . modern academ program also cover \n",
      "Cleaned Token Before =  such as machine learning, privacy evaluation and privacy-preserving systems: machine learning: troncoso studies the impact of machine learning algorithms\n",
      "Cleaned Token After =  machine learning , privacy evaluation privacy-preserving systems : machine learning : troncoso studies impact machine learning algorithms \n",
      "Cleaned Token After Stem =  machin learn , privaci evalu privacy-preserv system : machin learn : troncoso studi impact machin learn algorithm \n",
      "Cleaned Token Before =  back-propagation in multi-layer perceptrons the tool of choice for many machine learning tasks. one also can use a series of independent neural networks moderated\n",
      "Cleaned Token After =  back-propagation multi-layer perceptrons tool choice many machine learning tasks . one also use series independent neural networks moderated \n",
      "Cleaned Token After Stem =  back-propag multi-lay perceptron tool choic mani machin learn task . one also use seri independ neural network moder \n",
      "Cleaned Token Before =  of generalized linear models); and \"machine learning\" methods such as maximum entropy (maxent). ten machine learning algorithms used in sdm can be seen\n",
      "Cleaned Token After =  generalized linear models ) ; `` machine learning '' methods maximum entropy ( maxent ) . ten machine learning algorithms used sdm seen \n",
      "Cleaned Token After Stem =  gener linear model ) ; `` machin learn `` method maximum entropi ( maxent ) . ten machin learn algorithm use sdm seen \n",
      "Cleaned Token Before =  like neural networks, bayesian probability, fuzzy logic, machine learning, reinforcement learning, evolutionary computation and genetic algorithms. intelligent\n",
      "Cleaned Token After =  like neural networks , bayesian probability , fuzzy logic , machine learning , reinforcement learning , evolutionary computation genetic algorithms . intelligent \n",
      "Cleaned Token After Stem =  like neural network , bayesian probabl , fuzzi logic , machin learn , reinforc learn , evolutionari comput genet algorithm . intellig \n",
      "Cleaned Token Before =  used the term in its game-theoretic sense in his seminal paper on machine learning in checkers in 1959, but with a slightly different meaning: the \"ply\"\n",
      "Cleaned Token After =  used term game-theoretic sense seminal paper machine learning checkers 1959 , slightly different meaning : `` ply '' \n",
      "Cleaned Token After Stem =  use term game-theoret sens semin paper machin learn checker 1959 , slightli differ mean : `` pli `` \n",
      "Cleaned Token Before =  for automatic plant identification through photographs and based on machine learning. this project launched in 2009 has been developed by scientists (computer\n",
      "Cleaned Token After =  automatic plant identification photographs based machine learning . project launched 2009 developed scientists ( computer \n",
      "Cleaned Token After Stem =  automat plant identif photograph base machin learn . project launch 2009 develop scientist ( comput \n",
      "Cleaned Token Before =  acquired brightpoint security. in january 2017, servicenow acquired machine learning startup dxcontinuum. in october 2017, the company acquired the san\n",
      "Cleaned Token After =  acquired brightpoint security . january 2017 , servicenow acquired machine learning startup dxcontinuum . october 2017 , company acquired san \n",
      "Cleaned Token After Stem =  acquir brightpoint secur . januari 2017 , servicenow acquir machin learn startup dxcontinuum . octob 2017 , compani acquir san \n",
      "Cleaned Token Before =  visual learning is a learning style in the fleming vak/vark model where a learner needs to see information in order to process it. visual learners can\n",
      "Cleaned Token After =  visual learning learning style fleming vak/vark model learner needs see information order process . visual learners \n",
      "Cleaned Token After Stem =  visual learn learn style fleme vak/vark model learner need see inform order process . visual learner \n",
      "Cleaned Token Before =  created obstacles for developers. developers use computer vision and machine learning to recognize specific phonological parameters and epentheses unique\n",
      "Cleaned Token After =  created obstacles developers . developers use computer vision machine learning recognize specific phonological parameters epentheses unique \n",
      "Cleaned Token After Stem =  creat obstacl develop . develop use comput vision machin learn recogn specif phonolog paramet epenthes uniqu \n",
      "Cleaned Token Before =  semi-supervised learning to rank with preference regularization (pdf). cikm. radlinski, filip; joachims, thorsten (2007). active exploration for learning rankings\n",
      "Cleaned Token After =  semi-supervised learning rank preference regularization ( pdf ) . cikm . radlinski , filip ; joachims , thorsten ( 2007 ) . active exploration learning rankings \n",
      "Cleaned Token After Stem =  semi-supervis learn rank prefer regular ( pdf ) . cikm . radlinski , filip ; joachim , thorsten ( 2007 ) . activ explor learn rank \n",
      "Cleaned Token Before =  professor at george mason university and a pioneer in the field of machine learning. michalski was born in kalusz near lvov on 7 may 1937. he received\n",
      "Cleaned Token After =  professor george mason university pioneer field machine learning . michalski born kalusz near lvov 7 may 1937. received \n",
      "Cleaned Token After Stem =  professor georg mason univers pioneer field machin learn . michalski born kalusz near lvov 7 may 1937. receiv \n",
      "Cleaned Token Before =  gain access to advanced learning curriculum in emerging technologies, including mobile and web development, machine learning, artificial intelligence\n",
      "Cleaned Token After =  gain access advanced learning curriculum emerging technologies , including mobile web development , machine learning , artificial intelligence \n",
      "Cleaned Token After Stem =  gain access advanc learn curriculum emerg technolog , includ mobil web develop , machin learn , artifici intellig \n",
      "Cleaned Token Before =  chair in machine learning and computer vision in the department of computer science. urtasun uses artificial intelligence, particularly deep learning, to make\n",
      "Cleaned Token After =  chair machine learning computer vision department computer science . urtasun uses artificial intelligence , particularly deep learning , make \n",
      "Cleaned Token After Stem =  chair machin learn comput vision depart comput scienc . urtasun use artifici intellig , particularli deep learn , make \n",
      "Cleaned Token Before =  the discourse on underwriting has been dominated by the advent of machine learning in this space. these profound technological innovations are altering\n",
      "Cleaned Token After =  discourse underwriting dominated advent machine learning space . profound technological innovations altering \n",
      "Cleaned Token After Stem =  discours underwrit domin advent machin learn space . profound technolog innov alter \n",
      "Cleaned Token Before =  it makes or correct for outside disturbances, and cannot engage in machine learning. fundamentally, there are two types of control loop: open-loop (feedforward)\n",
      "Cleaned Token After =  makes correct outside disturbances , engage machine learning . fundamentally , two types control loop : open-loop ( feedforward ) \n",
      "Cleaned Token After Stem =  make correct outsid disturb , engag machin learn . fundament , two type control loop : open-loop ( feedforward ) \n",
      "Cleaned Token Before =  research and development company specialized in recommender systems and machine learning. scarab research was founded in 2009 by a group of european scientists\n",
      "Cleaned Token After =  research development company specialized recommender systems machine learning . scarab research founded 2009 group european scientists \n",
      "Cleaned Token After Stem =  research develop compani special recommend system machin learn . scarab research found 2009 group european scientist \n",
      "Cleaned Token Before =  cs.washington.edu/~guestrin/open-source.html \"scaling distributed machine learning with the parameter server\" (pdf). retrieved 2014-10-08. \"amalgamation\"\n",
      "Cleaned Token After =  cs.washington.edu/~guestrin/open-source.html `` scaling distributed machine learning parameter server '' ( pdf ) . retrieved 2014-10-08 . `` amalgamation '' \n",
      "Cleaned Token After Stem =  cs.washington.edu/~guestrin/open-source.html `` scale distribut machin learn paramet server `` ( pdf ) . retriev 2014-10-08 . `` amalgam `` \n",
      "Cleaned Token Before =  or cursive text one glyph or character at a time, usually involving machine learning. intelligent word recognition (iwr) – also targets handwritten printscript\n",
      "Cleaned Token After =  cursive text one glyph character time , usually involving machine learning . intelligent word recognition ( iwr ) – also targets handwritten printscript \n",
      "Cleaned Token After Stem =  cursiv text one glyph charact time , usual involv machin learn . intellig word recognit ( iwr ) – also target handwritten printscript \n",
      "Cleaned Token Before =  deepfakes controversy where porn videos were doctored utilizing deep machine learning so that the face of the actress was replaced by the software's opinion\n",
      "Cleaned Token After =  deepfakes controversy porn videos doctored utilizing deep machine learning face actress replaced software 's opinion \n",
      "Cleaned Token After Stem =  deepfak controversi porn video doctor util deep machin learn face actress replac softwar 's opinion \n",
      "Cleaned Token Before =  in machine learning, first-order inductive learner (foil) is a rule-based learning algorithm. developed in 1990 by ross quinlan, foil learns function-free\n",
      "Cleaned Token After =  machine learning , first-order inductive learner ( foil ) rule-based learning algorithm . developed 1990 ross quinlan , foil learns function-free \n",
      "Cleaned Token After Stem =  machin learn , first-ord induct learner ( foil ) rule-bas learn algorithm . develop 1990 ross quinlan , foil learn function-fre \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Token Before =  including oltp, data warehousing, spark, machine learning, text search, image analytics, data catalog, and deep learning. the platform allows oracle, mysql\n",
      "Cleaned Token After =  including oltp , data warehousing , spark , machine learning , text search , image analytics , data catalog , deep learning . platform allows oracle , mysql \n",
      "Cleaned Token After Stem =  includ oltp , data wareh , spark , machin learn , text search , imag analyt , data catalog , deep learn . platform allow oracl , mysql \n",
      "Cleaned Token Before =  rprop, short for resilient backpropagation, is a learning heuristic for supervised learning in feedforward artificial neural networks. this is a first-order\n",
      "Cleaned Token After =  rprop , short resilient backpropagation , learning heuristic supervised learning feedforward artificial neural networks . first-order \n",
      "Cleaned Token After Stem =  rprop , short resili backpropag , learn heurist supervis learn feedforward artifici neural network . first-ord \n",
      "Cleaned Token Before =  rankbrain is a machine learning-based search engine algorithm, the use of which was confirmed by google on 26 october 2015. it helps google to process\n",
      "Cleaned Token After =  rankbrain machine learning-based search engine algorithm , use confirmed google 26 october 2015. helps google process \n",
      "Cleaned Token After Stem =  rankbrain machin learning-bas search engin algorithm , use confirm googl 26 octob 2015. help googl process \n",
      "Cleaned Token Before =  a french canadian researcher interested in human communication and machine learning applied to a better understanding of human behavior. dr. louis-philippe\n",
      "Cleaned Token After =  french canadian researcher interested human communication machine learning applied better understanding human behavior . dr. louis-philippe \n",
      "Cleaned Token After Stem =  french canadian research interest human commun machin learn appli better understand human behavior . dr. louis-philipp \n",
      "Cleaned Token Before =  rnn is an open-source machine learning framework that implements recurrent neural network architectures, such as lstm and gru, natively in the r programming\n",
      "Cleaned Token After =  rnn open-source machine learning framework implements recurrent neural network architectures , lstm gru , natively r programming \n",
      "Cleaned Token After Stem =  rnn open-sourc machin learn framework implement recurr neural network architectur , lstm gru , nativ r program \n",
      "Cleaned Token Before =  is an american computer scientist who works in computer vision and machine learning. frome attended the university of mary washington for her undergraduate\n",
      "Cleaned Token After =  american computer scientist works computer vision machine learning . frome attended university mary washington undergraduate \n",
      "Cleaned Token After Stem =  american comput scientist work comput vision machin learn . frome attend univers mari washington undergradu \n",
      "Cleaned Token Before =  format has been increasing especially in the field of machine learning since many machine learning algorithms are inherently error-tolerant. precision is\n",
      "Cleaned Token After =  format increasing especially field machine learning since many machine learning algorithms inherently error-tolerant . precision \n",
      "Cleaned Token After Stem =  format increas especi field machin learn sinc mani machin learn algorithm inher error-toler . precis \n",
      "Cleaned Token Before =  computational statistics and machine learning at university college, london (uk). his main research area is statistical learning theory. he has contributed\n",
      "Cleaned Token After =  computational statistics machine learning university college , london ( uk ) . main research area statistical learning theory . contributed \n",
      "Cleaned Token After Stem =  comput statist machin learn univers colleg , london ( uk ) . main research area statist learn theori . contribut \n",
      "Cleaned Token Before =  intelligence based on machine learning, prediction and probability. he circulated the first report on non-semantic machine learning in 1956. solomonoff\n",
      "Cleaned Token After =  intelligence based machine learning , prediction probability . circulated first report non-semantic machine learning 1956. solomonoff \n",
      "Cleaned Token After Stem =  intellig base machin learn , predict probabl . circul first report non-semant machin learn 1956. solomonoff \n",
      "Cleaned Token Before =  and an area of research in statistical learning theory, that extend and generalize sparsity regularization learning methods. both sparsity and structured\n",
      "Cleaned Token After =  area research statistical learning theory , extend generalize sparsity regularization learning methods . sparsity structured \n",
      "Cleaned Token After Stem =  area research statist learn theori , extend gener sparsiti regular learn method . sparsiti structur \n",
      "Cleaned Token Before =  cyber security products and services and its artificial intelligence/machine learning technology. ampex's first great success was a line of reel-to-reel\n",
      "Cleaned Token After =  cyber security products services artificial intelligence/machine learning technology . ampex 's first great success line reel-to-reel \n",
      "Cleaned Token After Stem =  cyber secur product servic artifici intelligence/machin learn technolog . ampex 's first great success line reel-to-reel \n",
      "Cleaned Token Before =  computational tasks within artificial intelligence, including sub-fields like machine learning. quantum mechanics phenomena, superposition and entanglement, are allowing\n",
      "Cleaned Token After =  computational tasks within artificial intelligence , including sub-fields like machine learning . quantum mechanics phenomena , superposition entanglement , allowing \n",
      "Cleaned Token After Stem =  comput task within artifici intellig , includ sub-field like machin learn . quantum mechan phenomena , superposit entangl , allow \n",
      "Cleaned Token Before =  times, financial times and similar publications on topics including machine learning, the future of work, and the impact of algorithms used by search and\n",
      "Cleaned Token After =  times , financial times similar publications topics including machine learning , future work , impact algorithms used search \n",
      "Cleaned Token After Stem =  time , financi time similar public topic includ machin learn , futur work , impact algorithm use search \n",
      "Cleaned Token Before =  matrix and then adds a bias vector. géron, aurélien (2019). hands-on machine learning with scikit-learn, keras, and tensorflow : concepts, tools, and techniques\n",
      "Cleaned Token After =  matrix adds bias vector . géron , aurélien ( 2019 ) . hands-on machine learning scikit-learn , keras , tensorflow : concepts , tools , techniques \n",
      "Cleaned Token After Stem =  matrix add bia vector . géron , aurélien ( 2019 ) . hands-on machin learn scikit-learn , kera , tensorflow : concept , tool , techniqu \n",
      "Cleaned Token Before =  theoretical and applied machine learning. his work led to the development of the boosting ensemble algorithm used in machine learning. together with yoav\n",
      "Cleaned Token After =  theoretical applied machine learning . work led development boosting ensemble algorithm used machine learning . together yoav \n",
      "Cleaned Token After Stem =  theoret appli machin learn . work led develop boost ensembl algorithm use machin learn . togeth yoav \n",
      "Cleaned Token Before =  discovery, which later would become a ph.d. program in the broad area of machine learning and scientific discovery. in 2001 thrun spent a sabbatical year at\n",
      "Cleaned Token After =  discovery , later would become ph.d. program broad area machine learning scientific discovery . 2001 thrun spent sabbatical year \n",
      "Cleaned Token After Stem =  discoveri , later would becom ph.d. program broad area machin learn scientif discoveri . 2001 thrun spent sabbat year \n",
      "Cleaned Token Before =  university (vcu), located in richmond, virginia. his research is focused on machine learning, data mining, and biomedical informatics. krzysztof j. cios, a polish-american\n",
      "Cleaned Token After =  university ( vcu ) , located richmond , virginia . research focused machine learning , data mining , biomedical informatics . krzysztof j. cios , polish-american \n",
      "Cleaned Token After Stem =  univers ( vcu ) , locat richmond , virginia . research focus machin learn , data mine , biomed informat . krzysztof j. cio , polish-american \n",
      "Cleaned Token Before =  negation. decision stump ronald l. rivest (nov 1987). \"learning decision lists\" (pdf). machine learning. 2 (3): 229–246. doi:10.1023/a:1022607331053. adam\n",
      "Cleaned Token After =  negation . decision stump ronald l. rivest ( nov 1987 ) . `` learning decision lists '' ( pdf ) . machine learning . 2 ( 3 ) : 229–246 . doi:10.1023/a:1022607331053. adam \n",
      "Cleaned Token After Stem =  negat . decis stump ronald l. rivest ( nov 1987 ) . `` learn decis list `` ( pdf ) . machin learn . 2 ( 3 ) : 229–246 . doi:10.1023/a:1022607331053. adam \n",
      "Cleaned Token Before =  computer scientist who applies methods from statistical physics to machine learning and constraint satisfaction problems. she is a professor of physics\n",
      "Cleaned Token After =  computer scientist applies methods statistical physics machine learning constraint satisfaction problems . professor physics \n",
      "Cleaned Token After Stem =  comput scientist appli method statist physic machin learn constraint satisfact problem . professor physic \n",
      "Cleaned Token Before =  by both human and machines. datatech is an emerging industry that uses artificial intelligence, big data analysis and machine learning algorithms to improve\n",
      "Cleaned Token After =  human machines . datatech emerging industry uses artificial intelligence , big data analysis machine learning algorithms improve \n",
      "Cleaned Token After Stem =  human machin . datatech emerg industri use artifici intellig , big data analysi machin learn algorithm improv \n",
      "Cleaned Token Before =  developers of cleverbot are attempting to build a new version using machine learning techniques. a significant part of the engine behind cleverbot and an\n",
      "Cleaned Token After =  developers cleverbot attempting build new version using machine learning techniques . significant part engine behind cleverbot \n",
      "Cleaned Token After Stem =  develop cleverbot attempt build new version use machin learn techniqu . signific part engin behind cleverbot \n",
      "Cleaned Token Before =  cohen, w. (eds.). proceedings of the 1994 international conference on machine learning (san mateo/ca). morgan kaufmann. pp. 259–265. here p. 260 lf woodward\n",
      "Cleaned Token After =  cohen , w . ( eds. ) . proceedings 1994 international conference machine learning ( san mateo/ca ) . morgan kaufmann . pp . 259–265 . p. 260 lf woodward \n",
      "Cleaned Token After Stem =  cohen , w . ( ed . ) . proceed 1994 intern confer machin learn ( san mateo/ca ) . morgan kaufmann . pp . 259–265 . p. 260 lf woodward \n",
      "Cleaned Token Before =  platform which helps machine learning engineers build high quality ground truth datasets for training and validating machine learning models. it breaks down\n",
      "Cleaned Token After =  platform helps machine learning engineers build high quality ground truth datasets training validating machine learning models . breaks \n",
      "Cleaned Token After Stem =  platform help machin learn engin build high qualiti ground truth dataset train valid machin learn model . break \n",
      "Cleaned Token Before =  matrixnet is a proprietary machine learning algorithm developed by yandex and used widely throughout the company products. the algorithm is based on gradient\n",
      "Cleaned Token After =  matrixnet proprietary machine learning algorithm developed yandex used widely throughout company products . algorithm based gradient \n",
      "Cleaned Token After Stem =  matrixnet proprietari machin learn algorithm develop yandex use wide throughout compani product . algorithm base gradient \n",
      "Cleaned Token Before =  auditory learning is a learning style in which a person learns through listening. an auditory learner depends on listening and speaking as a main way of\n",
      "Cleaned Token After =  auditory learning learning style person learns listening . auditory learner depends listening speaking main way \n",
      "Cleaned Token After Stem =  auditori learn learn style person learn listen . auditori learner depend listen speak main way \n",
      "Cleaned Token Before =  expectation propagation (ep) is a technique in bayesian machine learning. ep finds approximations to a probability distribution. it uses an iterative approach\n",
      "Cleaned Token After =  expectation propagation ( ep ) technique bayesian machine learning . ep finds approximations probability distribution . uses iterative approach \n",
      "Cleaned Token After Stem =  expect propag ( ep ) techniqu bayesian machin learn . ep find approxim probabl distribut . use iter approach \n",
      "Cleaned Token Before =  dissemination of threat intelligence. recorded future uses patented machine learning and natural language processing methods to continuously collect and\n",
      "Cleaned Token After =  dissemination threat intelligence . recorded future uses patented machine learning natural language processing methods continuously collect \n",
      "Cleaned Token After Stem =  dissemin threat intellig . record futur use patent machin learn natur languag process method continu collect \n",
      "Cleaned Token Before =  variety of technological methods, including artificial intelligence, machine learning, and distributed computing, for its trading strategies. in 2016, overdeck\n",
      "Cleaned Token After =  variety technological methods , including artificial intelligence , machine learning , distributed computing , trading strategies . 2016 , overdeck \n",
      "Cleaned Token After Stem =  varieti technolog method , includ artifici intellig , machin learn , distribut comput , trade strategi . 2016 , overdeck \n",
      "Cleaned Token Before =  featured in multiple books such as mastering.net machine learning by packt publishing and f# for machine learning applications, featured in qcon san francisco\n",
      "Cleaned Token After =  featured multiple books mastering.net machine learning packt publishing f # machine learning applications , featured qcon san francisco \n",
      "Cleaned Token After Stem =  featur multipl book mastering.net machin learn packt publish f # machin learn applic , featur qcon san francisco \n",
      "Cleaned Token Before =  pune, india established by tcs in 1981.trddc undertakes research in machine learning, software engineering, process engineering and systems research. it\n",
      "Cleaned Token After =  pune , india established tcs 1981.trddc undertakes research machine learning , software engineering , process engineering systems research . \n",
      "Cleaned Token After Stem =  pune , india establish tc 1981.trddc undertak research machin learn , softwar engin , process engin system research . \n",
      "Cleaned Token Before =  with the discovery of generative adversarial networks (gans), and how machine learning algorithms could be used to generate images. one of the first ai-generated\n",
      "Cleaned Token After =  discovery generative adversarial networks ( gans ) , machine learning algorithms could used generate images . one first ai-generated \n",
      "Cleaned Token After Stem =  discoveri gener adversari network ( gan ) , machin learn algorithm could use gener imag . one first ai-gener \n",
      "Cleaned Token Before =  science, and a world leader in the fields of lifelong learning, artificial intelligence, machine learning, neural networks, and computational neuroscience\n",
      "Cleaned Token After =  science , world leader fields lifelong learning , artificial intelligence , machine learning , neural networks , computational neuroscience \n",
      "Cleaned Token After Stem =  scienc , world leader field lifelong learn , artifici intellig , machin learn , neural network , comput neurosci \n",
      "Cleaned Token Before =  predictive model, despite the machine learning algorithm being legitimate. the labelled data used to train a specific machine learning algorithm needs to be a\n",
      "Cleaned Token After =  predictive model , despite machine learning algorithm legitimate . labelled data used train specific machine learning algorithm needs \n",
      "Cleaned Token After Stem =  predict model , despit machin learn algorithm legitim . label data use train specif machin learn algorithm need \n",
      "Cleaned Token Before =  autonomous vehicles. deep learning expert system history of artificial intelligence intelligent personal assistant machine learning philosophy of artificial\n",
      "Cleaned Token After =  autonomous vehicles . deep learning expert system history artificial intelligence intelligent personal assistant machine learning philosophy artificial \n",
      "Cleaned Token After Stem =  autonom vehicl . deep learn expert system histori artifici intellig intellig person assist machin learn philosophi artifici \n",
      "Cleaned Token Before =  substantial regions in space, visual temporal attention modules enable machine learning algorithms to emphasize more on critical video frames in video analytics\n",
      "Cleaned Token After =  substantial regions space , visual temporal attention modules enable machine learning algorithms emphasize critical video frames video analytics \n",
      "Cleaned Token After Stem =  substanti region space , visual tempor attent modul enabl machin learn algorithm emphas critic video frame video analyt \n",
      "Cleaned Token Before =  1 if the input vector has an odd number of ones parity learning, a problem in machine learning parity of even and odd functions parity (physics), a symmetry\n",
      "Cleaned Token After =  1 input vector odd number ones parity learning , problem machine learning parity even odd functions parity ( physics ) , symmetry \n",
      "Cleaned Token After Stem =  1 input vector odd number one pariti learn , problem machin learn pariti even odd function pariti ( physic ) , symmetri \n",
      "Cleaned Token Before =  learning space or learning setting refers to a physical setting for a learning environment, a place in which teaching and learning occur. the term is commonly\n",
      "Cleaned Token After =  learning space learning setting refers physical setting learning environment , place teaching learning occur . term commonly \n",
      "Cleaned Token After Stem =  learn space learn set refer physic set learn environ , place teach learn occur . term commonli \n",
      "Cleaned Token Before =  pattern languages were introduced by dana angluin in the context of machine learning. given a finite set σ of constant symbols and a countable set x of\n",
      "Cleaned Token After =  pattern languages introduced dana angluin context machine learning . given finite set σ constant symbols countable set x \n",
      "Cleaned Token After Stem =  pattern languag introduc dana angluin context machin learn . given finit set σ constant symbol countabl set x \n",
      "Cleaned Token Before =  a leader in applying machine learning to agriculture. blue river has designed and integrated computer vision and machine learning technology that will\n",
      "Cleaned Token After =  leader applying machine learning agriculture . blue river designed integrated computer vision machine learning technology \n",
      "Cleaned Token After Stem =  leader appli machin learn agricultur . blue river design integr comput vision machin learn technolog \n",
      "Cleaned Token Before =   reinforcement learning, sports analysis, statistical learning and modelling. his current research interests include machine learning applications in\n",
      "Cleaned Token After =  reinforcement learning , sports analysis , statistical learning modelling . current research interests include machine learning applications \n",
      "Cleaned Token After Stem =  reinforc learn , sport analysi , statist learn model . current research interest includ machin learn applic \n",
      "Cleaned Token Before =  anodot is an american data analytics company that uses machine learning and artificial intelligence for business monitoring and anomaly detection. anodot\n",
      "Cleaned Token After =  anodot american data analytics company uses machine learning artificial intelligence business monitoring anomaly detection . anodot \n",
      "Cleaned Token After Stem =  anodot american data analyt compani use machin learn artifici intellig busi monitor anomali detect . anodot \n",
      "Cleaned Token Before =  fields such as quantitative finance, quantitative risk management, and machine learning in finance. it aims at both the advancement of theoretical understanding\n",
      "Cleaned Token After =  fields quantitative finance , quantitative risk management , machine learning finance . aims advancement theoretical understanding \n",
      "Cleaned Token After Stem =  field quantit financ , quantit risk manag , machin learn financ . aim advanc theoret understand \n",
      "Cleaned Token Before =  also presents the possibility of new hazards. these may arise from machine learning techniques leading to unpredictable behavior and inscrutability in\n",
      "Cleaned Token After =  also presents possibility new hazards . may arise machine learning techniques leading unpredictable behavior inscrutability \n",
      "Cleaned Token After Stem =  also present possibl new hazard . may aris machin learn techniqu lead unpredict behavior inscrut \n",
      "Cleaned Token Before =  been used for machine learning classification and data mining, for example for discovery of adverse drug reactions.  the bcnn learning rule has also been\n",
      "Cleaned Token After =  used machine learning classification data mining , example discovery adverse drug reactions . bcnn learning rule also \n",
      "Cleaned Token After Stem =  use machin learn classif data mine , exampl discoveri advers drug reaction . bcnn learn rule also \n",
      "Cleaned Token Before =  his contributions to audio signal processing, computer audition, and machine learning. he is currently an associate professor of computer science at the\n",
      "Cleaned Token After =  contributions audio signal processing , computer audition , machine learning . currently associate professor computer science \n",
      "Cleaned Token After Stem =  contribut audio signal process , comput audit , machin learn . current associ professor comput scienc \n",
      "Cleaned Token Before =  in machine learning the random subspace method, also called attribute bagging or feature bagging, is an ensemble learning method that attempts to reduce\n",
      "Cleaned Token After =  machine learning random subspace method , also called attribute bagging feature bagging , ensemble learning method attempts reduce \n",
      "Cleaned Token After Stem =  machin learn random subspac method , also call attribut bag featur bag , ensembl learn method attempt reduc \n",
      "Cleaned Token Before =  regularization in statistics, the method is known as ridge regression, in machine learning it is known as weight decay, and with multiple independent discoveries\n",
      "Cleaned Token After =  regularization statistics , method known ridge regression , machine learning known weight decay , multiple independent discoveries \n",
      "Cleaned Token After Stem =  regular statist , method known ridg regress , machin learn known weight decay , multipl independ discoveri \n",
      "Cleaned Token Before =  implementation of a case-based reasoning approach to machine learning. at the foundation of example-based machine translation is the idea of translation by analogy\n",
      "Cleaned Token After =  implementation case-based reasoning approach machine learning . foundation example-based machine translation idea translation analogy \n",
      "Cleaned Token After Stem =  implement case-bas reason approach machin learn . foundat example-bas machin translat idea translat analog \n",
      "Cleaned Token Before =  information system automated machine learning (automl), the process of automating the end-to-end process of applying machine learning to real-world problems\n",
      "Cleaned Token After =  information system automated machine learning ( automl ) , process automating end-to-end process applying machine learning real-world problems \n",
      "Cleaned Token After Stem =  inform system autom machin learn ( automl ) , process autom end-to-end process appli machin learn real-world problem \n",
      "Cleaned Token Before =  nearest neighbor (lmnn) classification is a statistical machine learning algorithm for metric learning. it learns a pseudometric designed for k-nearest neighbor\n",
      "Cleaned Token After =  nearest neighbor ( lmnn ) classification statistical machine learning algorithm metric learning . learns pseudometric designed k-nearest neighbor \n",
      "Cleaned Token After Stem =  nearest neighbor ( lmnn ) classif statist machin learn algorithm metric learn . learn pseudometr design k-nearest neighbor \n",
      "Cleaned Token Before =  application of mdp process in machine learning theory is called learning automata. this is also one type of reinforcement learning if the environment is stochastic\n",
      "Cleaned Token After =  application mdp process machine learning theory called learning automata . also one type reinforcement learning environment stochastic \n",
      "Cleaned Token After Stem =  applic mdp process machin learn theori call learn automata . also one type reinforc learn environ stochast \n",
      "Cleaned Token Before =  video series computerphile. pound's work focuses on the use of machine learning, deep learning, and bioimage analysis for the purpose of plant phenotyping\n",
      "Cleaned Token After =  video series computerphile . pound 's work focuses use machine learning , deep learning , bioimage analysis purpose plant phenotyping \n",
      "Cleaned Token After Stem =  video seri computerphil . pound 's work focus use machin learn , deep learn , bioimag analysi purpos plant phenotyp \n",
      "Cleaned Token Before =  vrs are appropriate for training, cyberspace is preferred for distance learning. in some cases these two types are even complementary to each other. this\n",
      "Cleaned Token After =  vrs appropriate training , cyberspace preferred distance learning . cases two types even complementary . \n",
      "Cleaned Token After Stem =  vr appropri train , cyberspac prefer distanc learn . case two type even complementari . \n",
      "Cleaned Token Before =  designations, and the associated genome sequences, are the input into the machine learning model training. this model, both the training and the assignment, has\n",
      "Cleaned Token After =  designations , associated genome sequences , input machine learning model training . model , training assignment , \n",
      "Cleaned Token After Stem =  design , associ genom sequenc , input machin learn model train . model , train assign , \n",
      "Cleaned Token Before =  add facial expressions to the images with the power of adobe sensei machine learning ai, which was introduced in 2017. batch editing and adding slideshows\n",
      "Cleaned Token After =  add facial expressions images power adobe sensei machine learning ai , introduced 2017. batch editing adding slideshows \n",
      "Cleaned Token After Stem =  add facial express imag power adob sensei machin learn ai , introduc 2017. batch edit ad slideshow \n",
      "Cleaned Token Before =  logical models, graphical models, rule systems, contextual focusing, and machine learning. practical or large-scale solutions avoid these complex methods and\n",
      "Cleaned Token After =  logical models , graphical models , rule systems , contextual focusing , machine learning . practical large-scale solutions avoid complex methods \n",
      "Cleaned Token After Stem =  logic model , graphic model , rule system , contextu focus , machin learn . practic large-scal solut avoid complex method \n",
      "Cleaned Token Before =  personalized learning, individualized instruction, personal learning environment and direct instruction all refer to efforts to tailor education to meet\n",
      "Cleaned Token After =  personalized learning , individualized instruction , personal learning environment direct instruction refer efforts tailor education meet \n",
      "Cleaned Token After Stem =  person learn , individu instruct , person learn environ direct instruct refer effort tailor educ meet \n",
      "Cleaned Token Before =   acquired by takara tomy in 2011 learning curve (machine learning), a tool to find out how much a machine learning model benefits from adding more training\n",
      "Cleaned Token After =  acquired takara tomy 2011 learning curve ( machine learning ) , tool find much machine learning model benefits adding training \n",
      "Cleaned Token After Stem =  acquir takara tomi 2011 learn curv ( machin learn ) , tool find much machin learn model benefit ad train \n",
      "Cleaned Token Before =  and san francisco, california. unbabel combines neural machine translation with machine learning and a crowdsourced model to differentiate itself from\n",
      "Cleaned Token After =  san francisco , california . unbabel combines neural machine translation machine learning crowdsourced model differentiate \n",
      "Cleaned Token After Stem =  san francisco , california . unbabel combin neural machin translat machin learn crowdsourc model differenti \n",
      "Cleaned Token Before =  computational learning theory, a mathematical theory to analyze machine learning algorithms. online machine learning, the process of teaching a machine. statistical\n",
      "Cleaned Token After =  computational learning theory , mathematical theory analyze machine learning algorithms . online machine learning , process teaching machine . statistical \n",
      "Cleaned Token After Stem =  comput learn theori , mathemat theori analyz machin learn algorithm . onlin machin learn , process teach machin . statist \n",
      "Cleaned Token Before =  engineering. currently it offers b.e. in artificial intelligence & machine learning, biotechnology engineering, civil engineering, computer & communications\n",
      "Cleaned Token After =  engineering . currently offers b.e . artificial intelligence & machine learning , biotechnology engineering , civil engineering , computer & communications \n",
      "Cleaned Token After Stem =  engin . current offer b.e . artifici intellig & machin learn , biotechnolog engin , civil engin , comput & commun \n",
      "Cleaned Token Before =  world. with data sets from this research, data scientists develop the machine learning algorithms and behavioral analysis that drive the cognito platform\n",
      "Cleaned Token After =  world . data sets research , data scientists develop machine learning algorithms behavioral analysis drive cognito platform \n",
      "Cleaned Token After Stem =  world . data set research , data scientist develop machin learn algorithm behavior analysi drive cognito platform \n",
      "Cleaned Token Before =  units improve restricted boltzmann machines\", 27th international conference on international conference on machine learning, icml'10, usa: omnipress, pp. 807–814\n",
      "Cleaned Token After =  units improve restricted boltzmann machines '' , 27th international conference international conference machine learning , icml'10 , usa : omnipress , pp . 807–814 \n",
      "Cleaned Token After Stem =  unit improv restrict boltzmann machin `` , 27th intern confer intern confer machin learn , icml'10 , usa : omnipress , pp . 807–814 \n",
      "Cleaned Token Before =  by analyzing all network interactions in real time and leveraging machine learning to identify threats, deliver critical applications, and secure investments\n",
      "Cleaned Token After =  analyzing network interactions real time leveraging machine learning identify threats , deliver critical applications , secure investments \n",
      "Cleaned Token After Stem =  analyz network interact real time leverag machin learn identifi threat , deliv critic applic , secur invest \n",
      "Cleaned Token Before =  german computer scientist and physicist, most noted for his work in machine learning and brain-computer interfaces. klaus-robert müller received his diplom\n",
      "Cleaned Token After =  german computer scientist physicist , noted work machine learning brain-computer interfaces . klaus-robert müller received diplom \n",
      "Cleaned Token After Stem =  german comput scientist physicist , note work machin learn brain-comput interfac . klaus-robert müller receiv diplom \n",
      "Cleaned Token Before =  carry out any other functions. unlike more traditional ai programs, the learning technology is intended as a form of entertainment rather than being used\n",
      "Cleaned Token After =  carry functions . unlike traditional ai programs , learning technology intended form entertainment rather used \n",
      "Cleaned Token After Stem =  carri function . unlik tradit ai program , learn technolog intend form entertain rather use \n",
      "Cleaned Token Before =  modelling is synonymous with, or largely overlapping with, the field of machine learning, as it is more commonly referred to in academic or research and development\n",
      "Cleaned Token After =  modelling synonymous , largely overlapping , field machine learning , commonly referred academic research development \n",
      "Cleaned Token After Stem =  model synonym , larg overlap , field machin learn , commonli refer academ research develop \n",
      "Cleaned Token Before =  on thresholded power iterations scikit-learn – python library for machine learning which contains sparse pca and other techniques in the decomposition\n",
      "Cleaned Token After =  thresholded power iterations scikit-learn – python library machine learning contains sparse pca techniques decomposition \n",
      "Cleaned Token After Stem =  threshold power iter scikit-learn – python librari machin learn contain spars pca techniqu decomposit \n",
      "Cleaned Token Before =  in machine learning, kernel methods arise from the assumption of an inner product space or similarity structure on inputs. for some such methods, such\n",
      "Cleaned Token After =  machine learning , kernel methods arise assumption inner product space similarity structure inputs . methods , \n",
      "Cleaned Token After Stem =  machin learn , kernel method aris assumpt inner product space similar structur input . method , \n",
      "Cleaned Token Before =  ehud shapiro laid the initial theoretical foundation for inductive machine learning in a logical setting. shapiro built their first implementation (model\n",
      "Cleaned Token After =  ehud shapiro laid initial theoretical foundation inductive machine learning logical setting . shapiro built first implementation ( model \n",
      "Cleaned Token After Stem =  ehud shapiro laid initi theoret foundat induct machin learn logic set . shapiro built first implement ( model \n",
      "Cleaned Token Before =  collaborative learning is a situation in which two or more people learn or attempt to learn something together. unlike individual learning, people engaged\n",
      "Cleaned Token After =  collaborative learning situation two people learn attempt learn something together . unlike individual learning , people engaged \n",
      "Cleaned Token After Stem =  collabor learn situat two peopl learn attempt learn someth togeth . unlik individu learn , peopl engag \n",
      "Cleaned Token Before =  describe and exchange predictive models produced by analytics and machine learning algorithms. it supports common models such as logistic regression and\n",
      "Cleaned Token After =  describe exchange predictive models produced analytics machine learning algorithms . supports common models logistic regression \n",
      "Cleaned Token After Stem =  describ exchang predict model produc analyt machin learn algorithm . support common model logist regress \n",
      "Cleaned Token Before =  recognize unusual go board positions. the ai engaged in reinforcement learning, playing against itself until it could anticipate its own moves and how\n",
      "Cleaned Token After =  recognize unusual go board positions . ai engaged reinforcement learning , playing could anticipate moves \n",
      "Cleaned Token After Stem =  recogn unusu go board posit . ai engag reinforc learn , play could anticip move \n",
      "Cleaned Token Before =  products and engineering. his research spans artificial intelligence, machine learning, computational advertising, data mining, and information retrieval\n",
      "Cleaned Token After =  products engineering . research spans artificial intelligence , machine learning , computational advertising , data mining , information retrieval \n",
      "Cleaned Token After Stem =  product engin . research span artifici intellig , machin learn , comput advertis , data mine , inform retriev \n",
      "Cleaned Token Before =  has also been increasingly involved in artificial intelligence and machine learning. its clients include media outlets, sports leagues and teams, fantasy\n",
      "Cleaned Token After =  also increasingly involved artificial intelligence machine learning . clients include media outlets , sports leagues teams , fantasy \n",
      "Cleaned Token After Stem =  also increasingli involv artifici intellig machin learn . client includ media outlet , sport leagu team , fantasi \n",
      "Cleaned Token Before =  probabilities to an uncertain proposition, and all being correct. many modern machine learning methods are based on objectivist bayesian principles. according to\n",
      "Cleaned Token After =  probabilities uncertain proposition , correct . many modern machine learning methods based objectivist bayesian principles . according \n",
      "Cleaned Token After Stem =  probabl uncertain proposit , correct . mani modern machin learn method base objectivist bayesian principl . accord \n",
      "Cleaned Token Before =  artifact reduction for limited angle tomography with deep learning prior. machine learning for medical image reconstruction. arxiv:1908.06792. doi:10\n",
      "Cleaned Token After =  artifact reduction limited angle tomography deep learning prior . machine learning medical image reconstruction . arxiv:1908.06792. doi:10 \n",
      "Cleaned Token After Stem =  artifact reduct limit angl tomographi deep learn prior . machin learn medic imag reconstruct . arxiv:1908.06792. doi:10 \n",
      "Cleaned Token Before =  libsvm and liblinear are two popular open source machine learning libraries, both developed at the national taiwan university and both written in c++ though\n",
      "Cleaned Token After =  libsvm liblinear two popular open source machine learning libraries , developed national taiwan university written c++ though \n",
      "Cleaned Token After Stem =  libsvm liblinear two popular open sourc machin learn librari , develop nation taiwan univers written c++ though \n",
      "Cleaned Token Before =  press, 1991. sutton, r. s. (ed.), reinforcement learning. reprinting of a special issue of machine learning journal. kluwer academic press, 1992 sutton is\n",
      "Cleaned Token After =  press , 1991. sutton , r. . ( ed . ) , reinforcement learning . reprinting special issue machine learning journal . kluwer academic press , 1992 sutton \n",
      "Cleaned Token After Stem =  press , 1991. sutton , r. . ( ed . ) , reinforc learn . reprint special issu machin learn journal . kluwer academ press , 1992 sutton \n",
      "Cleaned Token Before =  engineering, which involves the selection of features that are fed into machine learning algorithms, plays a key role in the sentiment classification performance\n",
      "Cleaned Token After =  engineering , involves selection features fed machine learning algorithms , plays key role sentiment classification performance \n",
      "Cleaned Token After Stem =  engin , involv select featur fed machin learn algorithm , play key role sentiment classif perform \n",
      "Cleaned Token Before =  ben; ganguli, surya (2017). \"continual learning through synaptic intelligence\". proceedings of machine learning research. 70: 3987–3995. arxiv:1703.04200\n",
      "Cleaned Token After =  ben ; ganguli , surya ( 2017 ) . `` continual learning synaptic intelligence '' . proceedings machine learning research . 70 : 3987–3995 . arxiv:1703.04200 \n",
      "Cleaned Token After Stem =  ben ; ganguli , surya ( 2017 ) . `` continu learn synapt intellig `` . proceed machin learn research . 70 : 3987–3995 . arxiv:1703.04200 \n",
      "Cleaned Token Before =  serving cloud-based tpus (tensor processing units) in order to develop machine learning software. development of tensorflow. the tensorflow research cloud\n",
      "Cleaned Token After =  serving cloud-based tpus ( tensor processing units ) order develop machine learning software . development tensorflow . tensorflow research cloud \n",
      "Cleaned Token After Stem =  serv cloud-bas tpu ( tensor process unit ) order develop machin learn softwar . develop tensorflow . tensorflow research cloud \n",
      "Cleaned Token Before =  computer science at princeton university. his work is primarily in machine learning. his research interests include topic models and he was one of the\n",
      "Cleaned Token After =  computer science princeton university . work primarily machine learning . research interests include topic models one \n",
      "Cleaned Token After Stem =  comput scienc princeton univers . work primarili machin learn . research interest includ topic model one \n",
      "Cleaned Token Before =   \"learning associative markov networks\", in brodley, carla e. (ed.), proceedings of the twenty-first international conference on machine learning (icml\n",
      "Cleaned Token After =  `` learning associative markov networks '' , brodley , carla e . ( ed . ) , proceedings twenty-first international conference machine learning ( icml \n",
      "Cleaned Token After Stem =  `` learn associ markov network `` , brodley , carla e . ( ed . ) , proceed twenty-first intern confer machin learn ( icml \n",
      "Cleaned Token Before =  (29 may 2017). \"arm's new processors are designed to power the machine-learning machines\". the verge. retrieved 10 july 2017. frumusanu, andrei (6 december\n",
      "Cleaned Token After =  ( 29 may 2017 ) . `` arm 's new processors designed power machine-learning machines '' . verge . retrieved 10 july 2017. frumusanu , andrei ( 6 december \n",
      "Cleaned Token After Stem =  ( 29 may 2017 ) . `` arm 's new processor design power machine-learn machin `` . verg . retriev 10 juli 2017. frumusanu , andrei ( 6 decemb \n",
      "Cleaned Token Before =  by extracting sentiment (positive or negative) from the text using machine learning methods like sentiment analysis and represents that sentiment in terms\n",
      "Cleaned Token After =  extracting sentiment ( positive negative ) text using machine learning methods like sentiment analysis represents sentiment terms \n",
      "Cleaned Token After Stem =  extract sentiment ( posit neg ) text use machin learn method like sentiment analysi repres sentiment term \n",
      "Cleaned Token Before =  a learning object is \"a collection of content items, practice items, and assessment items that are combined based on a single learning objective\". the\n",
      "Cleaned Token After =  learning object `` collection content items , practice items , assessment items combined based single learning objective '' . \n",
      "Cleaned Token After Stem =  learn object `` collect content item , practic item , assess item combin base singl learn object `` . \n",
      "Cleaned Token Before =  existing services. the apis provide functionality like analytics, machine learning as a service (the prediction api) or access to user data (when permission\n",
      "Cleaned Token After =  existing services . apis provide functionality like analytics , machine learning service ( prediction api ) access user data ( permission \n",
      "Cleaned Token After Stem =  exist servic . api provid function like analyt , machin learn servic ( predict api ) access user data ( permiss \n",
      "Cleaned Token Before =  for high school and college-level math problems. symbolab relies on machine learning algorithms for both search and solution aspects of the engine. start-up\n",
      "Cleaned Token After =  high school college-level math problems . symbolab relies machine learning algorithms search solution aspects engine . start-up \n",
      "Cleaned Token After Stem =  high school college-level math problem . symbolab reli machin learn algorithm search solut aspect engin . start-up \n",
      "Cleaned Token Before =  a cognitive computer combines artificial intelligence and machine-learning algorithms, in an approach which attempts to reproduce the behaviour of the\n",
      "Cleaned Token After =  cognitive computer combines artificial intelligence machine-learning algorithms , approach attempts reproduce behaviour \n",
      "Cleaned Token After Stem =  cognit comput combin artifici intellig machine-learn algorithm , approach attempt reproduc behaviour \n",
      "Cleaned Token Before =  platforms. a virtual machine (vm) such as the java virtual machine or .net clr. applications are compiled into a format similar to machine code, known as bytecode\n",
      "Cleaned Token After =  platforms . virtual machine ( vm ) java virtual machine .net clr . applications compiled format similar machine code , known bytecode \n",
      "Cleaned Token After Stem =  platform . virtual machin ( vm ) java virtual machin .net clr . applic compil format similar machin code , known bytecod \n",
      "Cleaned Token Before =  random variables using various mathematical methods from statistics and machine learning. dimensionality reduction is often used to reduce the problem of managing\n",
      "Cleaned Token After =  random variables using various mathematical methods statistics machine learning . dimensionality reduction often used reduce problem managing \n",
      "Cleaned Token After Stem =  random variabl use variou mathemat method statist machin learn . dimension reduct often use reduc problem manag \n",
      "Cleaned Token Before =  m-profile vector extension (mve), or helium, is for signal processing and machine learning applications. additional instruction set enhancements for loops and\n",
      "Cleaned Token After =  m-profile vector extension ( mve ) , helium , signal processing machine learning applications . additional instruction set enhancements loops \n",
      "Cleaned Token After Stem =  m-profil vector extens ( mve ) , helium , signal process machin learn applic . addit instruct set enhanc loop \n",
      "Cleaned Token Before =  spanned the fields of algorithms and combinatorics, cryptography, machine learning, and election integrity. rivest is one of the inventors of the rsa\n",
      "Cleaned Token After =  spanned fields algorithms combinatorics , cryptography , machine learning , election integrity . rivest one inventors rsa \n",
      "Cleaned Token After Stem =  span field algorithm combinator , cryptographi , machin learn , elect integr . rivest one inventor rsa \n",
      "Cleaned Token Before =  of neuroscience, physics, computer science, bioinformatics, machine learning, deep learning, and artificial intelligence. he has helped pioneer the new\n",
      "Cleaned Token After =  neuroscience , physics , computer science , bioinformatics , machine learning , deep learning , artificial intelligence . helped pioneer new \n",
      "Cleaned Token After Stem =  neurosci , physic , comput scienc , bioinformat , machin learn , deep learn , artifici intellig . help pioneer new \n",
      "Cleaned Token Before =  approaches to peer learning comes out of cognitive psychology, and is applied within a \"mainstream\" educational framework: \"peer learning is an educational\n",
      "Cleaned Token After =  approaches peer learning comes cognitive psychology , applied within `` mainstream '' educational framework : `` peer learning educational \n",
      "Cleaned Token After Stem =  approach peer learn come cognit psycholog , appli within `` mainstream `` educ framework : `` peer learn educ \n",
      "Cleaned Token Before =  august 2017). \"deepl schools other online translators with clever machine learning\". techcrunch. archived from the original on 20 february 2018. retrieved\n",
      "Cleaned Token After =  august 2017 ) . `` deepl schools online translators clever machine learning '' . techcrunch . archived original 20 february 2018. retrieved \n",
      "Cleaned Token After Stem =  august 2017 ) . `` deepl school onlin translat clever machin learn `` . techcrunch . archiv origin 20 februari 2018. retriev \n",
      "Cleaned Token Before =  goldilocks principle frequently appears in machine learning. the goldilocks learning rate is the learning rate that takes the fewest possible steps to\n",
      "Cleaned Token After =  goldilocks principle frequently appears machine learning . goldilocks learning rate learning rate takes fewest possible steps \n",
      "Cleaned Token After Stem =  goldilock principl frequent appear machin learn . goldilock learn rate learn rate take fewest possibl step \n",
      "Cleaned Token Before =  biologist and professor in the computational biology department and the machine learning department at the carnegie mellon school of computer science. bar-joseph\n",
      "Cleaned Token After =  biologist professor computational biology department machine learning department carnegie mellon school computer science . bar-joseph \n",
      "Cleaned Token After Stem =  biologist professor comput biolog depart machin learn depart carnegi mellon school comput scienc . bar-joseph \n",
      "Cleaned Token Before =  cognitive bias mitigation. machine learning, a branch of artificial intelligence, has been used to investigate human learning and decision making. one technique\n",
      "Cleaned Token After =  cognitive bias mitigation . machine learning , branch artificial intelligence , used investigate human learning decision making . one technique \n",
      "Cleaned Token After Stem =  cognit bia mitig . machin learn , branch artifici intellig , use investig human learn decis make . one techniqu \n",
      "Cleaned Token Before =  oran holtzman is the present ceo of the company. the technology uses machine learning to match user's makeup foundation shade to skin tone using data from\n",
      "Cleaned Token After =  oran holtzman present ceo company . technology uses machine learning match user 's makeup foundation shade skin tone using data \n",
      "Cleaned Token After Stem =  oran holtzman present ceo compani . technolog use machin learn match user 's makeup foundat shade skin tone use data \n",
      "Cleaned Token Before =  is a personal recommendations service created by yandex that uses machine learning technology. zen creates a feed of content that automatically adjusts\n",
      "Cleaned Token After =  personal recommendations service created yandex uses machine learning technology . zen creates feed content automatically adjusts \n",
      "Cleaned Token After Stem =  person recommend servic creat yandex use machin learn technolog . zen creat feed content automat adjust \n",
      "Cleaned Token Before =  – november 18, 2013) was a professor and researcher in the area of machine learning and applications to computational linguistics and computer vision.\n",
      "Cleaned Token After =  – november 18 , 2013 ) professor researcher area machine learning applications computational linguistics computer vision . \n",
      "Cleaned Token After Stem =  – novemb 18 , 2013 ) professor research area machin learn applic comput linguist comput vision . \n",
      "Cleaned Token Before =  in machine learning, repeated incremental pruning to produce error reduction (ripper) is a propositional rule learner proposed by william w. cohen as an\n",
      "Cleaned Token After =  machine learning , repeated incremental pruning produce error reduction ( ripper ) propositional rule learner proposed william w. cohen \n",
      "Cleaned Token After Stem =  machin learn , repeat increment prune produc error reduct ( ripper ) proposit rule learner propos william w. cohen \n",
      "Cleaned Token Before =  level symbols. in the 21st century, statistics-based approaches to machine learning simulate the way that the brain uses unconscious process to perceive\n",
      "Cleaned Token After =  level symbols . 21st century , statistics-based approaches machine learning simulate way brain uses unconscious process perceive \n",
      "Cleaned Token After Stem =  level symbol . 21st centuri , statistics-bas approach machin learn simul way brain use unconsci process perceiv \n",
      "Cleaned Token Before =  “the first company to apply artificial intelligence, algorithms, and machine learning to cyber security.” in february 2019, the company was acquired by blackberry\n",
      "Cleaned Token After =  “ first company apply artificial intelligence , algorithms , machine learning cyber security. ” february 2019 , company acquired blackberry \n",
      "Cleaned Token After Stem =  “ first compani appli artifici intellig , algorithm , machin learn cyber secur . ” februari 2019 , compani acquir blackberri \n",
      "Cleaned Token Before =  investments include quantum computing, superconducting computing, machine learning, and forecasting tournaments. iarpa characterizes its mission as follows:\n",
      "Cleaned Token After =  investments include quantum computing , superconducting computing , machine learning , forecasting tournaments . iarpa characterizes mission follows : \n",
      "Cleaned Token After Stem =  invest includ quantum comput , superconduct comput , machin learn , forecast tournament . iarpa character mission follow : \n",
      "Cleaned Token Before =  p. imlay, jr. dean of the college. his research interests focus on machine learning and artificial intelligence, particularly interactive and human-centered\n",
      "Cleaned Token After =  p. imlay , jr. dean college . research interests focus machine learning artificial intelligence , particularly interactive human-centered \n",
      "Cleaned Token After Stem =  p. imlay , jr. dean colleg . research interest focu machin learn artifici intellig , particularli interact human-cent \n",
      "Cleaned Token Before =  intelligence\" is applied when a machine mimics \"cognitive\" functions that humans associate with other human minds, such as \"learning\" and \"problem solving\". ascii\n",
      "Cleaned Token After =  intelligence '' applied machine mimics `` cognitive '' functions humans associate human minds , `` learning '' `` problem solving '' . ascii \n",
      "Cleaned Token After Stem =  intellig `` appli machin mimic `` cognit `` function human associ human mind , `` learn `` `` problem solv `` . ascii \n",
      "Cleaned Token Before =  the bestconditionexpression clark, p. and niblett, t (1989) the cn2 induction algorithm. machine learning 3(4):261-283. cn2 algorithm description v t e\n",
      "Cleaned Token After =  bestconditionexpression clark , p. niblett , ( 1989 ) cn2 induction algorithm . machine learning 3 ( 4 ) :261-283. cn2 algorithm description v e \n",
      "Cleaned Token After Stem =  bestconditionexpress clark , p. niblett , ( 1989 ) cn2 induct algorithm . machin learn 3 ( 4 ) :261-283. cn2 algorithm descript v e \n",
      "Cleaned Token Before =  cleansing. other relevant formulations include denormalization prior to machine learning modeling (informally denoting moving data to a \"wide form\" where all\n",
      "Cleaned Token After =  cleansing . relevant formulations include denormalization prior machine learning modeling ( informally denoting moving data `` wide form '' \n",
      "Cleaned Token After Stem =  cleans . relev formul includ denorm prior machin learn model ( inform denot move data `` wide form `` \n",
      "Cleaned Token Before =  under the gnu general public license.\" additive smoothing boosting (machine learning) decision stump principal component regression regularization (mathematics)\n",
      "Cleaned Token After =  gnu general public license . '' additive smoothing boosting ( machine learning ) decision stump principal component regression regularization ( mathematics ) \n",
      "Cleaned Token After Stem =  gnu gener public licens . `` addit smooth boost ( machin learn ) decis stump princip compon regress regular ( mathemat ) \n",
      "Cleaned Token Before =  form of automated computational detection, using computer vision and machine learning. self-report surveys typically consist of a set of questions given\n",
      "Cleaned Token After =  form automated computational detection , using computer vision machine learning . self-report surveys typically consist set questions given \n",
      "Cleaned Token After Stem =  form autom comput detect , use comput vision machin learn . self-report survey typic consist set question given \n",
      "Cleaned Token Before =  or .html, file extension for html hierarchical temporal memory, a machine learning mode htm personenvervoer, the hague, netherlands, public transport\n",
      "Cleaned Token After =  .html , file extension html hierarchical temporal memory , machine learning mode htm personenvervoer , hague , netherlands , public transport \n",
      "Cleaned Token After Stem =  .html , file extens html hierarch tempor memori , machin learn mode htm personenvervo , hagu , netherland , public transport \n",
      "Cleaned Token Before =  convolution compute kernel, in gpgpu programming kernel method, in machine learning in numerical analysis, a subroutine that performs a common numerical\n",
      "Cleaned Token After =  convolution compute kernel , gpgpu programming kernel method , machine learning numerical analysis , subroutine performs common numerical \n",
      "Cleaned Token After Stem =  convolut comput kernel , gpgpu program kernel method , machin learn numer analysi , subroutin perform common numer \n",
      "Cleaned Token Before =  anti-money laundering technology. the company uses artificial intelligence, machine learning and natural language processing to help regulated organisations manage\n",
      "Cleaned Token After =  anti-money laundering technology . company uses artificial intelligence , machine learning natural language processing help regulated organisations manage \n",
      "Cleaned Token After Stem =  anti-money launder technolog . compani use artifici intellig , machin learn natur languag process help regul organis manag \n",
      "Cleaned Token Before =  systems, communication systems, logistics and transportation, machine learning, etc. the objective of the stochastic scheduling problems can be regular\n",
      "Cleaned Token After =  systems , communication systems , logistics transportation , machine learning , etc . objective stochastic scheduling problems regular \n",
      "Cleaned Token After Stem =  system , commun system , logist transport , machin learn , etc . object stochast schedul problem regular \n",
      "Cleaned Token Before =  notebook interfaces are widely used for statistics, data science, machine learning, and computer algebra. at the notebook core is the idea of literate\n",
      "Cleaned Token After =  notebook interfaces widely used statistics , data science , machine learning , computer algebra . notebook core idea literate \n",
      "Cleaned Token After Stem =  notebook interfac wide use statist , data scienc , machin learn , comput algebra . notebook core idea liter \n",
      "Cleaned Token Before =  in machine learning, the delta rule is a gradient descent learning rule for updating the weights of the inputs to artificial neurons in a single-layer\n",
      "Cleaned Token After =  machine learning , delta rule gradient descent learning rule updating weights inputs artificial neurons single-layer \n",
      "Cleaned Token After Stem =  machin learn , delta rule gradient descent learn rule updat weight input artifici neuron single-lay \n",
      "Cleaned Token Before =  online education. a distance learning program can be completely distance learning, or a combination of distance learning and traditional classroom instruction\n",
      "Cleaned Token After =  online education . distance learning program completely distance learning , combination distance learning traditional classroom instruction \n",
      "Cleaned Token After Stem =  onlin educ . distanc learn program complet distanc learn , combin distanc learn tradit classroom instruct \n",
      "Cleaned Token Before =  algorithms to easily swap functions of varying complexity. in typical machine learning algorithms, these functions produce a scalar output. recent development\n",
      "Cleaned Token After =  algorithms easily swap functions varying complexity . typical machine learning algorithms , functions produce scalar output . recent development \n",
      "Cleaned Token After Stem =  algorithm easili swap function vari complex . typic machin learn algorithm , function produc scalar output . recent develop \n",
      "Cleaned Token Before =  sometimes styled as the microsoft cognitive toolkit, is a deprecated deep learning framework developed by microsoft research. microsoft cognitive toolkit\n",
      "Cleaned Token After =  sometimes styled microsoft cognitive toolkit , deprecated deep learning framework developed microsoft research . microsoft cognitive toolkit \n",
      "Cleaned Token After Stem =  sometim style microsoft cognit toolkit , deprec deep learn framework develop microsoft research . microsoft cognit toolkit \n",
      "Cleaned Token Before =  (and \"less robust\" logic) can be applied to learning algorithms. valiant essentially redefines machine learning as evolutionary. in general use, ecorithms\n",
      "Cleaned Token After =  ( `` less robust '' logic ) applied learning algorithms . valiant essentially redefines machine learning evolutionary . general use , ecorithms \n",
      "Cleaned Token After Stem =  ( `` less robust `` logic ) appli learn algorithm . valiant essenti redefin machin learn evolutionari . gener use , ecorithm \n",
      "Cleaned Token Before =  neurocomputing publishes articles in the field of machine learning and articial intelligence systems. the journal is published by elsevier. it is abstracted\n",
      "Cleaned Token After =  neurocomputing publishes articles field machine learning articial intelligence systems . journal published elsevier . abstracted \n",
      "Cleaned Token After Stem =  neurocomput publish articl field machin learn artici intellig system . journal publish elsevi . abstract \n",
      "Cleaned Token Before =  trax aims to deliver its retail watch image recognition product and machine learning capability to retailers to provide real-time shelf insights, such as\n",
      "Cleaned Token After =  trax aims deliver retail watch image recognition product machine learning capability retailers provide real-time shelf insights , \n",
      "Cleaned Token After Stem =  trax aim deliv retail watch imag recognit product machin learn capabl retail provid real-tim shelf insight , \n",
      "Cleaned Token Before =  announced that giannandrea had been appointed senior vice president of machine learning and artificial intelligence strategy at apple, the department rumored\n",
      "Cleaned Token After =  announced giannandrea appointed senior vice president machine learning artificial intelligence strategy apple , department rumored \n",
      "Cleaned Token After Stem =  announc giannandrea appoint senior vice presid machin learn artifici intellig strategi appl , depart rumor \n",
      "Cleaned Token Before =  sleep-learning (also known as hypnopædia, or hypnopedia) is an attempt to convey information to a sleeping person, typically by playing a sound recording\n",
      "Cleaned Token After =  sleep-learning ( also known hypnopædia , hypnopedia ) attempt convey information sleeping person , typically playing sound recording \n",
      "Cleaned Token After Stem =  sleep-learn ( also known hypnopædia , hypnopedia ) attempt convey inform sleep person , typic play sound record \n",
      "Cleaned Token Before =  term text analytics describes a set of linguistic, statistical, and machine learning techniques that model and structure the information content of textual\n",
      "Cleaned Token After =  term text analytics describes set linguistic , statistical , machine learning techniques model structure information content textual \n",
      "Cleaned Token After Stem =  term text analyt describ set linguist , statist , machin learn techniqu model structur inform content textual \n",
      "Cleaned Token Before =  extremal ensemble learning (eel) is a machine learning algorithmic paradigm for graph partitioning. eel creates an ensemble of partitions and then uses\n",
      "Cleaned Token After =  extremal ensemble learning ( eel ) machine learning algorithmic paradigm graph partitioning . eel creates ensemble partitions uses \n",
      "Cleaned Token After Stem =  extrem ensembl learn ( eel ) machin learn algorithm paradigm graph partit . eel creat ensembl partit use \n",
      "Cleaned Token Before =  a bsc in computer science in 2005. while at stanford he focused on machine learning, artificial intelligence, and natural language processing and did research\n",
      "Cleaned Token After =  bsc computer science 2005. stanford focused machine learning , artificial intelligence , natural language processing research \n",
      "Cleaned Token After Stem =  bsc comput scienc 2005. stanford focus machin learn , artifici intellig , natur languag process research \n",
      "Cleaned Token Before =  liao, jiaya jia \"deep edge-aware filters\" international conference on machine learning (icml), 2015. jianping shi, li xu, jiaya jia \"just noticeable defocus\n",
      "Cleaned Token After =  liao , jiaya jia `` deep edge-aware filters '' international conference machine learning ( icml ) , 2015. jianping shi , li xu , jiaya jia `` noticeable defocus \n",
      "Cleaned Token After Stem =  liao , jiaya jia `` deep edge-awar filter `` intern confer machin learn ( icml ) , 2015. jianp shi , li xu , jiaya jia `` notic defocu \n",
      "Cleaned Token Before =  large-scale semi-structured storage system. tensorflow, an open-source machine-learning software library. ghemawat was elected to the national academy of engineering\n",
      "Cleaned Token After =  large-scale semi-structured storage system . tensorflow , open-source machine-learning software library . ghemawat elected national academy engineering \n",
      "Cleaned Token After Stem =  large-scal semi-structur storag system . tensorflow , open-sourc machine-learn softwar librari . ghemawat elect nation academi engin \n",
      "Cleaned Token Before =  graduate programs are grounded in principles such as data analytics, machine learning, product management, product design, operations, and supply chain management\n",
      "Cleaned Token After =  graduate programs grounded principles data analytics , machine learning , product management , product design , operations , supply chain management \n",
      "Cleaned Token After Stem =  graduat program ground principl data analyt , machin learn , product manag , product design , oper , suppli chain manag \n",
      "Cleaned Token Before =  throughout north america and europe. in its ltl network, xpo logistics uses machine learning and predictive analytics to improve pricing algorithms and network\n",
      "Cleaned Token After =  throughout north america europe . ltl network , xpo logistics uses machine learning predictive analytics improve pricing algorithms network \n",
      "Cleaned Token After Stem =  throughout north america europ . ltl network , xpo logist use machin learn predict analyt improv price algorithm network \n",
      "Cleaned Token Before =  connectivism is a theoretical framework for understanding learning in a digital age. it emphasizes how internet technologies such as web browsers, search\n",
      "Cleaned Token After =  connectivism theoretical framework understanding learning digital age . emphasizes internet technologies web browsers , search \n",
      "Cleaned Token After Stem =  connectiv theoret framework understand learn digit age . emphas internet technolog web browser , search \n",
      "Cleaned Token Before =  database on human genotypes and phenotypes, and then subject it to machine learning so that it can help develop new ways to fight diseases associated with\n",
      "Cleaned Token After =  database human genotypes phenotypes , subject machine learning help develop new ways fight diseases associated \n",
      "Cleaned Token After Stem =  databas human genotyp phenotyp , subject machin learn help develop new way fight diseas associ \n",
      "Cleaned Token Before =  application of statistics, or to the related fields of probability or machine learning. also included are actuaries and demographers. contents:  a b c d e\n",
      "Cleaned Token After =  application statistics , related fields probability machine learning . also included actuaries demographers . contents : b c e \n",
      "Cleaned Token After Stem =  applic statist , relat field probabl machin learn . also includ actuari demograph . content : b c e \n",
      "Cleaned Token Before =  automata theory is the study of abstract machines and automata, as well as the computational problems that can be solved using them. it is a theory in\n",
      "Cleaned Token After =  automata theory study abstract machines automata , well computational problems solved using . theory \n",
      "Cleaned Token After Stem =  automata theori studi abstract machin automata , well comput problem solv use . theori \n",
      "Cleaned Token Before =  pedro (2015). the master algorithm: how the quest for the ultimate learning machine will remake our world. basic books. p. 37. isbn 9780465061921. stigler\n",
      "Cleaned Token After =  pedro ( 2015 ) . master algorithm : quest ultimate learning machine remake world . basic books . p. 37. isbn 9780465061921. stigler \n",
      "Cleaned Token After Stem =  pedro ( 2015 ) . master algorithm : quest ultim learn machin remak world . basic book . p. 37. isbn 9780465061921. stigler \n",
      "Cleaned Token Before =  dimensionality reduction that is particularly efficient in statistics, machine learning and algorithms. it was invented by moses charikar, kevin chen and martin\n",
      "Cleaned Token After =  dimensionality reduction particularly efficient statistics , machine learning algorithms . invented moses charikar , kevin chen martin \n",
      "Cleaned Token After Stem =  dimension reduct particularli effici statist , machin learn algorithm . invent mose charikar , kevin chen martin \n",
      "Cleaned Token Before =  to make the solution easier to find. it has been demonstrated that machine learning techniques can be applied to provide initial estimates similar to those\n",
      "Cleaned Token After =  make solution easier find . demonstrated machine learning techniques applied provide initial estimates similar \n",
      "Cleaned Token After Stem =  make solut easier find . demonstr machin learn techniqu appli provid initi estim similar \n",
      "Cleaned Token Before =  in machine learning, manifold regularization is a technique for using the shape of a dataset to constrain the functions that should be learned on that\n",
      "Cleaned Token After =  machine learning , manifold regularization technique using shape dataset constrain functions learned \n",
      "Cleaned Token After Stem =  machin learn , manifold regular techniqu use shape dataset constrain function learn \n",
      "Cleaned Token Before =  processing systems, decision support systems, knowledge management systems, learning management systems, database management systems, and office information\n",
      "Cleaned Token After =  processing systems , decision support systems , knowledge management systems , learning management systems , database management systems , office information \n",
      "Cleaned Token After Stem =  process system , decis support system , knowledg manag system , learn manag system , databas manag system , offic inform \n",
      "Cleaned Token Before =  in statistics and machine learning, discretization refers to the process of converting or partitioning continuous attributes, features or variables to\n",
      "Cleaned Token After =  statistics machine learning , discretization refers process converting partitioning continuous attributes , features variables \n",
      "Cleaned Token After Stem =  statist machin learn , discret refer process convert partit continu attribut , featur variabl \n",
      "Cleaned Token Before =  learning to detect network manipulation. graph deep learning is a method for applying powerful machine learning techniques to network-structured data. the result\n",
      "Cleaned Token After =  learning detect network manipulation . graph deep learning method applying powerful machine learning techniques network-structured data . result \n",
      "Cleaned Token After Stem =  learn detect network manipul . graph deep learn method appli power machin learn techniqu network-structur data . result \n",
      "Cleaned Token Before =  experimentation in the fields of linguistics, cognitive science, and machine learning; for artistic creation; and for language games. some people make constructed\n",
      "Cleaned Token After =  experimentation fields linguistics , cognitive science , machine learning ; artistic creation ; language games . people make constructed \n",
      "Cleaned Token After Stem =  experiment field linguist , cognit scienc , machin learn ; artist creation ; languag game . peopl make construct \n",
      "Cleaned Token Before =  transfer to speed up the automatic hyperparameter optimization process of machine learning algorithms. the method builds a multi-task gaussian process model on\n",
      "Cleaned Token After =  transfer speed automatic hyperparameter optimization process machine learning algorithms . method builds multi-task gaussian process model \n",
      "Cleaned Token After Stem =  transfer speed automat hyperparamet optim process machin learn algorithm . method build multi-task gaussian process model \n",
      "Cleaned Token Before =  1-112gbit/s, 400g ethernet  macs, pcie gen5 controllers and up to 1,760 machine learning processors (mlp) for mathematical operations with variable precision\n",
      "Cleaned Token After =  1-112gbit/s , 400g ethernet macs , pcie gen5 controllers 1,760 machine learning processors ( mlp ) mathematical operations variable precision \n",
      "Cleaned Token After Stem =  1-112gbit/ , 400g ethernet mac , pcie gen5 control 1,760 machin learn processor ( mlp ) mathemat oper variabl precis \n",
      "Cleaned Token Before =  able to apply data-intensive machine learning methods to biological data, such as deep learning (dl), reinforcement learning (rl), and their combination\n",
      "Cleaned Token After =  able apply data-intensive machine learning methods biological data , deep learning ( dl ) , reinforcement learning ( rl ) , combination \n",
      "Cleaned Token After Stem =  abl appli data-intens machin learn method biolog data , deep learn ( dl ) , reinforc learn ( rl ) , combin \n",
      "Cleaned Token Before =  in prediction error is considered learning. the robot then preferentially explores categories in which it is learning (or reducing prediction error) the\n",
      "Cleaned Token After =  prediction error considered learning . robot preferentially explores categories learning ( reducing prediction error ) \n",
      "Cleaned Token After Stem =  predict error consid learn . robot preferenti explor categori learn ( reduc predict error ) \n",
      "Cleaned Token Before =  award in 1976 for creating the machine learning program, am. he has worked on (symbolic, not statistical) machine learning (with his am and eurisko programs)\n",
      "Cleaned Token After =  award 1976 creating machine learning program , . worked ( symbolic , statistical ) machine learning ( eurisko programs ) \n",
      "Cleaned Token After Stem =  award 1976 creat machin learn program , . work ( symbol , statist ) machin learn ( eurisko program ) \n",
      "Cleaned Token Before =  mathematical sciences at new york university known for his work in machine learning, automata theory and algorithms, speech recognition and natural language\n",
      "Cleaned Token After =  mathematical sciences new york university known work machine learning , automata theory algorithms , speech recognition natural language \n",
      "Cleaned Token After Stem =  mathemat scienc new york univers known work machin learn , automata theori algorithm , speech recognit natur languag \n",
      "Cleaned Token Before =  and the director of the new interdisciplinary research center for machine learning at georgia tech (ml@gt). essa obtained his undergraduate degree in\n",
      "Cleaned Token After =  director new interdisciplinary research center machine learning georgia tech ( ml @ gt ) . essa obtained undergraduate degree \n",
      "Cleaned Token After Stem =  director new interdisciplinari research center machin learn georgia tech ( ml @ gt ) . essa obtain undergradu degre \n",
      "Cleaned Token Before =  processors, while more recent models emphasize performance for gaming and machine learning applications, without sacrificing power efficiency. the tegra apx 2500\n",
      "Cleaned Token After =  processors , recent models emphasize performance gaming machine learning applications , without sacrificing power efficiency . tegra apx 2500 \n",
      "Cleaned Token After Stem =  processor , recent model emphas perform game machin learn applic , without sacrif power effici . tegra apx 2500 \n",
      "Cleaned Token Before =  center for big data analytics. his main research interests are in machine learning, data analysis, parallel computing, network analysis, linear algebra\n",
      "Cleaned Token After =  center big data analytics . main research interests machine learning , data analysis , parallel computing , network analysis , linear algebra \n",
      "Cleaned Token After Stem =  center big data analyt . main research interest machin learn , data analysi , parallel comput , network analysi , linear algebra \n",
      "Cleaned Token Before =  partial differential equations, convex and combinatorial optimization, machine learning and statistical inference. daniel cremers received a bachelor's degree\n",
      "Cleaned Token After =  partial differential equations , convex combinatorial optimization , machine learning statistical inference . daniel cremers received bachelor 's degree \n",
      "Cleaned Token After Stem =  partial differenti equat , convex combinatori optim , machin learn statist infer . daniel cremer receiv bachelor 's degre \n",
      "Cleaned Token Before =  in the field of statistical learning theory, matrix regularization generalizes notions of vector regularization to cases where the object to be learned\n",
      "Cleaned Token After =  field statistical learning theory , matrix regularization generalizes notions vector regularization cases object learned \n",
      "Cleaned Token After Stem =  field statist learn theori , matrix regular gener notion vector regular case object learn \n",
      "Cleaned Token Before =  brian d. nord is an american astrophysicist and machine learning researcher at fermi national accelerator laboratory (also known as fermilab or fnal).\n",
      "Cleaned Token After =  brian d. nord american astrophysicist machine learning researcher fermi national accelerator laboratory ( also known fermilab fnal ) . \n",
      "Cleaned Token After Stem =  brian d. nord american astrophysicist machin learn research fermi nation acceler laboratori ( also known fermilab fnal ) . \n",
      "Cleaned Token Before =  features were added. at that time, it said it had raised funds to develop machine learning and ai. expedia became a minority investor in 2017, when traveloka\n",
      "Cleaned Token After =  features added . time , said raised funds develop machine learning ai . expedia became minority investor 2017 , traveloka \n",
      "Cleaned Token After Stem =  featur ad . time , said rais fund develop machin learn ai . expedia becam minor investor 2017 , traveloka \n",
      "Cleaned Token Before =  maximum entropy rate criterion may be used for feature selection in machine learning. since a stochastic process defined by a markov chain that is irreducible\n",
      "Cleaned Token After =  maximum entropy rate criterion may used feature selection machine learning . since stochastic process defined markov chain irreducible \n",
      "Cleaned Token After Stem =  maximum entropi rate criterion may use featur select machin learn . sinc stochast process defin markov chain irreduc \n",
      "Cleaned Token Before =  and information technologies/dual degree portugal phd in machine learning phd in machine learning/neural basis of cognition phd in robotics phd in robotics/neural\n",
      "Cleaned Token After =  information technologies/dual degree portugal phd machine learning phd machine learning/neural basis cognition phd robotics phd robotics/neural \n",
      "Cleaned Token After Stem =  inform technologies/du degre portug phd machin learn phd machin learning/neur basi cognit phd robot phd robotics/neur \n",
      "Cleaned Token Before =  relational learning (srl) framework for modeling probabilistic and relational domains. it is applicable to a variety of machine learning problems, such\n",
      "Cleaned Token After =  relational learning ( srl ) framework modeling probabilistic relational domains . applicable variety machine learning problems , \n",
      "Cleaned Token After Stem =  relat learn ( srl ) framework model probabilist relat domain . applic varieti machin learn problem , \n",
      "Cleaned Token Before =  and attributes bush's machine learning concepts to claude shannon's mechanical mouse and work with \"feedback and machine learning\". altavista dublin core\n",
      "Cleaned Token After =  attributes bush 's machine learning concepts claude shannon 's mechanical mouse work `` feedback machine learning '' . altavista dublin core \n",
      "Cleaned Token After Stem =  attribut bush 's machin learn concept claud shannon 's mechan mous work `` feedback machin learn `` . altavista dublin core \n",
      "Cleaned Token Before =  language, without requiring them previously to have been compiled into a machine language program. an interpreter generally uses one of the following strategies\n",
      "Cleaned Token After =  language , without requiring previously compiled machine language program . interpreter generally uses one following strategies \n",
      "Cleaned Token After Stem =  languag , without requir previous compil machin languag program . interpret gener use one follow strategi \n",
      "Cleaned Token Before =  wider array of adaptive systems such as artificial intelligence and machine learning. neural network simulators are software applications that are used\n",
      "Cleaned Token After =  wider array adaptive systems artificial intelligence machine learning . neural network simulators software applications used \n",
      "Cleaned Token After Stem =  wider array adapt system artifici intellig machin learn . neural network simul softwar applic use \n",
      "Cleaned Token Before =  hidden variables and the data itself. helmholtz machines are usually trained using an unsupervised learning algorithm, such as the wake-sleep algorithm.\n",
      "Cleaned Token After =  hidden variables data . helmholtz machines usually trained using unsupervised learning algorithm , wake-sleep algorithm . \n",
      "Cleaned Token After Stem =  hidden variabl data . helmholtz machin usual train use unsupervis learn algorithm , wake-sleep algorithm . \n",
      "Cleaned Token Before =  moving away from manual checks to a technological solution based on machine learning. the idea was built with four key aims: to help more people gain access\n",
      "Cleaned Token After =  moving away manual checks technological solution based machine learning . idea built four key aims : help people gain access \n",
      "Cleaned Token After Stem =  move away manual check technolog solut base machin learn . idea built four key aim : help peopl gain access \n",
      "Cleaned Token Before =  it online cvat.org. cvat supports the primary tasks of supervised machine learning: object detection, image classification, and image segmentation. cvat\n",
      "Cleaned Token After =  online cvat.org . cvat supports primary tasks supervised machine learning : object detection , image classification , image segmentation . cvat \n",
      "Cleaned Token After Stem =  onlin cvat.org . cvat support primari task supervis machin learn : object detect , imag classif , imag segment . cvat \n",
      "Cleaned Token Before =  is a german-american computer scientist specializing in robotics, machine learning, autonomous systems, and computational neuroscience. born in frankfurt\n",
      "Cleaned Token After =  german-american computer scientist specializing robotics , machine learning , autonomous systems , computational neuroscience . born frankfurt \n",
      "Cleaned Token After Stem =  german-american comput scientist special robot , machin learn , autonom system , comput neurosci . born frankfurt \n",
      "Cleaned Token Before =  into clean and structured formats.\" trifacta utilizes techniques in machine learning, data visualization, human-computer interaction, and parallel processing\n",
      "Cleaned Token After =  clean structured formats . '' trifacta utilizes techniques machine learning , data visualization , human-computer interaction , parallel processing \n",
      "Cleaned Token After Stem =  clean structur format . `` trifacta util techniqu machin learn , data visual , human-comput interact , parallel process \n",
      "Cleaned Token Before =  various areas in mathematical modelling such as operations research, machine learning, and optimization, which are usually implemented using software. supply\n",
      "Cleaned Token After =  various areas mathematical modelling operations research , machine learning , optimization , usually implemented using software . supply \n",
      "Cleaned Token After Stem =  variou area mathemat model oper research , machin learn , optim , usual implement use softwar . suppli \n",
      "Cleaned Token Before =  and give a well-defined output to the end-user. ai does this through machine learning algorithms. these algorithms can recognize patterns in behavior and\n",
      "Cleaned Token After =  give well-defined output end-user . ai machine learning algorithms . algorithms recognize patterns behavior \n",
      "Cleaned Token After Stem =  give well-defin output end-us . ai machin learn algorithm . algorithm recogn pattern behavior \n",
      "Cleaned Token Before =  learning engineering is the systematic application of evidence-based principles and methods from educational technology and the learning sciences to create\n",
      "Cleaned Token After =  learning engineering systematic application evidence-based principles methods educational technology learning sciences create \n",
      "Cleaned Token After Stem =  learn engin systemat applic evidence-bas principl method educ technolog learn scienc creat \n",
      "Cleaned Token Before =  computer science, with particular activity in the fields of machine learning, computational learning theory, algorithmic game theory, and algorithms. avrim\n",
      "Cleaned Token After =  computer science , particular activity fields machine learning , computational learning theory , algorithmic game theory , algorithms . avrim \n",
      "Cleaned Token After Stem =  comput scienc , particular activ field machin learn , comput learn theori , algorithm game theori , algorithm . avrim \n",
      "Cleaned Token Before =  is aiming to create a bridge between art and science using ai and machine learning, virtual reality, infrared systems or even microorganisms. giuseppe\n",
      "Cleaned Token After =  aiming create bridge art science using ai machine learning , virtual reality , infrared systems even microorganisms . giuseppe \n",
      "Cleaned Token After Stem =  aim creat bridg art scienc use ai machin learn , virtual realiti , infrar system even microorgan . giusepp \n",
      "Cleaned Token Before =  in machine learning and information retrieval, the cluster hypothesis is an assumption about the nature of the data handled in those fields, which takes\n",
      "Cleaned Token After =  machine learning information retrieval , cluster hypothesis assumption nature data handled fields , takes \n",
      "Cleaned Token After Stem =  machin learn inform retriev , cluster hypothesi assumpt natur data handl field , take \n",
      "Cleaned Token Before =  stochastic gradient-descent algorithms used in adaptive filtering and machine learning. in adaptive filtering the lms is used to mimic a desired filter by\n",
      "Cleaned Token After =  stochastic gradient-descent algorithms used adaptive filtering machine learning . adaptive filtering lms used mimic desired filter \n",
      "Cleaned Token After Stem =  stochast gradient-desc algorithm use adapt filter machin learn . adapt filter lm use mimic desir filter \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Token Before =  american actor michael i. jordan (born 1956), american researcher in machine learning and artificial intelligence michael jordan (insolvency baron) (born\n",
      "Cleaned Token After =  american actor michael i. jordan ( born 1956 ) , american researcher machine learning artificial intelligence michael jordan ( insolvency baron ) ( born \n",
      "Cleaned Token After Stem =  american actor michael i. jordan ( born 1956 ) , american research machin learn artifici intellig michael jordan ( insolv baron ) ( born \n",
      "Cleaned Token Before =  have been used to: design kernels that allow machine learning algorithms such as support vector machines to learn from string data find likely candidates\n",
      "Cleaned Token After =  used : design kernels allow machine learning algorithms support vector machines learn string data find likely candidates \n",
      "Cleaned Token After Stem =  use : design kernel allow machin learn algorithm support vector machin learn string data find like candid \n",
      "Cleaned Token Before =  machine learning at the university of pretoria. the intention is to foster the development of skills in artificial intelligence and machine learning technology\n",
      "Cleaned Token After =  machine learning university pretoria . intention foster development skills artificial intelligence machine learning technology \n",
      "Cleaned Token After Stem =  machin learn univers pretoria . intent foster develop skill artifici intellig machin learn technolog \n",
      "Cleaned Token Before =  engine provides personalized scientific news-feeds by using proprietary machine learning algorithms to \"aggregate, distill and recommend\" relevant content.\n",
      "Cleaned Token After =  engine provides personalized scientific news-feeds using proprietary machine learning algorithms `` aggregate , distill recommend '' relevant content . \n",
      "Cleaned Token After Stem =  engin provid person scientif news-fe use proprietari machin learn algorithm `` aggreg , distil recommend `` relev content . \n",
      "Cleaned Token Before =  tutor beta, adaptive courseware based on cognitive science principles, machine learning, and openstax content. aiming to compete with major publishers' offerings\n",
      "Cleaned Token After =  tutor beta , adaptive courseware based cognitive science principles , machine learning , openstax content . aiming compete major publishers ' offerings \n",
      "Cleaned Token After Stem =  tutor beta , adapt coursewar base cognit scienc principl , machin learn , openstax content . aim compet major publish ' offer \n",
      "Cleaned Token Before =  usually from a learner corpus. next, machine learning is applied to train classifiers, like support vector machines, for predicting the l1 of unseen texts\n",
      "Cleaned Token After =  usually learner corpus . next , machine learning applied train classifiers , like support vector machines , predicting l1 unseen texts \n",
      "Cleaned Token After Stem =  usual learner corpu . next , machin learn appli train classifi , like support vector machin , predict l1 unseen text \n",
      "Cleaned Token Before =  of study has its historical roots in numerous disciplines including machine learning, experimental psychology and bayesian statistics. as early as the 1860s\n",
      "Cleaned Token After =  study historical roots numerous disciplines including machine learning , experimental psychology bayesian statistics . early 1860s \n",
      "Cleaned Token After Stem =  studi histor root numer disciplin includ machin learn , experiment psycholog bayesian statist . earli 1860 \n",
      "Cleaned Token Before =  patterns (e.g., as specified by regular expressions), approaches that use machine learning techniques (classifiers, topic modeling, etc.) can take contextual\n",
      "Cleaned Token After =  patterns ( e.g. , specified regular expressions ) , approaches use machine learning techniques ( classifiers , topic modeling , etc . ) take contextual \n",
      "Cleaned Token After Stem =  pattern ( e.g . , specifi regular express ) , approach use machin learn techniqu ( classifi , topic model , etc . ) take contextu \n",
      "Cleaned Token Before =  2015 by matias muchnick, pablo zamora and karim pichara and utilizes machine learning to replicate dairy products in plant-based forms. notco is latin america's\n",
      "Cleaned Token After =  2015 matias muchnick , pablo zamora karim pichara utilizes machine learning replicate dairy products plant-based forms . notco latin america 's \n",
      "Cleaned Token After Stem =  2015 matia muchnick , pablo zamora karim pichara util machin learn replic dairi product plant-bas form . notco latin america 's \n",
      "Cleaned Token Before =  statistical risk raschka, sebastian (2019). python machine learning : machine learning and deep learning with python, scikit-learn, and tensorflow 2. birmingham:\n",
      "Cleaned Token After =  statistical risk raschka , sebastian ( 2019 ) . python machine learning : machine learning deep learning python , scikit-learn , tensorflow 2. birmingham : \n",
      "Cleaned Token After Stem =  statist risk raschka , sebastian ( 2019 ) . python machin learn : machin learn deep learn python , scikit-learn , tensorflow 2. birmingham : \n",
      "Cleaned Token Before =  university working on how to operationalize ethical considerations in machine learning engineering practice. a current mozilla fellow, she has been recognized\n",
      "Cleaned Token After =  university working operationalize ethical considerations machine learning engineering practice . current mozilla fellow , recognized \n",
      "Cleaned Token After Stem =  univers work operation ethic consider machin learn engin practic . current mozilla fellow , recogn \n",
      "Cleaned Token Before =  and india. the purpose of odsc events is to discuss data science and machine learning topics, as well as provide training sessions. open data science conference\n",
      "Cleaned Token After =  india . purpose odsc events discuss data science machine learning topics , well provide training sessions . open data science conference \n",
      "Cleaned Token After Stem =  india . purpos odsc event discuss data scienc machin learn topic , well provid train session . open data scienc confer \n",
      "Cleaned Token Before =  reinforcement learning approach to the traveling salesman problem\", proceedings of ml-95, twelfth international conference on machine learning, a. prieditis\n",
      "Cleaned Token After =  reinforcement learning approach traveling salesman problem '' , proceedings ml-95 , twelfth international conference machine learning , a. prieditis \n",
      "Cleaned Token After Stem =  reinforc learn approach travel salesman problem `` , proceed ml-95 , twelfth intern confer machin learn , a. priediti \n",
      "Cleaned Token Before =   ant colonies are also studied and modeled for their relevance in machine learning, complex interactive networks, stochasticity of encounter and interaction\n",
      "Cleaned Token After =  ant colonies also studied modeled relevance machine learning , complex interactive networks , stochasticity encounter interaction \n",
      "Cleaned Token After Stem =  ant coloni also studi model relev machin learn , complex interact network , stochast encount interact \n",
      "Cleaned Token Before =  predictors of mortality in young patients on chronic haemodialysis—a machine learning approach\". nephrology dialysis transplantation. doi:10.1093/ndt/gfaa128\n",
      "Cleaned Token After =  predictors mortality young patients chronic haemodialysis—a machine learning approach '' . nephrology dialysis transplantation . doi:10.1093/ndt/gfaa128 \n",
      "Cleaned Token After Stem =  predictor mortal young patient chronic haemodialysis—a machin learn approach `` . nephrolog dialysi transplant . doi:10.1093/ndt/gfaa128 \n",
      "Cleaned Token Before =  classical artificial neural network models (which are widely used in machine learning for the important task of pattern recognition) with the advantages\n",
      "Cleaned Token After =  classical artificial neural network models ( widely used machine learning important task pattern recognition ) advantages \n",
      "Cleaned Token After Stem =  classic artifici neural network model ( wide use machin learn import task pattern recognit ) advantag \n",
      "Cleaned Token Before =  function, machine learning programmers will use reward shaping to initially give the machine rewards for incremental progress in learning. yann lecun\n",
      "Cleaned Token After =  function , machine learning programmers use reward shaping initially give machine rewards incremental progress learning . yann lecun \n",
      "Cleaned Token After Stem =  function , machin learn programm use reward shape initi give machin reward increment progress learn . yann lecun \n",
      "Cleaned Token Before =  lehnert. the third millennium saw the introduction of systems using machine learning for text classification, such as the ibm watson. however, it is debated\n",
      "Cleaned Token After =  lehnert . third millennium saw introduction systems using machine learning text classification , ibm watson . however , debated \n",
      "Cleaned Token After Stem =  lehnert . third millennium saw introduct system use machin learn text classif , ibm watson . howev , debat \n",
      "Cleaned Token Before =  war machine (james rupert \"rhodey\" rhodes) is a fictional superhero appearing in american comic books published by marvel comics. james rhodes first appeared\n",
      "Cleaned Token After =  war machine ( james rupert `` rhodey '' rhodes ) fictional superhero appearing american comic books published marvel comics . james rhodes first appeared \n",
      "Cleaned Token After Stem =  war machin ( jame rupert `` rhodey `` rhode ) fiction superhero appear american comic book publish marvel comic . jame rhode first appear \n",
      "Cleaned Token Before =  unstructured data, and apply knowledge and actionable insights from data across a broad range of application domains. data science is related to data mining\n",
      "Cleaned Token After =  unstructured data , apply knowledge actionable insights data across broad range application domains . data science related data mining \n",
      "Cleaned Token After Stem =  unstructur data , appli knowledg action insight data across broad rang applic domain . data scienc relat data mine \n",
      "Cleaned Token Before =  a master of science in data science is an interdisciplinary degree program designed to provide studies in scientific methods, processes, and systems to\n",
      "Cleaned Token After =  master science data science interdisciplinary degree program designed provide studies scientific methods , processes , systems \n",
      "Cleaned Token After Stem =  master scienc data scienc interdisciplinari degre program design provid studi scientif method , process , system \n",
      "Cleaned Token Before =  open science data or open research data is a type of open data focused on publishing observations and results of scientific activities available for anyone\n",
      "Cleaned Token After =  open science data open research data type open data focused publishing observations results scientific activities available anyone \n",
      "Cleaned Token After Stem =  open scienc data open research data type open data focus publish observ result scientif activ avail anyon \n",
      "Cleaned Token Before =  visualization computer data processing data preservation data publication data protection data remanence data science data set data structure data warehouse database\n",
      "Cleaned Token After =  visualization computer data processing data preservation data publication data protection data remanence data science data set data structure data warehouse database \n",
      "Cleaned Token After Stem =  visual comput data process data preserv data public data protect data reman data scienc data set data structur data warehous databas \n",
      "Cleaned Token Before =  names, and is used in different business, science, and social science domains. in today's business world, data analysis plays a role in making decisions\n",
      "Cleaned Token After =  names , used different business , science , social science domains . today 's business world , data analysis plays role making decisions \n",
      "Cleaned Token After Stem =  name , use differ busi , scienc , social scienc domain . today 's busi world , data analysi play role make decis \n",
      "Cleaned Token Before =  in computer science, a data structure is a data organization, management, and storage format that enables efficient access and modification. more precisely\n",
      "Cleaned Token After =  computer science , data structure data organization , management , storage format enables efficient access modification . precisely \n",
      "Cleaned Token After Stem =  comput scienc , data structur data organ , manag , storag format enabl effici access modif . precis \n",
      "Cleaned Token Before =  codata is the committee on data of the international science council and was established as icsu committee on data for science and technology in 1966. codata\n",
      "Cleaned Token After =  codata committee data international science council established icsu committee data science technology 1966. codata \n",
      "Cleaned Token After Stem =  codata committe data intern scienc council establish icsu committe data scienc technolog 1966. codata \n",
      "Cleaned Token Before =  in computer science and computer programming, a data type or simply type is an attribute of data which tells the compiler or interpreter how the programmer\n",
      "Cleaned Token After =  computer science computer programming , data type simply type attribute data tells compiler interpreter programmer \n",
      "Cleaned Token After Stem =  comput scienc comput program , data type simpli type attribut data tell compil interpret programm \n",
      "Cleaned Token Before =  the city. big data ethics big data maturity model big memory data curation data defined storage data lineage data philanthropy data science datafication\n",
      "Cleaned Token After =  city . big data ethics big data maturity model big memory data curation data defined storage data lineage data philanthropy data science datafication \n",
      "Cleaned Token After Stem =  citi . big data ethic big data matur model big memori data curat data defin storag data lineag data philanthropi data scienc dataf \n",
      "Cleaned Token Before =  more specific applications. algorithms and data structures have been called the heart of computer science. programming language theory considers approaches\n",
      "Cleaned Token After =  specific applications . algorithms data structures called heart computer science . programming language theory considers approaches \n",
      "Cleaned Token After Stem =  specif applic . algorithm data structur call heart comput scienc . program languag theori consid approach \n",
      "Cleaned Token Before =  some authors that it is both an art and a science. to communicate information clearly and efficiently, data visualization uses statistical graphics, plots\n",
      "Cleaned Token After =  authors art science . communicate information clearly efficiently , data visualization uses statistical graphics , plots \n",
      "Cleaned Token After Stem =  author art scienc . commun inform clearli effici , data visual use statist graphic , plot \n",
      "Cleaned Token Before =  more recent related terms are geographic data science (named after data science) and geographic information science and technology (gisci&t). since its inception\n",
      "Cleaned Token After =  recent related terms geographic data science ( named data science ) geographic information science technology ( gisci & ) . since inception \n",
      "Cleaned Token After Stem =  recent relat term geograph data scienc ( name data scienc ) geograph inform scienc technolog ( gisci & ) . sinc incept \n",
      "Cleaned Token Before =  the nyu center for data science (cds) is a degree-granting graduate institute and research center at new york university. it was established in 2013 by\n",
      "Cleaned Token After =  nyu center data science ( cds ) degree-granting graduate institute research center new york university . established 2013 \n",
      "Cleaned Token After Stem =  nyu center data scienc ( cd ) degree-gr graduat institut research center new york univers . establish 2013 \n",
      "Cleaned Token Before =  the data science institute is a research institute at the imperial college london founded in may 2014. the institute is one of five global institutes at\n",
      "Cleaned Token After =  data science institute research institute imperial college london founded may 2014. institute one five global institutes \n",
      "Cleaned Token After Stem =  data scienc institut research institut imperi colleg london found may 2014. institut one five global institut \n",
      "Cleaned Token Before =  encoded can be text or numeric data. usual data size is from a few bytes up to 1556 bytes. the length of the encoded data depends on the number of cells\n",
      "Cleaned Token After =  encoded text numeric data . usual data size bytes 1556 bytes . length encoded data depends number cells \n",
      "Cleaned Token After Stem =  encod text numer data . usual data size byte 1556 byte . length encod data depend number cell \n",
      "Cleaned Token Before =  institute for data science (bids) is a central hub of research and education within uc berkeley designed to facilitate data-intensive science and earn grants\n",
      "Cleaned Token After =  institute data science ( bids ) central hub research education within uc berkeley designed facilitate data-intensive science earn grants \n",
      "Cleaned Token After Stem =  institut data scienc ( bid ) central hub research educ within uc berkeley design facilit data-intens scienc earn grant \n",
      "Cleaned Token Before =  philosophy behind open data has been long established (for example in the mertonian tradition of science), but the term \"open data\" itself is recent, gaining\n",
      "Cleaned Token After =  philosophy behind open data long established ( example mertonian tradition science ) , term `` open data '' recent , gaining \n",
      "Cleaned Token After Stem =  philosophi behind open data long establish ( exampl mertonian tradit scienc ) , term `` open data `` recent , gain \n",
      "Cleaned Token Before =  often overlooked, remain necessary in natural science. systematic data collection, including discovery science, succeeded natural history, which emerged in\n",
      "Cleaned Token After =  often overlooked , remain necessary natural science . systematic data collection , including discovery science , succeeded natural history , emerged \n",
      "Cleaned Token After Stem =  often overlook , remain necessari natur scienc . systemat data collect , includ discoveri scienc , succeed natur histori , emerg \n",
      "Cleaned Token Before =  data wrangling, sometimes referred to as data munging, is the process of transforming and mapping data from one \"raw\" data form into another format with\n",
      "Cleaned Token After =  data wrangling , sometimes referred data munging , process transforming mapping data one `` raw '' data form another format \n",
      "Cleaned Token After Stem =  data wrangl , sometim refer data mung , process transform map data one `` raw `` data form anoth format \n",
      "Cleaned Token Before =  exploratory data analysis is an approach of analyzing data sets to summarize their main characteristics, often using statistical graphics and other data visualization\n",
      "Cleaned Token After =  exploratory data analysis approach analyzing data sets summarize main characteristics , often using statistical graphics data visualization \n",
      "Cleaned Token After Stem =  exploratori data analysi approach analyz data set summar main characterist , often use statist graphic data visual \n",
      "Cleaned Token Before =  data science africa (dsa) is a non-profit knowledge sharing professional group that aims at bringing together leading researchers and practitioners working\n",
      "Cleaned Token After =  data science africa ( dsa ) non-profit knowledge sharing professional group aims bringing together leading researchers practitioners working \n",
      "Cleaned Token After Stem =  data scienc africa ( dsa ) non-profit knowledg share profession group aim bring togeth lead research practition work \n",
      "Cleaned Token Before =  in a computer science, a graph is an abstract data type that is meant to implement the undirected graph and directed graph concepts from the field of graph\n",
      "Cleaned Token After =  computer science , graph abstract data type meant implement undirected graph directed graph concepts field graph \n",
      "Cleaned Token After Stem =  comput scienc , graph abstract data type meant implement undirect graph direct graph concept field graph \n",
      "Cleaned Token Before =  a data science competition platform is used by businesses to host data science challenges that are hard to solve for one group. historically, crowdsourcing\n",
      "Cleaned Token After =  data science competition platform used businesses host data science challenges hard solve one group . historically , crowdsourcing \n",
      "Cleaned Token After Stem =  data scienc competit platform use busi host data scienc challeng hard solv one group . histor , crowdsourc \n",
      "Cleaned Token Before =  every three years. archival science blank media tax computer data storage computer memory content format data retention data transmission digital preservation\n",
      "Cleaned Token After =  every three years . archival science blank media tax computer data storage computer memory content format data retention data transmission digital preservation \n",
      "Cleaned Token After Stem =  everi three year . archiv scienc blank media tax comput data storag comput memori content format data retent data transmiss digit preserv \n",
      "Cleaned Token Before =   california by dr. margot gerritsen and karen matthys, the women in data science initiative (wids) encourages women from around the world to connect with\n",
      "Cleaned Token After =  california dr. margot gerritsen karen matthys , women data science initiative ( wids ) encourages women around world connect \n",
      "Cleaned Token After Stem =  california dr. margot gerritsen karen matthi , women data scienc initi ( wid ) encourag women around world connect \n",
      "Cleaned Token Before =  though closely allied field. computer science, computational science, data science, quantitative biology, operations research, control theory, cryptology\n",
      "Cleaned Token After =  though closely allied field . computer science , computational science , data science , quantitative biology , operations research , control theory , cryptology \n",
      "Cleaned Token After Stem =  though close alli field . comput scienc , comput scienc , data scienc , quantit biolog , oper research , control theori , cryptolog \n",
      "Cleaned Token Before =  technology and computer science, the pattern of applying one-way mutations on an immutable data state is called unidirectional data flow. separation of state\n",
      "Cleaned Token After =  technology computer science , pattern applying one-way mutations immutable data state called unidirectional data flow . separation state \n",
      "Cleaned Token After Stem =  technolog comput scienc , pattern appli one-way mutat immut data state call unidirect data flow . separ state \n",
      "Cleaned Token Before =  computing disciplines include computer engineering, computer science, cybersecurity, data science, information systems, information technology and software\n",
      "Cleaned Token After =  computing disciplines include computer engineering , computer science , cybersecurity , data science , information systems , information technology software \n",
      "Cleaned Token After Stem =  comput disciplin includ comput engin , comput scienc , cybersecur , data scienc , inform system , inform technolog softwar \n",
      "Cleaned Token Before =  programming languages for scientific computing (data science, machine learning applications, large-scale data processing, predictive analytics, etc.), that\n",
      "Cleaned Token After =  programming languages scientific computing ( data science , machine learning applications , large-scale data processing , predictive analytics , etc . ) , \n",
      "Cleaned Token After Stem =  program languag scientif comput ( data scienc , machin learn applic , large-scal data process , predict analyt , etc . ) , \n",
      "Cleaned Token Before =  applied data science (cads) is a private company established in malaysia in october 2015. cads's professed purpose is to nurture a new generation of data scientists\n",
      "Cleaned Token After =  applied data science ( cads ) private company established malaysia october 2015. cads 's professed purpose nurture new generation data scientists \n",
      "Cleaned Token After Stem =  appli data scienc ( cad ) privat compani establish malaysia octob 2015. cad 's profess purpos nurtur new gener data scientist \n",
      "Cleaned Token Before =  trust the data, and that can only come with incremental validation. automate as many stages of the data flow as possible including bi, data science, and analytics\n",
      "Cleaned Token After =  trust data , come incremental validation . automate many stages data flow possible including bi , data science , analytics \n",
      "Cleaned Token After Stem =  trust data , come increment valid . autom mani stage data flow possibl includ bi , data scienc , analyt \n",
      "Cleaned Token Before =  watson studio, formerly data science experience or dsx, is ibm’s software platform for data science. the platform consists of a workspace that includes\n",
      "Cleaned Token After =  watson studio , formerly data science experience dsx , ibm ’ software platform data science . platform consists workspace includes \n",
      "Cleaned Token After Stem =  watson studio , formerli data scienc experi dsx , ibm ’ softwar platform data scienc . platform consist workspac includ \n",
      "Cleaned Token Before =  full stack development and more on producing data scientists and data engineers are known as data science bootcamps. coding bootcamps may be selective\n",
      "Cleaned Token After =  full stack development producing data scientists data engineers known data science bootcamps . coding bootcamps may selective \n",
      "Cleaned Token After Stem =  full stack develop produc data scientist data engin known data scienc bootcamp . code bootcamp may select \n",
      "Cleaned Token Before =  with the older view of data systems as mere back-end it systems. more recently, with the adoption of data science the chief data officer is sometimes looked\n",
      "Cleaned Token After =  older view data systems mere back-end systems . recently , adoption data science chief data officer sometimes looked \n",
      "Cleaned Token After Stem =  older view data system mere back-end system . recent , adopt data scienc chief data offic sometim look \n",
      "Cleaned Token Before =  called \"kernels\". notebook interfaces are widely used for statistics, data science, machine learning, and computer algebra. at the notebook core is the\n",
      "Cleaned Token After =  called `` kernels '' . notebook interfaces widely used statistics , data science , machine learning , computer algebra . notebook core \n",
      "Cleaned Token After Stem =  call `` kernel `` . notebook interfac wide use statist , data scienc , machin learn , comput algebra . notebook core \n",
      "Cleaned Token Before =  that any given database transaction must change affected data only in allowed ways. any data written to the database must be valid according to all defined\n",
      "Cleaned Token After =  given database transaction must change affected data allowed ways . data written database must valid according defined \n",
      "Cleaned Token After Stem =  given databas transact must chang affect data allow way . data written databas must valid accord defin \n",
      "Cleaned Token Before =  citizens, and readers to have some data literacy. the concept is associated with data science, which is concerned with data analysis, usually through automated\n",
      "Cleaned Token After =  citizens , readers data literacy . concept associated data science , concerned data analysis , usually automated \n",
      "Cleaned Token After Stem =  citizen , reader data literaci . concept associ data scienc , concern data analysi , usual autom \n",
      "Cleaned Token Before =  secondary data refers to data that is collected by someone other than the primary user. common sources of secondary data for social science include censuses\n",
      "Cleaned Token After =  secondary data refers data collected someone primary user . common sources secondary data social science include censuses \n",
      "Cleaned Token After Stem =  secondari data refer data collect someon primari user . common sourc secondari data social scienc includ census \n",
      "Cleaned Token Before =  data sharing because transparency and openness are considered by many to be part of the scientific method. a number of funding agencies and science journals\n",
      "Cleaned Token After =  data sharing transparency openness considered many part scientific method . number funding agencies science journals \n",
      "Cleaned Token After Stem =  data share transpar open consid mani part scientif method . number fund agenc scienc journal \n",
      "Cleaned Token Before =  the textbook data science and predictive analytics: biomedical and health applications using r, authored by ivo d. dinov, was published in august 2018\n",
      "Cleaned Token After =  textbook data science predictive analytics : biomedical health applications using r , authored ivo d. dinov , published august 2018 \n",
      "Cleaned Token After Stem =  textbook data scienc predict analyt : biomed health applic use r , author ivo d. dinov , publish august 2018 \n",
      "Cleaned Token Before =  gisaid is a global science initiative and primary source established in 2008 that provides open-access to genomic data of influenza viruses and the coronavirus\n",
      "Cleaned Token After =  gisaid global science initiative primary source established 2008 provides open-access genomic data influenza viruses coronavirus \n",
      "Cleaned Token After Stem =  gisaid global scienc initi primari sourc establish 2008 provid open-access genom data influenza virus coronaviru \n",
      "Cleaned Token Before =  information science is associated with computer science, data science, psychology, technology, and intelligence agencies. however, information science also incorporates\n",
      "Cleaned Token After =  information science associated computer science , data science , psychology , technology , intelligence agencies . however , information science also incorporates \n",
      "Cleaned Token After Stem =  inform scienc associ comput scienc , data scienc , psycholog , technolog , intellig agenc . howev , inform scienc also incorpor \n",
      "Cleaned Token Before =  of michigan. she serves as the associate director for quantitative data sciences at university of michigan rogel cancer center. she is the chair elect\n",
      "Cleaned Token After =  michigan . serves associate director quantitative data sciences university michigan rogel cancer center . chair elect \n",
      "Cleaned Token After Stem =  michigan . serv associ director quantit data scienc univers michigan rogel cancer center . chair elect \n",
      "Cleaned Token Before =  learning, statistics, and database systems. data mining is an interdisciplinary subfield of computer science and statistics with an overall goal to extract\n",
      "Cleaned Token After =  learning , statistics , database systems . data mining interdisciplinary subfield computer science statistics overall goal extract \n",
      "Cleaned Token After Stem =  learn , statist , databas system . data mine interdisciplinari subfield comput scienc statist overal goal extract \n",
      "Cleaned Token Before =  research-like access to data data-driven science, an interdisciplinary field of scientific methods to extract knowledge from data data-driven control systems\n",
      "Cleaned Token After =  research-like access data data-driven science , interdisciplinary field scientific methods extract knowledge data data-driven control systems \n",
      "Cleaned Token After Stem =  research-lik access data data-driven scienc , interdisciplinari field scientif method extract knowledg data data-driven control system \n",
      "Cleaned Token Before =  commons attribution 4.0 international license. data science under gdpr with pseudonymization in the data pipeline published by dativa, 17 april 2018 \"introduction\n",
      "Cleaned Token After =  commons attribution 4.0 international license . data science gdpr pseudonymization data pipeline published dativa , 17 april 2018 `` introduction \n",
      "Cleaned Token After Stem =  common attribut 4.0 intern licens . data scienc gdpr pseudonym data pipelin publish dativa , 17 april 2018 `` introduct \n",
      "Cleaned Token Before =  panigassi in 2013 when they were writing a book about data science, data analytics, data management and how data practitioners were able to achieve their goals\n",
      "Cleaned Token After =  panigassi 2013 writing book data science , data analytics , data management data practitioners able achieve goals \n",
      "Cleaned Token After Stem =  panigassi 2013 write book data scienc , data analyt , data manag data practition abl achiev goal \n",
      "Cleaned Token Before =  faculty science ltd (formerly asi data science and advanced skills initiative ltd.) is a british technology company based in london, founded in 2014, by\n",
      "Cleaned Token After =  faculty science ltd ( formerly asi data science advanced skills initiative ltd. ) british technology company based london , founded 2014 , \n",
      "Cleaned Token After Stem =  faculti scienc ltd ( formerli asi data scienc advanc skill initi ltd. ) british technolog compani base london , found 2014 , \n",
      "Cleaned Token Before =  science data center (issdc) is a ground segment facility being established by isro in october 2008, as the primary data center for the payload data archives\n",
      "Cleaned Token After =  science data center ( issdc ) ground segment facility established isro october 2008 , primary data center payload data archives \n",
      "Cleaned Token After Stem =  scienc data center ( issdc ) ground segment facil establish isro octob 2008 , primari data center payload data archiv \n",
      "Cleaned Token Before =  programs also cover emerging computing fields like image processing, data science, robotics, bio-inspired computing, computational biology, autonomic computing\n",
      "Cleaned Token After =  programs also cover emerging computing fields like image processing , data science , robotics , bio-inspired computing , computational biology , autonomic computing \n",
      "Cleaned Token After Stem =  program also cover emerg comput field like imag process , data scienc , robot , bio-inspir comput , comput biolog , autonom comput \n",
      "Cleaned Token Before =  principled and controlled data creation, maintenance, and management, together with the capacity to add value to data\". in science, data curation may indicate\n",
      "Cleaned Token After =  principled controlled data creation , maintenance , management , together capacity add value data '' . science , data curation may indicate \n",
      "Cleaned Token After Stem =  principl control data creation , mainten , manag , togeth capac add valu data `` . scienc , data curat may indic \n",
      "Cleaned Token Before =  in computer science, an associative array, map, symbol table, or dictionary is an abstract data type composed of a collection of (key, value) pairs, such\n",
      "Cleaned Token After =  computer science , associative array , map , symbol table , dictionary abstract data type composed collection ( key , value ) pairs , \n",
      "Cleaned Token After Stem =  comput scienc , associ array , map , symbol tabl , dictionari abstract data type compos collect ( key , valu ) pair , \n",
      "Cleaned Token Before =  software, data science, and computer programming. contents:  a b c d e f g h i j k l m n o p q r s t u v w x y z see also references abstract data type (adt)\n",
      "Cleaned Token After =  software , data science , computer programming . contents : b c e f g h j k l n p q r u v w x z see also references abstract data type ( adt ) \n",
      "Cleaned Token After Stem =  softwar , data scienc , comput program . content : b c e f g h j k l n p q r u v w x z see also refer abstract data type ( adt ) \n",
      "Cleaned Token Before =  nasa space science data coordinated archive (nssdca) serves as the permanent archive for nasa space science mission data. \"space science\" includes astronomy\n",
      "Cleaned Token After =  nasa space science data coordinated archive ( nssdca ) serves permanent archive nasa space science mission data . `` space science '' includes astronomy \n",
      "Cleaned Token After Stem =  nasa space scienc data coordin archiv ( nssdca ) serv perman archiv nasa space scienc mission data . `` space scienc `` includ astronomi \n",
      "Cleaned Token Before =  real data. efforts have been made to construct general-purpose synthetic data generators to enable data science experiments. in general, synthetic data has\n",
      "Cleaned Token After =  real data . efforts made construct general-purpose synthetic data generators enable data science experiments . general , synthetic data \n",
      "Cleaned Token After Stem =  real data . effort made construct general-purpos synthet data gener enabl data scienc experi . gener , synthet data \n",
      "Cleaned Token Before =  binary data is data whose unit can take on only two possible states, traditionally labeled as 0 and 1 in accordance with the binary numeral system and\n",
      "Cleaned Token After =  binary data data whose unit take two possible states , traditionally labeled 0 1 accordance binary numeral system \n",
      "Cleaned Token After Stem =  binari data data whose unit take two possibl state , tradit label 0 1 accord binari numer system \n",
      "Cleaned Token Before =  computer science, marshalling or marshaling (us spelling) is the process of transforming the memory representation of an object into a data format suitable\n",
      "Cleaned Token After =  computer science , marshalling marshaling ( us spelling ) process transforming memory representation object data format suitable \n",
      "Cleaned Token After Stem =  comput scienc , marshal marshal ( us spell ) process transform memori represent object data format suitabl \n",
      "Cleaned Token Before =  questions and evaluate outcomes. data collection is a research component in all study fields, including physical and social sciences, humanities, and business\n",
      "Cleaned Token After =  questions evaluate outcomes . data collection research component study fields , including physical social sciences , humanities , business \n",
      "Cleaned Token After Stem =  question evalu outcom . data collect research compon studi field , includ physic social scienc , human , busi \n",
      "Cleaned Token Before =  in computer science, an array data structure, or simply an array, is a data structure consisting of a collection of elements (values or variables), each\n",
      "Cleaned Token After =  computer science , array data structure , simply array , data structure consisting collection elements ( values variables ) , \n",
      "Cleaned Token After Stem =  comput scienc , array data structur , simpli array , data structur consist collect element ( valu variabl ) , \n",
      "Cleaned Token Before =  company's products are used for data science and analytics. the software is designed to make advanced analytics accessible to any data worker. src llc, the predecessor\n",
      "Cleaned Token After =  company 's products used data science analytics . software designed make advanced analytics accessible data worker . src llc , predecessor \n",
      "Cleaned Token After Stem =  compani 's product use data scienc analyt . softwar design make advanc analyt access data worker . src llc , predecessor \n",
      "Cleaned Token Before =  classification of data using machine learning algorithms assigning a level of sensitivity to classified information in computer science, the data type of a piece\n",
      "Cleaned Token After =  classification data using machine learning algorithms assigning level sensitivity classified information computer science , data type piece \n",
      "Cleaned Token After Stem =  classif data use machin learn algorithm assign level sensit classifi inform comput scienc , data type piec \n",
      "Cleaned Token Before =  citizen science (cs; also known as community science, crowd science, crowd-sourced science, civic science, or volunteer monitoring) is scientific research\n",
      "Cleaned Token After =  citizen science ( cs ; also known community science , crowd science , crowd-sourced science , civic science , volunteer monitoring ) scientific research \n",
      "Cleaned Token After Stem =  citizen scienc ( cs ; also known commun scienc , crowd scienc , crowd-sourc scienc , civic scienc , volunt monitor ) scientif research \n",
      "Cleaned Token Before =  data portability is a concept to protect users from having their data stored in \"silos\" or \"walled gardens\" that are incompatible with one another, i\n",
      "Cleaned Token After =  data portability concept protect users data stored `` silos '' `` walled gardens '' incompatible one another , \n",
      "Cleaned Token After Stem =  data portabl concept protect user data store `` silo `` `` wall garden `` incompat one anoth , \n",
      "Cleaned Token Before =  retrieved february 3, 2018. \"navigating regulatory challenges in analytics, data science and ai\" (pdf). sia partners. retrieved march 27, 2019. \"what's the difference\n",
      "Cleaned Token After =  retrieved february 3 , 2018 . `` navigating regulatory challenges analytics , data science ai '' ( pdf ) . sia partners . retrieved march 27 , 2019 . `` 's difference \n",
      "Cleaned Token After Stem =  retriev februari 3 , 2018 . `` navig regulatori challeng analyt , data scienc ai `` ( pdf ) . sia partner . retriev march 27 , 2019 . `` 's differ \n",
      "Cleaned Token Before =  mohawk data sciences corporation (mds) was a 1964-launched company, started by former univac engineers; by 1985 they were struggling to sell-off part\n",
      "Cleaned Token After =  mohawk data sciences corporation ( mds ) 1964-launched company , started former univac engineers ; 1985 struggling sell-off part \n",
      "Cleaned Token After Stem =  mohawk data scienc corpor ( md ) 1964-launch compani , start former univac engin ; 1985 struggl sell-off part \n",
      "Cleaned Token Before =  project \"space science\". thefreedictionary.com. retrieved 2020-08-23. national space science data center (nssdc) – nasa science \"space science | define space\n",
      "Cleaned Token After =  project `` space science '' . thefreedictionary.com . retrieved 2020-08-23. national space science data center ( nssdc ) – nasa science `` space science | define space \n",
      "Cleaned Token After Stem =  project `` space scienc `` . thefreedictionary.com . retriev 2020-08-23. nation space scienc data center ( nssdc ) – nasa scienc `` space scienc | defin space \n",
      "Cleaned Token Before =  in computer science, a set is an abstract data type that can store unique values, without any particular order. it is a computer implementation of the\n",
      "Cleaned Token After =  computer science , set abstract data type store unique values , without particular order . computer implementation \n",
      "Cleaned Token After Stem =  comput scienc , set abstract data type store uniqu valu , without particular order . comput implement \n",
      "Cleaned Token Before =  computing & data sciences, which is an interdisciplinary academic unit that will train students in computing and enable them to combine data science with their\n",
      "Cleaned Token After =  computing & data sciences , interdisciplinary academic unit train students computing enable combine data science \n",
      "Cleaned Token After Stem =  comput & data scienc , interdisciplinari academ unit train student comput enabl combin data scienc \n",
      "Cleaned Token Before =  large number of public ontologies are related to the life sciences. life science data science tools that fail to implement these types of biomedical ontologies\n",
      "Cleaned Token After =  large number public ontologies related life sciences . life science data science tools fail implement types biomedical ontologies \n",
      "Cleaned Token After Stem =  larg number public ontolog relat life scienc . life scienc data scienc tool fail implement type biomed ontolog \n",
      "Cleaned Token Before =  process mining is a family of techniques relating the fields of data science and process management to support the analysis of operational processes based\n",
      "Cleaned Token After =  process mining family techniques relating fields data science process management support analysis operational processes based \n",
      "Cleaned Token After Stem =  process mine famili techniqu relat field data scienc process manag support analysi oper process base \n",
      "Cleaned Token Before =  management of geographic data\". it includes geomatics engineering (and surveying engineering) and is related to geospatial science (also geospatial engineering\n",
      "Cleaned Token After =  management geographic data '' . includes geomatics engineering ( surveying engineering ) related geospatial science ( also geospatial engineering \n",
      "Cleaned Token After Stem =  manag geograph data `` . includ geomat engin ( survey engin ) relat geospati scienc ( also geospati engin \n",
      "Cleaned Token Before =  data or data set(s) for public use thus to make them available to everyone to use as they wish. this practice is an integral part of the open science\n",
      "Cleaned Token After =  data data set ( ) public use thus make available everyone use wish . practice integral part open science \n",
      "Cleaned Token After Stem =  data data set ( ) public use thu make avail everyon use wish . practic integr part open scienc \n",
      "Cleaned Token Before =  vanderplas, jake (2016). \"data manipulations with pandas\". python data science handbook: essential tools for working with data. o'reilly. pp. 97–216.\n",
      "Cleaned Token After =  vanderplas , jake ( 2016 ) . `` data manipulations pandas '' . python data science handbook : essential tools working data . o'reilly . pp . 97–216 . \n",
      "Cleaned Token After Stem =  vanderpla , jake ( 2016 ) . `` data manipul panda `` . python data scienc handbook : essenti tool work data . o'reilli . pp . 97–216 . \n",
      "Cleaned Token Before =  in computer science, data validation is the process of ensuring data has undergone data cleansing to ensure they have, that is, that they are both correct\n",
      "Cleaned Token After =  computer science , data validation process ensuring data undergone data cleansing ensure , , correct \n",
      "Cleaned Token After Stem =  comput scienc , data valid process ensur data undergon data cleans ensur , , correct \n",
      "Cleaned Token Before =  neuroinformatics, bio-inspired computing, theoretical computer science, information systems, data science, information technology, autonomic computing, and behavior\n",
      "Cleaned Token After =  neuroinformatics , bio-inspired computing , theoretical computer science , information systems , data science , information technology , autonomic computing , behavior \n",
      "Cleaned Token After Stem =  neuroinformat , bio-inspir comput , theoret comput scienc , inform system , data scienc , inform technolog , autonom comput , behavior \n",
      "Cleaned Token Before =  norvig web data science award\". common crawl. retrieved july 31, 2014. \"norvig web data science award 2014\". dutch techcentre for life sciences. archived\n",
      "Cleaned Token After =  norvig web data science award '' . common crawl . retrieved july 31 , 2014 . `` norvig web data science award 2014 '' . dutch techcentre life sciences . archived \n",
      "Cleaned Token After Stem =  norvig web data scienc award `` . common crawl . retriev juli 31 , 2014 . `` norvig web data scienc award 2014 `` . dutch techcentr life scienc . archiv \n",
      "Cleaned Token Before =  a data dependency in computer science is a situation in which a program statement (instruction) refers to the data of a preceding statement. in compiler\n",
      "Cleaned Token After =  data dependency computer science situation program statement ( instruction ) refers data preceding statement . compiler \n",
      "Cleaned Token After Stem =  data depend comput scienc situat program statement ( instruct ) refer data preced statement . compil \n",
      "Cleaned Token Before =  dunnhumby is a global customer data science company. the company was formed by husband and wife team edwina dunn and clive humby. humby was a university\n",
      "Cleaned Token After =  dunnhumby global customer data science company . company formed husband wife team edwina dunn clive humby . humby university \n",
      "Cleaned Token After Stem =  dunnhumbi global custom data scienc compani . compani form husband wife team edwina dunn clive humbi . humbi univers \n",
      "Cleaned Token Before =  departments of computer science and electronic systems engineering accepted their first students, the ssrc data bank (later renamed the uk data archive) was established\n",
      "Cleaned Token After =  departments computer science electronic systems engineering accepted first students , ssrc data bank ( later renamed uk data archive ) established \n",
      "Cleaned Token After Stem =  depart comput scienc electron system engin accept first student , ssrc data bank ( later renam uk data archiv ) establish \n",
      "Cleaned Token Before =   mlflow and koalas, popular open source projects that span data engineering, data science and machine learning. databricks develops a web-based platform\n",
      "Cleaned Token After =  mlflow koalas , popular open source projects span data engineering , data science machine learning . databricks develops web-based platform \n",
      "Cleaned Token After Stem =  mlflow koala , popular open sourc project span data engin , data scienc machin learn . databrick develop web-bas platform \n",
      "Cleaned Token Before =  a data model (or datamodel) is an abstract model that organizes elements of data and standardizes how they relate to one another and to the properties\n",
      "Cleaned Token After =  data model ( datamodel ) abstract model organizes elements data standardizes relate one another properties \n",
      "Cleaned Token After Stem =  data model ( datamodel ) abstract model organ element data standard relat one anoth properti \n",
      "Cleaned Token Before =  computer science, an integer is a datum of integral data type, a data type that represents some range of mathematical integers. integral data types may\n",
      "Cleaned Token After =  computer science , integer datum integral data type , data type represents range mathematical integers . integral data types may \n",
      "Cleaned Token After Stem =  comput scienc , integ datum integr data type , data type repres rang mathemat integ . integr data type may \n",
      "Cleaned Token Before =  the general data protection regulation (eu) 2016/679 (gdpr) is a regulation in eu law on data protection and privacy in the european union (eu) and the\n",
      "Cleaned Token After =  general data protection regulation ( eu ) 2016/679 ( gdpr ) regulation eu law data protection privacy european union ( eu ) \n",
      "Cleaned Token After Stem =  gener data protect regul ( eu ) 2016/679 ( gdpr ) regul eu law data protect privaci european union ( eu ) \n",
      "Cleaned Token Before =  the data incubator is a data science education company. it offers corporate data science training and placement services. it is best known for an 8-week\n",
      "Cleaned Token After =  data incubator data science education company . offers corporate data science training placement services . best known 8-week \n",
      "Cleaned Token After Stem =  data incub data scienc educ compani . offer corpor data scienc train placement servic . best known 8-week \n",
      "Cleaned Token Before =  the icahn institute for data science and genomic technology is a biomedical and genomics research institute located in new york, ny. it is housed within\n",
      "Cleaned Token After =  icahn institute data science genomic technology biomedical genomics research institute located new york , ny . housed within \n",
      "Cleaned Token After Stem =  icahn institut data scienc genom technolog biomed genom research institut locat new york , ny . hous within \n",
      "Cleaned Token Before =  black swan data is a london-based technology and data science company that produces a social prediction saas platform called trendscope. trendscope uses\n",
      "Cleaned Token After =  black swan data london-based technology data science company produces social prediction saas platform called trendscope . trendscope uses \n",
      "Cleaned Token After Stem =  black swan data london-bas technolog data scienc compani produc social predict saa platform call trendscop . trendscop use \n",
      "Cleaned Token Before =  in computing, a data warehouse (dw or dwh), also known as an enterprise data warehouse (edw), is a system used for reporting and data analysis and is\n",
      "Cleaned Token After =  computing , data warehouse ( dw dwh ) , also known enterprise data warehouse ( edw ) , system used reporting data analysis \n",
      "Cleaned Token After Stem =  comput , data warehous ( dw dwh ) , also known enterpris data warehous ( edw ) , system use report data analysi \n",
      "Cleaned Token Before =  statistics, data transformation is the application of a deterministic mathematical function to each point in a data set—that is, each data point zi is\n",
      "Cleaned Token After =  statistics , data transformation application deterministic mathematical function point data set—that , data point zi \n",
      "Cleaned Token After Stem =  statist , data transform applic determinist mathemat function point data set—that , data point zi \n",
      "Cleaned Token Before =  enables non-experts, who are not familiar with data science, to quickly extract value from their data with a little effort, time, and cost.\"[citation\n",
      "Cleaned Token After =  enables non-experts , familiar data science , quickly extract value data little effort , time , cost . `` [ citation \n",
      "Cleaned Token After Stem =  enabl non-expert , familiar data scienc , quickli extract valu data littl effort , time , cost . `` [ citat \n",
      "Cleaned Token Before =  descriptions of earth science and environmental science data sets and services humanitarian data exchange(hdx) – the humanitarian data exchange (hdx) is an\n",
      "Cleaned Token After =  descriptions earth science environmental science data sets services humanitarian data exchange ( hdx ) – humanitarian data exchange ( hdx ) \n",
      "Cleaned Token After Stem =  descript earth scienc environment scienc data set servic humanitarian data exchang ( hdx ) – humanitarian data exchang ( hdx ) \n",
      "Cleaned Token Before =  theory of science (ivanov, 1972). one framework, dubbed \"zero defect data\" (hansen, 1991) adapts the principles of statistical process control to data quality\n",
      "Cleaned Token After =  theory science ( ivanov , 1972 ) . one framework , dubbed `` zero defect data '' ( hansen , 1991 ) adapts principles statistical process control data quality \n",
      "Cleaned Token After Stem =  theori scienc ( ivanov , 1972 ) . one framework , dub `` zero defect data `` ( hansen , 1991 ) adapt principl statist process control data qualiti \n",
      "Cleaned Token Before =  the data were collected through an app called \"this is your digital life\", developed by data scientist aleksandr kogan and his company global science research\n",
      "Cleaned Token After =  data collected app called `` digital life '' , developed data scientist aleksandr kogan company global science research \n",
      "Cleaned Token After Stem =  data collect app call `` digit life `` , develop data scientist aleksandr kogan compani global scienc research \n",
      "Cleaned Token Before =  in computer science, a data buffer (or just buffer) is a region of a physical memory storage used to temporarily store data while it is being moved from\n",
      "Cleaned Token After =  computer science , data buffer ( buffer ) region physical memory storage used temporarily store data moved \n",
      "Cleaned Token After Stem =  comput scienc , data buffer ( buffer ) region physic memori storag use temporarili store data move \n",
      "Cleaned Token Before =  data integrity is the maintenance of, and the assurance of, data accuracy and consistency over its entire life-cycle and is a critical aspect to the design\n",
      "Cleaned Token After =  data integrity maintenance , assurance , data accuracy consistency entire life-cycle critical aspect design \n",
      "Cleaned Token After Stem =  data integr mainten , assur , data accuraci consist entir life-cycl critic aspect design \n",
      "Cleaned Token Before =  in computer science, data that has several parts, known as a record, can be divided into fields. relational databases arrange data as sets of database\n",
      "Cleaned Token After =  computer science , data several parts , known record , divided fields . relational databases arrange data sets database \n",
      "Cleaned Token After Stem =  comput scienc , data sever part , known record , divid field . relat databas arrang data set databas \n",
      "Cleaned Token Before =  web-based data-science environment, work with other data scientists and machine learning engineers, and enter competitions to solve data science challenges\n",
      "Cleaned Token After =  web-based data-science environment , work data scientists machine learning engineers , enter competitions solve data science challenges \n",
      "Cleaned Token After Stem =  web-bas data-sci environ , work data scientist machin learn engin , enter competit solv data scienc challeng \n",
      "Cleaned Token Before =  often overlooked, remain necessary in natural science. systematic data collection, including discovery science, succeeded natural history, which emerged in\n",
      "Cleaned Token After =  often overlooked , remain necessary natural science . systematic data collection , including discovery science , succeeded natural history , emerged \n",
      "Cleaned Token After Stem =  often overlook , remain necessari natur scienc . systemat data collect , includ discoveri scienc , succeed natur histori , emerg \n",
      "Cleaned Token Before =  in computer science, an operation, function or expression is said to have a side effect if it modifies some state variable value(s) outside its local\n",
      "Cleaned Token After =  computer science , operation , function expression said side effect modifies state variable value ( ) outside local \n",
      "Cleaned Token After Stem =  comput scienc , oper , function express said side effect modifi state variabl valu ( ) outsid local \n",
      "Cleaned Token Before =  telescope science data analysis system (stsdas) is an iraf-based suite of astronomical software for reducing and analyzing astronomical data. it contains\n",
      "Cleaned Token After =  telescope science data analysis system ( stsdas ) iraf-based suite astronomical software reducing analyzing astronomical data . contains \n",
      "Cleaned Token After Stem =  telescop scienc data analysi system ( stsda ) iraf-bas suit astronom softwar reduc analyz astronom data . contain \n",
      "Cleaned Token Before =  predictive science, graph analytics, credit risk analysis, and fraud analytics. since analytics can require extensive computation (see big data), the algorithms\n",
      "Cleaned Token After =  predictive science , graph analytics , credit risk analysis , fraud analytics . since analytics require extensive computation ( see big data ) , algorithms \n",
      "Cleaned Token After Stem =  predict scienc , graph analyt , credit risk analysi , fraud analyt . sinc analyt requir extens comput ( see big data ) , algorithm \n",
      "Cleaned Token Before =  berkeley institute for data science (bids) nyu center for data science uw escience institute plos (public library of science) wikidata asapbio the gordon\n",
      "Cleaned Token After =  berkeley institute data science ( bids ) nyu center data science uw escience institute plos ( public library science ) wikidata asapbio gordon \n",
      "Cleaned Token After Stem =  berkeley institut data scienc ( bid ) nyu center data scienc uw escienc institut plo ( public librari scienc ) wikidata asapbio gordon \n",
      "Cleaned Token Before =  introduced the unityper, which enabled data entry directly to magnetic tape for univac systems. mohawk data sciences subsequently produced an improved magnetic\n",
      "Cleaned Token After =  introduced unityper , enabled data entry directly magnetic tape univac systems . mohawk data sciences subsequently produced improved magnetic \n",
      "Cleaned Token After Stem =  introduc unityp , enabl data entri directli magnet tape univac system . mohawk data scienc subsequ produc improv magnet \n",
      "Cleaned Token Before =  in computer science, a tree is a widely used abstract data type that simulates a hierarchical tree structure, with a root value and subtrees of children\n",
      "Cleaned Token After =  computer science , tree widely used abstract data type simulates hierarchical tree structure , root value subtrees children \n",
      "Cleaned Token After Stem =  comput scienc , tree wide use abstract data type simul hierarch tree structur , root valu subtre children \n",
      "Cleaned Token Before =  mathematical science rather than a branch of mathematics. while many scientific investigations make use of data, statistics is concerned with the use of data in\n",
      "Cleaned Token After =  mathematical science rather branch mathematics . many scientific investigations make use data , statistics concerned use data \n",
      "Cleaned Token After Stem =  mathemat scienc rather branch mathemat . mani scientif investig make use data , statist concern use data \n",
      "Cleaned Token Before =  or more measurements are missing. data often are missing in research in economics, sociology, and political science because governments or private entities\n",
      "Cleaned Token After =  measurements missing . data often missing research economics , sociology , political science governments private entities \n",
      "Cleaned Token After Stem =  measur miss . data often miss research econom , sociolog , polit scienc govern privat entiti \n",
      "Cleaned Token Before =  organization's data assets, including the metadata for those data assets. a data steward may share some responsibilities with a data custodian, such\n",
      "Cleaned Token After =  organization 's data assets , including metadata data assets . data steward may share responsibilities data custodian , \n",
      "Cleaned Token After Stem =  organ 's data asset , includ metadata data asset . data steward may share respons data custodian , \n",
      "Cleaned Token Before =  in computer science and information theory, data differencing or differential compression is producing a technical description of the difference between\n",
      "Cleaned Token After =  computer science information theory , data differencing differential compression producing technical description difference \n",
      "Cleaned Token After Stem =  comput scienc inform theori , data differenc differenti compress produc technic descript differ \n",
      "Cleaned Token Before =  post payments. in science and engineering, the terms data processing and information systems are considered too broad, and the term data processing is typically\n",
      "Cleaned Token After =  post payments . science engineering , terms data processing information systems considered broad , term data processing typically \n",
      "Cleaned Token After Stem =  post payment . scienc engin , term data process inform system consid broad , term data process typic \n",
      "Cleaned Token Before =  measurements in policy and management contexts. scientific data science is the use of data science to analyse research papers. it encompasses both qualitative\n",
      "Cleaned Token After =  measurements policy management contexts . scientific data science use data science analyse research papers . encompasses qualitative \n",
      "Cleaned Token After Stem =  measur polici manag context . scientif data scienc use data scienc analys research paper . encompass qualit \n",
      "Cleaned Token Before =  in data management include: data governance data asset data governance data steward data ethics data architecture data architecture data flows data modeling\n",
      "Cleaned Token After =  data management include : data governance data asset data governance data steward data ethics data architecture data architecture data flows data modeling \n",
      "Cleaned Token After Stem =  data manag includ : data govern data asset data govern data steward data ethic data architectur data architectur data flow data model \n",
      "Cleaned Token Before =  changing the way the module reads the record. data coupling data coupling occurs when modules share data through, for example, parameters. each datum is\n",
      "Cleaned Token After =  changing way module reads record . data coupling data coupling occurs modules share data , example , parameters . datum \n",
      "Cleaned Token After Stem =  chang way modul read record . data coupl data coupl occur modul share data , exampl , paramet . datum \n",
      "Cleaned Token Before =  raw data, that advances in science will emerge. advocates of open data argue that once citizens and civil society organizations have access to data from\n",
      "Cleaned Token After =  raw data , advances science emerge . advocates open data argue citizens civil society organizations access data \n",
      "Cleaned Token After Stem =  raw data , advanc scienc emerg . advoc open data argu citizen civil societi organ access data \n",
      "Cleaned Token Before =  data-intensive computing is a class of parallel computing applications which use a data parallel approach to process large volumes of data typically terabytes\n",
      "Cleaned Token After =  data-intensive computing class parallel computing applications use data parallel approach process large volumes data typically terabytes \n",
      "Cleaned Token After Stem =  data-intens comput class parallel comput applic use data parallel approach process larg volum data typic terabyt \n",
      "Cleaned Token Before =  understanding biological data, in particular when the data sets are large and complex. as an interdisciplinary field of science, bioinformatics combines\n",
      "Cleaned Token After =  understanding biological data , particular data sets large complex . interdisciplinary field science , bioinformatics combines \n",
      "Cleaned Token After Stem =  understand biolog data , particular data set larg complex . interdisciplinari field scienc , bioinformat combin \n",
      "Cleaned Token Before =  american mathematician, data scientist, and author. she is the founder of the blog mathbabe.org and has written books on data science, including the new york\n",
      "Cleaned Token After =  american mathematician , data scientist , author . founder blog mathbabe.org written books data science , including new york \n",
      "Cleaned Token After Stem =  american mathematician , data scientist , author . founder blog mathbabe.org written book data scienc , includ new york \n",
      "Cleaned Token Before =  data transmission and data reception (or, more broadly, data communication or digital communications) is the transfer and reception of data (a digital\n",
      "Cleaned Token After =  data transmission data reception ( , broadly , data communication digital communications ) transfer reception data ( digital \n",
      "Cleaned Token After Stem =  data transmiss data recept ( , broadli , data commun digit commun ) transfer recept data ( digit \n",
      "Cleaned Token Before =  parts of the data and then replacing, modifying, or deleting the dirty or coarse data. data cleansing may be performed interactively with data wrangling\n",
      "Cleaned Token After =  parts data replacing , modifying , deleting dirty coarse data . data cleansing may performed interactively data wrangling \n",
      "Cleaned Token After Stem =  part data replac , modifi , delet dirti coars data . data cleans may perform interact data wrangl \n",
      "Cleaned Token Before =  data exchange is the process of taking data structured under a source schema and transforming it into a target schema, so that the target data is an accurate\n",
      "Cleaned Token After =  data exchange process taking data structured source schema transforming target schema , target data accurate \n",
      "Cleaned Token After Stem =  data exchang process take data structur sourc schema transform target schema , target data accur \n",
      "Cleaned Token Before =  entrepreneur in the field of data science and customer-centric business strategies. since 2014, he has been chief data scientist of the consumer insights\n",
      "Cleaned Token After =  entrepreneur field data science customer-centric business strategies . since 2014 , chief data scientist consumer insights \n",
      "Cleaned Token After Stem =  entrepreneur field data scienc customer-centr busi strategi . sinc 2014 , chief data scientist consum insight \n",
      "Cleaned Token Before =  experimental data in science and engineering is data produced by a measurement, test method, experimental design or quasi-experimental design. in clinical\n",
      "Cleaned Token After =  experimental data science engineering data produced measurement , test method , experimental design quasi-experimental design . clinical \n",
      "Cleaned Token After Stem =  experiment data scienc engin data produc measur , test method , experiment design quasi-experiment design . clinic \n",
      "Cleaned Token Before =  of simultaneous computation; data safety in any multitasking or multithreaded environment. concurrency (computer science) – computing using multiple concurrent\n",
      "Cleaned Token After =  simultaneous computation ; data safety multitasking multithreaded environment . concurrency ( computer science ) – computing using multiple concurrent \n",
      "Cleaned Token After Stem =  simultan comput ; data safeti multitask multithread environ . concurr ( comput scienc ) – comput use multipl concurr \n",
      "Cleaned Token Before =  drew conway is an american data scientist known for his venn diagram definition of data science as well as applying data science to study terrorism. he is\n",
      "Cleaned Token After =  drew conway american data scientist known venn diagram definition data science well applying data science study terrorism . \n",
      "Cleaned Token After Stem =  drew conway american data scientist known venn diagram definit data scienc well appli data scienc studi terror . \n",
      "Cleaned Token Before =  in july 2020, mediaocean announced the acquisition of chicago-based data science and media technology company 4c insights. mediaocean is managed by ceo\n",
      "Cleaned Token After =  july 2020 , mediaocean announced acquisition chicago-based data science media technology company 4c insights . mediaocean managed ceo \n",
      "Cleaned Token After Stem =  juli 2020 , mediaocean announc acquisit chicago-bas data scienc media technolog compani 4c insight . mediaocean manag ceo \n",
      "Cleaned Token Before =  in that context. – john v. guttag in software engineering and computer science, abstraction is: the process of removing physical, spatial, or temporal\n",
      "Cleaned Token After =  context . – john v. guttag software engineering computer science , abstraction : process removing physical , spatial , temporal \n",
      "Cleaned Token After Stem =  context . – john v. guttag softwar engin comput scienc , abstract : process remov physic , spatial , tempor \n",
      "Cleaned Token Before =  open data science conference, or odsc, is an annual event held in boston, san francisco, brazil, london, and india. the purpose of odsc events is to discuss\n",
      "Cleaned Token After =  open data science conference , odsc , annual event held boston , san francisco , brazil , london , india . purpose odsc events discuss \n",
      "Cleaned Token After Stem =  open data scienc confer , odsc , annual event held boston , san francisco , brazil , london , india . purpos odsc event discuss \n",
      "Cleaned Token Before =  providers. cloudera data science workbench - a data science tool for secure collaboration and model development add-on for cloudera data platform cloudera\n",
      "Cleaned Token After =  providers . cloudera data science workbench - data science tool secure collaboration model development add-on cloudera data platform cloudera \n",
      "Cleaned Token After Stem =  provid . cloudera data scienc workbench - data scienc tool secur collabor model develop add-on cloudera data platform cloudera \n",
      "Cleaned Token Before =  them. data management remix culture open access open data – datasets and databases carrying an explicit data‑capable open license open science wilkinson\n",
      "Cleaned Token After =  . data management remix culture open access open data – datasets databases carrying explicit data‑capable open license open science wilkinson \n",
      "Cleaned Token After Stem =  . data manag remix cultur open access open data – dataset databas carri explicit data‑cap open licens open scienc wilkinson \n",
      "Cleaned Token Before =  achieved in practice by storing the state as data in computer data storage. programs have to transfer data to and from storage devices and have to provide\n",
      "Cleaned Token After =  achieved practice storing state data computer data storage . programs transfer data storage devices provide \n",
      "Cleaned Token After Stem =  achiev practic store state data comput data storag . program transfer data storag devic provid \n",
      "Cleaned Token Before =  in computer science, an object can be a variable, a data structure, a function, or a method, and as such, is a value in memory referenced by an identifier\n",
      "Cleaned Token After =  computer science , object variable , data structure , function , method , , value memory referenced identifier \n",
      "Cleaned Token After Stem =  comput scienc , object variabl , data structur , function , method , , valu memori referenc identifi \n",
      "Cleaned Token Before =  \"categorical encoding using label-encoding and one-hot-encoder\". towards data science. https://towardsdatascience.com/categorical-encoding-using-label-enc\n",
      "Cleaned Token After =  `` categorical encoding using label-encoding one-hot-encoder '' . towards data science . https : //towardsdatascience.com/categorical-encoding-using-label-enc \n",
      "Cleaned Token After Stem =  `` categor encod use label-encod one-hot-encod `` . toward data scienc . http : //towardsdatascience.com/categorical-encoding-using-label-enc \n",
      "Cleaned Token Before =  data dredging (or data fishing, data snooping, data butchery), also known as significance chasing, significance questing, selective inference, and p-hacking\n",
      "Cleaned Token After =  data dredging ( data fishing , data snooping , data butchery ) , also known significance chasing , significance questing , selective inference , p-hacking \n",
      "Cleaned Token After Stem =  data dredg ( data fish , data snoop , data butcheri ) , also known signific chase , signific quest , select infer , p-hack \n",
      "Cleaned Token Before =  computer science, synchronization refers to one of two distinct but related concepts: synchronization of processes, and synchronization of data. process\n",
      "Cleaned Token After =  computer science , synchronization refers one two distinct related concepts : synchronization processes , synchronization data . process \n",
      "Cleaned Token After Stem =  comput scienc , synchron refer one two distinct relat concept : synchron process , synchron data . process \n",
      "Cleaned Token Before =  natural sciences, which are provided as machine-readable data, complemented with a human oriented narrative. the journal was not the first to publish data papers\n",
      "Cleaned Token After =  natural sciences , provided machine-readable data , complemented human oriented narrative . journal first publish data papers \n",
      "Cleaned Token After Stem =  natur scienc , provid machine-read data , complement human orient narr . journal first publish data paper \n",
      "Cleaned Token Before =  data. the difference is that information resolves uncertainty. data can represent redundant symbols, but approaches information through optimal data compression\n",
      "Cleaned Token After =  data . difference information resolves uncertainty . data represent redundant symbols , approaches information optimal data compression \n",
      "Cleaned Token After Stem =  data . differ inform resolv uncertainti . data repres redund symbol , approach inform optim data compress \n",
      "Cleaned Token Before =  discovery, data mining and data science. he is the founder and president of kdnuggets, a discussion and learning website for business analytics, data mining\n",
      "Cleaned Token After =  discovery , data mining data science . founder president kdnuggets , discussion learning website business analytics , data mining \n",
      "Cleaned Token After Stem =  discoveri , data mine data scienc . founder presid kdnugget , discuss learn websit busi analyt , data mine \n",
      "Cleaned Token Before =  of data. it is seen as a part of artificial intelligence. machine learning algorithms build a model based on sample data, known as \"training data\", in\n",
      "Cleaned Token After =  data . seen part artificial intelligence . machine learning algorithms build model based sample data , known `` training data '' , \n",
      "Cleaned Token After Stem =  data . seen part artifici intellig . machin learn algorithm build model base sampl data , known `` train data `` , \n",
      "Cleaned Token Before =  in computer science, coinduction is a technique for defining and proving properties of systems of concurrent interacting objects. coinduction is the mathematical\n",
      "Cleaned Token After =  computer science , coinduction technique defining proving properties systems concurrent interacting objects . coinduction mathematical \n",
      "Cleaned Token After Stem =  comput scienc , coinduct techniqu defin prove properti system concurr interact object . coinduct mathemat \n",
      "Cleaned Token Before =  master of criminal justice master of creative technologies master of data science master of defence studies master of design master of divinity master\n",
      "Cleaned Token After =  master criminal justice master creative technologies master data science master defence studies master design master divinity master \n",
      "Cleaned Token After Stem =  master crimin justic master creativ technolog master data scienc master defenc studi master design master divin master \n",
      "Cleaned Token Before =  support to ursa labs in support of the labs focus on building a new data science runtime powered by apache arrow. in april 2019, rstudio pbc (at the time\n",
      "Cleaned Token After =  support ursa labs support labs focus building new data science runtime powered apache arrow . april 2019 , rstudio pbc ( time \n",
      "Cleaned Token After Stem =  support ursa lab support lab focu build new data scienc runtim power apach arrow . april 2019 , rstudio pbc ( time \n",
      "Cleaned Token Before =  in computer science, a list or sequence is an abstract data type that represents a countable number of ordered values, where the same value may occur\n",
      "Cleaned Token After =  computer science , list sequence abstract data type represents countable number ordered values , value may occur \n",
      "Cleaned Token After Stem =  comput scienc , list sequenc abstract data type repres countabl number order valu , valu may occur \n",
      "Cleaned Token Before =  technology (mit). skoltech’s work is in six areas: data science & artificial intelligence life sciences and biomedicine cutting-edge engineering & advanced\n",
      "Cleaned Token After =  technology ( mit ) . skoltech ’ work six areas : data science & artificial intelligence life sciences biomedicine cutting-edge engineering & advanced \n",
      "Cleaned Token After Stem =  technolog ( mit ) . skoltech ’ work six area : data scienc & artifici intellig life scienc biomedicin cutting-edg engin & advanc \n",
      "Cleaned Token Before =  in computer science, an abstract data type (adt) is a mathematical model for data types. an abstract data type is defined by its behavior (semantics)\n",
      "Cleaned Token After =  computer science , abstract data type ( adt ) mathematical model data types . abstract data type defined behavior ( semantics ) \n",
      "Cleaned Token After Stem =  comput scienc , abstract data type ( adt ) mathemat model data type . abstract data type defin behavior ( semant ) \n",
      "Cleaned Token Before =  sunsentinel.com. 17 august 1994. retrieved 2 november 2011. \"ibm to acquire data sciences\". new straits times. retrieved 29 august 2012. pdma acquires lifepro\n",
      "Cleaned Token After =  sunsentinel.com . 17 august 1994. retrieved 2 november 2011 . `` ibm acquire data sciences '' . new straits times . retrieved 29 august 2012. pdma acquires lifepro \n",
      "Cleaned Token After Stem =  sunsentinel.com . 17 august 1994. retriev 2 novemb 2011 . `` ibm acquir data scienc `` . new strait time . retriev 29 august 2012. pdma acquir lifepro \n",
      "Cleaned Token Before =  in data science and computational power, life scientists have been able to apply data-intensive machine learning methods to biological data, such as\n",
      "Cleaned Token After =  data science computational power , life scientists able apply data-intensive machine learning methods biological data , \n",
      "Cleaned Token After Stem =  data scienc comput power , life scientist abl appli data-intens machin learn method biolog data , \n",
      "Cleaned Token Before =  advocacy and adoption of open access publication, open data, crowdsourcing data, and citizen science. it is inspired in part by the success of open-source\n",
      "Cleaned Token After =  advocacy adoption open access publication , open data , crowdsourcing data , citizen science . inspired part success open-source \n",
      "Cleaned Token After Stem =  advocaci adopt open access public , open data , crowdsourc data , citizen scienc . inspir part success open-sourc \n",
      "Cleaned Token Before =  for statistics and data science. retrieved 22 april 2021. \"what's new in stata?\". stata: software for statistics and data science. statacorp. retrieved\n",
      "Cleaned Token After =  statistics data science . retrieved 22 april 2021 . `` 's new stata ? '' . stata : software statistics data science . statacorp . retrieved \n",
      "Cleaned Token After Stem =  statist data scienc . retriev 22 april 2021 . `` 's new stata ? `` . stata : softwar statist data scienc . statacorp . retriev \n",
      "Cleaned Token Before =  a speaker on business analytics, data mining, data science, and big data. he recently left his role as the chief data officer at barclays bank. fayyad\n",
      "Cleaned Token After =  speaker business analytics , data mining , data science , big data . recently left role chief data officer barclays bank . fayyad \n",
      "Cleaned Token After Stem =  speaker busi analyt , data mine , data scienc , big data . recent left role chief data offic barclay bank . fayyad \n",
      "Cleaned Token Before =  especially those for data storage and retrieval. according to acm europe and informatics europe, informatics is synonymous with computer science and computing\n",
      "Cleaned Token After =  especially data storage retrieval . according acm europe informatics europe , informatics synonymous computer science computing \n",
      "Cleaned Token After Stem =  especi data storag retriev . accord acm europ informat europ , informat synonym comput scienc comput \n",
      "Cleaned Token Before =  each topcoder community, open to every member: design, development, data science, and competitive programming. also, since the end of 2017, topcoder,\n",
      "Cleaned Token After =  topcoder community , open every member : design , development , data science , competitive programming . also , since end 2017 , topcoder , \n",
      "Cleaned Token After Stem =  topcod commun , open everi member : design , develop , data scienc , competit program . also , sinc end 2017 , topcod , \n",
      "Cleaned Token Before =  automation of data preparation, model development, feature engineering, and hyper-parameter optimization oracle accelerated data science (ads) sdk, a python\n",
      "Cleaned Token After =  automation data preparation , model development , feature engineering , hyper-parameter optimization oracle accelerated data science ( ads ) sdk , python \n",
      "Cleaned Token After Stem =  autom data prepar , model develop , featur engin , hyper-paramet optim oracl acceler data scienc ( ad ) sdk , python \n",
      "Cleaned Token Before =  codata, co-data or codata may refer to: committee on data for science and technology, publishers of the codata recommended values of physical constants\n",
      "Cleaned Token After =  codata , co-data codata may refer : committee data science technology , publishers codata recommended values physical constants \n",
      "Cleaned Token After Stem =  codata , co-data codata may refer : committe data scienc technolog , publish codata recommend valu physic constant \n",
      "Cleaned Token Before =  engineering discipline that augments data science with theory from social science, decision theory, and managerial science. its application provides a framework\n",
      "Cleaned Token After =  engineering discipline augments data science theory social science , decision theory , managerial science . application provides framework \n",
      "Cleaned Token After Stem =  engin disciplin augment data scienc theori social scienc , decis theori , manageri scienc . applic provid framework \n",
      "Cleaned Token Before =  rapidminer is a data science software platform developed by the company of the same name that provides an integrated environment for data preparation, machine\n",
      "Cleaned Token After =  rapidminer data science software platform developed company name provides integrated environment data preparation , machine \n",
      "Cleaned Token After Stem =  rapidmin data scienc softwar platform develop compani name provid integr environ data prepar , machin \n",
      "Cleaned Token Before =  data of research facilities, research results etc. it was revised in 2007 under the name revised fields of science and technology. natural sciences physical\n",
      "Cleaned Token After =  data research facilities , research results etc . revised 2007 name revised fields science technology . natural sciences physical \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Token After Stem =  data research facil , research result etc . revis 2007 name revis field scienc technolog . natur scienc physic \n",
      "Cleaned Token Before =  geographic data and information is defined in the iso/tc 211 series of standards as data and information having an implicit or explicit association with\n",
      "Cleaned Token After =  geographic data information defined iso/tc 211 series standards data information implicit explicit association \n",
      "Cleaned Token After Stem =  geograph data inform defin iso/tc 211 seri standard data inform implicit explicit associ \n",
      "Cleaned Token Before =  pangaea - data publisher for earth & environmental science world data center dataone 4tu.centre for research data in the social sciences, data libraries\n",
      "Cleaned Token After =  pangaea - data publisher earth & environmental science world data center dataone 4tu.centre research data social sciences , data libraries \n",
      "Cleaned Token After Stem =  pangaea - data publish earth & environment scienc world data center dataon 4tu.centr research data social scienc , data librari \n",
      "Cleaned Token Before =  peter arthur fox (5 may 1959 – 27 march 2021) was a data science and semantic escience researcher at rensselaer polytechnic institute (rpi), united states\n",
      "Cleaned Token After =  peter arthur fox ( 5 may 1959 – 27 march 2021 ) data science semantic escience researcher rensselaer polytechnic institute ( rpi ) , united states \n",
      "Cleaned Token After Stem =  peter arthur fox ( 5 may 1959 – 27 march 2021 ) data scienc semant escienc research renssela polytechn institut ( rpi ) , unit state \n",
      "Cleaned Token Before =  professor of computer science at the university of rochester and distinguished researcher with goergen institute for data science. he is interested in\n",
      "Cleaned Token After =  professor computer science university rochester distinguished researcher goergen institute data science . interested \n",
      "Cleaned Token After Stem =  professor comput scienc univers rochest distinguish research goergen institut data scienc . interest \n",
      "Cleaned Token Before =  (post-1960) computer systems, all data is digital. data exists in three states: data at rest, data in transit and data in use. data within a computer, in most\n",
      "Cleaned Token After =  ( post-1960 ) computer systems , data digital . data exists three states : data rest , data transit data use . data within computer , \n",
      "Cleaned Token After Stem =  ( post-1960 ) comput system , data digit . data exist three state : data rest , data transit data use . data within comput , \n",
      "Cleaned Token Before =  coding sorts qualitative data into predefined (nomothetic) categories that are reflective of the categories found in objective science. the variety, richness\n",
      "Cleaned Token After =  coding sorts qualitative data predefined ( nomothetic ) categories reflective categories found objective science . variety , richness \n",
      "Cleaned Token After Stem =  code sort qualit data predefin ( nomothet ) categori reflect categori found object scienc . varieti , rich \n",
      "Cleaned Token Before =  a safety data sheet (sds), material safety data sheet (msds), or product safety data sheet (psds) is a document that lists information relating to occupational\n",
      "Cleaned Token After =  safety data sheet ( sds ) , material safety data sheet ( msds ) , product safety data sheet ( psds ) document lists information relating occupational \n",
      "Cleaned Token After Stem =  safeti data sheet ( sd ) , materi safeti data sheet ( msd ) , product safeti data sheet ( psd ) document list inform relat occup \n",
      "Cleaned Token Before =  management science include: business analytics computer science data mining/data science/big data decision analysis decision intelligence engineering financial\n",
      "Cleaned Token After =  management science include : business analytics computer science data mining/data science/big data decision analysis decision intelligence engineering financial \n",
      "Cleaned Token After Stem =  manag scienc includ : busi analyt comput scienc data mining/data science/big data decis analysi decis intellig engin financi \n",
      "Cleaned Token Before =  interdisciplinary data science and master of information and data science (mids) are professional graduate degrees in data science designed to help meet\n",
      "Cleaned Token After =  interdisciplinary data science master information data science ( mids ) professional graduate degrees data science designed help meet \n",
      "Cleaned Token After Stem =  interdisciplinari data scienc master inform data scienc ( mid ) profession graduat degre data scienc design help meet \n",
      "Cleaned Token Before =  1985) is an american data scientist, entrepreneur, and the founder and chief executive officer of the data incubator, a data science training and placement\n",
      "Cleaned Token After =  1985 ) american data scientist , entrepreneur , founder chief executive officer data incubator , data science training placement \n",
      "Cleaned Token After Stem =  1985 ) american data scientist , entrepreneur , founder chief execut offic data incub , data scienc train placement \n",
      "Cleaned Token Before =  panel data and longitudinal data are both multi-dimensional data involving measurements over time. panel data is a subset of longitudinal data where observations\n",
      "Cleaned Token After =  panel data longitudinal data multi-dimensional data involving measurements time . panel data subset longitudinal data observations \n",
      "Cleaned Token After Stem =  panel data longitudin data multi-dimension data involv measur time . panel data subset longitudin data observ \n",
      "Cleaned Token Before =  july 1989) is an american data scientist and geographer, specializing in using geographic information system (gis) data science to track hurricanes, epidemiology\n",
      "Cleaned Token After =  july 1989 ) american data scientist geographer , specializing using geographic information system ( gis ) data science track hurricanes , epidemiology \n",
      "Cleaned Token After Stem =  juli 1989 ) american data scientist geograph , special use geograph inform system ( gi ) data scienc track hurrican , epidemiolog \n",
      "Cleaned Token Before =  of the language in data science. the r packaging system is also used by researchers to create compendia to organise research data, code and report files\n",
      "Cleaned Token After =  language data science . r packaging system also used researchers create compendia organise research data , code report files \n",
      "Cleaned Token After Stem =  languag data scienc . r packag system also use research creat compendia organis research data , code report file \n",
      "Cleaned Token Before =  in computer science, primitive data type is either of the following:[citation needed] a basic type is a data type provided by a programming language as\n",
      "Cleaned Token After =  computer science , primitive data type either following : [ citation needed ] basic type data type provided programming language \n",
      "Cleaned Token After Stem =  comput scienc , primit data type either follow : [ citat need ] basic type data type provid program languag \n",
      "Cleaned Token Before =  practice of data science at the olin business school at washington university in st. louis. she is also a senior fellow at the harvard data science initiative\n",
      "Cleaned Token After =  practice data science olin business school washington university st. louis . also senior fellow harvard data science initiative \n",
      "Cleaned Token After Stem =  practic data scienc olin busi school washington univers st. loui . also senior fellow harvard data scienc initi \n",
      "Cleaned Token Before =  in computer science, a heap is a specialized tree-based data structure which is essentially an almost complete tree that satisfies the heap property: in\n",
      "Cleaned Token After =  computer science , heap specialized tree-based data structure essentially almost complete tree satisfies heap property : \n",
      "Cleaned Token After Stem =  comput scienc , heap special tree-bas data structur essenti almost complet tree satisfi heap properti : \n",
      "Cleaned Token Before =  technology global entrepreneurship & development index data science institute institute for molecular science and engineering francis crick institute imperial\n",
      "Cleaned Token After =  technology global entrepreneurship & development index data science institute institute molecular science engineering francis crick institute imperial \n",
      "Cleaned Token After Stem =  technolog global entrepreneurship & develop index data scienc institut institut molecular scienc engin franci crick institut imperi \n",
      "Cleaned Token Before =  kind of science. champaign, il. p. 1069. isbn 1-57955-008-8. mahmud, salauddin (march 2012). \"an improved data compression method for general data\" (pdf)\n",
      "Cleaned Token After =  kind science . champaign , il . p. 1069. isbn 1-57955-008-8. mahmud , salauddin ( march 2012 ) . `` improved data compression method general data '' ( pdf ) \n",
      "Cleaned Token After Stem =  kind scienc . champaign , il . p. 1069. isbn 1-57955-008-8. mahmud , salauddin ( march 2012 ) . `` improv data compress method gener data `` ( pdf ) \n",
      "Cleaned Token Before =  statistics and in empirical sciences, a data generating process is a process in the real world that \"generates\" the data one is interested in. usually\n",
      "Cleaned Token After =  statistics empirical sciences , data generating process process real world `` generates '' data one interested . usually \n",
      "Cleaned Token After Stem =  statist empir scienc , data gener process process real world `` gener `` data one interest . usual \n",
      "Cleaned Token Before =  used in science and business and apply them to the personal sphere. narratives constitute a symbiotic relationship with bodies of large data. therefore\n",
      "Cleaned Token After =  used science business apply personal sphere . narratives constitute symbiotic relationship bodies large data . therefore \n",
      "Cleaned Token After Stem =  use scienc busi appli person sphere . narr constitut symbiot relationship bodi larg data . therefor \n",
      "Cleaned Token Before =  magnetic tape, as better, more capable computers became available. mohawk data sciences introduced a magnetic tape encoder in 1965, a system marketed as a keypunch\n",
      "Cleaned Token After =  magnetic tape , better , capable computers became available . mohawk data sciences introduced magnetic tape encoder 1965 , system marketed keypunch \n",
      "Cleaned Token After Stem =  magnet tape , better , capabl comput becam avail . mohawk data scienc introduc magnet tape encod 1965 , system market keypunch \n",
      "Cleaned Token Before =  dirty data, also known as rogue data, are inaccurate, incomplete or inconsistent data, especially in a computer system or database. dirty data can contain\n",
      "Cleaned Token After =  dirty data , also known rogue data , inaccurate , incomplete inconsistent data , especially computer system database . dirty data contain \n",
      "Cleaned Token After Stem =  dirti data , also known rogu data , inaccur , incomplet inconsist data , especi comput system databas . dirti data contain \n",
      "Cleaned Token Before =  interactive data visualization software exploratory data analysis machine learning data profiling data visualization foster open science, overview of data exploration\n",
      "Cleaned Token After =  interactive data visualization software exploratory data analysis machine learning data profiling data visualization foster open science , overview data exploration \n",
      "Cleaned Token After Stem =  interact data visual softwar exploratori data analysi machin learn data profil data visual foster open scienc , overview data explor \n",
      "Cleaned Token Before =  data modeling in software engineering is the process of creating a data model for an information system by applying certain formal techniques. data modeling\n",
      "Cleaned Token After =  data modeling software engineering process creating data model information system applying certain formal techniques . data modeling \n",
      "Cleaned Token After Stem =  data model softwar engin process creat data model inform system appli certain formal techniqu . data model \n",
      "Cleaned Token Before =  data is uninterpreted information. data or data may also refer to: data (word), an article about the english-language word data, an alias of french electronic\n",
      "Cleaned Token After =  data uninterpreted information . data data may also refer : data ( word ) , article english-language word data , alias french electronic \n",
      "Cleaned Token After Stem =  data uninterpret inform . data data may also refer : data ( word ) , articl english-languag word data , alia french electron \n",
      "Cleaned Token Before =  science, technology, engineering, and mathematics (stem), previously science, mathematics, engineering, and technology (smet), is a broad term used to\n",
      "Cleaned Token After =  science , technology , engineering , mathematics ( stem ) , previously science , mathematics , engineering , technology ( smet ) , broad term used \n",
      "Cleaned Token After Stem =  scienc , technolog , engin , mathemat ( stem ) , previous scienc , mathemat , engin , technolog ( smet ) , broad term use \n",
      "Cleaned Token Before =  in computer science, a composite data type or compound data type is any data type which can be constructed in a program using the programming language's\n",
      "Cleaned Token After =  computer science , composite data type compound data type data type constructed program using programming language 's \n",
      "Cleaned Token After Stem =  comput scienc , composit data type compound data type data type construct program use program languag 's \n",
      "Cleaned Token Before =  (1999) annual review of biophysics (1972) annual review of biomedical data science (2018) annual review of cancer biology (2017) annual review of cell and\n",
      "Cleaned Token After =  ( 1999 ) annual review biophysics ( 1972 ) annual review biomedical data science ( 2018 ) annual review cancer biology ( 2017 ) annual review cell \n",
      "Cleaned Token After Stem =  ( 1999 ) annual review biophys ( 1972 ) annual review biomed data scienc ( 2018 ) annual review cancer biolog ( 2017 ) annual review cell \n",
      "Cleaned Token Before =  research data archiving is the long-term storage of scholarly research data, including the natural sciences, social sciences, and life sciences. the various\n",
      "Cleaned Token After =  research data archiving long-term storage scholarly research data , including natural sciences , social sciences , life sciences . various \n",
      "Cleaned Token After Stem =  research data archiv long-term storag scholarli research data , includ natur scienc , social scienc , life scienc . variou \n",
      "Cleaned Token Before =  dataism is a term that has been used to describe the mindset or philosophy created by the emerging significance of big data. it was first used by david\n",
      "Cleaned Token After =  dataism term used describe mindset philosophy created emerging significance big data . first used david \n",
      "Cleaned Token After Stem =  dataism term use describ mindset philosophi creat emerg signific big data . first use david \n",
      "Cleaned Token Before =  therefore they refuse to develop data culture. data activism data analysis data governance data science open data research data alliance ramaswamy, poornima\n",
      "Cleaned Token After =  therefore refuse develop data culture . data activism data analysis data governance data science open data research data alliance ramaswamy , poornima \n",
      "Cleaned Token After Stem =  therefor refus develop data cultur . data activ data analysi data govern data scienc open data research data allianc ramaswami , poornima \n",
      "Cleaned Token Before =  protect against bad science and fraudulent data, government research-granting agencies such as the national science foundation, and science journals, including\n",
      "Cleaned Token After =  protect bad science fraudulent data , government research-granting agencies national science foundation , science journals , including \n",
      "Cleaned Token After Stem =  protect bad scienc fraudul data , govern research-gr agenc nation scienc foundat , scienc journal , includ \n",
      "Cleaned Token Before =  computational social science at the oxford internet institute (oii), university of oxford, a turing fellow at the alan turing institute for data science, and a research\n",
      "Cleaned Token After =  computational social science oxford internet institute ( oii ) , university oxford , turing fellow alan turing institute data science , research \n",
      "Cleaned Token After Stem =  comput social scienc oxford internet institut ( oii ) , univers oxford , ture fellow alan ture institut data scienc , research \n",
      "Cleaned Token Before =  science publishing group (spg) is an open-access publisher of academic journals and books established in 2012. it has an address in new york city but\n",
      "Cleaned Token After =  science publishing group ( spg ) open-access publisher academic journals books established 2012. address new york city \n",
      "Cleaned Token After Stem =  scienc publish group ( spg ) open-access publish academ journal book establish 2012. address new york citi \n",
      "Cleaned Token Before =  data degradation is the gradual corruption of computer data due to an accumulation of non-critical failures in a data storage device. the phenomenon is\n",
      "Cleaned Token After =  data degradation gradual corruption computer data due accumulation non-critical failures data storage device . phenomenon \n",
      "Cleaned Token After Stem =  data degrad gradual corrupt comput data due accumul non-crit failur data storag devic . phenomenon \n",
      "Cleaned Token Before =  the isc world data system (isc-wds) was created by the international science council's (isc) general assembly in october 2008. isc-wds goals are to preserve\n",
      "Cleaned Token After =  isc world data system ( isc-wds ) created international science council 's ( isc ) general assembly october 2008. isc-wds goals preserve \n",
      "Cleaned Token After Stem =  isc world data system ( isc-wd ) creat intern scienc council 's ( isc ) gener assembl octob 2008. isc-wd goal preserv \n",
      "Cleaned Token Before =  microsoft's r and python distributions that contain commonly used packages for data science, along with some proprietary packages (e.g. revoscalepy, revoscaler,\n",
      "Cleaned Token After =  microsoft 's r python distributions contain commonly used packages data science , along proprietary packages ( e.g . revoscalepy , revoscaler , \n",
      "Cleaned Token After Stem =  microsoft 's r python distribut contain commonli use packag data scienc , along proprietari packag ( e.g . revoscalepi , revoscal , \n",
      "Cleaned Token Before =  discovery science (also known as discovery-based science) is a scientific methodology which emphasizes analysis of large volumes of experimental data with\n",
      "Cleaned Token After =  discovery science ( also known discovery-based science ) scientific methodology emphasizes analysis large volumes experimental data \n",
      "Cleaned Token After Stem =  discoveri scienc ( also known discovery-bas scienc ) scientif methodolog emphas analysi larg volum experiment data \n",
      "Cleaned Token Before =  in computer science, a circular buffer, circular queue, cyclic buffer or ring buffer is a data structure that uses a single, fixed-size buffer as if it\n",
      "Cleaned Token After =  computer science , circular buffer , circular queue , cyclic buffer ring buffer data structure uses single , fixed-size buffer \n",
      "Cleaned Token After Stem =  comput scienc , circular buffer , circular queue , cyclic buffer ring buffer data structur use singl , fixed-s buffer \n",
      "Cleaned Token Before =  after completing her graduate studies in the decision sciences, kozyrkov studied data science, but was recruited by google before she completed her phd\n",
      "Cleaned Token After =  completing graduate studies decision sciences , kozyrkov studied data science , recruited google completed phd \n",
      "Cleaned Token After Stem =  complet graduat studi decis scienc , kozyrkov studi data scienc , recruit googl complet phd \n",
      "Cleaned Token Before =  towards data science. retrieved 25 september 2018. \"distributed ledger technology: beyond block chain\" (press release). government office for science (uk)\n",
      "Cleaned Token After =  towards data science . retrieved 25 september 2018 . `` distributed ledger technology : beyond block chain '' ( press release ) . government office science ( uk ) \n",
      "Cleaned Token After Stem =  toward data scienc . retriev 25 septemb 2018 . `` distribut ledger technolog : beyond block chain `` ( press releas ) . govern offic scienc ( uk ) \n",
      "Cleaned Token Before =  ordinal data is a categorical, statistical data type where the variables have natural, ordered categories and the distances between the categories is\n",
      "Cleaned Token After =  ordinal data categorical , statistical data type variables natural , ordered categories distances categories \n",
      "Cleaned Token After Stem =  ordin data categor , statist data type variabl natur , order categori distanc categori \n",
      "Cleaned Token Before =  grabs $14 million for its collaborative data science platform\". techcrunch. miller, ron. \"dataiku to enhance data tools with $28 million investment led\n",
      "Cleaned Token After =  grabs $ 14 million collaborative data science platform '' . techcrunch . miller , ron . `` dataiku enhance data tools $ 28 million investment led \n",
      "Cleaned Token After Stem =  grab $ 14 million collabor data scienc platform `` . techcrunch . miller , ron . `` dataiku enhanc data tool $ 28 million invest led \n",
      "Cleaned Token Before =  data lineage includes the data origin, what happens to it and where it moves over time. data lineage gives visibility while greatly simplifying the ability\n",
      "Cleaned Token After =  data lineage includes data origin , happens moves time . data lineage gives visibility greatly simplifying ability \n",
      "Cleaned Token After Stem =  data lineag includ data origin , happen move time . data lineag give visibl greatli simplifi abil \n",
      "Cleaned Token Before =  the auc data science initiative. this initiative offers technical classes to auc students who want to specialize in data science or learn data analysis\n",
      "Cleaned Token After =  auc data science initiative . initiative offers technical classes auc students want specialize data science learn data analysis \n",
      "Cleaned Token After Stem =  auc data scienc initi . initi offer technic class auc student want special data scienc learn data analysi \n",
      "Cleaned Token Before =  computer science and object-oriented programming, a passive data structure (pds, also termed a plain old data structure, or plain old data, pod) is a\n",
      "Cleaned Token After =  computer science object-oriented programming , passive data structure ( pds , also termed plain old data structure , plain old data , pod ) \n",
      "Cleaned Token After Stem =  comput scienc object-ori program , passiv data structur ( pd , also term plain old data structur , plain old data , pod ) \n",
      "Cleaned Token Before =  common data format (cdf) is a library and toolkit that was developed by the national space science data center (nssdc) at nasa starting in 1985. the software\n",
      "Cleaned Token After =  common data format ( cdf ) library toolkit developed national space science data center ( nssdc ) nasa starting 1985. software \n",
      "Cleaned Token After Stem =  common data format ( cdf ) librari toolkit develop nation space scienc data center ( nssdc ) nasa start 1985. softwar \n",
      "Cleaned Token Before =  in computing, data recovery is a process of salvaging (retrieving) inaccessible, lost, corrupted, damaged or formatted data from secondary storage, removable\n",
      "Cleaned Token After =  computing , data recovery process salvaging ( retrieving ) inaccessible , lost , corrupted , damaged formatted data secondary storage , removable \n",
      "Cleaned Token After Stem =  comput , data recoveri process salvag ( retriev ) inaccess , lost , corrupt , damag format data secondari storag , remov \n",
      "Cleaned Token Before =  in computer science, the expressions code as data and data as code refer to the duality between code and data, that allows computers to treat instructions\n",
      "Cleaned Token After =  computer science , expressions code data data code refer duality code data , allows computers treat instructions \n",
      "Cleaned Token After Stem =  comput scienc , express code data data code refer dualiti code data , allow comput treat instruct \n",
      "Cleaned Token Before =  provide usable frameworks for massive, growing data banks; for more, see consilience. the social sciences will for the foreseeable future be composed of\n",
      "Cleaned Token After =  provide usable frameworks massive , growing data banks ; , see consilience . social sciences foreseeable future composed \n",
      "Cleaned Token After Stem =  provid usabl framework massiv , grow data bank ; , see consili . social scienc forese futur compos \n",
      "Cleaned Token Before =  issn 2300-3065. \"digging deeper into data breaches: an exploratory data analysis of hacking breaches over time\". procedia computer science. 151: 1004–1009. 2019-01-01\n",
      "Cleaned Token After =  issn 2300-3065 . `` digging deeper data breaches : exploratory data analysis hacking breaches time '' . procedia computer science . 151 : 1004–1009 . 2019-01-01 \n",
      "Cleaned Token After Stem =  issn 2300-3065 . `` dig deeper data breach : exploratori data analysi hack breach time `` . procedia comput scienc . 151 : 1004–1009 . 2019-01-01 \n",
      "Cleaned Token Before =  analytica. like that company, data propria will focus on behavioral data science, which is essentially the practice of using data to target people with ads\n",
      "Cleaned Token After =  analytica . like company , data propria focus behavioral data science , essentially practice using data target people ads \n",
      "Cleaned Token After Stem =  analytica . like compani , data propria focu behavior data scienc , essenti practic use data target peopl ad \n",
      "Cleaned Token Before =  (2016), \"prov-jsonld: a json and linked data representation for provenance\" (pdf), lecture notes in computer science, springer international publishing, pp\n",
      "Cleaned Token After =  ( 2016 ) , `` prov-jsonld : json linked data representation provenance '' ( pdf ) , lecture notes computer science , springer international publishing , pp \n",
      "Cleaned Token After Stem =  ( 2016 ) , `` prov-jsonld : json link data represent proven `` ( pdf ) , lectur note comput scienc , springer intern publish , pp \n",
      "Cleaned Token Before =  master of science in business analytics (msba) is an interdisciplinary stem graduate professional degree that blends concepts from data science, computer\n",
      "Cleaned Token After =  master science business analytics ( msba ) interdisciplinary stem graduate professional degree blends concepts data science , computer \n",
      "Cleaned Token After Stem =  master scienc busi analyt ( msba ) interdisciplinari stem graduat profession degre blend concept data scienc , comput \n",
      "Cleaned Token Before =  may be used by data brokers center for minorities and people with disabilities in information technology computing computer science data processing health\n",
      "Cleaned Token After =  may used data brokers center minorities people disabilities information technology computing computer science data processing health \n",
      "Cleaned Token After Stem =  may use data broker center minor peopl disabl inform technolog comput comput scienc data process health \n",
      "Cleaned Token Before =  in computer science, a linked data structure is a data structure which consists of a set of data records (nodes) linked together and organized by references\n",
      "Cleaned Token After =  computer science , linked data structure data structure consists set data records ( nodes ) linked together organized references \n",
      "Cleaned Token After Stem =  comput scienc , link data structur data structur consist set data record ( node ) link togeth organ refer \n",
      "Cleaned Token Before =  machine learning company in san francisco, california. howard teaches data science at company singularity university. he is also a young global leader[citation\n",
      "Cleaned Token After =  machine learning company san francisco , california . howard teaches data science company singularity university . also young global leader [ citation \n",
      "Cleaned Token After Stem =  machin learn compani san francisco , california . howard teach data scienc compani singular univers . also young global leader [ citat \n",
      "Cleaned Token Before =  isbn 978-1-85960-653-7. simon s. young (2001). computerized data acquisition and analysis for the life sciences. cambridge university press. isbn 978-0-521-56570-7\n",
      "Cleaned Token After =  isbn 978-1-85960-653-7. simon s. young ( 2001 ) . computerized data acquisition analysis life sciences . cambridge university press . isbn 978-0-521-56570-7 \n",
      "Cleaned Token After Stem =  isbn 978-1-85960-653-7. simon s. young ( 2001 ) . computer data acquisit analysi life scienc . cambridg univers press . isbn 978-0-521-56570-7 \n",
      "Cleaned Token Before =  september 2017, they partnered with final mile to combine data science with behavioral science in march 2018, fractal analytics acquired behavioural architecture\n",
      "Cleaned Token After =  september 2017 , partnered final mile combine data science behavioral science march 2018 , fractal analytics acquired behavioural architecture \n",
      "Cleaned Token After Stem =  septemb 2017 , partner final mile combin data scienc behavior scienc march 2018 , fractal analyt acquir behaviour architectur \n",
      "Cleaned Token Before =  the broad family of ides, architect primarily aims at applications in data science. originally, it primarily focussed on the (statistical) programming language\n",
      "Cleaned Token After =  broad family ides , architect primarily aims applications data science . originally , primarily focussed ( statistical ) programming language \n",
      "Cleaned Token After Stem =  broad famili ide , architect primarili aim applic data scienc . origin , primarili focuss ( statist ) program languag \n",
      "Cleaned Token Before =  as model operations, or modelops. the automated machine learning and data science team (amlds), a small team within ibm research, which was formed to “apply\n",
      "Cleaned Token After =  model operations , modelops . automated machine learning data science team ( amlds ) , small team within ibm research , formed “ apply \n",
      "Cleaned Token After Stem =  model oper , modelop . autom machin learn data scienc team ( amld ) , small team within ibm research , form “ appli \n",
      "Cleaned Token Before =  master of applied data science (mads) degree in partnership with coursera. the degree is designed for people who want to become a data scientist by learning\n",
      "Cleaned Token After =  master applied data science ( mads ) degree partnership coursera . degree designed people want become data scientist learning \n",
      "Cleaned Token After Stem =  master appli data scienc ( mad ) degre partnership coursera . degre design peopl want becom data scientist learn \n",
      "Cleaned Token Before =  (2004-10-28), \"persistent data structures\", handbook of data structures and applications, chapman & hall/crc computer & information science series, chapman and\n",
      "Cleaned Token After =  ( 2004-10-28 ) , `` persistent data structures '' , handbook data structures applications , chapman & hall/crc computer & information science series , chapman \n",
      "Cleaned Token After Stem =  ( 2004-10-28 ) , `` persist data structur `` , handbook data structur applic , chapman & hall/crc comput & inform scienc seri , chapman \n",
      "Cleaned Token Before =  data (lieutenant commander data; mister data) is a character in the fictional star trek franchise. he appears in the television series star trek: the next\n",
      "Cleaned Token After =  data ( lieutenant commander data ; mister data ) character fictional star trek franchise . appears television series star trek : next \n",
      "Cleaned Token After Stem =  data ( lieuten command data ; mister data ) charact fiction star trek franchis . appear televis seri star trek : next \n",
      "Cleaned Token Before =  for statistical computing algorithms for statistical classification data science statistical methods in artificial intelligence free statistical software\n",
      "Cleaned Token After =  statistical computing algorithms statistical classification data science statistical methods artificial intelligence free statistical software \n",
      "Cleaned Token After Stem =  statist comput algorithm statist classif data scienc statist method artifici intellig free statist softwar \n",
      "Cleaned Token Before =  corporation. september 20, 2018. datascience.com, oracle +. \"datascience.com - enterprise data science platform provider\". datascience.com. \"intelligent student\n",
      "Cleaned Token After =  corporation . september 20 , 2018. datascience.com , oracle + . `` datascience.com - enterprise data science platform provider '' . datascience.com . `` intelligent student \n",
      "Cleaned Token After Stem =  corpor . septemb 20 , 2018. datascience.com , oracl + . `` datascience.com - enterpris data scienc platform provid `` . datascience.com . `` intellig student \n",
      "Cleaned Token Before =  university of illinois, but have moved on to offer master of computer science in data science and master of business administration (imba), both from university\n",
      "Cleaned Token After =  university illinois , moved offer master computer science data science master business administration ( imba ) , university \n",
      "Cleaned Token After Stem =  univers illinoi , move offer master comput scienc data scienc master busi administr ( imba ) , univers \n",
      "Cleaned Token Before =  data science in collaboration with suny, binghamton university, new york, usa. the nirma-binghamton university centre of excellence in data science will\n",
      "Cleaned Token After =  data science collaboration suny , binghamton university , new york , usa . nirma-binghamton university centre excellence data science \n",
      "Cleaned Token After Stem =  data scienc collabor suni , binghamton univers , new york , usa . nirma-binghamton univers centr excel data scienc \n",
      "Cleaned Token Before =  science that draws its data from records of past events, as opposed to \"experimental\" or \"operational\" science history of science this disambiguation page\n",
      "Cleaned Token After =  science draws data records past events , opposed `` experimental '' `` operational '' science history science disambiguation page \n",
      "Cleaned Token After Stem =  scienc draw data record past event , oppos `` experiment `` `` oper `` scienc histori scienc disambigu page \n",
      "Cleaned Token Before =  specializations offered in this program are quantitative finance, economics, data science & information systems, and strategy management. the sanctioned annual\n",
      "Cleaned Token After =  specializations offered program quantitative finance , economics , data science & information systems , strategy management . sanctioned annual \n",
      "Cleaned Token After Stem =  special offer program quantit financ , econom , data scienc & inform system , strategi manag . sanction annual \n",
      "Cleaned Token Before =  science and statistics. from the point of view of journalists, it represents \"an overlapping set of competencies drawn from disparate fields\". data journalism\n",
      "Cleaned Token After =  science statistics . point view journalists , represents `` overlapping set competencies drawn disparate fields '' . data journalism \n",
      "Cleaned Token After Stem =  scienc statist . point view journalist , repres `` overlap set compet drawn dispar field `` . data journal \n",
      "Cleaned Token Before =  data administration or data resource management is an organizational function working in the areas of information systems and computer science that plans\n",
      "Cleaned Token After =  data administration data resource management organizational function working areas information systems computer science plans \n",
      "Cleaned Token After Stem =  data administr data resourc manag organiz function work area inform system comput scienc plan \n",
      "Cleaned Token Before =  at new york university's center for data science as a research engineer as part of the moore–sloan data science environment. he received a b.a. in mathematics\n",
      "Cleaned Token After =  new york university 's center data science research engineer part moore–sloan data science environment . received b.a . mathematics \n",
      "Cleaned Token After Stem =  new york univers 's center data scienc research engin part moore–sloan data scienc environ . receiv b.a . mathemat \n",
      "Cleaned Token Before =  in computer programming, a rope, or cord, is a data structure composed of smaller strings that is used to efficiently store and manipulate a very long\n",
      "Cleaned Token After =  computer programming , rope , cord , data structure composed smaller strings used efficiently store manipulate long \n",
      "Cleaned Token After Stem =  comput program , rope , cord , data structur compos smaller string use effici store manipul long \n",
      "Cleaned Token Before =  professor of medicine, health research and policy, and of biomedical data science at stanford university school of medicine and a professor, by courtesy\n",
      "Cleaned Token After =  professor medicine , health research policy , biomedical data science stanford university school medicine professor , courtesy \n",
      "Cleaned Token After Stem =  professor medicin , health research polici , biomed data scienc stanford univers school medicin professor , courtesi \n",
      "Cleaned Token Before =  in computer science, the boolean data type is a data type that has one of two possible values (usually denoted true and false) which is intended to represent\n",
      "Cleaned Token After =  computer science , boolean data type data type one two possible values ( usually denoted true false ) intended represent \n",
      "Cleaned Token After Stem =  comput scienc , boolean data type data type one two possibl valu ( usual denot true fals ) intend repres \n",
      "Cleaned Token Before =  elsevier science bv. kaufman, l., & rousseeuw, p. j. (1990). finding groups in data - an introduction to cluster analysis. a wiley-science publication\n",
      "Cleaned Token After =  elsevier science bv . kaufman , l. , & rousseeuw , p. j . ( 1990 ) . finding groups data - introduction cluster analysis . wiley-science publication \n",
      "Cleaned Token After Stem =  elsevi scienc bv . kaufman , l. , & rousseeuw , p. j . ( 1990 ) . find group data - introduct cluster analysi . wiley-sci public \n",
      "Cleaned Token Before =  university located in kuala lumpur, malaysia focusing on health science and data science programmes at foundation (pre-university), undergraduate and postgraduate\n",
      "Cleaned Token After =  university located kuala lumpur , malaysia focusing health science data science programmes foundation ( pre-university ) , undergraduate postgraduate \n",
      "Cleaned Token After Stem =  univers locat kuala lumpur , malaysia focus health scienc data scienc programm foundat ( pre-univers ) , undergradu postgradu \n",
      "Cleaned Token Before =  2018, web of science started embedding partial information about the open access status of works, using unpaywall data. the web of science core collection\n",
      "Cleaned Token After =  2018 , web science started embedding partial information open access status works , using unpaywall data . web science core collection \n",
      "Cleaned Token After Stem =  2018 , web scienc start embed partial inform open access statu work , use unpaywal data . web scienc core collect \n",
      "Cleaned Token Before =  the program that focus on information science and computer science include: data science, data analytics, and data management; institutional repository\n",
      "Cleaned Token After =  program focus information science computer science include : data science , data analytics , data management ; institutional repository \n",
      "Cleaned Token After Stem =  program focu inform scienc comput scienc includ : data scienc , data analyt , data manag ; institut repositori \n",
      "Cleaned Token Before =  computer science: bs, bs-ms (dual degree), and ph.d. programme economic sciences: bs, bs-ms (dual degree), and ph.d. programme data science engineering:\n",
      "Cleaned Token After =  computer science : bs , bs-ms ( dual degree ) , ph.d. programme economic sciences : bs , bs-ms ( dual degree ) , ph.d. programme data science engineering : \n",
      "Cleaned Token After Stem =  comput scienc : bs , bs-m ( dual degre ) , ph.d. programm econom scienc : bs , bs-m ( dual degre ) , ph.d. programm data scienc engin : \n",
      "Cleaned Token Before =  personal data, also known as personal information or personally identifiable information (pii) is any information relating to an identifiable person. the\n",
      "Cleaned Token After =  personal data , also known personal information personally identifiable information ( pii ) information relating identifiable person . \n",
      "Cleaned Token After Stem =  person data , also known person inform person identifi inform ( pii ) inform relat identifi person . \n",
      "Cleaned Token Before =  data of recursive types are usually viewed as directed graphs. an important application of recursion in computer science is in defining dynamic data structures\n",
      "Cleaned Token After =  data recursive types usually viewed directed graphs . important application recursion computer science defining dynamic data structures \n",
      "Cleaned Token After Stem =  data recurs type usual view direct graph . import applic recurs comput scienc defin dynam data structur \n",
      "Cleaned Token Before =  intersection of three disciplines: data science, theory, and design. data science offers computational methods and techniques for data collection, pre-processing\n",
      "Cleaned Token After =  intersection three disciplines : data science , theory , design . data science offers computational methods techniques data collection , pre-processing \n",
      "Cleaned Token After Stem =  intersect three disciplin : data scienc , theori , design . data scienc offer comput method techniqu data collect , pre-process \n",
      "Cleaned Token Before =  data-science-course/articleshow/74467376.cms https://content.techgig.com/tcs-and-jai-hind-college-mumbai-announce-a-new-data-science-course/articleshow/74472830\n",
      "Cleaned Token After =  data-science-course/articleshow/74467376.cms https : //content.techgig.com/tcs-and-jai-hind-college-mumbai-announce-a-new-data-science-course/articleshow/74472830 \n",
      "Cleaned Token After Stem =  data-science-course/articleshow/74467376.cm http : //content.techgig.com/tcs-and-jai-hind-college-mumbai-announce-a-new-data-science-course/articleshow/74472830 \n",
      "Cleaned Token Before =  computer scientist, and artificial intelligence, machine learning, big data, data science, causality, knowledge representation, bioinformatics and health informatics\n",
      "Cleaned Token After =  computer scientist , artificial intelligence , machine learning , big data , data science , causality , knowledge representation , bioinformatics health informatics \n",
      "Cleaned Token After Stem =  comput scientist , artifici intellig , machin learn , big data , data scienc , causal , knowledg represent , bioinformat health informat \n",
      "Cleaned Token Before =  1137/141000671. s2cid 13026838. joshi, anshul (2016). julia for data science － explore the world of data science from scratch with julia by your side. packt. isbn 9781783553860\n",
      "Cleaned Token After =  1137/141000671 . s2cid 13026838. joshi , anshul ( 2016 ) . julia data science － explore world data science scratch julia side . packt . isbn 9781783553860 \n",
      "Cleaned Token After Stem =  1137/141000671 . s2cid 13026838. joshi , anshul ( 2016 ) . julia data scienc － explor world data scienc scratch julia side . packt . isbn 9781783553860 \n",
      "Cleaned Token Before =  in the c programming language, data types constitute the semantics and characteristics of storage of data elements. they are expressed in the language\n",
      "Cleaned Token After =  c programming language , data types constitute semantics characteristics storage data elements . expressed language \n",
      "Cleaned Token After Stem =  c program languag , data type constitut semant characterist storag data element . express languag \n",
      "Cleaned Token Before =  data retention defines the policies of persistent data and records management for meeting legal and business data archival requirements. although sometimes\n",
      "Cleaned Token After =  data retention defines policies persistent data records management meeting legal business data archival requirements . although sometimes \n",
      "Cleaned Token After Stem =  data retent defin polici persist data record manag meet legal busi data archiv requir . although sometim \n",
      "Cleaned Token Before =  and computer scientist who served as the chief data scientist of the united states office of science and technology policy. from 2015 to 2017. he is\n",
      "Cleaned Token After =  computer scientist served chief data scientist united states office science technology policy . 2015 2017. \n",
      "Cleaned Token After Stem =  comput scientist serv chief data scientist unit state offic scienc technolog polici . 2015 2017 . \n",
      "Cleaned Token Before =  variable rates of evolution among the theories and methods of science in response to new data. larry laudan has suggested pseudoscience has no scientific\n",
      "Cleaned Token After =  variable rates evolution among theories methods science response new data . larry laudan suggested pseudoscience scientific \n",
      "Cleaned Token After Stem =  variabl rate evolut among theori method scienc respons new data . larri laudan suggest pseudosci scientif \n",
      "Cleaned Token Before =  networks, and economic development, and has created applications of data science and artificial intelligence. hidalgo has authored or co-authored three\n",
      "Cleaned Token After =  networks , economic development , created applications data science artificial intelligence . hidalgo authored co-authored three \n",
      "Cleaned Token After Stem =  network , econom develop , creat applic data scienc artifici intellig . hidalgo author co-author three \n",
      "Cleaned Token Before =  donor pledged $252 million to help fund a new center for computing and data science. since 2000, berkeley alumni and faculty have received 40 nobel prizes\n",
      "Cleaned Token After =  donor pledged $ 252 million help fund new center computing data science . since 2000 , berkeley alumni faculty received 40 nobel prizes \n",
      "Cleaned Token After Stem =  donor pledg $ 252 million help fund new center comput data scienc . sinc 2000 , berkeley alumni faculti receiv 40 nobel prize \n",
      "Cleaned Token Before =  curricular computer science modules for grades 6-12. the 4 modules are bootstrap:algebra, bootstrap:reactive, bootstrap:data science, and bootstrap:physics\n",
      "Cleaned Token After =  curricular computer science modules grades 6-12. 4 modules bootstrap : algebra , bootstrap : reactive , bootstrap : data science , bootstrap : physics \n",
      "Cleaned Token After Stem =  curricular comput scienc modul grade 6-12 . 4 modul bootstrap : algebra , bootstrap : reactiv , bootstrap : data scienc , bootstrap : physic \n",
      "Cleaned Token Before =  data observation network for earth (dataone) is a platform for environmental and ecological science, to provide access to earth observational data. supported\n",
      "Cleaned Token After =  data observation network earth ( dataone ) platform environmental ecological science , provide access earth observational data . supported \n",
      "Cleaned Token After Stem =  data observ network earth ( dataon ) platform environment ecolog scienc , provid access earth observ data . support \n",
      "Cleaned Token Before =  to collect the data. statistics is the most widely used branch of mathematics in quantitative research outside of the physical sciences, and also finds\n",
      "Cleaned Token After =  collect data . statistics widely used branch mathematics quantitative research outside physical sciences , also finds \n",
      "Cleaned Token After Stem =  collect data . statist wide use branch mathemat quantit research outsid physic scienc , also find \n",
      "Cleaned Token Before =  time when few women were scientists junk science research paper mill retraction shapiro, m.f. (1992), \"data audit by a regulatory agency: its effect and\n",
      "Cleaned Token After =  time women scientists junk science research paper mill retraction shapiro , m.f . ( 1992 ) , `` data audit regulatory agency : effect \n",
      "Cleaned Token After Stem =  time women scientist junk scienc research paper mill retract shapiro , m.f . ( 1992 ) , `` data audit regulatori agenc : effect \n",
      "Cleaned Token Before =  (2019-12-01). \"predicting and explaining behavioral data with structured feature space decomposition\". epj data science. 8. doi:10.1140/epjds/s13688-019-0201-0.\n",
      "Cleaned Token After =  ( 2019-12-01 ) . `` predicting explaining behavioral data structured feature space decomposition '' . epj data science . 8. doi:10.1140/epjds/s13688-019-0201-0 . \n",
      "Cleaned Token After Stem =  ( 2019-12-01 ) . `` predict explain behavior data structur featur space decomposit `` . epj data scienc . 8. doi:10.1140/epjds/s13688-019-0201-0 . \n",
      "Cleaned Token Before =  2014, ieee escience conference series condensed the definition to \"escience promotes innovation in collaborative, computationally- or data-intensive research\n",
      "Cleaned Token After =  2014 , ieee escience conference series condensed definition `` escience promotes innovation collaborative , computationally- data-intensive research \n",
      "Cleaned Token After Stem =  2014 , ieee escienc confer seri condens definit `` escienc promot innov collabor , computationally- data-intens research \n",
      "Cleaned Token Before =  data integration involves combining data residing in different sources and providing users with a unified view of them. this process becomes significant\n",
      "Cleaned Token After =  data integration involves combining data residing different sources providing users unified view . process becomes significant \n",
      "Cleaned Token After Stem =  data integr involv combin data resid differ sourc provid user unifi view . process becom signific \n",
      "Cleaned Token Before =  official in the office of science and technology policy. the u.s. cto helps the president and their team harness the power of data, innovation and technology\n",
      "Cleaned Token After =  official office science technology policy . u.s. cto helps president team harness power data , innovation technology \n",
      "Cleaned Token After Stem =  offici offic scienc technolog polici . u.s. cto help presid team har power data , innov technolog \n",
      "Cleaned Token Before =  grouped data are data formed by aggregating individual observations of a variable into groups, so that a frequency distribution of these groups serves\n",
      "Cleaned Token After =  grouped data data formed aggregating individual observations variable groups , frequency distribution groups serves \n",
      "Cleaned Token After Stem =  group data data form aggreg individu observ variabl group , frequenc distribut group serv \n",
      "Cleaned Token Before =  (pdf), journal of data science, 9: 15–21. findley, d. f.; parzen, e. (1995), \"a conversation with hirotugu akaike\", statistical science, 10: 104–117, doi:10\n",
      "Cleaned Token After =  ( pdf ) , journal data science , 9 : 15–21 . findley , d. f. ; parzen , e. ( 1995 ) , `` conversation hirotugu akaike '' , statistical science , 10 : 104–117 , doi:10 \n",
      "Cleaned Token After Stem =  ( pdf ) , journal data scienc , 9 : 15–21 . findley , d. f. ; parzen , e. ( 1995 ) , `` convers hirotugu akaik `` , statist scienc , 10 : 104–117 , doi:10 \n",
      "Cleaned Token Before =  device or software program is said to be agnostic or data agnostic if the method or format of data transmission is irrelevant to the device or program’s\n",
      "Cleaned Token After =  device software program said agnostic data agnostic method format data transmission irrelevant device program ’ \n",
      "Cleaned Token After Stem =  devic softwar program said agnost data agnost method format data transmiss irrelev devic program ’ \n",
      "Cleaned Token Before =  the center for earth resources observation and science (eros) is a united states geological survey data management, systems development, and research field\n",
      "Cleaned Token After =  center earth resources observation science ( eros ) united states geological survey data management , systems development , research field \n",
      "Cleaned Token After Stem =  center earth resourc observ scienc ( ero ) unit state geolog survey data manag , system develop , research field \n",
      "Cleaned Token Before =  electrical engineering, mathematics, and computer science—for the purpose of designing efficient and reliable data transmission methods. this typically involves\n",
      "Cleaned Token After =  electrical engineering , mathematics , computer science—for purpose designing efficient reliable data transmission methods . typically involves \n",
      "Cleaned Token After Stem =  electr engin , mathemat , comput science—for purpos design effici reliabl data transmiss method . typic involv \n",
      "Cleaned Token Before =  the fourth paradigm: data-intensive scientific discovery is a 2009 anthology of essays on the topic of data science. editors tony hey, kristin michele\n",
      "Cleaned Token After =  fourth paradigm : data-intensive scientific discovery 2009 anthology essays topic data science . editors tony hey , kristin michele \n",
      "Cleaned Token After Stem =  fourth paradigm : data-intens scientif discoveri 2009 antholog essay topic data scienc . editor toni hey , kristin michel \n",
      "Cleaned Token Before =  the r programming language, and a categorical variable in statistics) is a data type consisting of a set of named values called elements, members, enumeral\n",
      "Cleaned Token After =  r programming language , categorical variable statistics ) data type consisting set named values called elements , members , enumeral \n",
      "Cleaned Token After Stem =  r program languag , categor variabl statist ) data type consist set name valu call element , member , enumer \n",
      "Cleaned Token Before =  computing, a persistent data structure is a data structure that always preserves the previous version of itself when it is modified. such data structures are effectively\n",
      "Cleaned Token After =  computing , persistent data structure data structure always preserves previous version modified . data structures effectively \n",
      "Cleaned Token After Stem =  comput , persist data structur data structur alway preserv previou version modifi . data structur effect \n",
      "Cleaned Token Before =  in computer science, a collision or clash is a situation that occurs when two distinct pieces of data have the same hash value, checksum, fingerprint\n",
      "Cleaned Token After =  computer science , collision clash situation occurs two distinct pieces data hash value , checksum , fingerprint \n",
      "Cleaned Token After Stem =  comput scienc , collis clash situat occur two distinct piec data hash valu , checksum , fingerprint \n",
      "Cleaned Token Before =  (born 1991) is an american data scientist known for analyzing political polls. he currently serves as head of data science with openlabs, a progressive\n",
      "Cleaned Token After =  ( born 1991 ) american data scientist known analyzing political polls . currently serves head data science openlabs , progressive \n",
      "Cleaned Token After Stem =  ( born 1991 ) american data scientist known analyz polit poll . current serv head data scienc openlab , progress \n",
      "Cleaned Token Before =  henry e. (11 may 2019). \"the challenge of big data and data science\". annual review of political science. 22 (1): 297–323. doi:10.1146/annurev-polisci-090216-023229\n",
      "Cleaned Token After =  henry e. ( 11 may 2019 ) . `` challenge big data data science '' . annual review political science . 22 ( 1 ) : 297–323 . doi:10.1146/annurev-polisci-090216-023229 \n",
      "Cleaned Token After Stem =  henri e. ( 11 may 2019 ) . `` challeng big data data scienc `` . annual review polit scienc . 22 ( 1 ) : 297–323 . doi:10.1146/annurev-polisci-090216-023229 \n",
      "Cleaned Token Before =  esdu (originally an acronym of \"engineering sciences data unit\" but now used on its own account) is an engineering advisory organisation based in the\n",
      "Cleaned Token After =  esdu ( originally acronym `` engineering sciences data unit '' used account ) engineering advisory organisation based \n",
      "Cleaned Token After Stem =  esdu ( origin acronym `` engin scienc data unit `` use account ) engin advisori organis base \n",
      "Cleaned Token Before =  graphics organizations, supercomputing facilities science portal general data presentation architecture data visualization mathematical visualization molecular\n",
      "Cleaned Token After =  graphics organizations , supercomputing facilities science portal general data presentation architecture data visualization mathematical visualization molecular \n",
      "Cleaned Token After Stem =  graphic organ , supercomput facil scienc portal gener data present architectur data visual mathemat visual molecular \n",
      "Cleaned Token Before =  principles to reduce the duplication of data, avoid data anomalies, ensure referential integrity, and simplify data management. it was defined in 1971 by\n",
      "Cleaned Token After =  principles reduce duplication data , avoid data anomalies , ensure referential integrity , simplify data management . defined 1971 \n",
      "Cleaned Token After Stem =  principl reduc duplic data , avoid data anomali , ensur referenti integr , simplifi data manag . defin 1971 \n",
      "Cleaned Token Before =  pure computer science, nor with computer engineering, although a wide domain in the former is used in cse (e.g., certain algorithms, data structures, parallel\n",
      "Cleaned Token After =  pure computer science , computer engineering , although wide domain former used cse ( e.g. , certain algorithms , data structures , parallel \n",
      "Cleaned Token After Stem =  pure comput scienc , comput engin , although wide domain former use cse ( e.g . , certain algorithm , data structur , parallel \n",
      "Cleaned Token Before =  narrative science is a technology company based in chicago, illinois that specializes in data storytelling. the company has two data storytelling products\n",
      "Cleaned Token After =  narrative science technology company based chicago , illinois specializes data storytelling . company two data storytelling products \n",
      "Cleaned Token After Stem =  narr scienc technolog compani base chicago , illinoi special data storytel . compani two data storytel product \n",
      "Cleaned Token Before =  hash minhash quotient filter ctrie many graph-based data structures are used in computer science and related fields: graph adjacency list adjacency matrix\n",
      "Cleaned Token After =  hash minhash quotient filter ctrie many graph-based data structures used computer science related fields : graph adjacency list adjacency matrix \n",
      "Cleaned Token After Stem =  hash minhash quotient filter ctrie mani graph-bas data structur use comput scienc relat field : graph adjac list adjac matrix \n",
      "Cleaned Token Before =  astronomical and geophysical data-analysis services. icsu icsu world data system (wds) icsu international council for science list of former wdcs v t e\n",
      "Cleaned Token After =  astronomical geophysical data-analysis services . icsu icsu world data system ( wds ) icsu international council science list former wdcs v e \n",
      "Cleaned Token After Stem =  astronom geophys data-analysi servic . icsu icsu world data system ( wd ) icsu intern council scienc list former wdc v e \n",
      "Cleaned Token Before =  szalay is an international leader in astronomy, cosmology, the science of big data, and data‐intensive computing. alexander sándor szalay, jr. was born in\n",
      "Cleaned Token After =  szalay international leader astronomy , cosmology , science big data , data‐intensive computing . alexander sándor szalay , jr. born \n",
      "Cleaned Token After Stem =  szalay intern leader astronomi , cosmolog , scienc big data , data‐intens comput . alexand sándor szalay , jr. born \n",
      "Cleaned Token Before =  the word data has generated considerable controversy on whether it is an uncountable noun used with verbs conjugated in the singular, or should be treated\n",
      "Cleaned Token After =  word data generated considerable controversy whether uncountable noun used verbs conjugated singular , treated \n",
      "Cleaned Token After Stem =  word data gener consider controversi whether uncount noun use verb conjug singular , treat \n",
      "Cleaned Token Before =  science fiction (sometimes shortened to sci-fi or sf) is a genre of speculative fiction that typically deals with imaginative and futuristic concepts\n",
      "Cleaned Token After =  science fiction ( sometimes shortened sci-fi sf ) genre speculative fiction typically deals imaginative futuristic concepts \n",
      "Cleaned Token After Stem =  scienc fiction ( sometim shorten sci-fi sf ) genr specul fiction typic deal imagin futurist concept \n",
      "Cleaned Token Before =  including the journal feminist economics data to knowledge lab (d2k) - campus hub for experiential learning in data science digital signal processing (dsp) -\n",
      "Cleaned Token After =  including journal feminist economics data knowledge lab ( d2k ) - campus hub experiential learning data science digital signal processing ( dsp ) - \n",
      "Cleaned Token After Stem =  includ journal feminist econom data knowledg lab ( d2k ) - campu hub experienti learn data scienc digit signal process ( dsp ) - \n",
      "Cleaned Token Before =  2020 the international sata science hackathon\". data science society. retrieved 16 december 2020. \"datathon 2020\". data republic. retrieved 16 december\n",
      "Cleaned Token After =  2020 international sata science hackathon '' . data science society . retrieved 16 december 2020 . `` datathon 2020 '' . data republic . retrieved 16 december \n",
      "Cleaned Token After Stem =  2020 intern sata scienc hackathon `` . data scienc societi . retriev 16 decemb 2020 . `` datathon 2020 `` . data republ . retriev 16 decemb \n",
      "Cleaned Token Before =  studies cognitive science creative writing data science (program managed by the division of computing, data science, & society) development studies disability\n",
      "Cleaned Token After =  studies cognitive science creative writing data science ( program managed division computing , data science , & society ) development studies disability \n",
      "Cleaned Token After Stem =  studi cognit scienc creativ write data scienc ( program manag divis comput , data scienc , & societi ) develop studi disabl \n",
      "Cleaned Token Before =  algorithms applied mathematics education computational science and engineering control and systems theory data mining and analytics discrete mathematics dynamical\n",
      "Cleaned Token After =  algorithms applied mathematics education computational science engineering control systems theory data mining analytics discrete mathematics dynamical \n",
      "Cleaned Token After Stem =  algorithm appli mathemat educ comput scienc engin control system theori data mine analyt discret mathemat dynam \n",
      "Cleaned Token Before =  data remanence is the residual representation of digital data that remains even after attempts have been made to remove or erase the data. this residue\n",
      "Cleaned Token After =  data remanence residual representation digital data remains even attempts made remove erase data . residue \n",
      "Cleaned Token After Stem =  data reman residu represent digit data remain even attempt made remov eras data . residu \n",
      "Cleaned Token Before =  about 24,000 jobs. the hpe data science institute was created in 2017, and was named by the hewlett packard enterprise data science institute with its 10 million\n",
      "Cleaned Token After =  24,000 jobs . hpe data science institute created 2017 , named hewlett packard enterprise data science institute 10 million \n",
      "Cleaned Token After Stem =  24,000 job . hpe data scienc institut creat 2017 , name hewlett packard enterpris data scienc institut 10 million \n",
      "Cleaned Token Before =  computer sciences is one of the nine colleges of northeastern university in boston, massachusetts. it specializes in computer science, data science and cybersecurity\n",
      "Cleaned Token After =  computer sciences one nine colleges northeastern university boston , massachusetts . specializes computer science , data science cybersecurity \n",
      "Cleaned Token After Stem =  comput scienc one nine colleg northeastern univers boston , massachusett . special comput scienc , data scienc cybersecur \n",
      "Cleaned Token Before =  reproducibility has been introduced in computational sciences: any results should be documented by making all data and code available in such a way that the computations\n",
      "Cleaned Token After =  reproducibility introduced computational sciences : results documented making data code available way computations \n",
      "Cleaned Token After Stem =  reproduc introduc comput scienc : result document make data code avail way comput \n",
      "Cleaned Token Before =  a data logger (also datalogger or data recorder) is an electronic device that records data over time or in relation to location either with a built in\n",
      "Cleaned Token After =  data logger ( also datalogger data recorder ) electronic device records data time relation location either built \n",
      "Cleaned Token After Stem =  data logger ( also datalogg data record ) electron devic record data time relat locat either built \n",
      "Cleaned Token Before =  spatial data science (csds) at the university of chicago. geoda has powerful capabilities to perform spatial analysis, multivariate exploratory data analysis\n",
      "Cleaned Token After =  spatial data science ( csds ) university chicago . geoda powerful capabilities perform spatial analysis , multivariate exploratory data analysis \n",
      "Cleaned Token After Stem =  spatial data scienc ( csd ) univers chicago . geoda power capabl perform spatial analysi , multivari exploratori data analysi \n",
      "Cleaned Token Before =  to become a business analyst | business analyst salary\". master's in data science. retrieved 2018-09-06. schreiner, k. (november 2007). \"the bridge and\n",
      "Cleaned Token After =  become business analyst | business analyst salary '' . master 's data science . retrieved 2018-09-06. schreiner , k. ( november 2007 ) . `` bridge \n",
      "Cleaned Token After Stem =  becom busi analyst | busi analyst salari `` . master 's data scienc . retriev 2018-09-06. schreiner , k. ( novemb 2007 ) . `` bridg \n",
      "Cleaned Token Before =  messages between data points\". science. 315 (5814): 972–976. bibcode:2007sci...315..972f. citeseerx 10.1.1.121.3145. doi:10.1126/science.1136800. pmid 17218491\n",
      "Cleaned Token After =  messages data points '' . science . 315 ( 5814 ) : 972–976 . bibcode:2007sci ... 315 .. 972f . citeseerx 10.1.1.121.3145. doi:10.1126/science.1136800 . pmid 17218491 \n",
      "Cleaned Token After Stem =  messag data point `` . scienc . 315 ( 5814 ) : 972–976 . bibcode:2007sci ... 315 .. 972f . citeseerx 10.1.1.121.3145. doi:10.1126/science.1136800 . pmid 17218491 \n",
      "Cleaned Token Before =  msc computer science ( artificial intelligence & data science) and phd (computer science / computer engineering or information science). research laboratories\n",
      "Cleaned Token After =  msc computer science ( artificial intelligence & data science ) phd ( computer science / computer engineering information science ) . research laboratories \n",
      "Cleaned Token After Stem =  msc comput scienc ( artifici intellig & data scienc ) phd ( comput scienc / comput engin inform scienc ) . research laboratori \n",
      "Cleaned Token Before =  academia: data science and artificial intelligence. in a timely initiative, iiit dharwad is launching a brand new btech program in data science and ai in\n",
      "Cleaned Token After =  academia : data science artificial intelligence . timely initiative , iiit dharwad launching brand new btech program data science ai \n",
      "Cleaned Token After Stem =  academia : data scienc artifici intellig . time initi , iiit dharwad launch brand new btech program data scienc ai \n",
      "Cleaned Token Before =  learning to analyse data sets in neuroscience and genomics. she is worried about increasing amounts of data in biomedical sciences. she was appointed to\n",
      "Cleaned Token After =  learning analyse data sets neuroscience genomics . worried increasing amounts data biomedical sciences . appointed \n",
      "Cleaned Token After Stem =  learn analys data set neurosci genom . worri increas amount data biomed scienc . appoint \n",
      "Cleaned Token Before =  for nanotechnology at university college london. he left to join asi data science (now faculty), a company founded by his brother marc warner in 2014,\n",
      "Cleaned Token After =  nanotechnology university college london . left join asi data science ( faculty ) , company founded brother marc warner 2014 , \n",
      "Cleaned Token After Stem =  nanotechnolog univers colleg london . left join asi data scienc ( faculti ) , compani found brother marc warner 2014 , \n",
      "Cleaned Token Before =   retrieved 17 october 2013. data science and big data analytics: discovering, analyzing, visualizing and presenting data. john wiley & sons. 19 december\n",
      "Cleaned Token After =  retrieved 17 october 2013. data science big data analytics : discovering , analyzing , visualizing presenting data . john wiley & sons . 19 december \n",
      "Cleaned Token After Stem =  retriev 17 octob 2013. data scienc big data analyt : discov , analyz , visual present data . john wiley & son . 19 decemb \n",
      "Cleaned Token Before =  data are applied in statistics, data warehouses, and in economics. there is a distinction between aggregate data and individual data. aggregate data refers\n",
      "Cleaned Token After =  data applied statistics , data warehouses , economics . distinction aggregate data individual data . aggregate data refers \n",
      "Cleaned Token After Stem =  data appli statist , data warehous , econom . distinct aggreg data individu data . aggreg data refer \n",
      "Cleaned Token Before =  september 2021, welcome its first cohort for the newly established master of data science for public policy programme. students can pursue study abroad opportunities\n",
      "Cleaned Token After =  september 2021 , welcome first cohort newly established master data science public policy programme . students pursue study abroad opportunities \n",
      "Cleaned Token After Stem =  septemb 2021 , welcom first cohort newli establish master data scienc public polici programm . student pursu studi abroad opportun \n",
      "Cleaned Token Before =  hadley; grolemund, garrett (2017). r for data science : import, tidy, transform, visualize, and model data. sebastopol, ca: o'reilly media. isbn 1491910399\n",
      "Cleaned Token After =  hadley ; grolemund , garrett ( 2017 ) . r data science : import , tidy , transform , visualize , model data . sebastopol , ca : o'reilly media . isbn 1491910399 \n",
      "Cleaned Token After Stem =  hadley ; grolemund , garrett ( 2017 ) . r data scienc : import , tidi , transform , visual , model data . sebastopol , ca : o'reilli media . isbn 1491910399 \n",
      "Cleaned Token Before =  of science and professor at the university of exeter, united kingdom. she is well-known for her work on scientific practices, data-centric science, and\n",
      "Cleaned Token After =  science professor university exeter , united kingdom . well-known work scientific practices , data-centric science , \n",
      "Cleaned Token After Stem =  scienc professor univers exet , unit kingdom . well-known work scientif practic , data-centr scienc , \n",
      "Cleaned Token Before =  features for neural networks, machine learning, image processing, geometry, data science, visualizations. mathematica includes a notebook interface and can produce\n",
      "Cleaned Token After =  features neural networks , machine learning , image processing , geometry , data science , visualizations . mathematica includes notebook interface produce \n",
      "Cleaned Token After Stem =  featur neural network , machin learn , imag process , geometri , data scienc , visual . mathematica includ notebook interfac produc \n",
      "Cleaned Token Before =  is a data scientist and an associate professor of statistics at the university of british columbia where she developed the master in data science program\n",
      "Cleaned Token After =  data scientist associate professor statistics university british columbia developed master data science program \n",
      "Cleaned Token After Stem =  data scientist associ professor statist univers british columbia develop master data scienc program \n",
      "Cleaned Token Before =  point-of-sale data grew and barcode readers led to a \"marketing information revolution.\" before conferences were organized with a \"marketing science\" label,\n",
      "Cleaned Token After =  point-of-sale data grew barcode readers led `` marketing information revolution . '' conferences organized `` marketing science '' label , \n",
      "Cleaned Token After Stem =  point-of-sal data grew barcod reader led `` market inform revolut . `` confer organ `` market scienc `` label , \n",
      "Cleaned Token Before =  unstructured data (or unstructured information) is information that either does not have a pre-defined data model or is not organized in a pre-defined\n",
      "Cleaned Token After =  unstructured data ( unstructured information ) information either pre-defined data model organized pre-defined \n",
      "Cleaned Token After Stem =  unstructur data ( unstructur inform ) inform either pre-defin data model organ pre-defin \n",
      "Cleaned Token Before =  \"information\" and \"graphics\") are graphic visual representations of information, data, or knowledge intended to present information quickly and clearly. they can\n",
      "Cleaned Token After =  `` information '' `` graphics '' ) graphic visual representations information , data , knowledge intended present information quickly clearly . \n",
      "Cleaned Token After Stem =  `` inform `` `` graphic `` ) graphic visual represent inform , data , knowledg intend present inform quickli clearli . \n",
      "Cleaned Token Before =  research and reports in gynecology and obstetrics research and reports on data science research and reports on genetics research in clinical dermatology sensory\n",
      "Cleaned Token After =  research reports gynecology obstetrics research reports data science research reports genetics research clinical dermatology sensory \n",
      "Cleaned Token After Stem =  research report gynecolog obstetr research report data scienc research report genet research clinic dermatolog sensori \n",
      "Cleaned Token Before =  the dynamics of the atmosphere, oceans and climate and environmental data science. she is a theoretician, numerical modeller and observational scientist\n",
      "Cleaned Token After =  dynamics atmosphere , oceans climate environmental data science . theoretician , numerical modeller observational scientist \n",
      "Cleaned Token After Stem =  dynam atmospher , ocean climat environment data scienc . theoretician , numer model observ scientist \n",
      "Cleaned Token Before =  verification quality control clinical data management data verification data entry clerk input (computer science) \"data entry ... person based jobs\" \"work\n",
      "Cleaned Token After =  verification quality control clinical data management data verification data entry clerk input ( computer science ) `` data entry ... person based jobs '' `` work \n",
      "Cleaned Token After Stem =  verif qualiti control clinic data manag data verif data entri clerk input ( comput scienc ) `` data entri ... person base job `` `` work \n",
      "Cleaned Token Before =  short for interactive data language, is a programming language used for data analysis. it is popular in particular areas of science, such as astronomy,\n",
      "Cleaned Token After =  short interactive data language , programming language used data analysis . popular particular areas science , astronomy , \n",
      "Cleaned Token After Stem =  short interact data languag , program languag use data analysi . popular particular area scienc , astronomi , \n",
      "Cleaned Token Before =  national laboratory and associate researcher at the berkeley institute for data science. pérez began working on ipython as a side project in 2001, and is a co-founder\n",
      "Cleaned Token After =  national laboratory associate researcher berkeley institute data science . pérez began working ipython side project 2001 , co-founder \n",
      "Cleaned Token After Stem =  nation laboratori associ research berkeley institut data scienc . pérez began work ipython side project 2001 , co-found \n",
      "Cleaned Token Before =  courses based on data wrangling and data science lines. weka – machine-learning algorithms that can be integrated in knime elki – data mining framework\n",
      "Cleaned Token After =  courses based data wrangling data science lines . weka – machine-learning algorithms integrated knime elki – data mining framework \n",
      "Cleaned Token After Stem =  cours base data wrangl data scienc line . weka – machine-learn algorithm integr knime elki – data mine framework \n",
      "Cleaned Token Before =  in computer science, an opaque data type is a data type whose concrete data structure is not defined in an interface. this enforces information hiding\n",
      "Cleaned Token After =  computer science , opaque data type data type whose concrete data structure defined interface . enforces information hiding \n",
      "Cleaned Token After Stem =  comput scienc , opaqu data type data type whose concret data structur defin interfac . enforc inform hide \n",
      "Cleaned Token Before =  include multi-terabyte/petabyte data warehouses and time series of image data. the data cube is used to represent data (sometimes called facts) along some\n",
      "Cleaned Token After =  include multi-terabyte/petabyte data warehouses time series image data . data cube used represent data ( sometimes called facts ) along \n",
      "Cleaned Token After Stem =  includ multi-terabyte/petabyt data warehous time seri imag data . data cube use repres data ( sometim call fact ) along \n",
      "Cleaned Token Before =  in computer science, a b-tree is a self-balancing tree data structure that maintains sorted data and allows searches, sequential access, insertions, and\n",
      "Cleaned Token After =  computer science , b-tree self-balancing tree data structure maintains sorted data allows searches , sequential access , insertions , \n",
      "Cleaned Token After Stem =  comput scienc , b-tree self-balanc tree data structur maintain sort data allow search , sequenti access , insert , \n",
      "Cleaned Token Before =  rexer analytics’s annual data miner survey is the largest survey of data mining, data science, and analytics professionals in the industry. it consists\n",
      "Cleaned Token After =  rexer analytics ’ annual data miner survey largest survey data mining , data science , analytics professionals industry . consists \n",
      "Cleaned Token After Stem =  rexer analyt ’ annual data miner survey largest survey data mine , data scienc , analyt profession industri . consist \n",
      "Cleaned Token Before =  as \"the art and science of extracting valuable hidden insights from vast amounts of semi-structured and unstructured social media data to enable informed\n",
      "Cleaned Token After =  `` art science extracting valuable hidden insights vast amounts semi-structured unstructured social media data enable informed \n",
      "Cleaned Token After Stem =  `` art scienc extract valuabl hidden insight vast amount semi-structur unstructur social media data enabl inform \n",
      "Cleaned Token Before =  data verification is a process in which different types of data are checked for accuracy and inconsistencies after data migration is done. it helps to\n",
      "Cleaned Token After =  data verification process different types data checked accuracy inconsistencies data migration done . helps \n",
      "Cleaned Token After Stem =  data verif process differ type data check accuraci inconsist data migrat done . help \n",
      "Cleaned Token Before =  a data haven, like a corporate haven or tax haven, is a refuge for uninterrupted or unregulated data. data havens are locations with legal environments\n",
      "Cleaned Token After =  data , like corporate tax , refuge uninterrupted unregulated data . data havens locations legal environments \n",
      "Cleaned Token After Stem =  data , like corpor tax , refug uninterrupt unregul data . data haven locat legal environ \n",
      "Cleaned Token Before =  supplementary chemical data on ethanol. except where noted otherwise, data relate to standard ambient temperature and pressure. external msds data obtained from\n",
      "Cleaned Token After =  supplementary chemical data ethanol . except noted otherwise , data relate standard ambient temperature pressure . external msds data obtained \n",
      "Cleaned Token After Stem =  supplementari chemic data ethanol . except note otherwis , data relat standard ambient temperatur pressur . extern msd data obtain \n",
      "Cleaned Token Before =  in computer science, a container is a class, a data structure, or an abstract data type (adt) whose instances are collections of other objects. in other\n",
      "Cleaned Token After =  computer science , container class , data structure , abstract data type ( adt ) whose instances collections objects . \n",
      "Cleaned Token After Stem =  comput scienc , contain class , data structur , abstract data type ( adt ) whose instanc collect object . \n",
      "Cleaned Token Before =  data erasure (sometimes referred to as data clearing, data wiping, or data destruction) is a software-based method of overwriting the data that aims to\n",
      "Cleaned Token After =  data erasure ( sometimes referred data clearing , data wiping , data destruction ) software-based method overwriting data aims \n",
      "Cleaned Token After Stem =  data erasur ( sometim refer data clear , data wipe , data destruct ) software-bas method overwrit data aim \n",
      "Cleaned Token Before =  mathematical and computational sciences at the institute for basic science. her research focuses on network and data science with an emphasis on modeling\n",
      "Cleaned Token After =  mathematical computational sciences institute basic science . research focuses network data science emphasis modeling \n",
      "Cleaned Token After Stem =  mathemat comput scienc institut basic scienc . research focus network data scienc emphasi model \n",
      "Cleaned Token Before =  institute\". klinkenberg, ralf. \"industrial data science - ids 2017 - overview of use cases\". industrial data science conference (ids 2017), dortmund, germany\n",
      "Cleaned Token After =  institute '' . klinkenberg , ralf . `` industrial data science - ids 2017 - overview use cases '' . industrial data science conference ( ids 2017 ) , dortmund , germany \n",
      "Cleaned Token After Stem =  institut `` . klinkenberg , ralf . `` industri data scienc - id 2017 - overview use case `` . industri data scienc confer ( id 2017 ) , dortmund , germani \n",
      "Cleaned Token Before =  projects at the leading edge of science—far-reaching projects at the intersection of biology and technology. the resulting data create free, publicly available\n",
      "Cleaned Token After =  projects leading edge science—far-reaching projects intersection biology technology . resulting data create free , publicly available \n",
      "Cleaned Token After Stem =  project lead edg science—far-reach project intersect biolog technolog . result data creat free , publicli avail \n",
      "Cleaned Token Before =  molecular, optical and plasma physics european physical journal ds: data science european physical journal e: soft matter and biological physics european\n",
      "Cleaned Token After =  molecular , optical plasma physics european physical journal ds : data science european physical journal e : soft matter biological physics european \n",
      "Cleaned Token After Stem =  molecular , optic plasma physic european physic journal ds : data scienc european physic journal e : soft matter biolog physic european \n",
      "Cleaned Token Before =  environmental data analysis (ceda) is a united kingdom organisation that serves the environmental science community by provision of data centres, data analysis\n",
      "Cleaned Token After =  environmental data analysis ( ceda ) united kingdom organisation serves environmental science community provision data centres , data analysis \n",
      "Cleaned Token After Stem =  environment data analysi ( ceda ) unit kingdom organis serv environment scienc commun provis data centr , data analysi \n",
      "Cleaned Token Before =  system analysis and big data science in austria. the csh was founded in 2015 as a joint initiative to foster big data science for the benefit of society\n",
      "Cleaned Token After =  system analysis big data science austria . csh founded 2015 joint initiative foster big data science benefit society \n",
      "Cleaned Token After Stem =  system analysi big data scienc austria . csh found 2015 joint initi foster big data scienc benefit societi \n",
      "Cleaned Token Before =  data bank (pdb) is a database for the three-dimensional structural data of large biological molecules, such as proteins and nucleic acids. the data,\n",
      "Cleaned Token After =  data bank ( pdb ) database three-dimensional structural data large biological molecules , proteins nucleic acids . data , \n",
      "Cleaned Token After Stem =  data bank ( pdb ) databas three-dimension structur data larg biolog molecul , protein nucleic acid . data , \n",
      "Cleaned Token Before =  data parallelism is parallelization across multiple processors in parallel computing environments. it focuses on distributing the data across different\n",
      "Cleaned Token After =  data parallelism parallelization across multiple processors parallel computing environments . focuses distributing data across different \n",
      "Cleaned Token After Stem =  data parallel parallel across multipl processor parallel comput environ . focus distribut data across differ \n",
      "Cleaned Token Before =  datameet is a user-generated community primarily focused around open data & data science in india. datameet was registered as a trust in february 2014\n",
      "Cleaned Token After =  datameet user-generated community primarily focused around open data & data science india . datameet registered trust february 2014 \n",
      "Cleaned Token After Stem =  datameet user-gener commun primarili focus around open data & data scienc india . datameet regist trust februari 2014 \n",
      "Cleaned Token Before =  transaction data is data describing an event (the change as a result of a transaction) and is usually described with verbs. transaction data always has\n",
      "Cleaned Token After =  transaction data data describing event ( change result transaction ) usually described verbs . transaction data always \n",
      "Cleaned Token After Stem =  transact data data describ event ( chang result transact ) usual describ verb . transact data alway \n",
      "Cleaned Token Before =  bioinformatician. he is the endowed chair in biological data science and director of the center of excellence for data-driven discovery at st. jude children’s research\n",
      "Cleaned Token After =  bioinformatician . endowed chair biological data science director center excellence data-driven discovery st. jude children ’ research \n",
      "Cleaned Token After Stem =  bioinformatician . endow chair biolog data scienc director center excel data-driven discoveri st. jude children ’ research \n",
      "Cleaned Token Before =  the registry of research data repositories (re3data.org) is an open science tool that offers researchers, funding organizations, libraries and publishers\n",
      "Cleaned Token After =  registry research data repositories ( re3data.org ) open science tool offers researchers , funding organizations , libraries publishers \n",
      "Cleaned Token After Stem =  registri research data repositori ( re3data.org ) open scienc tool offer research , fund organ , librari publish \n",
      "Cleaned Token Before =  digital data, in information theory and information systems, is the discrete, discontinuous representation of information or works. numbers and letters\n",
      "Cleaned Token After =  digital data , information theory information systems , discrete , discontinuous representation information works . numbers letters \n",
      "Cleaned Token After Stem =  digit data , inform theori inform system , discret , discontinu represent inform work . number letter \n",
      "Cleaned Token Before =  model data with naturally occurring outlier points. deletion of outlier data is a controversial practice frowned upon by many scientists and science instructors;\n",
      "Cleaned Token After =  model data naturally occurring outlier points . deletion outlier data controversial practice frowned upon many scientists science instructors ; \n",
      "Cleaned Token After Stem =  model data natur occur outlier point . delet outlier data controversi practic frown upon mani scientist scienc instructor ; \n",
      "Cleaned Token Before =  approved in the office of the international council for science (icsu): australian national data service (ands); deutsche zentralbibliothek für medizin\n",
      "Cleaned Token After =  approved office international council science ( icsu ) : australian national data service ( ands ) ; deutsche zentralbibliothek für medizin \n",
      "Cleaned Token After Stem =  approv offic intern council scienc ( icsu ) : australian nation data servic ( and ) ; deutsch zentralbibliothek für medizin \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Token Before =  political science is the scientific study of politics. it is a social science dealing with systems of governance and power, and the analysis of political\n",
      "Cleaned Token After =  political science scientific study politics . social science dealing systems governance power , analysis political \n",
      "Cleaned Token After Stem =  polit scienc scientif studi polit . social scienc deal system govern power , analysi polit \n",
      "Cleaned Token Before =  data augmentation in data analysis are techniques used to increase the amount of data by adding slightly modified copies of already existing data or newly\n",
      "Cleaned Token After =  data augmentation data analysis techniques used increase amount data adding slightly modified copies already existing data newly \n",
      "Cleaned Token After Stem =  data augment data analysi techniqu use increas amount data ad slightli modifi copi alreadi exist data newli \n",
      "Cleaned Token Before =  times company. retrieved 26 july 2015. \"in big data, preparing data is most of the work\". data science central. sullexis llc. retrieved 26 july 2015.\n",
      "Cleaned Token After =  times company . retrieved 26 july 2015 . `` big data , preparing data work '' . data science central . sullexis llc . retrieved 26 july 2015 . \n",
      "Cleaned Token After Stem =  time compani . retriev 26 juli 2015 . `` big data , prepar data work `` . data scienc central . sullexi llc . retriev 26 juli 2015 . \n",
      "Cleaned Token Before =  integral data type, and continuous variables with the real data type involving floating point computation. but the mapping of computer science data types\n",
      "Cleaned Token After =  integral data type , continuous variables real data type involving floating point computation . mapping computer science data types \n",
      "Cleaned Token After Stem =  integr data type , continu variabl real data type involv float point comput . map comput scienc data type \n",
      "Cleaned Token Before =  director of data carpentry. she is known for her work in open science and biomedical data science education. teal received her bachelors of science in cybernetics\n",
      "Cleaned Token After =  director data carpentry . known work open science biomedical data science education . teal received bachelors science cybernetics \n",
      "Cleaned Token After Stem =  director data carpentri . known work open scienc biomed data scienc educ . teal receiv bachelor scienc cybernet \n",
      "Cleaned Token Before =  and is affiliated with the institute for data, systems, and society (idss), the statistics and data science center and the mit operations research center\n",
      "Cleaned Token After =  affiliated institute data , systems , society ( idss ) , statistics data science center mit operations research center \n",
      "Cleaned Token After Stem =  affili institut data , system , societi ( idss ) , statist data scienc center mit oper research center \n",
      "Cleaned Token Before =  ball would fall in a roulette wheel given some input data. this outcome precursed data science and embodied the infancy of predictive analytics[citation\n",
      "Cleaned Token After =  ball would fall roulette wheel given input data . outcome precursed data science embodied infancy predictive analytics [ citation \n",
      "Cleaned Token After Stem =  ball would fall roulett wheel given input data . outcom precurs data scienc embodi infanc predict analyt [ citat \n",
      "Cleaned Token Before =  metadata is \"data that provides information about other data\". in other words, it is \"data about data\". many distinct types of metadata exist, including\n",
      "Cleaned Token After =  metadata `` data provides information data '' . words , `` data data '' . many distinct types metadata exist , including \n",
      "Cleaned Token After Stem =  metadata `` data provid inform data `` . word , `` data data `` . mani distinct type metadata exist , includ \n",
      "Cleaned Token Before =  washington dc: national science foundation. kitchin, r (2012). \"small data, data infrastructures and data brokers\". the data revolution. london: sage:\n",
      "Cleaned Token After =  washington dc : national science foundation . kitchin , r ( 2012 ) . `` small data , data infrastructures data brokers '' . data revolution . london : sage : \n",
      "Cleaned Token After Stem =  washington dc : nation scienc foundat . kitchin , r ( 2012 ) . `` small data , data infrastructur data broker `` . data revolut . london : sage : \n",
      "Cleaned Token Before =  brandstein, a.; horne, g. (1998). \"data farming: a meta-technique for research in the 21st century\". maneuver warfare science. quantico, va: marine corps combat\n",
      "Cleaned Token After =  brandstein , a. ; horne , g. ( 1998 ) . `` data farming : meta-technique research 21st century '' . maneuver warfare science . quantico , va : marine corps combat \n",
      "Cleaned Token After Stem =  brandstein , a. ; horn , g. ( 1998 ) . `` data farm : meta-techniqu research 21st centuri `` . maneuv warfar scienc . quantico , va : marin corp combat \n",
      "Cleaned Token Before =  garbage can also refer to garbled data; see data corruption. in computer science, garbage includes data, objects, or other regions of the memory of a\n",
      "Cleaned Token After =  garbage also refer garbled data ; see data corruption . computer science , garbage includes data , objects , regions memory \n",
      "Cleaned Token After Stem =  garbag also refer garbl data ; see data corrupt . comput scienc , garbag includ data , object , region memori \n",
      "Cleaned Token Before =  lee (2019). hands on with google data studio. wiley. isbn 9781119616085. lakshmanan, valliappa (2017). data science on the google cloud platform. o'reilly\n",
      "Cleaned Token After =  lee ( 2019 ) . hands google data studio . wiley . isbn 9781119616085. lakshmanan , valliappa ( 2017 ) . data science google cloud platform . o'reilly \n",
      "Cleaned Token After Stem =  lee ( 2019 ) . hand googl data studio . wiley . isbn 9781119616085. lakshmanan , valliappa ( 2017 ) . data scienc googl cloud platform . o'reilli \n",
      "Cleaned Token Before =  in computer science, information hiding is the principle of segregation of the design decisions in a computer program that are most likely to change,\n",
      "Cleaned Token After =  computer science , information hiding principle segregation design decisions computer program likely change , \n",
      "Cleaned Token After Stem =  comput scienc , inform hide principl segreg design decis comput program like chang , \n",
      "Cleaned Token Before =  17, 2007. acm conference on recommender systems recsys group at politecnico di milano data science: data to insights from mit (recommendation systems)\n",
      "Cleaned Token After =  17 , 2007. acm conference recommender systems recsys group politecnico di milano data science : data insights mit ( recommendation systems ) \n",
      "Cleaned Token After Stem =  17 , 2007. acm confer recommend system recsi group politecnico di milano data scienc : data insight mit ( recommend system ) \n",
      "Cleaned Token Before =  experts fear rush to finish tally will yield flawed data\". science. 369 (6509): 1285–1286. doi:10.1126/science.369.6509.1285. issn 0036-8075. pmid 32913083.\n",
      "Cleaned Token After =  experts fear rush finish tally yield flawed data '' . science . 369 ( 6509 ) : 1285–1286 . doi:10.1126/science.369.6509.1285 . issn 0036-8075. pmid 32913083 . \n",
      "Cleaned Token After Stem =  expert fear rush finish talli yield flaw data `` . scienc . 369 ( 6509 ) : 1285–1286 . doi:10.1126/science.369.6509.1285 . issn 0036-8075. pmid 32913083 . \n",
      "Cleaned Token Before =  and phd degrees in mathematics, computation, computational finance and data science. the institute also runs training programs in schools aimed at increasing\n",
      "Cleaned Token After =  phd degrees mathematics , computation , computational finance data science . institute also runs training programs schools aimed increasing \n",
      "Cleaned Token After Stem =  phd degre mathemat , comput , comput financ data scienc . institut also run train program school aim increas \n",
      "Cleaned Token Before =  hardware, software, data, people, and procedures that work together to produce quality information. similar to computer science, other disciplines can\n",
      "Cleaned Token After =  hardware , software , data , people , procedures work together produce quality information . similar computer science , disciplines \n",
      "Cleaned Token After Stem =  hardwar , softwar , data , peopl , procedur work togeth produc qualiti inform . similar comput scienc , disciplin \n",
      "Cleaned Token Before =  tessella is an international analytics and data science consulting services company. tessella was founded in 1980 by kevin gell. tessella moved to its\n",
      "Cleaned Token After =  tessella international analytics data science consulting services company . tessella founded 1980 kevin gell . tessella moved \n",
      "Cleaned Token After Stem =  tessella intern analyt data scienc consult servic compani . tessella found 1980 kevin gell . tessella move \n",
      "Cleaned Token Before =  > data science > web analytics > predictive analytics\". www.personali.com. retrieved 2018-10-22. finlay, steven (2014). predictive analytics, data mining\n",
      "Cleaned Token After =  > data science > web analytics > predictive analytics '' . www.personali.com . retrieved 2018-10-22. finlay , steven ( 2014 ) . predictive analytics , data mining \n",
      "Cleaned Token After Stem =  > data scienc > web analyt > predict analyt `` . www.personali.com . retriev 2018-10-22. finlay , steven ( 2014 ) . predict analyt , data mine \n",
      "Cleaned Token Before =  learning, human-machine collaboration, geometric and spatial reasoning, data science, conversational agents, and computer vision and image synthesis.[citation\n",
      "Cleaned Token After =  learning , human-machine collaboration , geometric spatial reasoning , data science , conversational agents , computer vision image synthesis . [ citation \n",
      "Cleaned Token After Stem =  learn , human-machin collabor , geometr spatial reason , data scienc , convers agent , comput vision imag synthesi . [ citat \n",
      "Cleaned Token Before =  is known as the branch school of école polytechnique for statistics, data science and machine learning. it is one of france's top schools of economics\n",
      "Cleaned Token After =  known branch school école polytechnique statistics , data science machine learning . one france 's top schools economics \n",
      "Cleaned Token After Stem =  known branch school école polytechniqu statist , data scienc machin learn . one franc 's top school econom \n",
      "Cleaned Token Before =  density-based analysis of t cell signaling in single-cell data\". science. 346 (6213): 1250689. doi:10.1126/science.1250689. pmc 4334155. pmid 25342659. spitzer, matthew\n",
      "Cleaned Token After =  density-based analysis cell signaling single-cell data '' . science . 346 ( 6213 ) : 1250689. doi:10.1126/science.1250689 . pmc 4334155. pmid 25342659. spitzer , matthew \n",
      "Cleaned Token After Stem =  density-bas analysi cell signal single-cel data `` . scienc . 346 ( 6213 ) : 1250689. doi:10.1126/science.1250689 . pmc 4334155. pmid 25342659. spitzer , matthew \n",
      "Cleaned Token Before =  computing library and information science undergraduate programs include: bachelor of science in computer science, data science, informatics, intelligent systems\n",
      "Cleaned Token After =  computing library information science undergraduate programs include : bachelor science computer science , data science , informatics , intelligent systems \n",
      "Cleaned Token After Stem =  comput librari inform scienc undergradu program includ : bachelor scienc comput scienc , data scienc , informat , intellig system \n",
      "Cleaned Token Before =  data science to social networks. a professor at new york university, he holds appointments in the department of biology, the center for data science and\n",
      "Cleaned Token After =  data science social networks . professor new york university , holds appointments department biology , center data science \n",
      "Cleaned Token After Stem =  data scienc social network . professor new york univers , hold appoint depart biolog , center data scienc \n",
      "Cleaned Token Before =  including p-hacking, publication bias, data dredging, and harking. it has recently gained prominence in the open science community as a potential solution\n",
      "Cleaned Token After =  including p-hacking , publication bias , data dredging , harking . recently gained prominence open science community potential solution \n",
      "Cleaned Token After Stem =  includ p-hack , public bia , data dredg , hark . recent gain promin open scienc commun potenti solut \n",
      "Cleaned Token Before =  classification of causes of data quality problems in data warehousing\". ijcsi international journal of computer science issue. 2. 7 (3). kimball, ralph\n",
      "Cleaned Token After =  classification causes data quality problems data warehousing '' . ijcsi international journal computer science issue . 2 . 7 ( 3 ) . kimball , ralph \n",
      "Cleaned Token After Stem =  classif caus data qualiti problem data wareh `` . ijcsi intern journal comput scienc issu . 2 . 7 ( 3 ) . kimbal , ralph \n",
      "Cleaned Token Before =  the purpose of data reduction can be two-fold: reduce the number of data records by eliminating invalid data or produce summary data and statistics at\n",
      "Cleaned Token After =  purpose data reduction two-fold : reduce number data records eliminating invalid data produce summary data statistics \n",
      "Cleaned Token After Stem =  purpos data reduct two-fold : reduc number data record elimin invalid data produc summari data statist \n",
      "Cleaned Token Before =  used to handle data editing data cleansing data pre-processing data wrangling iterative proportional fitting triangulation (social science) the errors that\n",
      "Cleaned Token After =  used handle data editing data cleansing data pre-processing data wrangling iterative proportional fitting triangulation ( social science ) errors \n",
      "Cleaned Token After Stem =  use handl data edit data cleans data pre-process data wrangl iter proport fit triangul ( social scienc ) error \n",
      "Cleaned Token Before =  the bachelor of computer science or bachelor of science in computer science (abbreviated bcompsc or bcs or bs cs or b.sc. cs) is a type of bachelor's degree\n",
      "Cleaned Token After =  bachelor computer science bachelor science computer science ( abbreviated bcompsc bcs bs cs b.sc . cs ) type bachelor 's degree \n",
      "Cleaned Token After Stem =  bachelor comput scienc bachelor scienc comput scienc ( abbrevi bcompsc bc bs cs b.sc . cs ) type bachelor 's degre \n",
      "Cleaned Token Before =  into data science techniques across a range of disciplines. therefore this research chair is focused on a multidisciplinary approach to data science and\n",
      "Cleaned Token After =  data science techniques across range disciplines . therefore research chair focused multidisciplinary approach data science \n",
      "Cleaned Token After Stem =  data scienc techniqu across rang disciplin . therefor research chair focus multidisciplinari approach data scienc \n",
      "Cleaned Token Before =  and other anti-infective therapeutic development programs\". harvard data science review. mit press (special issue 1 - covid-19). doi:10.1162/99608f92\n",
      "Cleaned Token After =  anti-infective therapeutic development programs '' . harvard data science review . mit press ( special issue 1 - covid-19 ) . doi:10.1162/99608f92 \n",
      "Cleaned Token After Stem =  anti-infect therapeut develop program `` . harvard data scienc review . mit press ( special issu 1 - covid-19 ) . doi:10.1162/99608f92 \n",
      "Cleaned Token Before =  (2019-02-09). \"breaking neural networks with adversarial attacks - towards data science\". medium. retrieved 2019-07-15. ackerman, evan (2017-08-04). \"slight\n",
      "Cleaned Token After =  ( 2019-02-09 ) . `` breaking neural networks adversarial attacks - towards data science '' . medium . retrieved 2019-07-15. ackerman , evan ( 2017-08-04 ) . `` slight \n",
      "Cleaned Token After Stem =  ( 2019-02-09 ) . `` break neural network adversari attack - toward data scienc `` . medium . retriev 2019-07-15. ackerman , evan ( 2017-08-04 ) . `` slight \n",
      "Cleaned Token Before =   obe (born may 29, 1958) is an english entrepreneur in the field of data science and customer-centric business strategy. since 2014, she has been the\n",
      "Cleaned Token After =  obe ( born may 29 , 1958 ) english entrepreneur field data science customer-centric business strategy . since 2014 , \n",
      "Cleaned Token After Stem =  obe ( born may 29 , 1958 ) english entrepreneur field data scienc customer-centr busi strategi . sinc 2014 , \n",
      "Cleaned Token Before =  looker data sciences, inc. is an american computer software company headquartered in santa cruz, california. it was acquired by google in 2019 and is\n",
      "Cleaned Token After =  looker data sciences , inc. american computer software company headquartered santa cruz , california . acquired google 2019 \n",
      "Cleaned Token After Stem =  looker data scienc , inc. american comput softwar compani headquart santa cruz , california . acquir googl 2019 \n",
      "Cleaned Token Before =  queues provide services in computer science, transport, and operations research where various entities such as data, objects, persons, or events are stored\n",
      "Cleaned Token After =  queues provide services computer science , transport , operations research various entities data , objects , persons , events stored \n",
      "Cleaned Token After Stem =  queue provid servic comput scienc , transport , oper research variou entiti data , object , person , event store \n",
      "Cleaned Token Before =   hyundai card has become known for its data science. the company has about 500 employees in its data science team, which is roughly one-third of its\n",
      "Cleaned Token After =  hyundai card become known data science . company 500 employees data science team , roughly one-third \n",
      "Cleaned Token After Stem =  hyundai card becom known data scienc . compani 500 employe data scienc team , roughli one-third \n",
      "Cleaned Token Before =  interdisciplinary field fusing theory-based psychometrics, learning and cognitive sciences, and data-driven ai-based computational models as applied to large-scale/high-dimensional\n",
      "Cleaned Token After =  interdisciplinary field fusing theory-based psychometrics , learning cognitive sciences , data-driven ai-based computational models applied large-scale/high-dimensional \n",
      "Cleaned Token After Stem =  interdisciplinari field fuse theory-bas psychometr , learn cognit scienc , data-driven ai-bas comput model appli large-scale/high-dimension \n",
      "Cleaned Token Before =  repositories include the open science framework, registry of research data repositories, and psychfiledrawer.org. sites like open science framework offer badges\n",
      "Cleaned Token After =  repositories include open science framework , registry research data repositories , psychfiledrawer.org . sites like open science framework offer badges \n",
      "Cleaned Token After Stem =  repositori includ open scienc framework , registri research data repositori , psychfiledrawer.org . site like open scienc framework offer badg \n",
      "Cleaned Token Before =  program. undergraduate and graduate programs in computer science, software engineering, data science, information systems, and computer security are offered\n",
      "Cleaned Token After =  program . undergraduate graduate programs computer science , software engineering , data science , information systems , computer security offered \n",
      "Cleaned Token After Stem =  program . undergradu graduat program comput scienc , softwar engin , data scienc , inform system , comput secur offer \n",
      "Cleaned Token Before =  business disciplines, such as: product management, project management, data science, management information systems (mis) and/or technology and innovation\n",
      "Cleaned Token After =  business disciplines , : product management , project management , data science , management information systems ( mis ) and/or technology innovation \n",
      "Cleaned Token After Stem =  busi disciplin , : product manag , project manag , data scienc , manag inform system ( mi ) and/or technolog innov \n",
      "Cleaned Token Before =  in chapel hill, nc. datagraph is used for creating publication quality graphics, particularly for research and science. visual data tools was founded in\n",
      "Cleaned Token After =  chapel hill , nc . datagraph used creating publication quality graphics , particularly research science . visual data tools founded \n",
      "Cleaned Token After Stem =  chapel hill , nc . datagraph use creat public qualiti graphic , particularli research scienc . visual data tool found \n",
      "Cleaned Token Before =  improve the accuracy of data system users’ data analyses. data processing persistent data structure crud persistence (computer science) paul beynon-davies\n",
      "Cleaned Token After =  improve accuracy data system users ’ data analyses . data processing persistent data structure crud persistence ( computer science ) paul beynon-davies \n",
      "Cleaned Token After Stem =  improv accuraci data system user ’ data analys . data process persist data structur crud persist ( comput scienc ) paul beynon-davi \n",
      "Cleaned Token Before =  advanced mathematics, computer science, algorithms and big data. in august 2015, the department of management science and innovation was renamed as the\n",
      "Cleaned Token After =  advanced mathematics , computer science , algorithms big data . august 2015 , department management science innovation renamed \n",
      "Cleaned Token After Stem =  advanc mathemat , comput scienc , algorithm big data . august 2015 , depart manag scienc innov renam \n",
      "Cleaned Token Before =  health, where he used data science in the fight against cancer on the data insights engineering team. he has three courses on datacamp published, which\n",
      "Cleaned Token After =  health , used data science fight cancer data insights engineering team . three courses datacamp published , \n",
      "Cleaned Token After Stem =  health , use data scienc fight cancer data insight engin team . three cours datacamp publish , \n",
      "Cleaned Token Before =  a data architect is a practitioner of data architecture, a data management discipline concerned with designing, creating, deploying and managing an organization's\n",
      "Cleaned Token After =  data architect practitioner data architecture , data management discipline concerned designing , creating , deploying managing organization 's \n",
      "Cleaned Token After Stem =  data architect practition data architectur , data manag disciplin concern design , creat , deploy manag organ 's \n",
      "Cleaned Token Before =  8/24-27, new york: data mining for social good\". www.kdd.org. \"data science view of the kdd 2014\". august 27, 2014. \"computer science conferences acceptance\n",
      "Cleaned Token After =  8/24-27 , new york : data mining social good '' . www.kdd.org . `` data science view kdd 2014 '' . august 27 , 2014 . `` computer science conferences acceptance \n",
      "Cleaned Token After Stem =  8/24-27 , new york : data mine social good `` . www.kdd.org . `` data scienc view kdd 2014 `` . august 27 , 2014 . `` comput scienc confer accept \n",
      "Cleaned Token Before =  school of business and the center for data science at new york university, former editor-in-chief of the journal big data. and the founder of sct capital,\n",
      "Cleaned Token After =  school business center data science new york university , former editor-in-chief journal big data . founder sct capital , \n",
      "Cleaned Token After Stem =  school busi center data scienc new york univers , former editor-in-chief journal big data . founder sct capit , \n",
      "Cleaned Token Before =  analysis, data science and statistics. statsmodels is built on top of the numerical libraries numpy and scipy, integrates with pandas for data handling\n",
      "Cleaned Token After =  analysis , data science statistics . statsmodels built top numerical libraries numpy scipy , integrates pandas data handling \n",
      "Cleaned Token After Stem =  analysi , data scienc statist . statsmodel built top numer librari numpi scipi , integr panda data handl \n",
      "Cleaned Token Before =  in computer science, the general meaning of input is to provide or give something to the computer, in other words, when a computer or device is receiving\n",
      "Cleaned Token After =  computer science , general meaning input provide give something computer , words , computer device receiving \n",
      "Cleaned Token After Stem =  comput scienc , gener mean input provid give someth comput , word , comput devic receiv \n",
      "Cleaned Token Before =  jake (2016). \"introduction to numpy\". python data science handbook: essential tools for working with data. o'reilly. pp. 33–96. isbn 978-1-4919-1205-8\n",
      "Cleaned Token After =  jake ( 2016 ) . `` introduction numpy '' . python data science handbook : essential tools working data . o'reilly . pp . 33–96 . isbn 978-1-4919-1205-8 \n",
      "Cleaned Token After Stem =  jake ( 2016 ) . `` introduct numpi `` . python data scienc handbook : essenti tool work data . o'reilli . pp . 33–96 . isbn 978-1-4919-1205-8 \n",
      "Cleaned Token Before =  grinnell college with a b.a. in computer science in 2000, and attended brown university. mason was the chief data scientist at bitly for four years. she\n",
      "Cleaned Token After =  grinnell college b.a . computer science 2000 , attended brown university . mason chief data scientist bitly four years . \n",
      "Cleaned Token After Stem =  grinnel colleg b.a . comput scienc 2000 , attend brown univers . mason chief data scientist bitli four year . \n",
      "Cleaned Token Before =  robotics. in 2012, he became the founding director of the nyu center for data science. on december 9, 2013, lecun became the first director of facebook ai\n",
      "Cleaned Token After =  robotics . 2012 , became founding director nyu center data science . december 9 , 2013 , lecun became first director facebook ai \n",
      "Cleaned Token After Stem =  robot . 2012 , becam found director nyu center data scienc . decemb 9 , 2013 , lecun becam first director facebook ai \n",
      "Cleaned Token Before =  to apply for a one-year master of science degree in social data science with the related dphil in social data science available from 2020 onward. the oxford\n",
      "Cleaned Token After =  apply one-year master science degree social data science related dphil social data science available 2020 onward . oxford \n",
      "Cleaned Token After Stem =  appli one-year master scienc degre social data scienc relat dphil social data scienc avail 2020 onward . oxford \n",
      "Cleaned Token Before =  of computer science 4th ed. nature publishing group. p. 865.cs1 maint: extra text: authors list (link) reddy, r.j. (2004). business data processing &\n",
      "Cleaned Token After =  computer science 4th ed . nature publishing group . p. 865.cs1 maint : extra text : authors list ( link ) reddy , r.j. ( 2004 ) . business data processing & \n",
      "Cleaned Token After Stem =  comput scienc 4th ed . natur publish group . p. 865.cs1 maint : extra text : author list ( link ) reddi , r.j. ( 2004 ) . busi data process & \n",
      "Cleaned Token Before =  school offers a variety of master's degrees in economics, finance, and data science. it has been ranked by repec among the top economics departments in the\n",
      "Cleaned Token After =  school offers variety master 's degrees economics , finance , data science . ranked repec among top economics departments \n",
      "Cleaned Token After Stem =  school offer varieti master 's degre econom , financ , data scienc . rank repec among top econom depart \n",
      "Cleaned Token Before =  mu sigma is an indian decision sciences firm that primarily offers data analytics services. the firm's name is derived from the statistical terms \"mu (μ)\"\n",
      "Cleaned Token After =  mu sigma indian decision sciences firm primarily offers data analytics services . firm 's name derived statistical terms `` mu ( μ ) '' \n",
      "Cleaned Token After Stem =  mu sigma indian decis scienc firm primarili offer data analyt servic . firm 's name deriv statist term `` mu ( μ ) `` \n",
      "Cleaned Token Before =  enigma is a data science company headquartered in new york city that specializes in providing data and intelligence about businesses. the company is mainly\n",
      "Cleaned Token After =  enigma data science company headquartered new york city specializes providing data intelligence businesses . company mainly \n",
      "Cleaned Token After Stem =  enigma data scienc compani headquart new york citi special provid data intellig busi . compani mainli \n",
      "Cleaned Token Before =  the data science team at greenplum. alpine's core product then, alpine miner, allowed for non-data scientists to create predictive analytics data models\n",
      "Cleaned Token After =  data science team greenplum . alpine 's core product , alpine miner , allowed non-data scientists create predictive analytics data models \n",
      "Cleaned Token After Stem =  data scienc team greenplum . alpin 's core product , alpin miner , allow non-data scientist creat predict analyt data model \n",
      "Cleaned Token Before =  in the social sciences, coding is an analytical process in which data, in both quantitative form (such as questionnaires results) or qualitative form\n",
      "Cleaned Token After =  social sciences , coding analytical process data , quantitative form ( questionnaires results ) qualitative form \n",
      "Cleaned Token After Stem =  social scienc , code analyt process data , quantit form ( questionnair result ) qualit form \n",
      "Cleaned Token Before =  in applied mathematics, topological data analysis (tda) is an approach to the analysis of datasets using techniques from topology. extraction of information\n",
      "Cleaned Token After =  applied mathematics , topological data analysis ( tda ) approach analysis datasets using techniques topology . extraction information \n",
      "Cleaned Token After Stem =  appli mathemat , topolog data analysi ( tda ) approach analysi dataset use techniqu topolog . extract inform \n",
      "Cleaned Token Before =  infrastructure to access the agency's open data. prior to working at nasa and with the white house office of science and technology policy, he wrote the open-source\n",
      "Cleaned Token After =  infrastructure access agency 's open data . prior working nasa white house office science technology policy , wrote open-source \n",
      "Cleaned Token After Stem =  infrastructur access agenc 's open data . prior work nasa white hous offic scienc technolog polici , wrote open-sourc \n",
      "Cleaned Token Before =  vapor over liquid. material safety data sheet for benzene: brown; lemay; bursten (2006). chemistry: the central science. upper saddle river, nj: pearson\n",
      "Cleaned Token After =  vapor liquid . material safety data sheet benzene : brown ; lemay ; bursten ( 2006 ) . chemistry : central science . upper saddle river , nj : pearson \n",
      "Cleaned Token After Stem =  vapor liquid . materi safeti data sheet benzen : brown ; lemay ; bursten ( 2006 ) . chemistri : central scienc . upper saddl river , nj : pearson \n",
      "Cleaned Token Before =  data synchronization is the process of establishing consistency among data from a source to a target data storage and vice versa and the continuous harmonization\n",
      "Cleaned Token After =  data synchronization process establishing consistency among data source target data storage vice versa continuous harmonization \n",
      "Cleaned Token After Stem =  data synchron process establish consist among data sourc target data storag vice versa continu harmon \n",
      "Cleaned Token Before =  statistics (ncses) gathers data from surveys and partnerships with other agencies to offer official data on the american science and engineering workforce\n",
      "Cleaned Token After =  statistics ( ncses ) gathers data surveys partnerships agencies offer official data american science engineering workforce \n",
      "Cleaned Token After Stem =  statist ( ncse ) gather data survey partnership agenc offer offici data american scienc engin workforc \n",
      "Cleaned Token Before =  in computer science, a stack is an abstract data type that serves as a collection of elements, with two main principal operations: push, which adds an\n",
      "Cleaned Token After =  computer science , stack abstract data type serves collection elements , two main principal operations : push , adds \n",
      "Cleaned Token After Stem =  comput scienc , stack abstract data type serv collect element , two main princip oper : push , add \n",
      "Cleaned Token Before =  reveals the perils of big-data science\". wired. retrieved 31 may 2016. cox, joseph. \"danish authorities investigate okcupid data dump\". motherboard. retrieved\n",
      "Cleaned Token After =  reveals perils big-data science '' . wired . retrieved 31 may 2016. cox , joseph . `` danish authorities investigate okcupid data dump '' . motherboard . retrieved \n",
      "Cleaned Token After Stem =  reveal peril big-data scienc `` . wire . retriev 31 may 2016. cox , joseph . `` danish author investig okcupid data dump `` . motherboard . retriev \n",
      "Cleaned Token Before =  the journal has a 2014 impact factor of 2.458. \"atomic data and nuclear data tables\". sciencedirect.com. retrieved 2016-06-04. cs1 maint: discouraged\n",
      "Cleaned Token After =  journal 2014 impact factor 2.458 . `` atomic data nuclear data tables '' . sciencedirect.com . retrieved 2016-06-04. cs1 maint : discouraged \n",
      "Cleaned Token After Stem =  journal 2014 impact factor 2.458 . `` atom data nuclear data tabl `` . sciencedirect.com . retriev 2016-06-04. cs1 maint : discourag \n",
      "Cleaned Token Before =  establishing a pattern lexicon, prompting the practitioners of computer science to contemplate their own design lexicon. usage of this metaphor within\n",
      "Cleaned Token After =  establishing pattern lexicon , prompting practitioners computer science contemplate design lexicon . usage metaphor within \n",
      "Cleaned Token After Stem =  establish pattern lexicon , prompt practition comput scienc contempl design lexicon . usag metaphor within \n",
      "Cleaned Token Before =  scientist who works in data science. he is currently a professor of computer science in the david r. cheriton school of computer science at the university\n",
      "Cleaned Token After =  scientist works data science . currently professor computer science david r. cheriton school computer science university \n",
      "Cleaned Token After Stem =  scientist work data scienc . current professor comput scienc david r. cheriton school comput scienc univers \n",
      "Cleaned Token Before =  data corruption refers to errors in computer data that occur during writing, reading, storage, transmission, or processing, which introduce unintended\n",
      "Cleaned Token After =  data corruption refers errors computer data occur writing , reading , storage , transmission , processing , introduce unintended \n",
      "Cleaned Token After Stem =  data corrupt refer error comput data occur write , read , storag , transmiss , process , introduc unintend \n",
      "Cleaned Token Before =  in computer science and data management, a commit is the making of a set of tentative changes permanent, marking the end of a transaction and providing\n",
      "Cleaned Token After =  computer science data management , commit making set tentative changes permanent , marking end transaction providing \n",
      "Cleaned Token After Stem =  comput scienc data manag , commit make set tent chang perman , mark end transact provid \n",
      "Cleaned Token Before =  perspective on data science, and in the presentation opportunities and perils in data science, he argued for a trans-disciplinary study of data science that includes\n",
      "Cleaned Token After =  perspective data science , presentation opportunities perils data science , argued trans-disciplinary study data science includes \n",
      "Cleaned Token After Stem =  perspect data scienc , present opportun peril data scienc , argu trans-disciplinari studi data scienc includ \n",
      "Cleaned Token Before =  for the world's most innovative companies in data science, acknowledging ubiome's work collecting data to develop tests for hpv and stis. \"ubiome to\n",
      "Cleaned Token After =  world 's innovative companies data science , acknowledging ubiome 's work collecting data develop tests hpv stis . `` ubiome \n",
      "Cleaned Token After Stem =  world 's innov compani data scienc , acknowledg ubiom 's work collect data develop test hpv sti . `` ubiom \n",
      "Cleaned Token Before =  institute for network science, since its founding, and chair of the newly established department of statistics and data science. daniel spielman attended\n",
      "Cleaned Token After =  institute network science , since founding , chair newly established department statistics data science . daniel spielman attended \n",
      "Cleaned Token After Stem =  institut network scienc , sinc found , chair newli establish depart statist data scienc . daniel spielman attend \n",
      "Cleaned Token Before =  forensic science, also known as criminalistics, is the application of science to criminal and civil laws, mainly—on the criminal side—during criminal investigation\n",
      "Cleaned Token After =  forensic science , also known criminalistics , application science criminal civil laws , mainly—on criminal side—during criminal investigation \n",
      "Cleaned Token After Stem =  forens scienc , also known criminalist , applic scienc crimin civil law , mainly—on crimin side—dur crimin investig \n",
      "Cleaned Token Before =  as a service (saas) data science company that provides a b2b customer data platform. the company's products unifies multiple data sources, 1st party and\n",
      "Cleaned Token After =  service ( saas ) data science company provides b2b customer data platform . company 's products unifies multiple data sources , 1st party \n",
      "Cleaned Token After Stem =  servic ( saa ) data scienc compani provid b2b custom data platform . compani 's product unifi multipl data sourc , 1st parti \n",
      "Cleaned Token Before =  high-performance computing applications. since 2015, altintas has served as chief data science officer of the san diego supercomputer center (sdsc), at the university\n",
      "Cleaned Token After =  high-performance computing applications . since 2015 , altintas served chief data science officer san diego supercomputer center ( sdsc ) , university \n",
      "Cleaned Token After Stem =  high-perform comput applic . sinc 2015 , altinta serv chief data scienc offic san diego supercomput center ( sdsc ) , univers \n",
      "Cleaned Token Before =  packages statsoft \"tibco software to acquire data science platform leader statistica\". \"tibco® data science\". tibco software inc. christian h. weiss \"commercial\n",
      "Cleaned Token After =  packages statsoft `` tibco software acquire data science platform leader statistica '' . `` tibco® data science '' . tibco software inc. christian h. weiss `` commercial \n",
      "Cleaned Token After Stem =  packag statsoft `` tibco softwar acquir data scienc platform leader statistica `` . `` tibco® data scienc `` . tibco softwar inc. christian h. weiss `` commerci \n",
      "Cleaned Token Before =  computer science (particularly computer vision, artificial intelligence, and computer graphics), as well as other engineering related areas such as data visualization\n",
      "Cleaned Token After =  computer science ( particularly computer vision , artificial intelligence , computer graphics ) , well engineering related areas data visualization \n",
      "Cleaned Token After Stem =  comput scienc ( particularli comput vision , artifici intellig , comput graphic ) , well engin relat area data visual \n",
      "Cleaned Token Before =   and data management components needed to solve computationally demanding problems the computing infrastructure that supports both the science and engineering\n",
      "Cleaned Token After =  data management components needed solve computationally demanding problems computing infrastructure supports science engineering \n",
      "Cleaned Token After Stem =  data manag compon need solv comput demand problem comput infrastructur support scienc engin \n",
      "Cleaned Token Before =  analytics, it management, master data management, enterprise architecture, business intelligence, big data, data science, and finance. records management\n",
      "Cleaned Token After =  analytics , management , master data management , enterprise architecture , business intelligence , big data , data science , finance . records management \n",
      "Cleaned Token After Stem =  analyt , manag , master data manag , enterpris architectur , busi intellig , big data , data scienc , financ . record manag \n",
      "Cleaned Token Before =  pangaea - data publisher for earth & environmental science is a digital data library and a data publisher for earth system science. data can be georeferenced\n",
      "Cleaned Token After =  pangaea - data publisher earth & environmental science digital data library data publisher earth system science . data georeferenced \n",
      "Cleaned Token After Stem =  pangaea - data publish earth & environment scienc digit data librari data publish earth system scienc . data georeferenc \n",
      "Cleaned Token Before =  a database is an organized collection of data, generally stored and accessed electronically from a computer system. where databases are more complex they\n",
      "Cleaned Token After =  database organized collection data , generally stored accessed electronically computer system . databases complex \n",
      "Cleaned Token After Stem =  databas organ collect data , gener store access electron comput system . databas complex \n",
      "Cleaned Token Before =  that combine big data with health policy and climate change. she is a professor of biostatistics, co-director of the harvard data science initiative, and\n",
      "Cleaned Token After =  combine big data health policy climate change . professor biostatistics , co-director harvard data science initiative , \n",
      "Cleaned Token After Stem =  combin big data health polici climat chang . professor biostatist , co-director harvard data scienc initi , \n",
      "Cleaned Token Before =  or accessibility. replication in computing can refer to: data replication, where the same data is stored on multiple storage devices computation replication\n",
      "Cleaned Token After =  accessibility . replication computing refer : data replication , data stored multiple storage devices computation replication \n",
      "Cleaned Token After Stem =  access . replic comput refer : data replic , data store multipl storag devic comput replic \n",
      "Cleaned Token Before =  mapping, and spatial data science tools. the company is positioned as a location intelligence platform due to tools with an aptitude for data analysis and visualization\n",
      "Cleaned Token After =  mapping , spatial data science tools . company positioned location intelligence platform due tools aptitude data analysis visualization \n",
      "Cleaned Token After Stem =  map , spatial data scienc tool . compani posit locat intellig platform due tool aptitud data analysi visual \n",
      "Cleaned Token Before =  in computer science, a k-d tree (short for k-dimensional tree) is a space-partitioning data structure for organizing points in a k-dimensional space.\n",
      "Cleaned Token After =  computer science , k-d tree ( short k-dimensional tree ) space-partitioning data structure organizing points k-dimensional space . \n",
      "Cleaned Token After Stem =  comput scienc , k-d tree ( short k-dimension tree ) space-partit data structur organ point k-dimension space . \n",
      "Cleaned Token Before =  appraisal from pioneer venus probe data\". science. 205 (4401): 46–49. bibcode:1979sci...205...46s. doi:10.1126/science.205.4401.46. jstor 1748510. hoffman\n",
      "Cleaned Token After =  appraisal pioneer venus probe data '' . science . 205 ( 4401 ) : 46–49 . bibcode:1979sci ... 205 ... 46s . doi:10.1126/science.205.4401.46 . jstor 1748510. hoffman \n",
      "Cleaned Token After Stem =  apprais pioneer venu probe data `` . scienc . 205 ( 4401 ) : 46–49 . bibcode:1979sci ... 205 ... 46 . doi:10.1126/science.205.4401.46 . jstor 1748510. hoffman \n",
      "Cleaned Token Before =  taught courses in political economy and data analysis while publishing three quantitatively inclined political science books. in 1975, while at princeton,\n",
      "Cleaned Token After =  taught courses political economy data analysis publishing three quantitatively inclined political science books . 1975 , princeton , \n",
      "Cleaned Token After Stem =  taught cours polit economi data analysi publish three quantit inclin polit scienc book . 1975 , princeton , \n",
      "Cleaned Token Before =  the history of science is the study of the development of science, including both the natural and social sciences (the history of the arts and humanities\n",
      "Cleaned Token After =  history science study development science , including natural social sciences ( history arts humanities \n",
      "Cleaned Token After Stem =  histori scienc studi develop scienc , includ natur social scienc ( histori art human \n",
      "Cleaned Token Before =  appraisal from pioneer venus probe data\". science. 205 (4401): 46–49. bibcode:1979sci...205...46s. doi:10.1126/science.205.4401.46. jstor 1748510. hoffman\n",
      "Cleaned Token After =  appraisal pioneer venus probe data '' . science . 205 ( 4401 ) : 46–49 . bibcode:1979sci ... 205 ... 46s . doi:10.1126/science.205.4401.46 . jstor 1748510. hoffman \n",
      "Cleaned Token After Stem =  apprais pioneer venu probe data `` . scienc . 205 ( 4401 ) : 46–49 . bibcode:1979sci ... 205 ... 46 . doi:10.1126/science.205.4401.46 . jstor 1748510. hoffman \n",
      "Cleaned Token Before =  engineering professor, whose research has focused on signal processing and data science. she is the first female dean of the engineering school at new york university\n",
      "Cleaned Token After =  engineering professor , whose research focused signal processing data science . first female dean engineering school new york university \n",
      "Cleaned Token After Stem =  engin professor , whose research focus signal process data scienc . first femal dean engin school new york univers \n",
      "Cleaned Token Before =  social sciences study-level information. this information is described as metadata by the standard. begun in 1995, the effort brings together data professionals\n",
      "Cleaned Token After =  social sciences study-level information . information described metadata standard . begun 1995 , effort brings together data professionals \n",
      "Cleaned Token After Stem =  social scienc study-level inform . inform describ metadata standard . begun 1995 , effort bring togeth data profession \n",
      "Cleaned Token Before =  constructing a user's profile using his or her social data. in general, profiling refers to the data science process of generating a person's profile with computerized\n",
      "Cleaned Token After =  constructing user 's profile using social data . general , profiling refers data science process generating person 's profile computerized \n",
      "Cleaned Token After Stem =  construct user 's profil use social data . gener , profil refer data scienc process gener person 's profil computer \n",
      "Cleaned Token Before =  and systems (mims), a professional master's degree in information and data science (mids), a professional master's degree in information and cybersecurity\n",
      "Cleaned Token After =  systems ( mims ) , professional master 's degree information data science ( mids ) , professional master 's degree information cybersecurity \n",
      "Cleaned Token After Stem =  system ( mim ) , profession master 's degre inform data scienc ( mid ) , profession master 's degre inform cybersecur \n",
      "Cleaned Token Before =  appointment in the institute for data intensive engineering and sciences, and vogelstein is the director of the biomedical data science focus area for the johns\n",
      "Cleaned Token After =  appointment institute data intensive engineering sciences , vogelstein director biomedical data science focus area johns \n",
      "Cleaned Token After Stem =  appoint institut data intens engin scienc , vogelstein director biomed data scienc focu area john \n",
      "Cleaned Token Before =  and data systems section at the laboratory. mattmann graduated from the university of southern california (usc) in 2007 with a phd in computer science studying\n",
      "Cleaned Token After =  data systems section laboratory . mattmann graduated university southern california ( usc ) 2007 phd computer science studying \n",
      "Cleaned Token After Stem =  data system section laboratori . mattmann graduat univers southern california ( usc ) 2007 phd comput scienc studi \n",
      "Cleaned Token Before =  1956) is a professor in the departments of statistics and biomedical data science at stanford university. he was a professor at the university of toronto\n",
      "Cleaned Token After =  1956 ) professor departments statistics biomedical data science stanford university . professor university toronto \n",
      "Cleaned Token After Stem =  1956 ) professor depart statist biomed data scienc stanford univers . professor univers toronto \n",
      "Cleaned Token Before =  mysciencework is a technology company that provides a suite of advanced data-driven solutions for research institutions, scientific publishers and private-sector\n",
      "Cleaned Token After =  mysciencework technology company provides suite advanced data-driven solutions research institutions , scientific publishers private-sector \n",
      "Cleaned Token After Stem =  mysciencework technolog compani provid suit advanc data-driven solut research institut , scientif publish private-sector \n",
      "Cleaned Token Before =  quality data over time to assess the health of local waters, or help discover and name new species of insect. an emerging branch of citizen science are community\n",
      "Cleaned Token After =  quality data time assess health local waters , help discover name new species insect . emerging branch citizen science community \n",
      "Cleaned Token After Stem =  qualiti data time assess health local water , help discov name new speci insect . emerg branch citizen scienc commun \n",
      "Cleaned Token Before =  one definition of open science holds that it is the movement to make scientific research (including publications, data, physical samples, and software)\n",
      "Cleaned Token After =  one definition open science holds movement make scientific research ( including publications , data , physical samples , software ) \n",
      "Cleaned Token After Stem =  one definit open scienc hold movement make scientif research ( includ public , data , physic sampl , softwar ) \n",
      "Cleaned Token Before =  open press and other publications globally and referenced in data aggregator and science libraries. knoema launched in 2014 under a collaboration with\n",
      "Cleaned Token After =  open press publications globally referenced data aggregator science libraries . knoema launched 2014 collaboration \n",
      "Cleaned Token After Stem =  open press public global referenc data aggreg scienc librari . knoema launch 2014 collabor \n",
      "Cleaned Token Before =  philosophy in computer sciences. university of wisconsin-madison. retrieved 9 june 2012. \"parity lost and parity regained\". \"an analysis of data corruption in\n",
      "Cleaned Token After =  philosophy computer sciences . university wisconsin-madison . retrieved 9 june 2012 . `` parity lost parity regained '' . `` analysis data corruption \n",
      "Cleaned Token After Stem =  philosophi comput scienc . univers wisconsin-madison . retriev 9 june 2012 . `` pariti lost pariti regain `` . `` analysi data corrupt \n",
      "Cleaned Token Before =  business intelligence software visual analytics artificial intelligence data science machine learning dynamic queries, starfield displays, and the path to\n",
      "Cleaned Token After =  business intelligence software visual analytics artificial intelligence data science machine learning dynamic queries , starfield displays , path \n",
      "Cleaned Token After Stem =  busi intellig softwar visual analyt artifici intellig data scienc machin learn dynam queri , starfield display , path \n",
      "Cleaned Token Before =  encouraging data sharing and also by increasing the prestige of people who share. data citation is an emerging topic in computer science and it has been\n",
      "Cleaned Token After =  encouraging data sharing also increasing prestige people share . data citation emerging topic computer science \n",
      "Cleaned Token After Stem =  encourag data share also increas prestig peopl share . data citat emerg topic comput scienc \n",
      "Cleaned Token Before =  science (m.s.) in computer science professional masters of computer science (m.c.s.) online mcs is offered in partnership with coursera. mcs in data science(mcs-ds)\n",
      "Cleaned Token After =  science ( m.s . ) computer science professional masters computer science ( m.c.s . ) online mcs offered partnership coursera . mcs data science ( mcs-ds ) \n",
      "Cleaned Token After Stem =  scienc ( m. . ) comput scienc profession master comput scienc ( m.c. . ) onlin mc offer partnership coursera . mc data scienc ( mcs-d ) \n",
      "Cleaned Token Before =  in computer science, a record (also called a structure, struct, or compound data) is a basic data structure. records in a database or spreadsheet are\n",
      "Cleaned Token After =  computer science , record ( also called structure , struct , compound data ) basic data structure . records database spreadsheet \n",
      "Cleaned Token After Stem =  comput scienc , record ( also call structur , struct , compound data ) basic data structur . record databas spreadsheet \n",
      "Cleaned Token Before =  bah is a gambian mathematician and chair of data science at the african institute for mathematical sciences (aims). he is an assistant professor at stellenbosch\n",
      "Cleaned Token After =  bah gambian mathematician chair data science african institute mathematical sciences ( aims ) . assistant professor stellenbosch \n",
      "Cleaned Token After Stem =  bah gambian mathematician chair data scienc african institut mathemat scienc ( aim ) . assist professor stellenbosch \n",
      "Cleaned Token Before =  registration process is necessary to contribute information to the site. most data in the database is provided by volunteer contributors. the site enables registered\n",
      "Cleaned Token After =  registration process necessary contribute information site . data database provided volunteer contributors . site enables registered \n",
      "Cleaned Token After Stem =  registr process necessari contribut inform site . data databas provid volunt contributor . site enabl regist \n",
      "Cleaned Token Before =  pandemic. our world in data is cited in academic scientific journals, medicine and global health journals, and social science journals. the bbc and publications\n",
      "Cleaned Token After =  pandemic . world data cited academic scientific journals , medicine global health journals , social science journals . bbc publications \n",
      "Cleaned Token After Stem =  pandem . world data cite academ scientif journal , medicin global health journal , social scienc journal . bbc public \n",
      "Cleaned Token Before =  bradley (2016-11-17). data wrangling with r. cham. isbn 9783319455990. oclc 964404346. hadley, wickham (2017). r for data science : import, tidy, transform\n",
      "Cleaned Token After =  bradley ( 2016-11-17 ) . data wrangling r. cham . isbn 9783319455990. oclc 964404346. hadley , wickham ( 2017 ) . r data science : import , tidy , transform \n",
      "Cleaned Token After Stem =  bradley ( 2016-11-17 ) . data wrangl r. cham . isbn 9783319455990. oclc 964404346. hadley , wickham ( 2017 ) . r data scienc : import , tidi , transform \n",
      "Cleaned Token Before =  education. woz u offers courses in software development, cyber security and data science that lasts approximately 33 weeks, with one to two hours of lectures\n",
      "Cleaned Token After =  education . woz u offers courses software development , cyber security data science lasts approximately 33 weeks , one two hours lectures \n",
      "Cleaned Token After Stem =  educ . woz u offer cours softwar develop , cyber secur data scienc last approxim 33 week , one two hour lectur \n",
      "Cleaned Token Before =  sciences, pp. 4114–4121. abstract. • referred to in the journal of economic literature classification codes under jel: c8 – data collection and data estimation\n",
      "Cleaned Token After =  sciences , pp . 4114–4121 . abstract . • referred journal economic literature classification codes jel : c8 – data collection data estimation \n",
      "Cleaned Token After Stem =  scienc , pp . 4114–4121 . abstract . • refer journal econom literatur classif code jel : c8 – data collect data estim \n",
      "Cleaned Token Before =  a spatial data infrastructure (sdi) is a data infrastructure implementing a framework of geographic data, metadata, users and tools that are interactively\n",
      "Cleaned Token After =  spatial data infrastructure ( sdi ) data infrastructure implementing framework geographic data , metadata , users tools interactively \n",
      "Cleaned Token After Stem =  spatial data infrastructur ( sdi ) data infrastructur implement framework geograph data , metadata , user tool interact \n",
      "Cleaned Token Before =  in computer science, a purely functional data structure is a data structure that can be implemented in a purely functional language. the main difference\n",
      "Cleaned Token After =  computer science , purely functional data structure data structure implemented purely functional language . main difference \n",
      "Cleaned Token After Stem =  comput scienc , pure function data structur data structur implement pure function languag . main differ \n",
      "Cleaned Token Before =  the sound of a neutron star\". science. hermann, t; ritter, h. \"listen to your data: model-based sonification for data analysis\". advances in intelligent\n",
      "Cleaned Token After =  sound neutron star '' . science . hermann , ; ritter , h. `` listen data : model-based sonification data analysis '' . advances intelligent \n",
      "Cleaned Token After Stem =  sound neutron star `` . scienc . hermann , ; ritter , h. `` listen data : model-bas sonif data analysi `` . advanc intellig \n",
      "Cleaned Token Before =  community of norway. until 1 march 2016 it was known as norwegian social science data services. the agency is owned by the ministry of education and research\n",
      "Cleaned Token After =  community norway . 1 march 2016 known norwegian social science data services . agency owned ministry education research \n",
      "Cleaned Token After Stem =  commun norway . 1 march 2016 known norwegian social scienc data servic . agenc own ministri educ research \n",
      "Cleaned Token Before =  source and follow its directions. msds search engine science stuff fisher scientific. table data obtained from crc handbook of chemistry and physics 44th\n",
      "Cleaned Token After =  source follow directions . msds search engine science stuff fisher scientific . table data obtained crc handbook chemistry physics 44th \n",
      "Cleaned Token After Stem =  sourc follow direct . msd search engin scienc stuff fisher scientif . tabl data obtain crc handbook chemistri physic 44th \n",
      "Cleaned Token Before =  2016. estimating suicide occurrence statistics using google trends. epj data science, 5(1), p.32. bousquet, jean, robyn e. o'hehir, josep m. anto, gennaro\n",
      "Cleaned Token After =  2016. estimating suicide occurrence statistics using google trends . epj data science , 5 ( 1 ) , p.32 . bousquet , jean , robyn e. o'hehir , josep m. anto , gennaro \n",
      "Cleaned Token After Stem =  2016. estim suicid occurr statist use googl trend . epj data scienc , 5 ( 1 ) , p.32 . bousquet , jean , robyn e. o'hehir , josep m. anto , gennaro \n",
      "Cleaned Token Before =  hardware information science, an interdisciplinary study of information data science, the field related to data analysis and data engineering information\n",
      "Cleaned Token After =  hardware information science , interdisciplinary study information data science , field related data analysis data engineering information \n",
      "Cleaned Token After Stem =  hardwar inform scienc , interdisciplinari studi inform data scienc , field relat data analysi data engin inform \n",
      "Cleaned Token Before =  in computer software, a data access object (dao) is a pattern that provides an abstract interface to some type of database or other persistence mechanism\n",
      "Cleaned Token After =  computer software , data access object ( dao ) pattern provides abstract interface type database persistence mechanism \n",
      "Cleaned Token After Stem =  comput softwar , data access object ( dao ) pattern provid abstract interfac type databas persist mechan \n",
      "Cleaned Token Before =  director of the center for data science and public policy, research associate professor in the department of computer science, and a senior fellow at the\n",
      "Cleaned Token After =  director center data science public policy , research associate professor department computer science , senior fellow \n",
      "Cleaned Token After Stem =  director center data scienc public polici , research associ professor depart comput scienc , senior fellow \n",
      "Cleaned Token Before =  altmetric, or altmetric.com, is a data science company that tracks where published research is mentioned online, and provides tools and services to institutions\n",
      "Cleaned Token After =  altmetric , altmetric.com , data science company tracks published research mentioned online , provides tools services institutions \n",
      "Cleaned Token After Stem =  altmetr , altmetric.com , data scienc compani track publish research mention onlin , provid tool servic institut \n",
      "Cleaned Token Before =  expand and enhance open-source software for scientific computing and data science\". retrieved 13 august 2015. \"recent software system award news\". \"jupyter\n",
      "Cleaned Token After =  expand enhance open-source software scientific computing data science '' . retrieved 13 august 2015 . `` recent software system award news '' . `` jupyter \n",
      "Cleaned Token After Stem =  expand enhanc open-sourc softwar scientif comput data scienc `` . retriev 13 august 2015 . `` recent softwar system award news `` . `` jupyt \n",
      "Cleaned Token Before =  \"the key word in 'data science' is not data, it is science\". simply statistics. hayashi, chikio (1 january 1998). \"what is data science? fundamental concepts\n",
      "Cleaned Token After =  `` key word 'data science ' data , science '' . simply statistics . hayashi , chikio ( 1 january 1998 ) . `` data science ? fundamental concepts \n",
      "Cleaned Token After Stem =  `` key word 'data scienc ' data , scienc `` . simpli statist . hayashi , chikio ( 1 januari 1998 ) . `` data scienc ? fundament concept \n",
      "Cleaned Token Before =  python for data analysis. http://wesmckinney.com/blog/announcing-ursalabs/ kopf, dan. \"meet the man behind the most important tool in data science\", quartz\n",
      "Cleaned Token After =  python data analysis . http : //wesmckinney.com/blog/announcing-ursalabs/ kopf , dan . `` meet man behind important tool data science '' , quartz \n",
      "Cleaned Token After Stem =  python data analysi . http : //wesmckinney.com/blog/announcing-ursalabs/ kopf , dan . `` meet man behind import tool data scienc `` , quartz \n",
      "Cleaned Token Before =  4 october 2018. \"announcing omnisci 4.8: bridging the analytics and data science chasm\". 15 aug 2019. enea adds fine-grain locking and cascaded deletes\n",
      "Cleaned Token After =  4 october 2018 . `` announcing omnisci 4.8 : bridging analytics data science chasm '' . 15 aug 2019. enea adds fine-grain locking cascaded deletes \n",
      "Cleaned Token After Stem =  4 octob 2018 . `` announc omnisci 4.8 : bridg analyt data scienc chasm `` . 15 aug 2019. enea add fine-grain lock cascad delet \n",
      "Cleaned Token Before =  mexican physicist, data scientist, tv host, educator and entrepreneur who dedicates her career to promoting education in science, technology, engineering\n",
      "Cleaned Token After =  mexican physicist , data scientist , tv host , educator entrepreneur dedicates career promoting education science , technology , engineering \n",
      "Cleaned Token After Stem =  mexican physicist , data scientist , tv host , educ entrepreneur dedic career promot educ scienc , technolog , engin \n",
      "Cleaned Token Before =  this page provides supplementary chemical data on acetonitrile. the handling of this chemical may incur notable safety precautions. it is highly recommend\n",
      "Cleaned Token After =  page provides supplementary chemical data acetonitrile . handling chemical may incur notable safety precautions . highly recommend \n",
      "Cleaned Token After Stem =  page provid supplementari chemic data acetonitril . handl chemic may incur notabl safeti precaut . highli recommend \n",
      "Cleaned Token Before =  avanessians director of the data science institute at columbia university, where she is also a professor of computer science. until june 30, 2017, she was\n",
      "Cleaned Token After =  avanessians director data science institute columbia university , also professor computer science . june 30 , 2017 , \n",
      "Cleaned Token After Stem =  avanessian director data scienc institut columbia univers , also professor comput scienc . june 30 , 2017 , \n",
      "Cleaned Token Before =  challenges in several focus areas: data science and cyberinfrastructure; environmental sciences; and biomedical and health sciences. renci was founded in january\n",
      "Cleaned Token After =  challenges several focus areas : data science cyberinfrastructure ; environmental sciences ; biomedical health sciences . renci founded january \n",
      "Cleaned Token After Stem =  challeng sever focu area : data scienc cyberinfrastructur ; environment scienc ; biomed health scienc . renci found januari \n",
      "Cleaned Token Before =  work has focused on solidifying a vision for data science, including a framework for veridical data science and a framework for interpretable machine learning\n",
      "Cleaned Token After =  work focused solidifying vision data science , including framework veridical data science framework interpretable machine learning \n",
      "Cleaned Token After Stem =  work focus solidifi vision data scienc , includ framework verid data scienc framework interpret machin learn \n",
      "Cleaned Token Before =  realized the lodes that could be extracted from data science. in addition to analyzing massive amounts of data, the firm builds useful tools for people, organizations\n",
      "Cleaned Token After =  realized lodes could extracted data science . addition analyzing massive amounts data , firm builds useful tools people , organizations \n",
      "Cleaned Token After Stem =  realiz lode could extract data scienc . addit analyz massiv amount data , firm build use tool peopl , organ \n",
      "Cleaned Token Before =  data commingling, in computer science, occurs when different items or kinds of data are stored in such a way that they become commonly accessible when\n",
      "Cleaned Token After =  data commingling , computer science , occurs different items kinds data stored way become commonly accessible \n",
      "Cleaned Token After Stem =  data commingl , comput scienc , occur differ item kind data store way becom commonli access \n",
      "Cleaned Token Before =  dictionary of acronyms in library and information sciences. isbn 3110957825. interactive data entry/access (data general corp. - us) idea eriksen, denise c.\n",
      "Cleaned Token After =  dictionary acronyms library information sciences . isbn 3110957825. interactive data entry/access ( data general corp. - us ) idea eriksen , denise c . \n",
      "Cleaned Token After Stem =  dictionari acronym librari inform scienc . isbn 3110957825. interact data entry/access ( data gener corp. - us ) idea eriksen , denis c . \n",
      "Cleaned Token Before =  ontario where she currently holds a tier i canada research chair in data science. she was a professor at the university of waterloo, canada, where she\n",
      "Cleaned Token After =  ontario currently holds tier canada research chair data science . professor university waterloo , canada , \n",
      "Cleaned Token After Stem =  ontario current hold tier canada research chair data scienc . professor univers waterloo , canada , \n",
      "Cleaned Token Before =  robustness at scale machine; star, data science location: 1a 06/07 level: intermediate secondary topics: hardcore data science tamara broderickaverage. \"speaker:\n",
      "Cleaned Token After =  robustness scale machine ; star , data science location : 1a 06/07 level : intermediate secondary topics : hardcore data science tamara broderickaverage . `` speaker : \n",
      "Cleaned Token After Stem =  robust scale machin ; star , data scienc locat : 1a 06/07 level : intermedi secondari topic : hardcor data scienc tamara broderickaverag . `` speaker : \n",
      "Cleaned Token Before =  in quantum computing. she is currently the director of the center for data science at nyu and professor at the courant institute kempe was born in east\n",
      "Cleaned Token After =  quantum computing . currently director center data science nyu professor courant institute kempe born east \n",
      "Cleaned Token After Stem =  quantum comput . current director center data scienc nyu professor courant institut kemp born east \n",
      "Cleaned Token Before =  biology and disease helmholtz research school of radiation science munich school for data science official website coordinates: 48°13′21″n 11°35′36″e﻿ / ﻿48\n",
      "Cleaned Token After =  biology disease helmholtz research school radiation science munich school data science official website coordinates : 48°13′21″n 11°35′36″e﻿ / ﻿48 \n",
      "Cleaned Token After Stem =  biolog diseas helmholtz research school radiat scienc munich school data scienc offici websit coordin : 48°13′21″n 11°35′36″e﻿ / ﻿48 \n",
      "Cleaned Token Before =  data preprocessing is an important step in the data mining process. the phrase \"garbage in, garbage out\" is particularly applicable to data mining and\n",
      "Cleaned Token After =  data preprocessing important step data mining process . phrase `` garbage , garbage '' particularly applicable data mining \n",
      "Cleaned Token After Stem =  data preprocess import step data mine process . phrase `` garbag , garbag `` particularli applic data mine \n",
      "Cleaned Token Before =  and data science skills to researchers through instructional workshops. the carpentries is made up of three programs areas: software carpentry, data carpentry\n",
      "Cleaned Token After =  data science skills researchers instructional workshops . carpentries made three programs areas : software carpentry , data carpentry \n",
      "Cleaned Token After Stem =  data scienc skill research instruct workshop . carpentri made three program area : softwar carpentri , data carpentri \n",
      "Cleaned Token Before =  machine, retrieved 21 february 2012 neufert ernst and peter, architects' data, 3rd english edition, blackwell sciences neufert foundation: about the book\n",
      "Cleaned Token After =  machine , retrieved 21 february 2012 neufert ernst peter , architects ' data , 3rd english edition , blackwell sciences neufert foundation : book \n",
      "Cleaned Token After Stem =  machin , retriev 21 februari 2012 neufert ernst peter , architect ' data , 3rd english edit , blackwel scienc neufert foundat : book \n",
      "Cleaned Token Before =  college of pharmacy college of veterinary medicine graduate school of data science graduate school of public health graduate school of public administration\n",
      "Cleaned Token After =  college pharmacy college veterinary medicine graduate school data science graduate school public health graduate school public administration \n",
      "Cleaned Token After Stem =  colleg pharmaci colleg veterinari medicin graduat school data scienc graduat school public health graduat school public administr \n",
      "Cleaned Token Before =  chemistry, plant science, zoology, mineralogy, oceanography, limnology, soil science, geology and physical geography, and atmospheric science) to the study\n",
      "Cleaned Token After =  chemistry , plant science , zoology , mineralogy , oceanography , limnology , soil science , geology physical geography , atmospheric science ) study \n",
      "Cleaned Token After Stem =  chemistri , plant scienc , zoolog , mineralog , oceanographi , limnolog , soil scienc , geolog physic geographi , atmospher scienc ) studi \n",
      "Cleaned Token Before =  aquatic sciences, sound, market fluctuations, heart rates, frequency domain in electroencephalography signals, digital images, molecular motion, and data science\n",
      "Cleaned Token After =  aquatic sciences , sound , market fluctuations , heart rates , frequency domain electroencephalography signals , digital images , molecular motion , data science \n",
      "Cleaned Token After Stem =  aquat scienc , sound , market fluctuat , heart rate , frequenc domain electroencephalographi signal , digit imag , molecular motion , data scienc \n",
      "Cleaned Token Before =  consultant and serial entrepreneur specialising in digital management and data science. after his doctorate at the whu – otto beisheim school of management\n",
      "Cleaned Token After =  consultant serial entrepreneur specialising digital management data science . doctorate whu – otto beisheim school management \n",
      "Cleaned Token After Stem =  consult serial entrepreneur specialis digit manag data scienc . doctor whu – otto beisheim school manag \n",
      "Cleaned Token Before =  the indian institute of science (iisc) is a public, deemed, research university for higher education and research in science, engineering, design, and\n",
      "Cleaned Token After =  indian institute science ( iisc ) public , deemed , research university higher education research science , engineering , design , \n",
      "Cleaned Token After Stem =  indian institut scienc ( iisc ) public , deem , research univers higher educ research scienc , engin , design , \n",
      "Cleaned Token Before =  when the master ciri data was updated. financial support for the ciri data project came from the united states' national science foundation; the world\n",
      "Cleaned Token After =  master ciri data updated . financial support ciri data project came united states ' national science foundation ; world \n",
      "Cleaned Token After Stem =  master ciri data updat . financi support ciri data project came unit state ' nation scienc foundat ; world \n",
      "Cleaned Token Before =  oracle announced that it had acquired datascience.com, a privately held cloud workspace platform for data science projects and workloads. oracle provides\n",
      "Cleaned Token After =  oracle announced acquired datascience.com , privately held cloud workspace platform data science projects workloads . oracle provides \n",
      "Cleaned Token After Stem =  oracl announc acquir datascience.com , privat held cloud workspac platform data scienc project workload . oracl provid \n",
      "Cleaned Token Before =   all sources concur with the data above except in the instances listed separately: http://physics.nist.gov/physrefdata/ionenergy/ionenergy.html ; retrieved\n",
      "Cleaned Token After =  sources concur data except instances listed separately : http : //physics.nist.gov/physrefdata/ionenergy/ionenergy.html ; retrieved \n",
      "Cleaned Token After Stem =  sourc concur data except instanc list separ : http : //physics.nist.gov/physrefdata/ionenergy/ionenergy.html ; retriev \n",
      "Cleaned Token Before =   (2003). \"exploiting unlabeled data for improving accuracy of predictive data mining\". center for information science and technology – via temple university\n",
      "Cleaned Token After =  ( 2003 ) . `` exploiting unlabeled data improving accuracy predictive data mining '' . center information science technology – via temple university \n",
      "Cleaned Token After Stem =  ( 2003 ) . `` exploit unlabel data improv accuraci predict data mine `` . center inform scienc technolog – via templ univers \n",
      "Cleaned Token Before =  abacus data is a canadian polling and market research firm based in ottawa, ontario. it was founded in august 2010, soon after its founder david coletto\n",
      "Cleaned Token After =  abacus data canadian polling market research firm based ottawa , ontario . founded august 2010 , soon founder david coletto \n",
      "Cleaned Token After Stem =  abacu data canadian poll market research firm base ottawa , ontario . found august 2010 , soon founder david coletto \n",
      "Cleaned Token Before =  characteristic of hard science include producing testable predictions, performing controlled experiments, relying on quantifiable data and mathematical models\n",
      "Cleaned Token After =  characteristic hard science include producing testable predictions , performing controlled experiments , relying quantifiable data mathematical models \n",
      "Cleaned Token After Stem =  characterist hard scienc includ produc testabl predict , perform control experi , reli quantifi data mathemat model \n",
      "Cleaned Token Before =  of machine learning and data science. he is also the founder of a research center and international conferences in data science and engineering. he is\n",
      "Cleaned Token After =  machine learning data science . also founder research center international conferences data science engineering . \n",
      "Cleaned Token After Stem =  machin learn data scienc . also founder research center intern confer data scienc engin . \n",
      "Cleaned Token Before =  in distributed computing, a conflict-free replicated data type (crdt) is a data structure which can be replicated across multiple computers in a network\n",
      "Cleaned Token After =  distributed computing , conflict-free replicated data type ( crdt ) data structure replicated across multiple computers network \n",
      "Cleaned Token After Stem =  distribut comput , conflict-fre replic data type ( crdt ) data structur replic across multipl comput network \n",
      "Cleaned Token Before =  in information technology and computer science, a system is described as stateful if it is designed to remember preceding events or user interactions;\n",
      "Cleaned Token After =  information technology computer science , system described stateful designed remember preceding events user interactions ; \n",
      "Cleaned Token After Stem =  inform technolog comput scienc , system describ state design rememb preced event user interact ; \n",
      "Cleaned Token Before =  gathering and analyzing data, implementing models on computers, solving them, experimenting with them—all this is part of management science research on the modeling\n",
      "Cleaned Token After =  gathering analyzing data , implementing models computers , solving , experimenting them—all part management science research modeling \n",
      "Cleaned Token After Stem =  gather analyz data , implement model comput , solv , experi them—al part manag scienc research model \n",
      "Cleaned Token Before =  in computer science, a hash tree (or hash trie) is a persistent data structure that can be used to implement sets and maps, intended to replace hash tables\n",
      "Cleaned Token After =  computer science , hash tree ( hash trie ) persistent data structure used implement sets maps , intended replace hash tables \n",
      "Cleaned Token After Stem =  comput scienc , hash tree ( hash trie ) persist data structur use implement set map , intend replac hash tabl \n",
      "Cleaned Token Before =  data-flow analysis is a technique for gathering information about the possible set of values calculated at various points in a computer program. a program's\n",
      "Cleaned Token After =  data-flow analysis technique gathering information possible set values calculated various points computer program . program 's \n",
      "Cleaned Token After Stem =  data-flow analysi techniqu gather inform possibl set valu calcul variou point comput program . program 's \n",
      "Cleaned Token Before =  its programs in the sciences and health sciences, une also offers degrees in the marine sciences, data science, environmental science, mathematics, business\n",
      "Cleaned Token After =  programs sciences health sciences , une also offers degrees marine sciences , data science , environmental science , mathematics , business \n",
      "Cleaned Token After Stem =  program scienc health scienc , une also offer degre marin scienc , data scienc , environment scienc , mathemat , busi \n",
      "Cleaned Token Before =  professor of statistics and professor of computer science at purdue university, known for his work on data visualization, particularly on nonparametric regression\n",
      "Cleaned Token After =  professor statistics professor computer science purdue university , known work data visualization , particularly nonparametric regression \n",
      "Cleaned Token After Stem =  professor statist professor comput scienc purdu univers , known work data visual , particularli nonparametr regress \n",
      "Cleaned Token Before =  special interest is the intersection of data, art and technology. he adopts an interdisciplinary approach to data science, drawing on various branches of applied\n",
      "Cleaned Token After =  special interest intersection data , art technology . adopts interdisciplinary approach data science , drawing various branches applied \n",
      "Cleaned Token After Stem =  special interest intersect data , art technolog . adopt interdisciplinari approach data scienc , draw variou branch appli \n",
      "Cleaned Token Before =  baker science stuff table data obtained from crc handbook of chemistry and physics 44th ed. see also: carbon tetrachloride (data page) butanone (data page)\n",
      "Cleaned Token After =  baker science stuff table data obtained crc handbook chemistry physics 44th ed . see also : carbon tetrachloride ( data page ) butanone ( data page ) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Token After Stem =  baker scienc stuff tabl data obtain crc handbook chemistri physic 44th ed . see also : carbon tetrachlorid ( data page ) butanon ( data page ) \n",
      "Cleaned Token Before =  in computer science, peek is an operation on certain abstract data types, specifically sequential collections such as stacks and queues, which returns\n",
      "Cleaned Token After =  computer science , peek operation certain abstract data types , specifically sequential collections stacks queues , returns \n",
      "Cleaned Token After Stem =  comput scienc , peek oper certain abstract data type , specif sequenti collect stack queue , return \n",
      "Cleaned Token Before =  networking data truncation occurs when data or a data stream (such as a file) is stored in a location too short to hold its entire length. data truncation\n",
      "Cleaned Token After =  networking data truncation occurs data data stream ( file ) stored location short hold entire length . data truncation \n",
      "Cleaned Token After Stem =  network data truncat occur data data stream ( file ) store locat short hold entir length . data truncat \n",
      "Cleaned Token Before =  in data warehousing. data extraction involves extracting data from homogeneous or heterogeneous sources; data transformation processes data by data cleaning\n",
      "Cleaned Token After =  data warehousing . data extraction involves extracting data homogeneous heterogeneous sources ; data transformation processes data data cleaning \n",
      "Cleaned Token After Stem =  data wareh . data extract involv extract data homogen heterogen sourc ; data transform process data data clean \n",
      "Cleaned Token Before =  in computer science, an implicit data structure or space-efficient data structure is a data structure that stores very little information other than the\n",
      "Cleaned Token After =  computer science , implicit data structure space-efficient data structure data structure stores little information \n",
      "Cleaned Token After Stem =  comput scienc , implicit data structur space-effici data structur data structur store littl inform \n",
      "Cleaned Token Before =  projects and for his wide-ranging publications in the fields of statistics, data science and health economics. friedman was born in new york city and received\n",
      "Cleaned Token After =  projects wide-ranging publications fields statistics , data science health economics . friedman born new york city received \n",
      "Cleaned Token After Stem =  project wide-rang public field statist , data scienc health econom . friedman born new york citi receiv \n",
      "Cleaned Token Before =  in computer science, contextualization is the process of identifying the data relevant to an entity (e.g., a person or a city) based on the entity's contextual\n",
      "Cleaned Token After =  computer science , contextualization process identifying data relevant entity ( e.g. , person city ) based entity 's contextual \n",
      "Cleaned Token After Stem =  comput scienc , contextu process identifi data relev entiti ( e.g . , person citi ) base entiti 's contextu \n",
      "Cleaned Token Before =  describe sets of data in their simplest form. since the 1970s, the primary way companies have performed data science has been to hire teams of data scientists\n",
      "Cleaned Token After =  describe sets data simplest form . since 1970s , primary way companies performed data science hire teams data scientists \n",
      "Cleaned Token After Stem =  describ set data simplest form . sinc 1970 , primari way compani perform data scienc hire team data scientist \n",
      "Cleaned Token Before =  ability to access and process data and to perform data science tasks. it has interactive visual programming tools using data workflows, and it has coding\n",
      "Cleaned Token After =  ability access process data perform data science tasks . interactive visual programming tools using data workflows , coding \n",
      "Cleaned Token After Stem =  abil access process data perform data scienc task . interact visual program tool use data workflow , code \n",
      "Cleaned Token Before =  director of the data science and learning division at argonne national laboratory, and a professor in the department of computer science at the university\n",
      "Cleaned Token After =  director data science learning division argonne national laboratory , professor department computer science university \n",
      "Cleaned Token After Stem =  director data scienc learn divis argonn nation laboratori , professor depart comput scienc univers \n",
      "Cleaned Token Before =  algorithms + data structures = programs is a 1976 book written by niklaus wirth covering some of the fundamental topics of computer programming, particularly\n",
      "Cleaned Token After =  algorithms + data structures = programs 1976 book written niklaus wirth covering fundamental topics computer programming , particularly \n",
      "Cleaned Token After Stem =  algorithm + data structur = program 1976 book written niklau wirth cover fundament topic comput program , particularli \n",
      "Cleaned Token Before =  from wikisource textbooks from wikibooks resources from wikiversity data science: data to insights from mit (machine learning) popular online course by andrew\n",
      "Cleaned Token After =  wikisource textbooks wikibooks resources wikiversity data science : data insights mit ( machine learning ) popular online course andrew \n",
      "Cleaned Token After Stem =  wikisourc textbook wikibook resourc wikivers data scienc : data insight mit ( machin learn ) popular onlin cours andrew \n",
      "Cleaned Token Before =  for existing data. however, science has shown repeatedly that future data often support more complex theories than do existing data. science prefers the\n",
      "Cleaned Token After =  existing data . however , science shown repeatedly future data often support complex theories existing data . science prefers \n",
      "Cleaned Token After Stem =  exist data . howev , scienc shown repeatedli futur data often support complex theori exist data . scienc prefer \n",
      "Cleaned Token Before =  the data encryption standard (des /ˌdiːˌiːˈɛs, dɛz/) is a symmetric-key algorithm for the encryption of digital data. although its short key length of\n",
      "Cleaned Token After =  data encryption standard ( des /ˌdiːˌiːˈɛs , dɛz/ ) symmetric-key algorithm encryption digital data . although short key length \n",
      "Cleaned Token After Stem =  data encrypt standard ( de /ˌdiːˌiːˈɛ , dɛz/ ) symmetric-key algorithm encrypt digit data . although short key length \n",
      "Cleaned Token Before =  science, and it is known that he was dismissive of astronomy, which at the beginning of the 20th century was still gathering largely descriptive data\n",
      "Cleaned Token After =  science , known dismissive astronomy , beginning 20th century still gathering largely descriptive data \n",
      "Cleaned Token After Stem =  scienc , known dismiss astronomi , begin 20th centuri still gather larg descript data \n",
      "Cleaned Token Before =  data fusion is the process of integrating multiple data sources to produce more consistent, accurate, and useful information than that provided by any\n",
      "Cleaned Token After =  data fusion process integrating multiple data sources produce consistent , accurate , useful information provided \n",
      "Cleaned Token After Stem =  data fusion process integr multipl data sourc produc consist , accur , use inform provid \n",
      "Cleaned Token Before =  intelligence), bs (civil engineering), bs (computer science), bs (cyber security and digital forensics), bs (data science), bs (electrical engineering), and bs (software\n",
      "Cleaned Token After =  intelligence ) , bs ( civil engineering ) , bs ( computer science ) , bs ( cyber security digital forensics ) , bs ( data science ) , bs ( electrical engineering ) , bs ( software \n",
      "Cleaned Token After Stem =  intellig ) , bs ( civil engin ) , bs ( comput scienc ) , bs ( cyber secur digit forens ) , bs ( data scienc ) , bs ( electr engin ) , bs ( softwar \n",
      "Cleaned Token Before =  in the field of programming a data transfer object (dto) is an object that carries data between processes. the motivation for its use is that communication\n",
      "Cleaned Token After =  field programming data transfer object ( dto ) object carries data processes . motivation use communication \n",
      "Cleaned Token After Stem =  field program data transfer object ( dto ) object carri data process . motiv use commun \n",
      "Cleaned Token Before =  organized around three fields: digital security, communication systems and data science. eurecom provides graduate and post graduate courses including doctoral\n",
      "Cleaned Token After =  organized around three fields : digital security , communication systems data science . eurecom provides graduate post graduate courses including doctoral \n",
      "Cleaned Token After Stem =  organ around three field : digit secur , commun system data scienc . eurecom provid graduat post graduat cours includ doctor \n",
      "Cleaned Token Before =  uses of strings, a string in computer science may refer generically to any sequence of homogeneously typed data. a bit string or byte string, for example\n",
      "Cleaned Token After =  uses strings , string computer science may refer generically sequence homogeneously typed data . bit string byte string , example \n",
      "Cleaned Token After Stem =  use string , string comput scienc may refer gener sequenc homogen type data . bit string byte string , exampl \n",
      "Cleaned Token Before =  also known as quantitative analysis numerical data, also known as quantitative data quantification (science) qualitative this disambiguation page lists\n",
      "Cleaned Token After =  also known quantitative analysis numerical data , also known quantitative data quantification ( science ) qualitative disambiguation page lists \n",
      "Cleaned Token After Stem =  also known quantit analysi numer data , also known quantit data quantif ( scienc ) qualit disambigu page list \n",
      "Cleaned Token Before =  data technologies and applications (dta) is a peer-reviewed academic, interdisciplinary journal concerning any topic related to web science, data analytics\n",
      "Cleaned Token After =  data technologies applications ( dta ) peer-reviewed academic , interdisciplinary journal concerning topic related web science , data analytics \n",
      "Cleaned Token After Stem =  data technolog applic ( dta ) peer-review academ , interdisciplinari journal concern topic relat web scienc , data analyt \n",
      "Cleaned Token Before =  chemometrics is the science of extracting information from chemical systems by data-driven means. chemometrics is inherently interdisciplinary, using\n",
      "Cleaned Token After =  chemometrics science extracting information chemical systems data-driven means . chemometrics inherently interdisciplinary , using \n",
      "Cleaned Token After Stem =  chemometr scienc extract inform chemic system data-driven mean . chemometr inher interdisciplinari , use \n",
      "Cleaned Token Before =  chemical from a reliable source and follow its directions. science stuff mallinckrodt baker. table data obtained from crc handbook of chemistry and physics,\n",
      "Cleaned Token After =  chemical reliable source follow directions . science stuff mallinckrodt baker . table data obtained crc handbook chemistry physics , \n",
      "Cleaned Token After Stem =  chemic reliabl sourc follow direct . scienc stuff mallinckrodt baker . tabl data obtain crc handbook chemistri physic , \n",
      "Cleaned Token Before =  automatic data processing, inc. (adp) is an american provider of human resources management software and services. in 1949, henry taub founded automatic\n",
      "Cleaned Token After =  automatic data processing , inc. ( adp ) american provider human resources management software services . 1949 , henry taub founded automatic \n",
      "Cleaned Token After Stem =  automat data process , inc. ( adp ) american provid human resourc manag softwar servic . 1949 , henri taub found automat \n",
      "Cleaned Token Before =  and data science. the advent of the computer has enabled new applications: studying and using the new computer technology itself (computer science) to\n",
      "Cleaned Token After =  data science . advent computer enabled new applications : studying using new computer technology ( computer science ) \n",
      "Cleaned Token After Stem =  data scienc . advent comput enabl new applic : studi use new comput technolog ( comput scienc ) \n",
      "Cleaned Token Before =  sciences (traditional computer science), software engineering, data science, information economics, information systems, computational social science\n",
      "Cleaned Token After =  sciences ( traditional computer science ) , software engineering , data science , information economics , information systems , computational social science \n",
      "Cleaned Token After Stem =  scienc ( tradit comput scienc ) , softwar engin , data scienc , inform econom , inform system , comput social scienc \n",
      "Cleaned Token Before =  gratings. thematic maps, charts, data science, spreadsheets, and other tools use graphical means to visualize quantitative data. color is often used as one\n",
      "Cleaned Token After =  gratings . thematic maps , charts , data science , spreadsheets , tools use graphical means visualize quantitative data . color often used one \n",
      "Cleaned Token After Stem =  grate . themat map , chart , data scienc , spreadsheet , tool use graphic mean visual quantit data . color often use one \n",
      "Cleaned Token Before =  the us national science foundation (nsf) plans to develop new research environments in which advanced computational, collaborative, data acquisition and\n",
      "Cleaned Token After =  us national science foundation ( nsf ) plans develop new research environments advanced computational , collaborative , data acquisition \n",
      "Cleaned Token After Stem =  us nation scienc foundat ( nsf ) plan develop new research environ advanc comput , collabor , data acquisit \n",
      "Cleaned Token Before =  computer data storage is a technology consisting of computer components and recording media that are used to retain digital data. it is a core function\n",
      "Cleaned Token After =  computer data storage technology consisting computer components recording media used retain digital data . core function \n",
      "Cleaned Token After Stem =  comput data storag technolog consist comput compon record media use retain digit data . core function \n",
      "Cleaned Token Before =  algorithms, data structures, and data abstraction. for example, binary trees were studied in ap computer science ab but not in ap computer science a. the use\n",
      "Cleaned Token After =  algorithms , data structures , data abstraction . example , binary trees studied ap computer science ab ap computer science a. use \n",
      "Cleaned Token After Stem =  algorithm , data structur , data abstract . exampl , binari tree studi ap comput scienc ab ap comput scienc a. use \n",
      "Cleaned Token Before =  mathematics (secondary), and computer science (secondary) at duke university. he is also a microsoft data science investigator at microsoft innovation\n",
      "Cleaned Token After =  mathematics ( secondary ) , computer science ( secondary ) duke university . also microsoft data science investigator microsoft innovation \n",
      "Cleaned Token After Stem =  mathemat ( secondari ) , comput scienc ( secondari ) duke univers . also microsoft data scienc investig microsoft innov \n",
      "Cleaned Token Before =  students is evaluated. contextual data about the conditions in which participating students learn mathematics and science are collected from the students\n",
      "Cleaned Token After =  students evaluated . contextual data conditions participating students learn mathematics science collected students \n",
      "Cleaned Token After Stem =  student evalu . contextu data condit particip student learn mathemat scienc collect student \n",
      "Cleaned Token Before =  aquatic science gis and public health giscorps gis day gis in archaeology grass gis gvsig historical gis integrated geo systems list of gis data sources\n",
      "Cleaned Token After =  aquatic science gis public health giscorps gis day gis archaeology grass gis gvsig historical gis integrated geo systems list gis data sources \n",
      "Cleaned Token After Stem =  aquat scienc gi public health giscorp gi day gi archaeolog grass gi gvsig histor gi integr geo system list gi data sourc \n",
      "Cleaned Token Before =  diverse data science and data management needs to fulfill both their overarching objectives and their day-to-day tasks. the deep carbon observatory data science\n",
      "Cleaned Token After =  diverse data science data management needs fulfill overarching objectives day-to-day tasks . deep carbon observatory data science \n",
      "Cleaned Token After Stem =  divers data scienc data manag need fulfil overarch object day-to-day task . deep carbon observatori data scienc \n",
      "Cleaned Token Before =  derived from omega/mars express data\". science. 312 (5772): 400–404. bibcode:2006sci...312..400b. doi:10.1126/science.1122659. pmid 16627738. s2cid 13968348\n",
      "Cleaned Token After =  derived omega/mars express data '' . science . 312 ( 5772 ) : 400–404 . bibcode:2006sci ... 312 .. 400b . doi:10.1126/science.1122659 . pmid 16627738. s2cid 13968348 \n",
      "Cleaned Token After Stem =  deriv omega/mar express data `` . scienc . 312 ( 5772 ) : 400–404 . bibcode:2006sci ... 312 .. 400b . doi:10.1126/science.1122659 . pmid 16627738. s2cid 13968348 \n",
      "Cleaned Token Before =  sold by dassault systèmes for processing and analyzing data. originally used in the natural sciences, the product's basic etl (extract, transform, load)\n",
      "Cleaned Token After =  sold dassault systèmes processing analyzing data . originally used natural sciences , product 's basic etl ( extract , transform , load ) \n",
      "Cleaned Token After Stem =  sold dassault systèm process analyz data . origin use natur scienc , product 's basic etl ( extract , transform , load ) \n",
      "Cleaned Token Before =  cooperation research equipment center center for data science as of 2016, tokyo university of science had academic exchange agreements with 75 overseas\n",
      "Cleaned Token After =  cooperation research equipment center center data science 2016 , tokyo university science academic exchange agreements 75 overseas \n",
      "Cleaned Token After Stem =  cooper research equip center center data scienc 2016 , tokyo univers scienc academ exchang agreement 75 oversea \n",
      "Cleaned Token Before =  associate provost for computing and data sciences and the william fairfield warren distinguished professor of computer science at boston university. prior to\n",
      "Cleaned Token After =  associate provost computing data sciences william fairfield warren distinguished professor computer science boston university . prior \n",
      "Cleaned Token After Stem =  associ provost comput data scienc william fairfield warren distinguish professor comput scienc boston univers . prior \n",
      "Cleaned Token Before =  open government data (ogd) platform india or data.gov.in is a platform for supporting open data initiative of government of india. this portal is a single-point\n",
      "Cleaned Token After =  open government data ( ogd ) platform india data.gov.in platform supporting open data initiative government india . portal single-point \n",
      "Cleaned Token After Stem =  open govern data ( ogd ) platform india data.gov.in platform support open data initi govern india . portal single-point \n",
      "Cleaned Token Before =  established some of the earliest programs in various fields such as data science, computer science, electrical engineering, and nuclear engineering. the college's\n",
      "Cleaned Token After =  established earliest programs various fields data science , computer science , electrical engineering , nuclear engineering . college 's \n",
      "Cleaned Token After Stem =  establish earliest program variou field data scienc , comput scienc , electr engin , nuclear engin . colleg 's \n",
      "Cleaned Token Before =  philological and literary sciences, mass communications, juridical sciences, economics, computer science and data science. the university began its life\n",
      "Cleaned Token After =  philological literary sciences , mass communications , juridical sciences , economics , computer science data science . university began life \n",
      "Cleaned Token After Stem =  philolog literari scienc , mass commun , jurid scienc , econom , comput scienc data scienc . univers began life \n",
      "Cleaned Token Before =  magnetic tape data storage is a system for storing digital information on magnetic tape using digital recording. historically, tape was an important medium\n",
      "Cleaned Token After =  magnetic tape data storage system storing digital information magnetic tape using digital recording . historically , tape important medium \n",
      "Cleaned Token After Stem =  magnet tape data storag system store digit inform magnet tape use digit record . histor , tape import medium \n",
      "Cleaned Token Before =  free-form natural laws from experimental data\". science. american association for the advancement of science. 324 (5923): 81–85. bibcode:2009sci...324\n",
      "Cleaned Token After =  free-form natural laws experimental data '' . science . american association advancement science . 324 ( 5923 ) : 81–85 . bibcode:2009sci ... 324 \n",
      "Cleaned Token After Stem =  free-form natur law experiment data `` . scienc . american associ advanc scienc . 324 ( 5923 ) : 81–85 . bibcode:2009sci ... 324 \n",
      "Cleaned Token Before =  electrical, electronics and communication, computer science, robotics, data science), master of technology degrees (computer aided structural engineering\n",
      "Cleaned Token After =  electrical , electronics communication , computer science , robotics , data science ) , master technology degrees ( computer aided structural engineering \n",
      "Cleaned Token After Stem =  electr , electron commun , comput scienc , robot , data scienc ) , master technolog degre ( comput aid structur engin \n",
      "Cleaned Token Before =  dark data is data which is acquired through various computer network operations but not used in any manner to derive insights or for decision making. the\n",
      "Cleaned Token After =  dark data data acquired various computer network operations used manner derive insights decision making . \n",
      "Cleaned Token After Stem =  dark data data acquir variou comput network oper use manner deriv insight decis make . \n",
      "Cleaned Token Before =  scientific analysis of various dimensions of behavior. behavioral sciences abstract empirical data to investigate the decision processes and communication strategies\n",
      "Cleaned Token After =  scientific analysis various dimensions behavior . behavioral sciences abstract empirical data investigate decision processes communication strategies \n",
      "Cleaned Token After Stem =  scientif analysi variou dimens behavior . behavior scienc abstract empir data investig decis process commun strategi \n",
      "Cleaned Token Before =  philosophy of science is a branch of philosophy concerned with the foundations, methods, and implications of science. the central questions of this study\n",
      "Cleaned Token After =  philosophy science branch philosophy concerned foundations , methods , implications science . central questions study \n",
      "Cleaned Token After Stem =  philosophi scienc branch philosophi concern foundat , method , implic scienc . central question studi \n",
      "Cleaned Token Before =  types of data: control information and user data (payload). the control information provides data the network needs to deliver the user data, for example\n",
      "Cleaned Token After =  types data : control information user data ( payload ) . control information provides data network needs deliver user data , example \n",
      "Cleaned Token After Stem =  type data : control inform user data ( payload ) . control inform provid data network need deliv user data , exampl \n",
      "Cleaned Token Before =  data science and director of the school of data science and professor of biomedical engineering and was the first associate director for data science\n",
      "Cleaned Token After =  data science director school data science professor biomedical engineering first associate director data science \n",
      "Cleaned Token After Stem =  data scienc director school data scienc professor biomed engin first associ director data scienc \n",
      "Cleaned Token Before =  of data, technology, the public expectation of privacy, and the legal and political issues surrounding them. it is also known as data privacy or data protection\n",
      "Cleaned Token After =  data , technology , public expectation privacy , legal political issues surrounding . also known data privacy data protection \n",
      "Cleaned Token After Stem =  data , technolog , public expect privaci , legal polit issu surround . also known data privaci data protect \n",
      "Cleaned Token Before =  evaluation of the broader contexts of qualitative data. in some social sciences such as sociology, quantitative data are difficult to obtain, either because laboratory\n",
      "Cleaned Token After =  evaluation broader contexts qualitative data . social sciences sociology , quantitative data difficult obtain , either laboratory \n",
      "Cleaned Token After Stem =  evalu broader context qualit data . social scienc sociolog , quantit data difficult obtain , either laboratori \n",
      "Cleaned Token Before =  data drilling (also drilldown) refers to any of various operations and transformations on tabular, relational, and multidimensional data. the term has\n",
      "Cleaned Token After =  data drilling ( also drilldown ) refers various operations transformations tabular , relational , multidimensional data . term \n",
      "Cleaned Token After Stem =  data drill ( also drilldown ) refer variou oper transform tabular , relat , multidimension data . term \n",
      "Cleaned Token Before =  computer science department at mit. he is director of statistics and data science center at mit. he received a b.tech. degree in computer science from iit\n",
      "Cleaned Token After =  computer science department mit . director statistics data science center mit . received b.tech . degree computer science iit \n",
      "Cleaned Token After Stem =  comput scienc depart mit . director statist data scienc center mit . receiv b.tech . degre comput scienc iit \n",
      "Cleaned Token Before =  alan turing institute is the united kingdom's national institute for data science and artificial intelligence, founded in 2015. it is named after alan\n",
      "Cleaned Token After =  alan turing institute united kingdom 's national institute data science artificial intelligence , founded 2015. named alan \n",
      "Cleaned Token After Stem =  alan ture institut unit kingdom 's nation institut data scienc artifici intellig , found 2015. name alan \n",
      "Cleaned Token Before =  in computer science, a disjoint-set data structure, also called a union–find data structure or merge–find set, is a data structure that stores a collection\n",
      "Cleaned Token After =  computer science , disjoint-set data structure , also called union–find data structure merge–find set , data structure stores collection \n",
      "Cleaned Token After Stem =  comput scienc , disjoint-set data structur , also call union–find data structur merge–find set , data structur store collect \n",
      "Cleaned Token Before =  data archaeology refers to the art and science of recovering computer data encoded and/or encrypted in now obsolete media or formats. data archaeology\n",
      "Cleaned Token After =  data archaeology refers art science recovering computer data encoded and/or encrypted obsolete media formats . data archaeology \n",
      "Cleaned Token After Stem =  data archaeolog refer art scienc recov comput data encod and/or encrypt obsolet media format . data archaeolog \n",
      "Cleaned Token Before =  the theory of sense data is a view in the philosophy of perception, popularly held in the early 20th century by philosophers such as bertrand russell,\n",
      "Cleaned Token After =  theory sense data view philosophy perception , popularly held early 20th century philosophers bertrand russell , \n",
      "Cleaned Token After Stem =  theori sens data view philosophi percept , popularli held earli 20th centuri philosoph bertrand russel , \n",
      "Cleaned Token Before =  data science. he is a senior staff scientist at the berkeley national laboratory, head of the prokaryote super program and leads the microbiome data science\n",
      "Cleaned Token After =  data science . senior staff scientist berkeley national laboratory , head prokaryote super program leads microbiome data science \n",
      "Cleaned Token After Stem =  data scienc . senior staff scientist berkeley nation laboratori , head prokaryot super program lead microbiom data scienc \n",
      "Cleaned Token Before =  storing, retrieving, and processing data. the development of biocomputers has been made possible by the expanding new science of nanobiotechnology. biocontrol\n",
      "Cleaned Token After =  storing , retrieving , processing data . development biocomputers made possible expanding new science nanobiotechnology . biocontrol \n",
      "Cleaned Token After Stem =  store , retriev , process data . develop biocomput made possibl expand new scienc nanobiotechnolog . biocontrol \n",
      "Cleaned Token Before =  the presence of women in science spans the earliest times of the history of science wherein they have made significant contributions. historians with an\n",
      "Cleaned Token After =  presence women science spans earliest times history science wherein made significant contributions . historians \n",
      "Cleaned Token After Stem =  presenc women scienc span earliest time histori scienc wherein made signific contribut . historian \n",
      "Cleaned Token Before =  computer science, a 2–3 tree is a tree data structure, where every node with children (internal node) has either two children (2-node) and one data element\n",
      "Cleaned Token After =  computer science , 2–3 tree tree data structure , every node children ( internal node ) either two children ( 2-node ) one data element \n",
      "Cleaned Token After Stem =  comput scienc , 2–3 tree tree data structur , everi node children ( intern node ) either two children ( 2-node ) one data element \n",
      "Cleaned Token Before =  csc – it center for science ltd. (also known as finnish it center for science) provides it support and modeling, computing and information services for\n",
      "Cleaned Token After =  csc – center science ltd. ( also known finnish center science ) provides support modeling , computing information services \n",
      "Cleaned Token After Stem =  csc – center scienc ltd. ( also known finnish center scienc ) provid support model , comput inform servic \n",
      "Cleaned Token Before =  based at uc santa barbara's marine science institute. his research focuses on using tools from ecology, data science, and marine policy for ocean conservation\n",
      "Cleaned Token After =  based uc santa barbara 's marine science institute . research focuses using tools ecology , data science , marine policy ocean conservation \n",
      "Cleaned Token After Stem =  base uc santa barbara 's marin scienc institut . research focus use tool ecolog , data scienc , marin polici ocean conserv \n",
      "Cleaned Token Before =  the following outline is provided as a topical overview of science: science is both the systematic effort of acquiring knowledge through observation, experimentation\n",
      "Cleaned Token After =  following outline provided topical overview science : science systematic effort acquiring knowledge observation , experimentation \n",
      "Cleaned Token After Stem =  follow outlin provid topic overview scienc : scienc systemat effort acquir knowledg observ , experiment \n",
      "Cleaned Token Before =  foster provost is professor of data science and information systems and andre meyer faculty fellow at new york university's stern school of business. he\n",
      "Cleaned Token After =  foster provost professor data science information systems andre meyer faculty fellow new york university 's stern school business . \n",
      "Cleaned Token After Stem =  foster provost professor data scienc inform system andr meyer faculti fellow new york univers 's stern school busi . \n",
      "Cleaned Token Before =  data centre (bodc) is a national facility for looking after and distributing data about the marine environment. bodc is the designated marine science\n",
      "Cleaned Token After =  data centre ( bodc ) national facility looking distributing data marine environment . bodc designated marine science \n",
      "Cleaned Token After Stem =  data centr ( bodc ) nation facil look distribut data marin environ . bodc design marin scienc \n",
      "Cleaned Token Before =  system. patients may use their leverage as data producers to demand more transparency, open science, clearer data use consent, more patient engagement in\n",
      "Cleaned Token After =  system . patients may use leverage data producers demand transparency , open science , clearer data use consent , patient engagement \n",
      "Cleaned Token After Stem =  system . patient may use leverag data produc demand transpar , open scienc , clearer data use consent , patient engag \n",
      "Cleaned Token Before =  science and engineering methodologies to education and training. its advocates emphasize the need to connect computing technology and generated data with\n",
      "Cleaned Token After =  science engineering methodologies education training . advocates emphasize need connect computing technology generated data \n",
      "Cleaned Token After Stem =  scienc engin methodolog educ train . advoc emphas need connect comput technolog gener data \n",
      "Cleaned Token Before =  president-elect andrew mccallum \"umass center for data science partners with chan zuckerberg initiative to accelerate science and medicine\". umass.edu. retrieved 2018-01-26\n",
      "Cleaned Token After =  president-elect andrew mccallum `` umass center data science partners chan zuckerberg initiative accelerate science medicine '' . umass.edu . retrieved 2018-01-26 \n",
      "Cleaned Token After Stem =  president-elect andrew mccallum `` umass center data scienc partner chan zuckerberg initi acceler scienc medicin `` . umass.edu . retriev 2018-01-26 \n",
      "Cleaned Token Before =  methods. h2o.ai is an open source data science and machine learning platform knime is a machine learning and data mining software implemented in java\n",
      "Cleaned Token After =  methods . h2o.ai open source data science machine learning platform knime machine learning data mining software implemented java \n",
      "Cleaned Token After Stem =  method . h2o.ai open sourc data scienc machin learn platform knime machin learn data mine softwar implement java \n",
      "Cleaned Token Before =  from a reliable source and follow its directions. siri science stuff fisher scientific table data obtained from crc handbook of chemistry and physics 44th\n",
      "Cleaned Token After =  reliable source follow directions . siri science stuff fisher scientific table data obtained crc handbook chemistry physics 44th \n",
      "Cleaned Token After Stem =  reliabl sourc follow direct . siri scienc stuff fisher scientif tabl data obtain crc handbook chemistri physic 44th \n",
      "Cleaned Token Before =  courses through coursera, as part of their data science specialization. his most popular course is the data scientist's toolbox., which he instructed along\n",
      "Cleaned Token After =  courses coursera , part data science specialization . popular course data scientist 's toolbox. , instructed along \n",
      "Cleaned Token After Stem =  cours coursera , part data scienc special . popular cours data scientist 's toolbox . , instruct along \n",
      "Cleaned Token Before =  \"pioneer 1\". us national space science data center. retrieved 3 december 2013. \"pioneer 2\". us national space science data center. retrieved 3 december\n",
      "Cleaned Token After =  `` pioneer 1 '' . us national space science data center . retrieved 3 december 2013 . `` pioneer 2 '' . us national space science data center . retrieved 3 december \n",
      "Cleaned Token After Stem =  `` pioneer 1 `` . us nation space scienc data center . retriev 3 decemb 2013 . `` pioneer 2 `` . us nation space scienc data center . retriev 3 decemb \n",
      "Cleaned Token Before =  journal publishing high-quality papers in all areas of statistics and data science, including theory, methods, and applications. first issued in 1991, this\n",
      "Cleaned Token After =  journal publishing high-quality papers areas statistics data science , including theory , methods , applications . first issued 1991 , \n",
      "Cleaned Token After Stem =  journal publish high-qual paper area statist data scienc , includ theori , method , applic . first issu 1991 , \n",
      "Cleaned Token Before =  economic theory with selections from finance and data analytics, including machine learning and data science. entry requirements are undergraduate work in\n",
      "Cleaned Token After =  economic theory selections finance data analytics , including machine learning data science . entry requirements undergraduate work \n",
      "Cleaned Token After Stem =  econom theori select financ data analyt , includ machin learn data scienc . entri requir undergradu work \n",
      "Cleaned Token Before =  research and development spending science of science policy science policy \"- royal society\" (pdf). royalsociety.org. \"oecd data: gross domestic spending on\n",
      "Cleaned Token After =  research development spending science science policy science policy `` - royal society '' ( pdf ) . royalsociety.org . `` oecd data : gross domestic spending \n",
      "Cleaned Token After Stem =  research develop spend scienc scienc polici scienc polici `` - royal societi `` ( pdf ) . royalsociety.org . `` oecd data : gross domest spend \n",
      "Cleaned Token Before =  as sales of a product).\" list of statisticians history of statistics data science \"o*net online: 15-2041.00 - statisticians\". retrieved 29 january 2017\n",
      "Cleaned Token After =  sales product ) . '' list statisticians history statistics data science `` * net online : 15-2041.00 - statisticians '' . retrieved 29 january 2017 \n",
      "Cleaned Token After Stem =  sale product ) . `` list statistician histori statist data scienc `` * net onlin : 15-2041.00 - statistician `` . retriev 29 januari 2017 \n",
      "Cleaned Token Before =  objectivity in science is an attempt to uncover truths about the natural world by eliminating personal biases, emotions, and false beliefs. it is often\n",
      "Cleaned Token After =  objectivity science attempt uncover truths natural world eliminating personal biases , emotions , false beliefs . often \n",
      "Cleaned Token After Stem =  object scienc attempt uncov truth natur world elimin person bias , emot , fals belief . often \n",
      "Cleaned Token Before =  and data structures are regarded as standards in their fields. he is the ibm professor of engineering and applied mathematics in computer science at cornell\n",
      "Cleaned Token After =  data structures regarded standards fields . ibm professor engineering applied mathematics computer science cornell \n",
      "Cleaned Token After Stem =  data structur regard standard field . ibm professor engin appli mathemat comput scienc cornel \n",
      "Cleaned Token Before =  centre for research data (short name: 4tu.researchdata) (formerly known as 3tu.datacentrum) is a data archive for research data in science and engineering\n",
      "Cleaned Token After =  centre research data ( short name : 4tu.researchdata ) ( formerly known 3tu.datacentrum ) data archive research data science engineering \n",
      "Cleaned Token After Stem =  centr research data ( short name : 4tu.researchdata ) ( formerli known 3tu.datacentrum ) data archiv research data scienc engin \n",
      "Cleaned Token Before =  timestamp, and transaction data (generally represented as a merkle tree). the timestamp proves that the transaction data existed when the block was published\n",
      "Cleaned Token After =  timestamp , transaction data ( generally represented merkle tree ) . timestamp proves transaction data existed block published \n",
      "Cleaned Token After Stem =  timestamp , transact data ( gener repres merkl tree ) . timestamp prove transact data exist block publish \n",
      "Cleaned Token Before =  and data science bachelor of technology degree in biotechnology, polymer technology, information technology, artificial intelligence and data science, bachelor\n",
      "Cleaned Token After =  data science bachelor technology degree biotechnology , polymer technology , information technology , artificial intelligence data science , bachelor \n",
      "Cleaned Token After Stem =  data scienc bachelor technolog degre biotechnolog , polym technolog , inform technolog , artifici intellig data scienc , bachelor \n",
      "Cleaned Token Before =  boeing’s domain lead for artificial intelligence, cybersecurity and data science. jetter is the first african-american woman btf. anne kao (bstf) - boeing\n",
      "Cleaned Token After =  boeing ’ domain lead artificial intelligence , cybersecurity data science . jetter first african-american woman btf . anne kao ( bstf ) - boeing \n",
      "Cleaned Token After Stem =  boe ’ domain lead artifici intellig , cybersecur data scienc . jetter first african-american woman btf . ann kao ( bstf ) - boe \n",
      "Cleaned Token Before =  otherwise result from passing data through a stateful firewall. the science dmz is designed to handle high volume data transfers, typical with scientific\n",
      "Cleaned Token After =  otherwise result passing data stateful firewall . science dmz designed handle high volume data transfers , typical scientific \n",
      "Cleaned Token After Stem =  otherwis result pass data state firewal . scienc dmz design handl high volum data transfer , typic scientif \n",
      "Cleaned Token Before =  follow its directions. msds from em science in the sdsdata.org database ptcl safety web site science stuff table data obtained from crc handbook of chemistry\n",
      "Cleaned Token After =  follow directions . msds em science sdsdata.org database ptcl safety web site science stuff table data obtained crc handbook chemistry \n",
      "Cleaned Token After Stem =  follow direct . msd em scienc sdsdata.org databas ptcl safeti web site scienc stuff tabl data obtain crc handbook chemistri \n",
      "Cleaned Token Before =  source and follow its directions. sigma aldrich siri science stuff fisher scientific table data obtained from crc handbook of chemistry and physics 44th\n",
      "Cleaned Token After =  source follow directions . sigma aldrich siri science stuff fisher scientific table data obtained crc handbook chemistry physics 44th \n",
      "Cleaned Token After Stem =  sourc follow direct . sigma aldrich siri scienc stuff fisher scientif tabl data obtain crc handbook chemistri physic 44th \n",
      "Cleaned Token Before =  in computer science, a pile is an abstract data type for storing data in a loosely ordered way. there are two different usages of the term; one refers\n",
      "Cleaned Token After =  computer science , pile abstract data type storing data loosely ordered way . two different usages term ; one refers \n",
      "Cleaned Token After Stem =  comput scienc , pile abstract data type store data loos order way . two differ usag term ; one refer \n",
      "Cleaned Token Before =  about the many facets of data science. in a series of lectures, the participants will be introduced to the field of data science from different vantage\n",
      "Cleaned Token After =  many facets data science . series lectures , participants introduced field data science different vantage \n",
      "Cleaned Token After Stem =  mani facet data scienc . seri lectur , particip introduc field data scienc differ vantag \n",
      "Cleaned Token Before =  statistical inference is the process of using data analysis to infer properties of an underlying distribution of probability. inferential statistical analysis\n",
      "Cleaned Token After =  statistical inference process using data analysis infer properties underlying distribution probability . inferential statistical analysis \n",
      "Cleaned Token After Stem =  statist infer process use data analysi infer properti underli distribut probabl . inferenti statist analysi \n",
      "Cleaned Token Before =  (insofe) is an applied engineering school with area of focus in data science / big data analytics. it is located in hyderabad, telangana; bengaluru, karnataka;\n",
      "Cleaned Token After =  ( insofe ) applied engineering school area focus data science / big data analytics . located hyderabad , telangana ; bengaluru , karnataka ; \n",
      "Cleaned Token After Stem =  ( insof ) appli engin school area focu data scienc / big data analyt . locat hyderabad , telangana ; bengaluru , karnataka ; \n",
      "Cleaned Token Before =  structure of the data. statistical graphics have been central to the development of science and date to the earliest attempts to analyse data. many familiar\n",
      "Cleaned Token After =  structure data . statistical graphics central development science date earliest attempts analyse data . many familiar \n",
      "Cleaned Token After Stem =  structur data . statist graphic central develop scienc date earliest attempt analys data . mani familiar \n",
      "Cleaned Token Before =  and kart, lisa, (march 20, 2012). emerging role of the data scientist and the art of data science gartner. mccormick northwestern engineering prescriptive\n",
      "Cleaned Token After =  kart , lisa , ( march 20 , 2012 ) . emerging role data scientist art data science gartner . mccormick northwestern engineering prescriptive \n",
      "Cleaned Token After Stem =  kart , lisa , ( march 20 , 2012 ) . emerg role data scientist art data scienc gartner . mccormick northwestern engin prescript \n",
      "Cleaned Token Before =  re-identified in combination with other pieces of available data and basic computer science techniques. the protection of human subjects ('common rule#signatories')\n",
      "Cleaned Token After =  re-identified combination pieces available data basic computer science techniques . protection human subjects ( 'common rule # signatories ' ) \n",
      "Cleaned Token After Stem =  re-identifi combin piec avail data basic comput scienc techniqu . protect human subject ( 'common rule # signatori ' ) \n",
      "Cleaned Token Before =  in computer science, a concurrent data structure is a particular way of storing and organizing data for access by multiple computing threads (or processes)\n",
      "Cleaned Token After =  computer science , concurrent data structure particular way storing organizing data access multiple computing threads ( processes ) \n",
      "Cleaned Token After Stem =  comput scienc , concurr data structur particular way store organ data access multipl comput thread ( process ) \n",
      "Cleaned Token Before =  this page contains tables of azeotrope data for various binary and ternary mixtures of solvents. the data include the composition of a mixture by weight\n",
      "Cleaned Token After =  page contains tables azeotrope data various binary ternary mixtures solvents . data include composition mixture weight \n",
      "Cleaned Token After Stem =  page contain tabl azeotrop data variou binari ternari mixtur solvent . data includ composit mixtur weight \n",
      "Cleaned Token Before =  the national science foundation. he holds editorial positions for the journals epj data science, network science, and peerj computer science. he has served\n",
      "Cleaned Token After =  national science foundation . holds editorial positions journals epj data science , network science , peerj computer science . served \n",
      "Cleaned Token After Stem =  nation scienc foundat . hold editori posit journal epj data scienc , network scienc , peerj comput scienc . serv \n",
      "Cleaned Token Before =  editor-in-chief of statistical science, and editor-in-chief of statistical analysis and data mining, the asa data science journal. he has over 200 publications\n",
      "Cleaned Token After =  editor-in-chief statistical science , editor-in-chief statistical analysis data mining , asa data science journal . 200 publications \n",
      "Cleaned Token After Stem =  editor-in-chief statist scienc , editor-in-chief statist analysi data mine , asa data scienc journal . 200 public \n",
      "Cleaned Token Before =  fellow at the alan turing institute, the uk's national centre for ai and data science, and the uk government's department for digital, culture, media and sport\n",
      "Cleaned Token After =  fellow alan turing institute , uk 's national centre ai data science , uk government 's department digital , culture , media sport \n",
      "Cleaned Token After Stem =  fellow alan ture institut , uk 's nation centr ai data scienc , uk govern 's depart digit , cultur , media sport \n",
      "Cleaned Token Before =  of the data lab, which helps scottish industry innovate through data science and artificial intelligence. docherty completed a computer science degree\n",
      "Cleaned Token After =  data lab , helps scottish industry innovate data science artificial intelligence . docherty completed computer science degree \n",
      "Cleaned Token After Stem =  data lab , help scottish industri innov data scienc artifici intellig . docherti complet comput scienc degre \n",
      "Cleaned Token Before =  in systems science, a sampled-data system is a control system in which a continuous-time plant is controlled with a digital device. under periodic sampling\n",
      "Cleaned Token After =  systems science , sampled-data system control system continuous-time plant controlled digital device . periodic sampling \n",
      "Cleaned Token After Stem =  system scienc , sampled-data system control system continuous-tim plant control digit devic . period sampl \n",
      "Cleaned Token Before =  in data management, the time scale of the data determines how it is processed and stored. dynamic data or transactional data is information that is periodically\n",
      "Cleaned Token After =  data management , time scale data determines processed stored . dynamic data transactional data information periodically \n",
      "Cleaned Token After Stem =  data manag , time scale data determin process store . dynam data transact data inform period \n",
      "Cleaned Token Before =  is a data science process that abandons etls and complex batch data pipelines in favor of cloud-native and microservices paradigms. continuous data processing\n",
      "Cleaned Token After =  data science process abandons etls complex batch data pipelines favor cloud-native microservices paradigms . continuous data processing \n",
      "Cleaned Token After Stem =  data scienc process abandon etl complex batch data pipelin favor cloud-n microservic paradigm . continu data process \n",
      "Cleaned Token Before =  now is odbc more important for data access and data virtualization of data integration in data analytic and data science scenarios. these new requirements\n",
      "Cleaned Token After =  odbc important data access data virtualization data integration data analytic data science scenarios . new requirements \n",
      "Cleaned Token After Stem =  odbc import data access data virtual data integr data analyt data scienc scenario . new requir \n",
      "Cleaned Token Before =  in computer science, a reference is a value that enables a program to indirectly access a particular datum, such as a variable's value or a record, in\n",
      "Cleaned Token After =  computer science , reference value enables program indirectly access particular datum , variable 's value record , \n",
      "Cleaned Token After Stem =  comput scienc , refer valu enabl program indirectli access particular datum , variabl 's valu record , \n",
      "Cleaned Token Before =  design, data communications, database design, project management and security. the degree typically includes coursework in both computer science and business\n",
      "Cleaned Token After =  design , data communications , database design , project management security . degree typically includes coursework computer science business \n",
      "Cleaned Token After Stem =  design , data commun , databas design , project manag secur . degre typic includ coursework comput scienc busi \n",
      "Cleaned Token Before =  that the enlightenment values of reason, science, and humanism have brought progress; shows our progress with data that health, prosperity, safety, peace\n",
      "Cleaned Token After =  enlightenment values reason , science , humanism brought progress ; shows progress data health , prosperity , safety , peace \n",
      "Cleaned Token After Stem =  enlighten valu reason , scienc , human brought progress ; show progress data health , prosper , safeti , peac \n",
      "Cleaned Token Before =  egolf (2015). the advertising age encyclopedia of advertising. when data science and traditional market research collide published on november 24, 2020\n",
      "Cleaned Token After =  egolf ( 2015 ) . advertising age encyclopedia advertising . data science traditional market research collide published november 24 , 2020 \n",
      "Cleaned Token After Stem =  egolf ( 2015 ) . advertis age encyclopedia advertis . data scienc tradit market research collid publish novemb 24 , 2020 \n",
      "Cleaned Token Before =  or even individuals who \"might be working in their basement on some data-science project and might have an idea for how to solve an important problem\"\n",
      "Cleaned Token After =  even individuals `` might working basement data-science project might idea solve important problem '' \n",
      "Cleaned Token After Stem =  even individu `` might work basement data-sci project might idea solv import problem `` \n",
      "Cleaned Token Before =  possible data fraud on the part of author stapel. these findings of the university's interim report included fabrication of data in this science paper.\n",
      "Cleaned Token After =  possible data fraud part author stapel . findings university 's interim report included fabrication data science paper . \n",
      "Cleaned Token After Stem =  possibl data fraud part author stapel . find univers 's interim report includ fabric data scienc paper . \n",
      "Cleaned Token Before =  \"a fistful of datas\" is the 134th episode of the american science fiction television series star trek: the next generation, the eighth episode of the\n",
      "Cleaned Token After =  `` fistful datas '' 134th episode american science fiction television series star trek : next generation , eighth episode \n",
      "Cleaned Token After Stem =  `` fist data `` 134th episod american scienc fiction televis seri star trek : next gener , eighth episod \n",
      "Cleaned Token Before =  public. the field of science education includes work in science content, science process (the scientific method), some social science, and some teaching\n",
      "Cleaned Token After =  public . field science education includes work science content , science process ( scientific method ) , social science , teaching \n",
      "Cleaned Token After Stem =  public . field scienc educ includ work scienc content , scienc process ( scientif method ) , social scienc , teach \n",
      "Cleaned Token Before =  business, public policy, computer science, psychology, statistics and data science, and social and decision sciences. raymond augustine bauer, kenneth\n",
      "Cleaned Token After =  business , public policy , computer science , psychology , statistics data science , social decision sciences . raymond augustine bauer , kenneth \n",
      "Cleaned Token After Stem =  busi , public polici , comput scienc , psycholog , statist data scienc , social decis scienc . raymond augustin bauer , kenneth \n",
      "Cleaned Token Before =  data is the statistical data type consisting of categorical variables or of data that has been converted into that form, for example as grouped data.\n",
      "Cleaned Token After =  data statistical data type consisting categorical variables data converted form , example grouped data . \n",
      "Cleaned Token After Stem =  data statist data type consist categor variabl data convert form , exampl group data . \n",
      "Cleaned Token Before =  science fiction (or sci-fi) is a film genre that uses speculative, fictional science-based depictions of phenomena that are not fully accepted by mainstream\n",
      "Cleaned Token After =  science fiction ( sci-fi ) film genre uses speculative , fictional science-based depictions phenomena fully accepted mainstream \n",
      "Cleaned Token After Stem =  scienc fiction ( sci-fi ) film genr use specul , fiction science-bas depict phenomena fulli accept mainstream \n",
      "Cleaned Token Before =  applied science is the use of the scientific method and knowledge to attain practical goals. it includes a broad range of disciplines such as engineering\n",
      "Cleaned Token After =  applied science use scientific method knowledge attain practical goals . includes broad range disciplines engineering \n",
      "Cleaned Token After Stem =  appli scienc use scientif method knowledg attain practic goal . includ broad rang disciplin engin \n",
      "Cleaned Token Before =   \"improving the traditional information management in natural sciences\", data science journal, 2009, 8, 18-26, doi 10.2481/dsj.8.18 durham university\n",
      "Cleaned Token After =  `` improving traditional information management natural sciences '' , data science journal , 2009 , 8 , 18-26 , doi 10.2481/dsj.8.18 durham university \n",
      "Cleaned Token After Stem =  `` improv tradit inform manag natur scienc `` , data scienc journal , 2009 , 8 , 18-26 , doi 10.2481/dsj.8.18 durham univers \n",
      "Cleaned Token Before =  polling, or polled operation, in computer science, refers to actively sampling the status of an external device by a client program as a synchronous activity\n",
      "Cleaned Token After =  polling , polled operation , computer science , refers actively sampling status external device client program synchronous activity \n",
      "Cleaned Token After Stem =  poll , poll oper , comput scienc , refer activ sampl statu extern devic client program synchron activ \n",
      "Cleaned Token Before =  statistics be renamed data science and statisticians data scientists. he also presented his lecture entitled \"statistics = data science?\" as the first of\n",
      "Cleaned Token After =  statistics renamed data science statisticians data scientists . also presented lecture entitled `` statistics = data science ? '' first \n",
      "Cleaned Token After Stem =  statist renam data scienc statistician data scientist . also present lectur entitl `` statist = data scienc ? `` first \n",
      "Cleaned Token Before =  acquisition were the greenplum database, chorus (a management tool), and data science labs. greenplum had customers in vertical markets including ebay. it\n",
      "Cleaned Token After =  acquisition greenplum database , chorus ( management tool ) , data science labs . greenplum customers vertical markets including ebay . \n",
      "Cleaned Token After Stem =  acquisit greenplum databas , choru ( manag tool ) , data scienc lab . greenplum custom vertic market includ ebay . \n",
      "Cleaned Token Before =  maria airoldi is the millard e. gladfelter professor of statistics and data science in the fox school of business at temple university, and a principal investigator\n",
      "Cleaned Token After =  maria airoldi millard e. gladfelter professor statistics data science fox school business temple university , principal investigator \n",
      "Cleaned Token After Stem =  maria airoldi millard e. gladfelt professor statist data scienc fox school busi templ univers , princip investig \n",
      "Cleaned Token Before =  computer science professor emeritus, national expert on election systems jennifer lewis priestley, professor of statistics and data science, developed\n",
      "Cleaned Token After =  computer science professor emeritus , national expert election systems jennifer lewis priestley , professor statistics data science , developed \n",
      "Cleaned Token After Stem =  comput scienc professor emeritu , nation expert elect system jennif lewi priestley , professor statist data scienc , develop \n",
      "Cleaned Token Before =  15 july 2016. \"nasa - nssdc - spacecraft - details\". national space science data center. retrieved 1 october 2012. \"jonathan's space report no. 640\".\n",
      "Cleaned Token After =  15 july 2016 . `` nasa - nssdc - spacecraft - details '' . national space science data center . retrieved 1 october 2012 . `` jonathan 's space report . 640 '' . \n",
      "Cleaned Token After Stem =  15 juli 2016 . `` nasa - nssdc - spacecraft - detail `` . nation space scienc data center . retriev 1 octob 2012 . `` jonathan 's space report . 640 `` . \n",
      "Cleaned Token Before =  chemical from a reliable source and follow its directions. science stuff baker fisher eastman table data obtained from crc handbook of chemistry and physics\n",
      "Cleaned Token After =  chemical reliable source follow directions . science stuff baker fisher eastman table data obtained crc handbook chemistry physics \n",
      "Cleaned Token After Stem =  chemic reliabl sourc follow direct . scienc stuff baker fisher eastman tabl data obtain crc handbook chemistri physic \n",
      "Cleaned Token Before =  that you seek the safety data sheet (sds) for this chemical from a reliable source and follow its directions. siri science stuff (ammonia solution) linstrom\n",
      "Cleaned Token After =  seek safety data sheet ( sds ) chemical reliable source follow directions . siri science stuff ( ammonia solution ) linstrom \n",
      "Cleaned Token After Stem =  seek safeti data sheet ( sd ) chemic reliabl sourc follow direct . siri scienc stuff ( ammonia solut ) linstrom \n",
      "Cleaned Token Before =  the spatial data file (sdf) is a single-user geodatabase file format developed by autodesk. the file format is the native spatial data storage format for\n",
      "Cleaned Token After =  spatial data file ( sdf ) single-user geodatabase file format developed autodesk . file format native spatial data storage format \n",
      "Cleaned Token After Stem =  spatial data file ( sdf ) single-us geodatabas file format develop autodesk . file format nativ spatial data storag format \n",
      "Cleaned Token Before =  machine generated data\". monash research. monash, curt. \"examples and definition of machine-generated data\". monash research. science logic. \"gartner ten\n",
      "Cleaned Token After =  machine generated data '' . monash research . monash , curt . `` examples definition machine-generated data '' . monash research . science logic . `` gartner ten \n",
      "Cleaned Token After Stem =  machin gener data `` . monash research . monash , curt . `` exampl definit machine-gener data `` . monash research . scienc logic . `` gartner ten \n",
      "Cleaned Token Before =  areas of network science, statistical physics, and complex systems. he is currently an associate professor of network and data science at the central european\n",
      "Cleaned Token After =  areas network science , statistical physics , complex systems . currently associate professor network data science central european \n",
      "Cleaned Token After Stem =  area network scienc , statist physic , complex system . current associ professor network data scienc central european \n",
      "Cleaned Token Before =  the interdisciplinary field of materials science, also commonly termed materials science and engineering, covers the design and discovery of new materials\n",
      "Cleaned Token After =  interdisciplinary field materials science , also commonly termed materials science engineering , covers design discovery new materials \n",
      "Cleaned Token After Stem =  interdisciplinari field materi scienc , also commonli term materi scienc engin , cover design discoveri new materi \n",
      "Cleaned Token Before =  science, observation can also involve the perception and recording of data via the use of scientific instruments. the term may also refer to any data\n",
      "Cleaned Token After =  science , observation also involve perception recording data via use scientific instruments . term may also refer data \n",
      "Cleaned Token After Stem =  scienc , observ also involv percept record data via use scientif instrument . term may also refer data \n",
      "Cleaned Token Before =  \"learn\" from data without being explicitly programmed. data science involves the application of machine learning to extract knowledge from data. subfields\n",
      "Cleaned Token After =  `` learn '' data without explicitly programmed . data science involves application machine learning extract knowledge data . subfields \n",
      "Cleaned Token After Stem =  `` learn `` data without explicitli program . data scienc involv applic machin learn extract knowledg data . subfield \n",
      "Cleaned Token Before =  and particle physics and affiliated faculty member at nyu's center for data science. he is an experimental particle physicist working, primarily, on the\n",
      "Cleaned Token After =  particle physics affiliated faculty member nyu 's center data science . experimental particle physicist working , primarily , \n",
      "Cleaned Token After Stem =  particl physic affili faculti member nyu 's center data scienc . experiment particl physicist work , primarili , \n",
      "Cleaned Token Before =  institution with programmes video game development, bioinformatics, and data science. something that has contributed to establishing skövde and the university\n",
      "Cleaned Token After =  institution programmes video game development , bioinformatics , data science . something contributed establishing skövde university \n",
      "Cleaned Token After Stem =  institut programm video game develop , bioinformat , data scienc . someth contribut establish skövde univers \n",
      "Cleaned Token Before =  this is a list of data breaches, using data compiled from various sources, including press reports, government news releases, and mainstream news articles\n",
      "Cleaned Token After =  list data breaches , using data compiled various sources , including press reports , government news releases , mainstream news articles \n",
      "Cleaned Token After Stem =  list data breach , use data compil variou sourc , includ press report , govern news releas , mainstream news articl \n",
      "Cleaned Token Before =  computer science at stanford university. they specialized in visualization techniques for exploring and analyzing relational databases and data cubes, and\n",
      "Cleaned Token After =  computer science stanford university . specialized visualization techniques exploring analyzing relational databases data cubes , \n",
      "Cleaned Token After Stem =  comput scienc stanford univers . special visual techniqu explor analyz relat databas data cube , \n",
      "Cleaned Token Before =  the payment card industry data security standard (pci dss) is an information security standard for organizations that handle branded credit cards from\n",
      "Cleaned Token After =  payment card industry data security standard ( pci dss ) information security standard organizations handle branded credit cards \n",
      "Cleaned Token After Stem =  payment card industri data secur standard ( pci dss ) inform secur standard organ handl brand credit card \n",
      "Cleaned Token Before =  forecasting methodology makes frequent use of mathematics, statistics and data science. political forecasting as it pertains to elections is related to psephology\n",
      "Cleaned Token After =  forecasting methodology makes frequent use mathematics , statistics data science . political forecasting pertains elections related psephology \n",
      "Cleaned Token After Stem =  forecast methodolog make frequent use mathemat , statist data scienc . polit forecast pertain elect relat psepholog \n",
      "Cleaned Token Before =  university of washington escience institute, one of three partners (along with berkeley and new york university) in the data science environments effort sponsored\n",
      "Cleaned Token After =  university washington escience institute , one three partners ( along berkeley new york university ) data science environments effort sponsored \n",
      "Cleaned Token After Stem =  univers washington escienc institut , one three partner ( along berkeley new york univers ) data scienc environ effort sponsor \n",
      "Cleaned Token Before =  computational social science revolutionizes both fundamental legs of the scientific method: empirical research, especially through big data, by analyzing the\n",
      "Cleaned Token After =  computational social science revolutionizes fundamental legs scientific method : empirical research , especially big data , analyzing \n",
      "Cleaned Token After Stem =  comput social scienc revolution fundament leg scientif method : empir research , especi big data , analyz \n",
      "Cleaned Token Before =  oceanography and other earth science disciplines. earth sciences graphics software includes the capability to read specialized data formats such as netcdf,\n",
      "Cleaned Token After =  oceanography earth science disciplines . earth sciences graphics software includes capability read specialized data formats netcdf , \n",
      "Cleaned Token After Stem =  oceanographi earth scienc disciplin . earth scienc graphic softwar includ capabl read special data format netcdf , \n",
      "Cleaned Token Before =  education company that offers 12-week bootcamps for web development and data science, as well as part-time up-skilling courses, with locations across canada\n",
      "Cleaned Token After =  education company offers 12-week bootcamps web development data science , well part-time up-skilling courses , locations across canada \n",
      "Cleaned Token After Stem =  educ compani offer 12-week bootcamp web develop data scienc , well part-tim up-skil cours , locat across canada \n",
      "Cleaned Token Before =  the form of recorded data, which may be the subject of analysis (e.g. by scientists). in a second sense \"empirical\" in science may be synonymous with\n",
      "Cleaned Token After =  form recorded data , may subject analysis ( e.g . scientists ) . second sense `` empirical '' science may synonymous \n",
      "Cleaned Token After Stem =  form record data , may subject analysi ( e.g . scientist ) . second sens `` empir `` scienc may synonym \n",
      "Cleaned Token Before =  pseudonymization is a data management and de-identification procedure by which personally identifiable information fields within a data record are replaced\n",
      "Cleaned Token After =  pseudonymization data management de-identification procedure personally identifiable information fields within data record replaced \n",
      "Cleaned Token After Stem =  pseudonym data manag de-identif procedur person identifi inform field within data record replac \n",
      "Cleaned Token Before =  civis analytics is an eric schmidt-backed data science software and consultancy company founded by dan wagner in 2013. wagner served as the chief analytics\n",
      "Cleaned Token After =  civis analytics eric schmidt-backed data science software consultancy company founded dan wagner 2013. wagner served chief analytics \n",
      "Cleaned Token After Stem =  civi analyt eric schmidt-back data scienc softwar consult compani found dan wagner 2013. wagner serv chief analyt \n",
      "Cleaned Token Before =  on real-time data. data science digitization/ digitalization digital transformation big data ethics of artificial intelligence big data ethics machine\n",
      "Cleaned Token After =  real-time data . data science digitization/ digitalization digital transformation big data ethics artificial intelligence big data ethics machine \n",
      "Cleaned Token After Stem =  real-tim data . data scienc digitization/ digit digit transform big data ethic artifici intellig big data ethic machin \n",
      "Cleaned Token Before =  consists of a variable that may hold such a data structure. some programming languages support special data types, called union types, to describe such\n",
      "Cleaned Token After =  consists variable may hold data structure . programming languages support special data types , called union types , describe \n",
      "Cleaned Token After Stem =  consist variabl may hold data structur . program languag support special data type , call union type , describ \n",
      "Cleaned Token Before =  themes: cellular biology, clinical sciences, genetics, infection and immunity, population health, and data science. the institute was established in 1986\n",
      "Cleaned Token After =  themes : cellular biology , clinical sciences , genetics , infection immunity , population health , data science . institute established 1986 \n",
      "Cleaned Token After Stem =  theme : cellular biolog , clinic scienc , genet , infect immun , popul health , data scienc . institut establish 1986 \n",
      "Cleaned Token Before =  artificial intelligence & machine learning artificial intelligence & data science pg courses m.tech vlsi & embedded systems master of business administration\n",
      "Cleaned Token After =  artificial intelligence & machine learning artificial intelligence & data science pg courses m.tech vlsi & embedded systems master business administration \n",
      "Cleaned Token After Stem =  artifici intellig & machin learn artifici intellig & data scienc pg cours m.tech vlsi & embed system master busi administr \n",
      "Cleaned Token Before =  environmental research, presented by nsw environment, energy and science (dpie) excellence in data science, presented by the university of technology sydney excellence\n",
      "Cleaned Token After =  environmental research , presented nsw environment , energy science ( dpie ) excellence data science , presented university technology sydney excellence \n",
      "Cleaned Token After Stem =  environment research , present nsw environ , energi scienc ( dpie ) excel data scienc , present univers technolog sydney excel \n",
      "Cleaned Token Before =  companies take their business decisions. caos not only bring strong data science backed actionable insights to the table, but also own the resulting 'roi'/'impact'\n",
      "Cleaned Token After =  companies take business decisions . caos bring strong data science backed actionable insights table , also resulting 'roi'/'impact ' \n",
      "Cleaned Token After Stem =  compani take busi decis . cao bring strong data scienc back action insight tabl , also result 'roi'/'impact ' \n",
      "Cleaned Token Before =  three-body problem (chinese: 三体; lit. 'three-body'; pinyin: sān tǐ) is a science fiction novel by the chinese writer liu cixin. the title refers to the\n",
      "Cleaned Token After =  three-body problem ( chinese : 三体 ; lit . 'three-body ' ; pinyin : sān tǐ ) science fiction novel chinese writer liu cixin . title refers \n",
      "Cleaned Token After Stem =  three-bodi problem ( chines : 三体 ; lit . 'three-bodi ' ; pinyin : sān tǐ ) scienc fiction novel chines writer liu cixin . titl refer \n",
      "Cleaned Token Before =  page provides supplementary chemical data on aluminium oxide. siri science stuff except where noted otherwise, data relate to standard ambient temperature\n",
      "Cleaned Token After =  page provides supplementary chemical data aluminium oxide . siri science stuff except noted otherwise , data relate standard ambient temperature \n",
      "Cleaned Token After Stem =  page provid supplementari chemic data aluminium oxid . siri scienc stuff except note otherwis , data relat standard ambient temperatur \n",
      "Cleaned Token Before =  waiver for the research data. other organisations questioned the current scientific culture, making a call for more open, public science. for coronavirus studies\n",
      "Cleaned Token After =  waiver research data . organisations questioned current scientific culture , making call open , public science . coronavirus studies \n",
      "Cleaned Token After Stem =  waiver research data . organis question current scientif cultur , make call open , public scienc . coronaviru studi \n",
      "Cleaned Token Before =  has become an important partner for sport science is mainly connected with \"the fact that the use of data and media, the design of models, the analysis\n",
      "Cleaned Token After =  become important partner sport science mainly connected `` fact use data media , design models , analysis \n",
      "Cleaned Token After Stem =  becom import partner sport scienc mainli connect `` fact use data media , design model , analysi \n",
      "Cleaned Token Before =  in computer science, a collection or container is a grouping of some variable number of data items (possibly zero) that have some shared significance to\n",
      "Cleaned Token After =  computer science , collection container grouping variable number data items ( possibly zero ) shared significance \n",
      "Cleaned Token After Stem =  comput scienc , collect contain group variabl number data item ( possibl zero ) share signific \n",
      "Cleaned Token Before =  springer science+business media. archived from the original on 2017-11-07. retrieved 2017-02-14. cs1 maint: discouraged parameter (link) \"data & knowledge\n",
      "Cleaned Token After =  springer science+business media . archived original 2017-11-07. retrieved 2017-02-14. cs1 maint : discouraged parameter ( link ) `` data & knowledge \n",
      "Cleaned Token After Stem =  springer science+busi media . archiv origin 2017-11-07. retriev 2017-02-14. cs1 maint : discourag paramet ( link ) `` data & knowledg \n",
      "Cleaned Token Before =  systems as a design science\". scandinavian journal of information systems. 19 (2): 39. watts s; shankaranarayanan g & even a (2009). \"data quality assessment\n",
      "Cleaned Token After =  systems design science '' . scandinavian journal information systems . 19 ( 2 ) : 39. watts ; shankaranarayanan g & even ( 2009 ) . `` data quality assessment \n",
      "Cleaned Token After Stem =  system design scienc `` . scandinavian journal inform system . 19 ( 2 ) : 39. watt ; shankaranarayanan g & even ( 2009 ) . `` data qualiti assess \n",
      "Cleaned Token Before =  in computer science, multiple buffering is the use of more than one buffer to hold a block of data, so that a \"reader\" will see a complete (though perhaps\n",
      "Cleaned Token After =  computer science , multiple buffering use one buffer hold block data , `` reader '' see complete ( though perhaps \n",
      "Cleaned Token After Stem =  comput scienc , multipl buffer use one buffer hold block data , `` reader `` see complet ( though perhap \n",
      "Cleaned Token Before =  semantic data model approach. prentice-hall international series in computer science. michael hammer and dennis mcleod (1978). \"the semantic data model:\n",
      "Cleaned Token After =  semantic data model approach . prentice-hall international series computer science . michael hammer dennis mcleod ( 1978 ) . `` semantic data model : \n",
      "Cleaned Token After Stem =  semant data model approach . prentice-hal intern seri comput scienc . michael hammer denni mcleod ( 1978 ) . `` semant data model : \n",
      "Cleaned Token Before =  institute for data science at the new jersey institute of technology. previously, he served as a professor, chair of the school of computational science and engineering\n",
      "Cleaned Token After =  institute data science new jersey institute technology . previously , served professor , chair school computational science engineering \n",
      "Cleaned Token After Stem =  institut data scienc new jersey institut technolog . previous , serv professor , chair school comput scienc engin \n",
      "Cleaned Token Before =  aid those learning data analysis. peng has written or contributed to ten different books, including r programming for data science, which lays the foundation\n",
      "Cleaned Token After =  aid learning data analysis . peng written contributed ten different books , including r programming data science , lays foundation \n",
      "Cleaned Token After Stem =  aid learn data analysi . peng written contribut ten differ book , includ r program data scienc , lay foundat \n",
      "Cleaned Token Before =  applied in a wide range of domains like healthcare, customer surveys, data science programs, advanced manufacturing and bayesian network applications. kenett\n",
      "Cleaned Token After =  applied wide range domains like healthcare , customer surveys , data science programs , advanced manufacturing bayesian network applications . kenett \n",
      "Cleaned Token After Stem =  appli wide rang domain like healthcar , custom survey , data scienc program , advanc manufactur bayesian network applic . kenett \n",
      "Cleaned Token Before =  police science is the study and research which deals with police work. studies and research in criminology, forensic science, psychiatry, psychology,\n",
      "Cleaned Token After =  police science study research deals police work . studies research criminology , forensic science , psychiatry , psychology , \n",
      "Cleaned Token After Stem =  polic scienc studi research deal polic work . studi research criminolog , forens scienc , psychiatri , psycholog , \n",
      "Cleaned Token Before =  in computer science, a ball tree, balltree or metric tree, is a space partitioning data structure for organizing points in a multi-dimensional space.\n",
      "Cleaned Token After =  computer science , ball tree , balltree metric tree , space partitioning data structure organizing points multi-dimensional space . \n",
      "Cleaned Token After Stem =  comput scienc , ball tree , balltre metric tree , space partit data structur organ point multi-dimension space . \n",
      "Cleaned Token Before =  of other methods, such as interviews, semiotic visual analysis, and data science; and it is adaptable: it can be used to study many types of online sites\n",
      "Cleaned Token After =  methods , interviews , semiotic visual analysis , data science ; adaptable : used study many types online sites \n",
      "Cleaned Token After Stem =  method , interview , semiot visual analysi , data scienc ; adapt : use studi mani type onlin site \n",
      "Cleaned Token Before =  present) the center for data-driven discovery center for data science and technology caltech announces new center supports data-driven research v t e\n",
      "Cleaned Token After =  present ) center data-driven discovery center data science technology caltech announces new center supports data-driven research v e \n",
      "Cleaned Token After Stem =  present ) center data-driven discoveri center data scienc technolog caltech announc new center support data-driven research v e \n",
      "Cleaned Token Before =  institute for data science & artificial intelligence. \"institute for data science and artificial intelligence | institute for data science & artificial\n",
      "Cleaned Token After =  institute data science & artificial intelligence . `` institute data science artificial intelligence | institute data science & artificial \n",
      "Cleaned Token After Stem =  institut data scienc & artifici intellig . `` institut data scienc artifici intellig | institut data scienc & artifici \n",
      "Cleaned Token Before =  \"distributed data storage - an overview | sciencedirect topics\". cs1 maint: discouraged parameter (link) \"bigtable: google's distributed data store\".\n",
      "Cleaned Token After =  `` distributed data storage - overview | sciencedirect topics '' . cs1 maint : discouraged parameter ( link ) `` bigtable : google 's distributed data store '' . \n",
      "Cleaned Token After Stem =  `` distribut data storag - overview | sciencedirect topic `` . cs1 maint : discourag paramet ( link ) `` bigtabl : googl 's distribut data store `` . \n",
      "Cleaned Token Before =  sequences: computer science and computational biology. usa: cambridge university press. isbn 0-521-58519-8. dictionary of algorithms and data structures: longest\n",
      "Cleaned Token After =  sequences : computer science computational biology . usa : cambridge university press . isbn 0-521-58519-8. dictionary algorithms data structures : longest \n",
      "Cleaned Token After Stem =  sequenc : comput scienc comput biolog . usa : cambridg univers press . isbn 0-521-58519-8. dictionari algorithm data structur : longest \n",
      "Cleaned Token Before =  of computer science and co faculty director of the harvard data science initiative. from 2013–17, he was area dean for computer science. parkes is a\n",
      "Cleaned Token After =  computer science co faculty director harvard data science initiative . 2013–17 , area dean computer science . parkes \n",
      "Cleaned Token After Stem =  comput scienc co faculti director harvard data scienc initi . 2013–17 , area dean comput scienc . park \n",
      "Cleaned Token Before =  professor of computer science at yale university. in 2018, gerstein was named co-director of the yale center for biomedical data science. after graduating\n",
      "Cleaned Token After =  professor computer science yale university . 2018 , gerstein named co-director yale center biomedical data science . graduating \n",
      "Cleaned Token After Stem =  professor comput scienc yale univers . 2018 , gerstein name co-director yale center biomed data scienc . graduat \n",
      "Cleaned Token Before =  sifted (formerly veriship) is the leading logistics data-science platform that helps shippers save money by optimizing business decisions. though originally\n",
      "Cleaned Token After =  sifted ( formerly veriship ) leading logistics data-science platform helps shippers save money optimizing business decisions . though originally \n",
      "Cleaned Token After Stem =  sift ( formerli veriship ) lead logist data-sci platform help shipper save money optim busi decis . though origin \n",
      "Cleaned Token Before =  scientist and businesswoman, who serves as the chief executive officer of datascience limited, an it research company that she founded. she was born in nyamira\n",
      "Cleaned Token After =  scientist businesswoman , serves chief executive officer datascience limited , research company founded . born nyamira \n",
      "Cleaned Token After Stem =  scientist businesswoman , serv chief execut offic datasci limit , research compani found . born nyamira \n",
      "Cleaned Token Before =  deterrence profiling (information science) data mining geolocation software neural networks artificial intelligence patterns data clustering statistics labelling\n",
      "Cleaned Token After =  deterrence profiling ( information science ) data mining geolocation software neural networks artificial intelligence patterns data clustering statistics labelling \n",
      "Cleaned Token After Stem =  deterr profil ( inform scienc ) data mine geoloc softwar neural network artifici intellig pattern data cluster statist label \n",
      "Cleaned Token Before =  a data distribution tool with a version control feature for tracking changes and publishing data sets. it is primarily used for data-driven science, but\n",
      "Cleaned Token After =  data distribution tool version control feature tracking changes publishing data sets . primarily used data-driven science , \n",
      "Cleaned Token After Stem =  data distribut tool version control featur track chang publish data set . primarili use data-driven scienc , \n",
      "Cleaned Token Before =  actuarial science provides data collection, measurement, estimating, forecasting, and valuation tools to provide financial and underwriting data for management\n",
      "Cleaned Token After =  actuarial science provides data collection , measurement , estimating , forecasting , valuation tools provide financial underwriting data management \n",
      "Cleaned Token After Stem =  actuari scienc provid data collect , measur , estim , forecast , valuat tool provid financi underwrit data manag \n",
      "Cleaned Token Before =  sciencedirect is a website which provides access to a large bibliographic database of scientific and medical publications of the dutch publisher elsevier\n",
      "Cleaned Token After =  sciencedirect website provides access large bibliographic database scientific medical publications dutch publisher elsevier \n",
      "Cleaned Token After Stem =  sciencedirect websit provid access larg bibliograph databas scientif medic public dutch publish elsevi \n",
      "Cleaned Token Before =  a data management plan or dmp is a formal document that outlines how data are to be handled both during a research project, and after the project is completed\n",
      "Cleaned Token After =  data management plan dmp formal document outlines data handled research project , project completed \n",
      "Cleaned Token After Stem =  data manag plan dmp formal document outlin data handl research project , project complet \n",
      "Cleaned Token Before =  statistics and computational neuroscience in the department of statistics and data science, the machine learning department, and the neuroscience institute at carnegie\n",
      "Cleaned Token After =  statistics computational neuroscience department statistics data science , machine learning department , neuroscience institute carnegie \n",
      "Cleaned Token After Stem =  statist comput neurosci depart statist data scienc , machin learn depart , neurosci institut carnegi \n",
      "Cleaned Token Before =  arthur zimek is a professor in data mining, data science and machine learning at the university of southern denmark in odense, denmark. he graduated from\n",
      "Cleaned Token After =  arthur zimek professor data mining , data science machine learning university southern denmark odense , denmark . graduated \n",
      "Cleaned Token After Stem =  arthur zimek professor data mine , data scienc machin learn univers southern denmark odens , denmark . graduat \n",
      "Cleaned Token Before =  childhood (1989) faculty of economic studies & political science (2014) faculty of computing and data science (2019) alexandria university also opened branches\n",
      "Cleaned Token After =  childhood ( 1989 ) faculty economic studies & political science ( 2014 ) faculty computing data science ( 2019 ) alexandria university also opened branches \n",
      "Cleaned Token After Stem =  childhood ( 1989 ) faculti econom studi & polit scienc ( 2014 ) faculti comput data scienc ( 2019 ) alexandria univers also open branch \n",
      "Cleaned Token Before =  a. little (13 august 2019). machine learning for signal processing: data science, algorithms, and computational statistics. oup oxford. isbn 978-0-19-102431-3\n",
      "Cleaned Token After =  a. little ( 13 august 2019 ) . machine learning signal processing : data science , algorithms , computational statistics . oup oxford . isbn 978-0-19-102431-3 \n",
      "Cleaned Token After Stem =  a. littl ( 13 august 2019 ) . machin learn signal process : data scienc , algorithm , comput statist . oup oxford . isbn 978-0-19-102431-3 \n",
      "Cleaned Token Before =  the space telescope science institute (stsci) is the science operations center for the hubble space telescope (hst) and for the james webb space telescope\n",
      "Cleaned Token After =  space telescope science institute ( stsci ) science operations center hubble space telescope ( hst ) james webb space telescope \n",
      "Cleaned Token After Stem =  space telescop scienc institut ( stsci ) scienc oper center hubbl space telescop ( hst ) jame webb space telescop \n",
      "Cleaned Token Before =  cryptography and computer science, a hash tree or merkle tree is a tree in which every leaf node is labelled with the cryptographic hash of a data block, and every\n",
      "Cleaned Token After =  cryptography computer science , hash tree merkle tree tree every leaf node labelled cryptographic hash data block , every \n",
      "Cleaned Token After Stem =  cryptographi comput scienc , hash tree merkl tree tree everi leaf node label cryptograph hash data block , everi \n",
      "Cleaned Token Before =  misleading graph, also known as a distorted graph, is a graph that misrepresents data, constituting a misuse of statistics and with the result that an incorrect\n",
      "Cleaned Token After =  misleading graph , also known distorted graph , graph misrepresents data , constituting misuse statistics result incorrect \n",
      "Cleaned Token After Stem =  mislead graph , also known distort graph , graph misrepres data , constitut misus statist result incorrect \n",
      "Cleaned Token Before =  pushing the limits of data extraction\". alleywatch. september 17, 2018. \"sisense acquires periscope data to build integrated data science and analytics solution\"\n",
      "Cleaned Token After =  pushing limits data extraction '' . alleywatch . september 17 , 2018 . `` sisense acquires periscope data build integrated data science analytics solution '' \n",
      "Cleaned Token After Stem =  push limit data extract `` . alleywatch . septemb 17 , 2018 . `` sisens acquir periscop data build integr data scienc analyt solut `` \n",
      "Cleaned Token Before =  systems development masters of science in computational data science (mcds) master of science in music and technology masters in biotechnology innovation\n",
      "Cleaned Token After =  systems development masters science computational data science ( mcds ) master science music technology masters biotechnology innovation \n",
      "Cleaned Token After Stem =  system develop master scienc comput data scienc ( mcd ) master scienc music technolog master biotechnolog innov \n",
      "Cleaned Token Before =  machine was built.\" — paul allen, fortune \"traf-o-data\". new mexico museum of natural history and science. archived from the original on march 23, 2012.\n",
      "Cleaned Token After =  machine built . '' — paul allen , fortune `` traf-o-data '' . new mexico museum natural history science . archived original march 23 , 2012 . \n",
      "Cleaned Token After Stem =  machin built . `` — paul allen , fortun `` traf-o-data `` . new mexico museum natur histori scienc . archiv origin march 23 , 2012 . \n",
      "Cleaned Token Before =  and weevils cometology – study of comets computer science – study of processes that interact with data conchology – study of shells connectomics – study\n",
      "Cleaned Token After =  weevils cometology – study comets computer science – study processes interact data conchology – study shells connectomics – study \n",
      "Cleaned Token After Stem =  weevil cometolog – studi comet comput scienc – studi process interact data concholog – studi shell connectom – studi \n",
      "Cleaned Token Before =  construction, mechatronics, software engineering, computer science and it, beauty and wellness, data science, retail, logistics and ports as well as architecture\n",
      "Cleaned Token After =  construction , mechatronics , software engineering , computer science , beauty wellness , data science , retail , logistics ports well architecture \n",
      "Cleaned Token After Stem =  construct , mechatron , softwar engin , comput scienc , beauti well , data scienc , retail , logist port well architectur \n",
      "Cleaned Token Before =  dna digital data storage is the process of encoding and decoding binary data to and from synthesized strands of dna. while dna as a storage medium has\n",
      "Cleaned Token After =  dna digital data storage process encoding decoding binary data synthesized strands dna . dna storage medium \n",
      "Cleaned Token After Stem =  dna digit data storag process encod decod binari data synthes strand dna . dna storag medium \n",
      "Cleaned Token Before =  this is a list of gis data sources (including some geoportals) that provide information sets that can be used in geographic information systems (gis) and\n",
      "Cleaned Token After =  list gis data sources ( including geoportals ) provide information sets used geographic information systems ( gis ) \n",
      "Cleaned Token After Stem =  list gi data sourc ( includ geoport ) provid inform set use geograph inform system ( gi ) \n",
      "Cleaned Token Before =  space sciences laboratory at uc berkeley, and released under the gnu general public license. fits hdf5 csv list of file formats netcdf the simple data format\n",
      "Cleaned Token After =  space sciences laboratory uc berkeley , released gnu general public license . fits hdf5 csv list file formats netcdf simple data format \n",
      "Cleaned Token After Stem =  space scienc laboratori uc berkeley , releas gnu gener public licens . fit hdf5 csv list file format netcdf simpl data format \n",
      "Cleaned Token Before =  computer science to implement static lookup tables to hold multiple values which have the same data type. sorting an array is useful in organising data in ordered\n",
      "Cleaned Token After =  computer science implement static lookup tables hold multiple values data type . sorting array useful organising data ordered \n",
      "Cleaned Token After Stem =  comput scienc implement static lookup tabl hold multipl valu data type . sort array use organis data order \n",
      "Cleaned Token Before =  a node is a basic unit of a data structure, such as a linked list or tree data structure. nodes contain data and also may link to other nodes. links between\n",
      "Cleaned Token After =  node basic unit data structure , linked list tree data structure . nodes contain data also may link nodes . links \n",
      "Cleaned Token After Stem =  node basic unit data structur , link list tree data structur . node contain data also may link node . link \n",
      "Cleaned Token Before =  for data entry a validation component to check user data a reporting tool for analysis of the collected data edc systems are used by life sciences organizations\n",
      "Cleaned Token After =  data entry validation component check user data reporting tool analysis collected data edc systems used life sciences organizations \n",
      "Cleaned Token After Stem =  data entri valid compon check user data report tool analysi collect data edc system use life scienc organ \n",
      "Cleaned Token Before =  while acquiring science and then slews to earth-pointing to downlink the data, although some instruments like marsis or radio science might be operated\n",
      "Cleaned Token After =  acquiring science slews earth-pointing downlink data , although instruments like marsis radio science might operated \n",
      "Cleaned Token After Stem =  acquir scienc slew earth-point downlink data , although instrument like marsi radio scienc might oper \n",
      "Cleaned Token Before =  business administration (honours) in management bachelor of science (honours) in data science and business intelligence on 30 october 2018, the chief executive-in-council\n",
      "Cleaned Token After =  business administration ( honours ) management bachelor science ( honours ) data science business intelligence 30 october 2018 , chief executive-in-council \n",
      "Cleaned Token After Stem =  busi administr ( honour ) manag bachelor scienc ( honour ) data scienc busi intellig 30 octob 2018 , chief executive-in-council \n",
      "Cleaned Token Before =  science but amateurs in dealing with criminals. it is relatively easy to cheat although difficult to know exactly how many scientists fabricate data.\n",
      "Cleaned Token After =  science amateurs dealing criminals . relatively easy cheat although difficult know exactly many scientists fabricate data . \n",
      "Cleaned Token After Stem =  scienc amateur deal crimin . rel easi cheat although difficult know exactli mani scientist fabric data . \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Token Before =  in computer science, dynamization is the process of transforming a static data structure into a dynamic one. although static data structures may provide\n",
      "Cleaned Token After =  computer science , dynamization process transforming static data structure dynamic one . although static data structures may provide \n",
      "Cleaned Token After Stem =  comput scienc , dynam process transform static data structur dynam one . although static data structur may provid \n",
      "Cleaned Token Before =  measurements in science are reported as decimal fractions, as opposed to fractions with any other system of denominators. a decimal data type could be implemented\n",
      "Cleaned Token After =  measurements science reported decimal fractions , opposed fractions system denominators . decimal data type could implemented \n",
      "Cleaned Token After Stem =  measur scienc report decim fraction , oppos fraction system denomin . decim data type could implement \n",
      "Cleaned Token Before =  5d optical data storage (sometimes known as superman memory crystal) is a nanostructured glass for permanently recording digital data using femtosecond\n",
      "Cleaned Token After =  5d optical data storage ( sometimes known superman memory crystal ) nanostructured glass permanently recording digital data using femtosecond \n",
      "Cleaned Token After Stem =  5d optic data storag ( sometim known superman memori crystal ) nanostructur glass perman record digit data use femtosecond \n",
      "Cleaned Token Before =  experiments on big transaction data for market segmentation.\" proceedings of the 2014 international conference on big data science and computing. acm, 2014\n",
      "Cleaned Token After =  experiments big transaction data market segmentation . '' proceedings 2014 international conference big data science computing . acm , 2014 \n",
      "Cleaned Token After Stem =  experi big transact data market segment . `` proceed 2014 intern confer big data scienc comput . acm , 2014 \n",
      "Cleaned Token Before =  is a brazilian american computer scientist and data scientist. he is a professor of computer science and engineering at the new york university tandon\n",
      "Cleaned Token After =  brazilian american computer scientist data scientist . professor computer science engineering new york university tandon \n",
      "Cleaned Token After Stem =  brazilian american comput scientist data scientist . professor comput scienc engin new york univers tandon \n",
      "Cleaned Token Before =  david f. carr a brief history of dataease the probert encyclopedia of science & technology entry for dataease the dataease relational database system a\n",
      "Cleaned Token After =  david f. carr brief history dataease probert encyclopedia science & technology entry dataease dataease relational database system \n",
      "Cleaned Token After Stem =  david f. carr brief histori dataeas probert encyclopedia scienc & technolog entri dataeas dataeas relat databas system \n",
      "Cleaned Token Before =  canadian-american statistician and a professor in the department of statistics & data science and the machine learning department at carnegie mellon university. wasserman\n",
      "Cleaned Token After =  canadian-american statistician professor department statistics & data science machine learning department carnegie mellon university . wasserman \n",
      "Cleaned Token After Stem =  canadian-american statistician professor depart statist & data scienc machin learn depart carnegi mellon univers . wasserman \n",
      "Cleaned Token Before =  at the university of chicago. his primary research interests are data science and data-intensive computing. grossman has worked in several fields. his\n",
      "Cleaned Token After =  university chicago . primary research interests data science data-intensive computing . grossman worked several fields . \n",
      "Cleaned Token After Stem =  univers chicago . primari research interest data scienc data-intens comput . grossman work sever field . \n",
      "Cleaned Token Before =  mallinckrodt baker science stuff table data obtained from crc handbook of chemistry and physics 44th ed. see also: m-xylene (data page) p-xylene (data page) aniline\n",
      "Cleaned Token After =  mallinckrodt baker science stuff table data obtained crc handbook chemistry physics 44th ed . see also : m-xylene ( data page ) p-xylene ( data page ) aniline \n",
      "Cleaned Token After Stem =  mallinckrodt baker scienc stuff tabl data obtain crc handbook chemistri physic 44th ed . see also : m-xylen ( data page ) p-xylen ( data page ) anilin \n",
      "Cleaned Token Before =  industrial data processing is a branch of applied computer science that covers the area of design and programming of computerized systems which are not\n",
      "Cleaned Token After =  industrial data processing branch applied computer science covers area design programming computerized systems \n",
      "Cleaned Token After Stem =  industri data process branch appli comput scienc cover area design program computer system \n",
      "Cleaned Token Before =  public data. this large and frequently updated data source has been described as a new type of scientific instrument for the social sciences. several\n",
      "Cleaned Token After =  public data . large frequently updated data source described new type scientific instrument social sciences . several \n",
      "Cleaned Token After Stem =  public data . larg frequent updat data sourc describ new type scientif instrument social scienc . sever \n",
      "Cleaned Token Before =  in functional programming, a generalized algebraic data type (gadt, also first-class phantom type, guarded recursive datatype, or equality-qualified type)\n",
      "Cleaned Token After =  functional programming , generalized algebraic data type ( gadt , also first-class phantom type , guarded recursive datatype , equality-qualified type ) \n",
      "Cleaned Token After Stem =  function program , gener algebra data type ( gadt , also first-class phantom type , guard recurs datatyp , equality-qualifi type ) \n",
      "Cleaned Token Before =  department of defense effort to create a portable programming language for data processing. it was originally seen as a stopgap, but the department of defense\n",
      "Cleaned Token After =  department defense effort create portable programming language data processing . originally seen stopgap , department defense \n",
      "Cleaned Token After Stem =  depart defens effort creat portabl program languag data process . origin seen stopgap , depart defens \n",
      "Cleaned Token Before =  november 27, 1955), popularly known as bill nye the science guy, is an american mechanical engineer, science communicator, and television presenter. he is best\n",
      "Cleaned Token After =  november 27 , 1955 ) , popularly known bill nye science guy , american mechanical engineer , science communicator , television presenter . best \n",
      "Cleaned Token After Stem =  novemb 27 , 1955 ) , popularli known bill nye scienc guy , american mechan engin , scienc commun , televis present . best \n",
      "Cleaned Token Before =  computer science (outline) humanistic informatics database (outline) distributed database object database relational database data management data mining\n",
      "Cleaned Token After =  computer science ( outline ) humanistic informatics database ( outline ) distributed database object database relational database data management data mining \n",
      "Cleaned Token After Stem =  comput scienc ( outlin ) humanist informat databas ( outlin ) distribut databas object databas relat databas data manag data mine \n",
      "Cleaned Token Before =  southern university of science and technology (sustech) simplified chinese: 南方科技大学; traditional chinese: 南方科技大學; pinyin: nánfāng kējì dàxué) is a public\n",
      "Cleaned Token After =  southern university science technology ( sustech ) simplified chinese : 南方科技大学 ; traditional chinese : 南方科技大學 ; pinyin : nánfāng kējì dàxué ) public \n",
      "Cleaned Token After Stem =  southern univers scienc technolog ( sustech ) simplifi chines : 南方科技大学 ; tradit chines : 南方科技大學 ; pinyin : nánfāng kējì dàxué ) public \n",
      "Cleaned Token Before =  worldwidescience alliance – the library has been a member of this global science search engine since june 2008. datacite – nrc's national science library\n",
      "Cleaned Token After =  worldwidescience alliance – library member global science search engine since june 2008. datacite – nrc 's national science library \n",
      "Cleaned Token After Stem =  worldwidesci allianc – librari member global scienc search engin sinc june 2008. datacit – nrc 's nation scienc librari \n",
      "Cleaned Token Before =  astronomy, physical sciences, materials science, space weather, meteorology, and human research including space medicine and the life sciences. scientists on\n",
      "Cleaned Token After =  astronomy , physical sciences , materials science , space weather , meteorology , human research including space medicine life sciences . scientists \n",
      "Cleaned Token After Stem =  astronomi , physic scienc , materi scienc , space weather , meteorolog , human research includ space medicin life scienc . scientist \n",
      "Cleaned Token Before =  or educators citizen science data repositories sky surveys cloud storage networks high-speed high-bandwidth for decades, science gateways existed in various\n",
      "Cleaned Token After =  educators citizen science data repositories sky surveys cloud storage networks high-speed high-bandwidth decades , science gateways existed various \n",
      "Cleaned Token After Stem =  educ citizen scienc data repositori sky survey cloud storag network high-spe high-bandwidth decad , scienc gateway exist variou \n",
      "Cleaned Token Before =  aiddata is a research and innovation lab located at the college of william & mary that seeks to make development finance more transparent, accountable\n",
      "Cleaned Token After =  aiddata research innovation lab located college william & mary seeks make development finance transparent , accountable \n",
      "Cleaned Token After Stem =  aiddata research innov lab locat colleg william & mari seek make develop financ transpar , account \n",
      "Cleaned Token Before =  computational biology, data science & analytics, environmental studies (environmental biology), food science & technology, life sciences, mathematics/applied\n",
      "Cleaned Token After =  computational biology , data science & analytics , environmental studies ( environmental biology ) , food science & technology , life sciences , mathematics/applied \n",
      "Cleaned Token After Stem =  comput biolog , data scienc & analyt , environment studi ( environment biolog ) , food scienc & technolog , life scienc , mathematics/appli \n",
      "Cleaned Token Before =  (tum-ias), the munich center for technology in society (mcts), the munich data science institute (mdsi), the munich school of engineering (mse), the munich\n",
      "Cleaned Token After =  ( tum-ias ) , munich center technology society ( mcts ) , munich data science institute ( mdsi ) , munich school engineering ( mse ) , munich \n",
      "Cleaned Token After Stem =  ( tum-ia ) , munich center technolog societi ( mct ) , munich data scienc institut ( mdsi ) , munich school engin ( mse ) , munich \n",
      "Cleaned Token Before =  results of regime-classification schemes from political science literature, including polity data series and the democracy-dictatorship index. democracy-dictatorship\n",
      "Cleaned Token After =  results regime-classification schemes political science literature , including polity data series democracy-dictatorship index . democracy-dictatorship \n",
      "Cleaned Token After Stem =  result regime-classif scheme polit scienc literatur , includ politi data seri democracy-dictatorship index . democracy-dictatorship \n",
      "Cleaned Token Before =  learning sciences. the field is closely tied to that of learning analytics, and the two have been compared and contrasted. educational data mining refers\n",
      "Cleaned Token After =  learning sciences . field closely tied learning analytics , two compared contrasted . educational data mining refers \n",
      "Cleaned Token After Stem =  learn scienc . field close tie learn analyt , two compar contrast . educ data mine refer \n",
      "Cleaned Token Before =  suspends vast advise data-sifting system\". christian science monitor. 2007-08-28. issn 0882-7729. retrieved 2020-08-10. us plans massive data sweep, february\n",
      "Cleaned Token After =  suspends vast advise data-sifting system '' . christian science monitor . 2007-08-28. issn 0882-7729. retrieved 2020-08-10. us plans massive data sweep , february \n",
      "Cleaned Token After Stem =  suspend vast advis data-sift system `` . christian scienc monitor . 2007-08-28. issn 0882-7729. retriev 2020-08-10. us plan massiv data sweep , februari \n",
      "Cleaned Token Before =  christiane floyd. naur disliked the term computer science and suggested it be called datalogy or data science. the former term has been adopted in denmark\n",
      "Cleaned Token After =  christiane floyd . naur disliked term computer science suggested called datalogy data science . former term adopted denmark \n",
      "Cleaned Token After Stem =  christian floyd . naur dislik term comput scienc suggest call datalog data scienc . former term adopt denmark \n",
      "Cleaned Token Before =  computer science, data stream clustering is defined as the clustering of data that arrive continuously such as telephone records, multimedia data, financial\n",
      "Cleaned Token After =  computer science , data stream clustering defined clustering data arrive continuously telephone records , multimedia data , financial \n",
      "Cleaned Token After Stem =  comput scienc , data stream cluster defin cluster data arriv continu telephon record , multimedia data , financi \n",
      "Cleaned Token Before =  astronomy, basic science, sustainable plants and 200 interactive and realistic exhibits. it is to have four learning suites: marker space, 'big data centre',\n",
      "Cleaned Token After =  astronomy , basic science , sustainable plants 200 interactive realistic exhibits . four learning suites : marker space , 'big data centre ' , \n",
      "Cleaned Token After Stem =  astronomi , basic scienc , sustain plant 200 interact realist exhibit . four learn suit : marker space , 'big data centr ' , \n",
      "Cleaned Token Before =  (1983). the use of computer-monitored data in information science. journal of the american society for information science, 44, 247−256 winscp.net, xml logging\n",
      "Cleaned Token After =  ( 1983 ) . use computer-monitored data information science . journal american society information science , 44 , 247−256 winscp.net , xml logging \n",
      "Cleaned Token After Stem =  ( 1983 ) . use computer-monitor data inform scienc . journal american societi inform scienc , 44 , 247−256 winscp.net , xml log \n",
      "Cleaned Token Before =  the polity data series is a widely used data series in political science research. the latest version, polity v, contains coded annual information on\n",
      "Cleaned Token After =  polity data series widely used data series political science research . latest version , polity v , contains coded annual information \n",
      "Cleaned Token After Stem =  politi data seri wide use data seri polit scienc research . latest version , politi v , contain code annual inform \n",
      "Cleaned Token Before =  \"elementary, dear data\" is the third episode of the second season of the american science fiction television series star trek: the next generation, the\n",
      "Cleaned Token After =  `` elementary , dear data '' third episode second season american science fiction television series star trek : next generation , \n",
      "Cleaned Token After Stem =  `` elementari , dear data `` third episod second season american scienc fiction televis seri star trek : next gener , \n",
      "Cleaned Token Before =  polyanalyst is a data science software platform developed by megaputer intelligence that provides an environment for text mining, data mining, machine\n",
      "Cleaned Token After =  polyanalyst data science software platform developed megaputer intelligence provides environment text mining , data mining , machine \n",
      "Cleaned Token After Stem =  polyanalyst data scienc softwar platform develop megaput intellig provid environ text mine , data mine , machin \n",
      "Cleaned Token Before =  \"further normalization of the data base relational model\". (presented at courant computer science symposia series 6, \"data base systems\", new york city\n",
      "Cleaned Token After =  `` normalization data base relational model '' . ( presented courant computer science symposia series 6 , `` data base systems '' , new york city \n",
      "Cleaned Token After Stem =  `` normal data base relat model `` . ( present courant comput scienc symposia seri 6 , `` data base system `` , new york citi \n",
      "Cleaned Token Before =  gather data on biodiversity for use in science. ebird is an example of crowdsourcing, and has been hailed as an example of democratizing science, treating\n",
      "Cleaned Token After =  gather data biodiversity use science . ebird example crowdsourcing , hailed example democratizing science , treating \n",
      "Cleaned Token After Stem =  gather data biodivers use scienc . ebird exampl crowdsourc , hail exampl democrat scienc , treat \n",
      "Cleaned Token Before =  innovation centre (nic) that houses programmes in design, humanities, and data sciences is located in kirulapone, colombo. the national institute of business\n",
      "Cleaned Token After =  innovation centre ( nic ) houses programmes design , humanities , data sciences located kirulapone , colombo . national institute business \n",
      "Cleaned Token After Stem =  innov centr ( nic ) hous programm design , human , data scienc locat kirulapon , colombo . nation institut busi \n",
      "Cleaned Token Before =  science. communications satellites transmit computer data, telephone calls, and radio and television broadcasts. weather satellites furnish the data necessary\n",
      "Cleaned Token After =  science . communications satellites transmit computer data , telephone calls , radio television broadcasts . weather satellites furnish data necessary \n",
      "Cleaned Token After Stem =  scienc . commun satellit transmit comput data , telephon call , radio televis broadcast . weather satellit furnish data necessari \n",
      "Cleaned Token Before =  cognitive science is the interdisciplinary, scientific study of the mind and its processes. it examines the nature, the tasks, and the functions of cognition\n",
      "Cleaned Token After =  cognitive science interdisciplinary , scientific study mind processes . examines nature , tasks , functions cognition \n",
      "Cleaned Token After Stem =  cognit scienc interdisciplinari , scientif studi mind process . examin natur , task , function cognit \n",
      "Cleaned Token Before =  research institution having research areas like advanced computation and data science, medicinal chemistry, natural products chemistry, synthetic organic chemistry\n",
      "Cleaned Token After =  research institution research areas like advanced computation data science , medicinal chemistry , natural products chemistry , synthetic organic chemistry \n",
      "Cleaned Token After Stem =  research institut research area like advanc comput data scienc , medicin chemistri , natur product chemistri , synthet organ chemistri \n",
      "Cleaned Token Before =  institute for big data analytics. the faculty of computer science offers several undergraduate programs including: bachelor of computer science (with/without\n",
      "Cleaned Token After =  institute big data analytics . faculty computer science offers several undergraduate programs including : bachelor computer science ( with/without \n",
      "Cleaned Token After Stem =  institut big data analyt . faculti comput scienc offer sever undergradu program includ : bachelor comput scienc ( with/without \n",
      "Cleaned Token Before =  lower isolation level increases the ability of many users to access the same data at the same time, but increases the number of concurrency effects (such as\n",
      "Cleaned Token After =  lower isolation level increases ability many users access data time , increases number concurrency effects ( \n",
      "Cleaned Token After Stem =  lower isol level increas abil mani user access data time , increas number concurr effect ( \n",
      "Cleaned Token Before =  education in ōtsu campus, the faculty of economics and the faculty of data science, the first for faculty in japan, in hikone campus. each faculty has a\n",
      "Cleaned Token After =  education ōtsu campus , faculty economics faculty data science , first faculty japan , hikone campus . faculty \n",
      "Cleaned Token After Stem =  educ ōtsu campu , faculti econom faculti data scienc , first faculti japan , hikon campu . faculti \n",
      "Cleaned Token Before =  activists can use evidence from data-driven science to support claims about social issues. a twofold classification of data activism has been proposed by\n",
      "Cleaned Token After =  activists use evidence data-driven science support claims social issues . twofold classification data activism proposed \n",
      "Cleaned Token After Stem =  activist use evid data-driven scienc support claim social issu . twofold classif data activ propos \n",
      "Cleaned Token Before =  the effect of these new locations over the transport demand. as data science and big data technologies become available to transport modelling, research\n",
      "Cleaned Token After =  effect new locations transport demand . data science big data technologies become available transport modelling , research \n",
      "Cleaned Token After Stem =  effect new locat transport demand . data scienc big data technolog becom avail transport model , research \n",
      "Cleaned Token Before =  department of science department of data science medical course (six-year) nursing course (four-year) international college of arts and sciences will be reorganized\n",
      "Cleaned Token After =  department science department data science medical course ( six-year ) nursing course ( four-year ) international college arts sciences reorganized \n",
      "Cleaned Token After Stem =  depart scienc depart data scienc medic cours ( six-year ) nurs cours ( four-year ) intern colleg art scienc reorgan \n",
      "Cleaned Token Before =  professor of bioengineering, genetics, medicine, and biomedical data science (and of computer science, by courtesy) and past chairman of the bioengineering department\n",
      "Cleaned Token After =  professor bioengineering , genetics , medicine , biomedical data science ( computer science , courtesy ) past chairman bioengineering department \n",
      "Cleaned Token After Stem =  professor bioengin , genet , medicin , biomed data scienc ( comput scienc , courtesi ) past chairman bioengin depart \n",
      "Cleaned Token Before =  a series of data points, possibly subject to constraints. curve fitting can involve either interpolation, where an exact fit to the data is required,\n",
      "Cleaned Token After =  series data points , possibly subject constraints . curve fitting involve either interpolation , exact fit data required , \n",
      "Cleaned Token After Stem =  seri data point , possibl subject constraint . curv fit involv either interpol , exact fit data requir , \n",
      "Cleaned Token Before =  artistic expression. information design is closely related to the field of data visualization and is often taught as part of graphic design courses. the\n",
      "Cleaned Token After =  artistic expression . information design closely related field data visualization often taught part graphic design courses . \n",
      "Cleaned Token After Stem =  artist express . inform design close relat field data visual often taught part graphic design cours . \n",
      "Cleaned Token Before =  in computer science, hash tree may refer to: hashed array tree hash tree (persistent data structure), an implementation strategy for sets and maps merkle\n",
      "Cleaned Token After =  computer science , hash tree may refer : hashed array tree hash tree ( persistent data structure ) , implementation strategy sets maps merkle \n",
      "Cleaned Token After Stem =  comput scienc , hash tree may refer : hash array tree hash tree ( persist data structur ) , implement strategi set map merkl \n",
      "Cleaned Token Before =  hierarchical data format (hdf) is a set of file formats (hdf4, hdf5) designed to store and organize large amounts of data. originally developed at the\n",
      "Cleaned Token After =  hierarchical data format ( hdf ) set file formats ( hdf4 , hdf5 ) designed store organize large amounts data . originally developed \n",
      "Cleaned Token After Stem =  hierarch data format ( hdf ) set file format ( hdf4 , hdf5 ) design store organ larg amount data . origin develop \n",
      "Cleaned Token Before =  the expression junk science is used to describe scientific data, research, or analysis considered by the person using the phrase to be spurious or fraudulent\n",
      "Cleaned Token After =  expression junk science used describe scientific data , research , analysis considered person using phrase spurious fraudulent \n",
      "Cleaned Token After Stem =  express junk scienc use describ scientif data , research , analysi consid person use phrase spuriou fraudul \n",
      "Cleaned Token Before =  and william j. catacosinos. lowin simultaneously founded solid state data sciences (ssds). ssds was one of the first developers of the mos/lsi integrated\n",
      "Cleaned Token After =  william j. catacosinos . lowin simultaneously founded solid state data sciences ( ssds ) . ssds one first developers mos/lsi integrated \n",
      "Cleaned Token After Stem =  william j. catacosino . lowin simultan found solid state data scienc ( ssd ) . ssd one first develop mos/lsi integr \n",
      "Cleaned Token Before =  computer science, where it operated until 2011 before moving to harvard. the university of north carolina at charlotte is also running a data privacy lab\n",
      "Cleaned Token After =  computer science , operated 2011 moving harvard . university north carolina charlotte also running data privacy lab \n",
      "Cleaned Token After Stem =  comput scienc , oper 2011 move harvard . univers north carolina charlott also run data privaci lab \n",
      "Cleaned Token Before =  professor of data science with the department of statistics at the london school of economics, where he is also director of the msc data science programme\n",
      "Cleaned Token After =  professor data science department statistics london school economics , also director msc data science programme \n",
      "Cleaned Token After Stem =  professor data scienc depart statist london school econom , also director msc data scienc programm \n",
      "Cleaned Token Before =  social sciences, marketing, and official statistics. the methods involved in survey data collection are any of a number of ways in which data can be collected\n",
      "Cleaned Token After =  social sciences , marketing , official statistics . methods involved survey data collection number ways data collected \n",
      "Cleaned Token After Stem =  social scienc , market , offici statist . method involv survey data collect number way data collect \n",
      "Cleaned Token Before =  a graph model, data is structured as nodes (vertices in math and network science) and relationships (edges in math and network science) to focus on how\n",
      "Cleaned Token After =  graph model , data structured nodes ( vertices math network science ) relationships ( edges math network science ) focus \n",
      "Cleaned Token After Stem =  graph model , data structur node ( vertic math network scienc ) relationship ( edg math network scienc ) focu \n",
      "Cleaned Token Before =  of science degrees in chemical engineering, civil engineering, computer science, electrical engineering, environmental engineering, data science, computer\n",
      "Cleaned Token After =  science degrees chemical engineering , civil engineering , computer science , electrical engineering , environmental engineering , data science , computer \n",
      "Cleaned Token After Stem =  scienc degre chemic engin , civil engin , comput scienc , electr engin , environment engin , data scienc , comput \n",
      "Cleaned Token Before =  food science is the basic science and applied science of food; its scope starts at overlap with agricultural science and nutritional science and leads\n",
      "Cleaned Token After =  food science basic science applied science food ; scope starts overlap agricultural science nutritional science leads \n",
      "Cleaned Token After Stem =  food scienc basic scienc appli scienc food ; scope start overlap agricultur scienc nutrit scienc lead \n",
      "Cleaned Token Before =  applies data science to social genome data to answer fundamental questions about human society and population health much like bioinformatics applies data science\n",
      "Cleaned Token After =  applies data science social genome data answer fundamental questions human society population health much like bioinformatics applies data science \n",
      "Cleaned Token After Stem =  appli data scienc social genom data answer fundament question human societi popul health much like bioinformat appli data scienc \n",
      "Cleaned Token Before =  \"ca18209 - european network for web-centred linguistic data science\". cost. european cooperation in science and technology. retrieved 10 december 2019. for a\n",
      "Cleaned Token After =  `` ca18209 - european network web-centred linguistic data science '' . cost . european cooperation science technology . retrieved 10 december 2019. \n",
      "Cleaned Token After Stem =  `` ca18209 - european network web-centr linguist data scienc `` . cost . european cooper scienc technolog . retriev 10 decemb 2019 . \n",
      "Cleaned Token Before =  in partnership with amazon web services, bs computer science with specialization in data science specialization track, bs information technology with\n",
      "Cleaned Token After =  partnership amazon web services , bs computer science specialization data science specialization track , bs information technology \n",
      "Cleaned Token After Stem =  partnership amazon web servic , bs comput scienc special data scienc special track , bs inform technolog \n",
      "Cleaned Token Before =  and disease research. the organization practices open science, in that they make all their data and resources publicly available for researchers to access\n",
      "Cleaned Token After =  disease research . organization practices open science , make data resources publicly available researchers access \n",
      "Cleaned Token After Stem =  diseas research . organ practic open scienc , make data resourc publicli avail research access \n",
      "Cleaned Token Before =  currently completing his data science master's degree from the university of denver and is a student ambassador for the data science master's program. mashinchi\n",
      "Cleaned Token After =  currently completing data science master 's degree university denver student ambassador data science master 's program . mashinchi \n",
      "Cleaned Token After Stem =  current complet data scienc master 's degre univers denver student ambassador data scienc master 's program . mashinchi \n",
      "Cleaned Token Before =  iterative proportional fitting for a method of data enhancement applied in statistics, economics and computer science bogdan, r. c. & biklen, s. k. (2006). qualitative\n",
      "Cleaned Token After =  iterative proportional fitting method data enhancement applied statistics , economics computer science bogdan , r. c. & biklen , s. k. ( 2006 ) . qualitative \n",
      "Cleaned Token After Stem =  iter proport fit method data enhanc appli statist , econom comput scienc bogdan , r. c. & biklen , s. k. ( 2006 ) . qualit \n",
      "Cleaned Token Before =  particularly in helping to analyse data and in spotting patterns too broad for a human to intuitively perceive. while information science is sometimes confused with\n",
      "Cleaned Token After =  particularly helping analyse data spotting patterns broad human intuitively perceive . information science sometimes confused \n",
      "Cleaned Token After Stem =  particularli help analys data spot pattern broad human intuit perceiv . inform scienc sometim confus \n",
      "Cleaned Token Before =  institute for data science and professor at university of rochester. he is interested in knowledge representation, artificial intelligence, data science and pervasive\n",
      "Cleaned Token After =  institute data science professor university rochester . interested knowledge representation , artificial intelligence , data science pervasive \n",
      "Cleaned Token After Stem =  institut data scienc professor univers rochest . interest knowledg represent , artifici intellig , data scienc pervas \n",
      "Cleaned Token Before =  efficient data collection, management, and data mining. the dddas concept - and the term - was proposed by frederica darema for the national science foundation\n",
      "Cleaned Token After =  efficient data collection , management , data mining . dddas concept - term - proposed frederica darema national science foundation \n",
      "Cleaned Token After Stem =  effici data collect , manag , data mine . ddda concept - term - propos frederica darema nation scienc foundat \n",
      "Cleaned Token Before =  in software technology master in social work/msw m.sc. in big data analytics (data science) master of computer application. aravind adiga, winner of the\n",
      "Cleaned Token After =  software technology master social work/msw m.sc . big data analytics ( data science ) master computer application . aravind adiga , winner \n",
      "Cleaned Token After Stem =  softwar technolog master social work/msw m.sc . big data analyt ( data scienc ) master comput applic . aravind adiga , winner \n",
      "Cleaned Token Before =  arrangement of data in rows and columns, or possibly in a more complex structure. tables are widely used in communication, research, and data analysis. tables\n",
      "Cleaned Token After =  arrangement data rows columns , possibly complex structure . tables widely used communication , research , data analysis . tables \n",
      "Cleaned Token After Stem =  arrang data row column , possibl complex structur . tabl wide use commun , research , data analysi . tabl \n",
      "Cleaned Token Before =  and information technology 9 computer science and engineering(iot) 10computer science and engineering (data science) the ips academy m.e. and m.tech. programs\n",
      "Cleaned Token After =  information technology 9 computer science engineering ( iot ) 10computer science engineering ( data science ) ips academy m.e . m.tech . programs \n",
      "Cleaned Token After Stem =  inform technolog 9 comput scienc engin ( iot ) 10comput scienc engin ( data scienc ) ip academi m.e . m.tech . program \n",
      "Cleaned Token Before =  brandeis marshall is an american data scientist and full professor of computer science at spelman college, where she is the former chair of the department\n",
      "Cleaned Token After =  brandeis marshall american data scientist full professor computer science spelman college , former chair department \n",
      "Cleaned Token After Stem =  brandei marshal american data scientist full professor comput scienc spelman colleg , former chair depart \n",
      "Cleaned Token Before =  on innovative data systems research (cidr) is a biennial computer science conference focused on research into new techniques for data management. it\n",
      "Cleaned Token After =  innovative data systems research ( cidr ) biennial computer science conference focused research new techniques data management . \n",
      "Cleaned Token After Stem =  innov data system research ( cidr ) biennial comput scienc confer focus research new techniqu data manag . \n",
      "Cleaned Token Before =  chair of the computer science department as well as a tenured professor of computer science and director of the master of data science program at illinois\n",
      "Cleaned Token After =  chair computer science department well tenured professor computer science director master data science program illinois \n",
      "Cleaned Token After Stem =  chair comput scienc depart well tenur professor comput scienc director master data scienc program illinoi \n",
      "Cleaned Token Before =  clearing-house of data and information regarding nutrition. in 1949, it was authorized to conduct research in the applied science of food, as well. the\n",
      "Cleaned Token After =  clearing-house data information regarding nutrition . 1949 , authorized conduct research applied science food , well . \n",
      "Cleaned Token After Stem =  clearing-hous data inform regard nutrit . 1949 , author conduct research appli scienc food , well . \n",
      "Cleaned Token Before =  in computational gastronomy, an emerging data science of food, flavors and health. by blending food with data and computation he has helped establish the\n",
      "Cleaned Token After =  computational gastronomy , emerging data science food , flavors health . blending food data computation helped establish \n",
      "Cleaned Token After Stem =  comput gastronomi , emerg data scienc food , flavor health . blend food data comput help establish \n",
      "Cleaned Token Before =  torben pedersen and mukesh mohania. \"data warehousing and knowledge discovery.\" heidelberg, germany: springer science and business media, 2009. isbn 978-3642037290\n",
      "Cleaned Token After =  torben pedersen mukesh mohania . `` data warehousing knowledge discovery . '' heidelberg , germany : springer science business media , 2009. isbn 978-3642037290 \n",
      "Cleaned Token After Stem =  torben pedersen mukesh mohania . `` data wareh knowledg discoveri . `` heidelberg , germani : springer scienc busi media , 2009. isbn 978-3642037290 \n",
      "Cleaned Token Before =  science foundation ireland (sfi) is the statutory body in the republic of ireland with responsibility for funding oriented basic and applied research\n",
      "Cleaned Token After =  science foundation ireland ( sfi ) statutory body republic ireland responsibility funding oriented basic applied research \n",
      "Cleaned Token After Stem =  scienc foundat ireland ( sfi ) statutori bodi republ ireland respons fund orient basic appli research \n",
      "Cleaned Token Before =  2020-09-02. \"function reference\". dplyr.tidyverse.org. retrieved 2021-02-06. grolemund, garrett; wickham, hadley. 5 data transformation | r for data science.\n",
      "Cleaned Token After =  2020-09-02 . `` function reference '' . dplyr.tidyverse.org . retrieved 2021-02-06. grolemund , garrett ; wickham , hadley . 5 data transformation | r data science . \n",
      "Cleaned Token After Stem =  2020-09-02 . `` function refer `` . dplyr.tidyverse.org . retriev 2021-02-06. grolemund , garrett ; wickham , hadley . 5 data transform | r data scienc . \n",
      "Cleaned Token Before =  control data corporation (cdc) was a mainframe and supercomputer firm. cdc was one of the nine major united states computer companies through most of the\n",
      "Cleaned Token After =  control data corporation ( cdc ) mainframe supercomputer firm . cdc one nine major united states computer companies \n",
      "Cleaned Token After Stem =  control data corpor ( cdc ) mainfram supercomput firm . cdc one nine major unit state comput compani \n",
      "Cleaned Token Before =  and visualization, image and video analysis, and visual analytics in data science. hanspeter pfister received his master's degree in 1991 in electrical\n",
      "Cleaned Token After =  visualization , image video analysis , visual analytics data science . hanspeter pfister received master 's degree 1991 electrical \n",
      "Cleaned Token After Stem =  visual , imag video analysi , visual analyt data scienc . hanspet pfister receiv master 's degre 1991 electr \n",
      "Cleaned Token Before =  \"interview: data science in der automobilbranche\". data science blog. 27 march 2017. retrieved 26 may 2017. \"artificial intelligence and data science in the\n",
      "Cleaned Token After =  `` interview : data science der automobilbranche '' . data science blog . 27 march 2017. retrieved 26 may 2017 . `` artificial intelligence data science \n",
      "Cleaned Token After Stem =  `` interview : data scienc der automobilbranch `` . data scienc blog . 27 march 2017. retriev 26 may 2017 . `` artifici intellig data scienc \n",
      "Cleaned Token Before =  facebook–cambridge analytica data scandal and also as a public relations response to that problem. in 2018, social science one described the data as being about a\n",
      "Cleaned Token After =  facebook–cambridge analytica data scandal also public relations response problem . 2018 , social science one described data \n",
      "Cleaned Token After Stem =  facebook–cambridg analytica data scandal also public relat respons problem . 2018 , social scienc one describ data \n",
      "Cleaned Token Before =  on computational ecology and ecological data science ecological data nsf datanet call for proposals dataone data conservancy [1], ecoinformatics summer\n",
      "Cleaned Token After =  computational ecology ecological data science ecological data nsf datanet call proposals dataone data conservancy [ 1 ] , ecoinformatics summer \n",
      "Cleaned Token After Stem =  comput ecolog ecolog data scienc ecolog data nsf datanet call propos dataon data conserv [ 1 ] , ecoinformat summer \n",
      "Cleaned Token Before =  and data science community\". www.kaggle.com. retrieved 2020-05-04. import.io. \"web data integration: revolutionizing the way you work with web data\". www\n",
      "Cleaned Token After =  data science community '' . www.kaggle.com . retrieved 2020-05-04. import.io . `` web data integration : revolutionizing way work web data '' . www \n",
      "Cleaned Token After Stem =  data scienc commun `` . www.kaggle.com . retriev 2020-05-04. import.io . `` web data integr : revolution way work web data `` . www \n",
      "Cleaned Token Before =  in computer science, a succinct data structure is a data structure which uses an amount of space that is \"close\" to the information-theoretic lower bound\n",
      "Cleaned Token After =  computer science , succinct data structure data structure uses amount space `` close '' information-theoretic lower bound \n",
      "Cleaned Token After Stem =  comput scienc , succinct data structur data structur use amount space `` close `` information-theoret lower bound \n",
      "Cleaned Token Before =  in mathematical optimization and computer science, heuristic (from greek εὑρίσκω \"i find, discover\") is a technique designed for solving a problem more\n",
      "Cleaned Token After =  mathematical optimization computer science , heuristic ( greek εὑρίσκω `` find , discover '' ) technique designed solving problem \n",
      "Cleaned Token After Stem =  mathemat optim comput scienc , heurist ( greek εὑρίσκω `` find , discov `` ) techniqu design solv problem \n",
      "Cleaned Token Before =  environmental sciences aiming at data, information and knowledge integration, the application of computational intelligence to environmental data as well as\n",
      "Cleaned Token After =  environmental sciences aiming data , information knowledge integration , application computational intelligence environmental data well \n",
      "Cleaned Token After Stem =  environment scienc aim data , inform knowledg integr , applic comput intellig environment data well \n",
      "Cleaned Token Before =  m.sc. computer science m.sc. data science and business analytics m.phil. in computer science ph.d. in computer science b.sc. mathematics m.phil. in mathematics\n",
      "Cleaned Token After =  m.sc . computer science m.sc . data science business analytics m.phil . computer science ph.d. computer science b.sc . mathematics m.phil . mathematics \n",
      "Cleaned Token After Stem =  m.sc . comput scienc m.sc . data scienc busi analyt m.phil . comput scienc ph.d. comput scienc b.sc . mathemat m.phil . mathemat \n",
      "Cleaned Token Before =  statistical procedures which can be used for the analysis of categorical data, also known as data on the nominal scale and as categorical variables. bowker's test\n",
      "Cleaned Token After =  statistical procedures used analysis categorical data , also known data nominal scale categorical variables . bowker 's test \n",
      "Cleaned Token After Stem =  statist procedur use analysi categor data , also known data nomin scale categor variabl . bowker 's test \n",
      "Cleaned Token Before =  econometrics; economics and management) law data science and machine learning for social sciences and humanities; data science; machine learning lyon 2 is part of\n",
      "Cleaned Token After =  econometrics ; economics management ) law data science machine learning social sciences humanities ; data science ; machine learning lyon 2 part \n",
      "Cleaned Token After Stem =  econometr ; econom manag ) law data scienc machin learn social scienc human ; data scienc ; machin learn lyon 2 part \n",
      "Cleaned Token Before =  computer science and trustworthy systems. unsw was a founding member of national ict australia (nicta), which merged with csiro in 2015 to form data61. cse\n",
      "Cleaned Token After =  computer science trustworthy systems . unsw founding member national ict australia ( nicta ) , merged csiro 2015 form data61 . cse \n",
      "Cleaned Token After Stem =  comput scienc trustworthi system . unsw found member nation ict australia ( nicta ) , merg csiro 2015 form data61 . cse \n",
      "Cleaned Token Before =  liverpool opened as a center for computer aided materials science, where robotic formulation, data capture and modeling are being integrated into development\n",
      "Cleaned Token After =  liverpool opened center computer aided materials science , robotic formulation , data capture modeling integrated development \n",
      "Cleaned Token After Stem =  liverpool open center comput aid materi scienc , robot formul , data captur model integr develop \n",
      "Cleaned Token Before =  pair discuss data analytics, covering statistical computation, data cleaning, and r packages. the show is among the more popular data science and statistics\n",
      "Cleaned Token After =  pair discuss data analytics , covering statistical computation , data cleaning , r packages . show among popular data science statistics \n",
      "Cleaned Token After Stem =  pair discuss data analyt , cover statist comput , data clean , r packag . show among popular data scienc statist \n",
      "Cleaned Token Before =  nrrd (\"nearly raw raster data\") is a library and file format for the representation and processing of n-dimensional raster data. it is intended to support\n",
      "Cleaned Token After =  nrrd ( `` nearly raw raster data '' ) library file format representation processing n-dimensional raster data . intended support \n",
      "Cleaned Token After Stem =  nrrd ( `` nearli raw raster data `` ) librari file format represent process n-dimension raster data . intend support \n",
      "Cleaned Token Before =  qualifications through the humanities and social sciences (hss) department and the computational and data sciences (cds) department. it also has a field station\n",
      "Cleaned Token After =  qualifications humanities social sciences ( hss ) department computational data sciences ( cds ) department . also field station \n",
      "Cleaned Token After Stem =  qualif human social scienc ( hss ) depart comput data scienc ( cd ) depart . also field station \n",
      "Cleaned Token Before =  archival science, or archival studies, is the study and theory of building and curating archives, which are collections of documents, recordings and data storage\n",
      "Cleaned Token After =  archival science , archival studies , study theory building curating archives , collections documents , recordings data storage \n",
      "Cleaned Token After Stem =  archiv scienc , archiv studi , studi theori build curat archiv , collect document , record data storag \n",
      "Cleaned Token Before =  uses historical precinct voting data, public opinion polls, campaign finance information and similar statistical data. the term was coined in 1948 in\n",
      "Cleaned Token After =  uses historical precinct voting data , public opinion polls , campaign finance information similar statistical data . term coined 1948 \n",
      "Cleaned Token After Stem =  use histor precinct vote data , public opinion poll , campaign financ inform similar statist data . term coin 1948 \n",
      "Cleaned Token Before =  cosmological context. research groups: astronomical data, compact objects, cosmology x data science, dynamics, galaxy formation, gravitational wave astronomy\n",
      "Cleaned Token After =  cosmological context . research groups : astronomical data , compact objects , cosmology x data science , dynamics , galaxy formation , gravitational wave astronomy \n",
      "Cleaned Token After Stem =  cosmolog context . research group : astronom data , compact object , cosmolog x data scienc , dynam , galaxi format , gravit wave astronomi \n",
      "Cleaned Token Before =  this page provides supplementary chemical data on acetaldehyde. the handling of this chemical may require safety precautions. the directions on the material\n",
      "Cleaned Token After =  page provides supplementary chemical data acetaldehyde . handling chemical may require safety precautions . directions material \n",
      "Cleaned Token After Stem =  page provid supplementari chemic data acetaldehyd . handl chemic may requir safeti precaut . direct materi \n",
      "Cleaned Token Before =  editor says he believes retracted hauser paper contains fabricated data\". science insider. archived from the original on august 29, 2010. retrieved august\n",
      "Cleaned Token After =  editor says believes retracted hauser paper contains fabricated data '' . science insider . archived original august 29 , 2010. retrieved august \n",
      "Cleaned Token After Stem =  editor say believ retract hauser paper contain fabric data `` . scienc insid . archiv origin august 29 , 2010. retriev august \n",
      "Cleaned Token Before =  on data. such algorithms function by making data-driven predictions or decisions, through building a mathematical model from input data. the data used\n",
      "Cleaned Token After =  data . algorithms function making data-driven predictions decisions , building mathematical model input data . data used \n",
      "Cleaned Token After Stem =  data . algorithm function make data-driven predict decis , build mathemat model input data . data use \n",
      "Cleaned Token Before =  and distribute data from nasa's past and current satellites and field measurement programs. nsidc also supports the national science foundation through\n",
      "Cleaned Token After =  distribute data nasa 's past current satellites field measurement programs . nsidc also supports national science foundation \n",
      "Cleaned Token After Stem =  distribut data nasa 's past current satellit field measur program . nsidc also support nation scienc foundat \n",
      "Cleaned Token Before =  biology is the natural science that studies life and living organisms, including their physical structure, chemical processes, molecular interactions\n",
      "Cleaned Token After =  biology natural science studies life living organisms , including physical structure , chemical processes , molecular interactions \n",
      "Cleaned Token After Stem =  biolog natur scienc studi life live organ , includ physic structur , chemic process , molecular interact \n",
      "Cleaned Token Before =  forums\". audio science review. retrieved 9 january 2021. \"master review index\". audio science review. retrieved 18 august 2020. \"the speaker data revolution\"\n",
      "Cleaned Token After =  forums '' . audio science review . retrieved 9 january 2021 . `` master review index '' . audio science review . retrieved 18 august 2020 . `` speaker data revolution '' \n",
      "Cleaned Token After Stem =  forum `` . audio scienc review . retriev 9 januari 2021 . `` master review index `` . audio scienc review . retriev 18 august 2020 . `` speaker data revolut `` \n",
      "Cleaned Token Before =  studies which have pooled data on religion and science from 1981–2001, have noted that countries with greater faith in science also often have stronger\n",
      "Cleaned Token After =  studies pooled data religion science 1981–2001 , noted countries greater faith science also often stronger \n",
      "Cleaned Token After Stem =  studi pool data religion scienc 1981–2001 , note countri greater faith scienc also often stronger \n",
      "Cleaned Token Before =  and genetics aquatic food production - safety and quality aquaculture data science development and natural resource economics ecology feed manufacturing\n",
      "Cleaned Token After =  genetics aquatic food production - safety quality aquaculture data science development natural resource economics ecology feed manufacturing \n",
      "Cleaned Token After Stem =  genet aquat food product - safeti qualiti aquacultur data scienc develop natur resourc econom ecolog feed manufactur \n",
      "Cleaned Token Before =  harnessing the data revolution, one of nsf’s 10 big ideas. she helped to create new programs to support data science foundations as well as data-intensive\n",
      "Cleaned Token After =  harnessing data revolution , one nsf ’ 10 big ideas . helped create new programs support data science foundations well data-intensive \n",
      "Cleaned Token After Stem =  har data revolut , one nsf ’ 10 big idea . help creat new program support data scienc foundat well data-intens \n",
      "Cleaned Token Before =  application of recursion in computer science is in defining dynamic data structures such as lists and trees. recursive data structures can dynamically grow\n",
      "Cleaned Token After =  application recursion computer science defining dynamic data structures lists trees . recursive data structures dynamically grow \n",
      "Cleaned Token After Stem =  applic recurs comput scienc defin dynam data structur list tree . recurs data structur dynam grow \n",
      "Cleaned Token Before =  data usa is a free platform that allows users to collect, analyze, and visualize shared u.s. government data. launched on april 4, 2016, data usa is the\n",
      "Cleaned Token After =  data usa free platform allows users collect , analyze , visualize shared u.s. government data . launched april 4 , 2016 , data usa \n",
      "Cleaned Token After Stem =  data usa free platform allow user collect , analyz , visual share u.s. govern data . launch april 4 , 2016 , data usa \n",
      "Cleaned Token Before =  quantitative biomedical sciences at geisel school of medicine of dartmouth college from 2010 until 2015. he's the editor-in-chief of the biodata mining journal\n",
      "Cleaned Token After =  quantitative biomedical sciences geisel school medicine dartmouth college 2010 2015. 's editor-in-chief biodata mining journal \n",
      "Cleaned Token After Stem =  quantit biomed scienc geisel school medicin dartmouth colleg 2010 2015 . 's editor-in-chief biodata mine journal \n",
      "Cleaned Token Before =  enterprise data science institute as an ai/ml faculty researcher. this is to promote research, education, services, operations and outreach in data science and\n",
      "Cleaned Token After =  enterprise data science institute ai/ml faculty researcher . promote research , education , services , operations outreach data science \n",
      "Cleaned Token After Stem =  enterpris data scienc institut ai/ml faculti research . promot research , educ , servic , oper outreach data scienc \n",
      "Cleaned Token Before =  data integrity questions\". science. retrieved 5 june 2020. hopkins, jared s.; gold, russell (4 june 2020). \"hydroxychloroquine studies tied to data firm\n",
      "Cleaned Token After =  data integrity questions '' . science . retrieved 5 june 2020. hopkins , jared s. ; gold , russell ( 4 june 2020 ) . `` hydroxychloroquine studies tied data firm \n",
      "Cleaned Token After Stem =  data integr question `` . scienc . retriev 5 june 2020. hopkin , jare s. ; gold , russel ( 4 june 2020 ) . `` hydroxychloroquin studi tie data firm \n",
      "Cleaned Token Before =  testable on the basis of observed data modelled as the realised values taken by a collection of random variables. a set of data is modelled as being realised\n",
      "Cleaned Token After =  testable basis observed data modelled realised values taken collection random variables . set data modelled realised \n",
      "Cleaned Token After Stem =  testabl basi observ data model realis valu taken collect random variabl . set data model realis \n",
      "Cleaned Token Before =  in computer science, an offset within an array or other data structure object is an integer indicating the distance (displacement) between the beginning\n",
      "Cleaned Token After =  computer science , offset within array data structure object integer indicating distance ( displacement ) beginning \n",
      "Cleaned Token After Stem =  comput scienc , offset within array data structur object integ indic distanc ( displac ) begin \n",
      "Cleaned Token Before =  graph hosted by the wikimedia foundation. it is a common source of open data that wikimedia projects such as wikipedia, and anyone else, can use under\n",
      "Cleaned Token After =  graph hosted wikimedia foundation . common source open data wikimedia projects wikipedia , anyone else , use \n",
      "Cleaned Token After Stem =  graph host wikimedia foundat . common sourc open data wikimedia project wikipedia , anyon els , use \n",
      "Cleaned Token Before =  the behavioral science unit (bsu) is the original name of a unit within the federal bureau of investigation's (fbi) training division at quantico, virginia\n",
      "Cleaned Token After =  behavioral science unit ( bsu ) original name unit within federal bureau investigation 's ( fbi ) training division quantico , virginia \n",
      "Cleaned Token After Stem =  behavior scienc unit ( bsu ) origin name unit within feder bureau investig 's ( fbi ) train divis quantico , virginia \n",
      "Cleaned Token Before =  method of grouping data that is transmitted over a digital network into packets. packets are made of a header and a payload. data in the header is used\n",
      "Cleaned Token After =  method grouping data transmitted digital network packets . packets made header payload . data header used \n",
      "Cleaned Token After Stem =  method group data transmit digit network packet . packet made header payload . data header use \n",
      "Cleaned Token Before =  and computer science, mutual recursion is a form of recursion where two mathematical or computational objects, such as functions or data types, are defined\n",
      "Cleaned Token After =  computer science , mutual recursion form recursion two mathematical computational objects , functions data types , defined \n",
      "Cleaned Token After Stem =  comput scienc , mutual recurs form recurs two mathemat comput object , function data type , defin \n",
      "Cleaned Token Before =  the direct edge market data distribution platform. on 23 jan 2012, data explorers announced a partnership with narrative science to create a securities\n",
      "Cleaned Token After =  direct edge market data distribution platform . 23 jan 2012 , data explorers announced partnership narrative science create securities \n",
      "Cleaned Token After Stem =  direct edg market data distribut platform . 23 jan 2012 , data explor announc partnership narr scienc creat secur \n",
      "Cleaned Token Before =  today, resulting in true data ownership as well as improved privacy. in october 2016, he joined the department of computer science at oxford university as\n",
      "Cleaned Token After =  today , resulting true data ownership well improved privacy . october 2016 , joined department computer science oxford university \n",
      "Cleaned Token After Stem =  today , result true data ownership well improv privaci . octob 2016 , join depart comput scienc oxford univers \n",
      "Cleaned Token Before =  \"macroinstruction\", from greek combining form μακρο- 'long, large') in computer science is a rule or pattern that specifies how a certain input should be mapped\n",
      "Cleaned Token After =  `` macroinstruction '' , greek combining form μακρο- 'long , large ' ) computer science rule pattern specifies certain input mapped \n",
      "Cleaned Token After Stem =  `` macroinstruct `` , greek combin form μακρο- 'long , larg ' ) comput scienc rule pattern specifi certain input map \n",
      "Cleaned Token Before =  example, data produced during human subject research might be de-identified to preserve the privacy of research participants. biological data may be de-identified\n",
      "Cleaned Token After =  example , data produced human subject research might de-identified preserve privacy research participants . biological data may de-identified \n",
      "Cleaned Token After Stem =  exampl , data produc human subject research might de-identifi preserv privaci research particip . biolog data may de-identifi \n",
      "Cleaned Token Before =  the university of texas health science center at houston (uthealth) is a public academic health science center in houston, texas. it was created in 1972\n",
      "Cleaned Token After =  university texas health science center houston ( uthealth ) public academic health science center houston , texas . created 1972 \n",
      "Cleaned Token After Stem =  univers texa health scienc center houston ( uthealth ) public academ health scienc center houston , texa . creat 1972 \n",
      "Cleaned Token Before =  of the semantic web is to make internet data machine-readable. to enable the encoding of semantics with the data, technologies such as resource description\n",
      "Cleaned Token After =  semantic web make internet data machine-readable . enable encoding semantics data , technologies resource description \n",
      "Cleaned Token After Stem =  semant web make internet data machine-read . enabl encod semant data , technolog resourc descript \n",
      "Cleaned Token Before =  mount data is a mountain located in the cordillera central mountain range rising to a height of 2,310 metres (7,580 ft) in the north of luzon island, philippines\n",
      "Cleaned Token After =  mount data mountain located cordillera central mountain range rising height 2,310 metres ( 7,580 ft ) north luzon island , philippines \n",
      "Cleaned Token After Stem =  mount data mountain locat cordillera central mountain rang rise height 2,310 metr ( 7,580 ft ) north luzon island , philippin \n",
      "Cleaned Token Before =  and relayed data packets to earth from a variety of mars landers, rovers and orbiters for as long as ten years, at an extremely high data rate. such a\n",
      "Cleaned Token After =  relayed data packets earth variety mars landers , rovers orbiters long ten years , extremely high data rate . \n",
      "Cleaned Token After Stem =  relay data packet earth varieti mar lander , rover orbit long ten year , extrem high data rate . \n",
      "Cleaned Token Before =  not-for-profit organisation that produces news, views and analysis about science and technology in the context of global development. it primarily engages\n",
      "Cleaned Token After =  not-for-profit organisation produces news , views analysis science technology context global development . primarily engages \n",
      "Cleaned Token After Stem =  not-for-profit organis produc news , view analysi scienc technolog context global develop . primarili engag \n",
      "Cleaned Token Before =  says\". retrieved august 10, 2012. \"mars science laboratory, communications with earth\". jpl. \"curiosity's data communication with earth\". nasa. retrieved\n",
      "Cleaned Token After =  says '' . retrieved august 10 , 2012 . `` mars science laboratory , communications earth '' . jpl . `` curiosity 's data communication earth '' . nasa . retrieved \n",
      "Cleaned Token After Stem =  say `` . retriev august 10 , 2012 . `` mar scienc laboratori , commun earth `` . jpl . `` curios 's data commun earth `` . nasa . retriev \n",
      "Cleaned Token Before =  in computer science, canonicalization (sometimes standardization or normalization) is a process for converting data that has more than one possible representation\n",
      "Cleaned Token After =  computer science , canonicalization ( sometimes standardization normalization ) process converting data one possible representation \n",
      "Cleaned Token After Stem =  comput scienc , canonic ( sometim standard normal ) process convert data one possibl represent \n",
      "Cleaned Token Before =  clinicaltrials.gov science.gov government 2.0 open government initiative data.gov.uk data.gov.in ckan usafacts open data in the united states \"about data.gov\". retrieved\n",
      "Cleaned Token After =  clinicaltrials.gov science.gov government 2.0 open government initiative data.gov.uk data.gov.in ckan usafacts open data united states `` data.gov '' . retrieved \n",
      "Cleaned Token After Stem =  clinicaltrials.gov science.gov govern 2.0 open govern initi data.gov.uk data.gov.in ckan usafact open data unit state `` data.gov `` . retriev \n",
      "Cleaned Token Before =  galit shmueli is a data scientist who works in taiwan as tsing hua distinguished professor at the institute of service science, national tsing hua university\n",
      "Cleaned Token After =  galit shmueli data scientist works taiwan tsing hua distinguished professor institute service science , national tsing hua university \n",
      "Cleaned Token After Stem =  galit shmueli data scientist work taiwan tsing hua distinguish professor institut servic scienc , nation tsing hua univers \n",
      "Cleaned Token Before =  presentations, software, and data development. metascience evidence-based policy evidence-based practices the science of science policy: a federal research\n",
      "Cleaned Token After =  presentations , software , data development . metascience evidence-based policy evidence-based practices science science policy : federal research \n",
      "Cleaned Token After Stem =  present , softwar , data develop . metasci evidence-bas polici evidence-bas practic scienc scienc polici : feder research \n",
      "Cleaned Token Before =  and data science to impact all aspects of life and society, elmagarmid has been promoting the transformation of higher education towards more ai/data science\n",
      "Cleaned Token After =  data science impact aspects life society , elmagarmid promoting transformation higher education towards ai/data science \n",
      "Cleaned Token After Stem =  data scienc impact aspect life societi , elmagarmid promot transform higher educ toward ai/data scienc \n",
      "Cleaned Token Before =  electronic data processing (edp) can refer to the use of automated methods to process commercial data. typically, this uses relatively simple, repetitive\n",
      "Cleaned Token After =  electronic data processing ( edp ) refer use automated methods process commercial data . typically , uses relatively simple , repetitive \n",
      "Cleaned Token After Stem =  electron data process ( edp ) refer use autom method process commerci data . typic , use rel simpl , repetit \n",
      "Cleaned Token Before =  chemical data on sodium sulfate. the handling of this chemical may incur notable safety precautions. it is highly recommend that you seek the safety data sheet\n",
      "Cleaned Token After =  chemical data sodium sulfate . handling chemical may incur notable safety precautions . highly recommend seek safety data sheet \n",
      "Cleaned Token After Stem =  chemic data sodium sulfat . handl chemic may incur notabl safeti precaut . highli recommend seek safeti data sheet \n",
      "Cleaned Token Before =  and follow its directions. siri science stuff (dihydrate) science stuff (.1 m solution) except where noted otherwise, data relate to standard ambient temperature\n",
      "Cleaned Token After =  follow directions . siri science stuff ( dihydrate ) science stuff ( .1 solution ) except noted otherwise , data relate standard ambient temperature \n",
      "Cleaned Token After Stem =  follow direct . siri scienc stuff ( dihydr ) scienc stuff ( .1 solut ) except note otherwis , data relat standard ambient temperatur \n",
      "Cleaned Token Before =  new branches btech in csbs(computer science and business system) and btech in artificial intelligence and data science. for the undergraduate course, the\n",
      "Cleaned Token After =  new branches btech csbs ( computer science business system ) btech artificial intelligence data science . undergraduate course , \n",
      "Cleaned Token After Stem =  new branch btech csb ( comput scienc busi system ) btech artifici intellig data scienc . undergradu cours , \n",
      "Cleaned Token Before =  constructing new data points within the range of a discrete set of known data points. in engineering and science, one often has a number of data points, obtained\n",
      "Cleaned Token After =  constructing new data points within range discrete set known data points . engineering science , one often number data points , obtained \n",
      "Cleaned Token After Stem =  construct new data point within rang discret set known data point . engin scienc , one often number data point , obtain \n",
      "Cleaned Token Before =  specialization in data science computer science informatics and innovation (business analysis and it governance) computer science mathematics physics\n",
      "Cleaned Token After =  specialization data science computer science informatics innovation ( business analysis governance ) computer science mathematics physics \n",
      "Cleaned Token After Stem =  special data scienc comput scienc informat innov ( busi analysi govern ) comput scienc mathemat physic \n",
      "Cleaned Token Before =  a data embassy is a solution traditionally implemented by nation states to ensure a country’s digital continuity with particular respect to critical databases\n",
      "Cleaned Token After =  data embassy solution traditionally implemented nation states ensure country ’ digital continuity particular respect critical databases \n",
      "Cleaned Token After Stem =  data embassi solut tradit implement nation state ensur countri ’ digit continu particular respect critic databas \n",
      "Cleaned Token Before =  (acm). he has been elected to the endowed professorship nokia chair in data science. \"phd family tree of jon's\". retrieved 2 dec 2020. cs1 maint: discouraged\n",
      "Cleaned Token After =  ( acm ) . elected endowed professorship nokia chair data science . `` phd family tree jon 's '' . retrieved 2 dec 2020. cs1 maint : discouraged \n",
      "Cleaned Token After Stem =  ( acm ) . elect endow professorship nokia chair data scienc . `` phd famili tree jon 's `` . retriev 2 dec 2020. cs1 maint : discourag \n",
      "Cleaned Token Before =  the national science board (nsb) of the united states establishes the policies of the national science foundation (nsf) within the framework of applicable\n",
      "Cleaned Token After =  national science board ( nsb ) united states establishes policies national science foundation ( nsf ) within framework applicable \n",
      "Cleaned Token After Stem =  nation scienc board ( nsb ) unit state establish polici nation scienc foundat ( nsf ) within framework applic \n",
      "Cleaned Token Before =  profile berlin school of economics and law int. j. of big data management int. j. of data science personal blog. faculty profile - at berlin school of economics\n",
      "Cleaned Token After =  profile berlin school economics law int . j. big data management int . j. data science personal blog . faculty profile - berlin school economics \n",
      "Cleaned Token After Stem =  profil berlin school econom law int . j. big data manag int . j. data scienc person blog . faculti profil - berlin school econom \n",
      "Cleaned Token Before =  last question\" is a science fiction short story by american writer isaac asimov. it first appeared in the november 1956 issue of science fiction quarterly\n",
      "Cleaned Token After =  last question '' science fiction short story american writer isaac asimov . first appeared november 1956 issue science fiction quarterly \n",
      "Cleaned Token After Stem =  last question `` scienc fiction short stori american writer isaac asimov . first appear novemb 1956 issu scienc fiction quarterli \n",
      "Cleaned Token Before =  mathematics, statistical mechanics from physics, data mining and information visualization from computer science, inferential modeling from statistics, and\n",
      "Cleaned Token After =  mathematics , statistical mechanics physics , data mining information visualization computer science , inferential modeling statistics , \n",
      "Cleaned Token After Stem =  mathemat , statist mechan physic , data mine inform visual comput scienc , inferenti model statist , \n",
      "Cleaned Token Before =  human science (or human sciences in the plural) studies the philosophical, biological, social, and cultural aspects of human life. human science aims to\n",
      "Cleaned Token After =  human science ( human sciences plural ) studies philosophical , biological , social , cultural aspects human life . human science aims \n",
      "Cleaned Token After Stem =  human scienc ( human scienc plural ) studi philosoph , biolog , social , cultur aspect human life . human scienc aim \n",
      "Cleaned Token Before =  internet public data transmission service national research and education network x.25 § history council, national research; sciences, division on engineering\n",
      "Cleaned Token After =  internet public data transmission service national research education network x.25 § history council , national research ; sciences , division engineering \n",
      "Cleaned Token After Stem =  internet public data transmiss servic nation research educ network x.25 § histori council , nation research ; scienc , divis engin \n",
      "Cleaned Token Before =  conducted in 1984 by the bbc popular science programme tomorrow's world. in the outcome of the experiment, one set of data yielded positive results and another\n",
      "Cleaned Token After =  conducted 1984 bbc popular science programme tomorrow 's world . outcome experiment , one set data yielded positive results another \n",
      "Cleaned Token After Stem =  conduct 1984 bbc popular scienc programm tomorrow 's world . outcom experi , one set data yield posit result anoth \n",
      "Cleaned Token Before =  high-performance computing, data science and big data. some database systems are designed to run mostly in memory, rarely if ever retrieving data from disk or flash\n",
      "Cleaned Token After =  high-performance computing , data science big data . database systems designed run mostly memory , rarely ever retrieving data disk flash \n",
      "Cleaned Token After Stem =  high-perform comput , data scienc big data . databas system design run mostli memori , rare ever retriev data disk flash \n",
      "Cleaned Token Before =  the centre for cognitive and brain sciences, the centre for artificial intelligence, the centre for data science and the centre for innovation and entrepreneurship\n",
      "Cleaned Token After =  centre cognitive brain sciences , centre artificial intelligence , centre data science centre innovation entrepreneurship \n",
      "Cleaned Token After Stem =  centr cognit brain scienc , centr artifici intellig , centr data scienc centr innov entrepreneurship \n",
      "Cleaned Token Before =  science and technology. archived from the original (queriable database) on 5 may 2006. retrieved 9 june 2007. \"binary vapor-liquid equilibrium data\"\n",
      "Cleaned Token After =  science technology . archived original ( queriable database ) 5 may 2006. retrieved 9 june 2007 . `` binary vapor-liquid equilibrium data '' \n",
      "Cleaned Token After Stem =  scienc technolog . archiv origin ( queriabl databas ) 5 may 2006. retriev 9 june 2007 . `` binari vapor-liquid equilibrium data `` \n",
      "Cleaned Token Before =  madison in 1999 for a thesis in data mining. from 1999 to 2015, gehrke was a professor in the department of computer science at cornell university. his research\n",
      "Cleaned Token After =  madison 1999 thesis data mining . 1999 2015 , gehrke professor department computer science cornell university . research \n",
      "Cleaned Token After Stem =  madison 1999 thesi data mine . 1999 2015 , gehrk professor depart comput scienc cornel univers . research \n",
      "Cleaned Token Before =  multifunction hand-held device performs sensor environment scans, data recording, and data analysis--hence the word \"tricorder\" to refer to the three functions\n",
      "Cleaned Token After =  multifunction hand-held device performs sensor environment scans , data recording , data analysis -- hence word `` tricorder '' refer three functions \n",
      "Cleaned Token After Stem =  multifunct hand-held devic perform sensor environ scan , data record , data analysi -- henc word `` tricord `` refer three function \n",
      "Cleaned Token Before =  computer graphics is a sub-field of computer science which studies methods for digitally synthesizing and manipulating visual content. although the term\n",
      "Cleaned Token After =  computer graphics sub-field computer science studies methods digitally synthesizing manipulating visual content . although term \n",
      "Cleaned Token After Stem =  comput graphic sub-field comput scienc studi method digit synthes manipul visual content . although term \n",
      "Cleaned Token Before =  technology. it is one of nasa's astrophysics data centers, along with the high energy astrophysics science archive research center (heasarc), the mikulski\n",
      "Cleaned Token After =  technology . one nasa 's astrophysics data centers , along high energy astrophysics science archive research center ( heasarc ) , mikulski \n",
      "Cleaned Token After Stem =  technolog . one nasa 's astrophys data center , along high energi astrophys scienc archiv research center ( heasarc ) , mikulski \n",
      "Cleaned Token Before =  \"data's day\" is the 85th episode of the american science fiction television series star trek: the next generation, the 11th episode of the fourth season\n",
      "Cleaned Token After =  `` data 's day '' 85th episode american science fiction television series star trek : next generation , 11th episode fourth season \n",
      "Cleaned Token After Stem =  `` data 's day `` 85th episod american scienc fiction televis seri star trek : next gener , 11th episod fourth season \n",
      "Cleaned Token Before =  pitfalls and potentials inherent in the archaeological data and research process. ai science is an emerging discipline that attempts to uncover, quantitatively\n",
      "Cleaned Token After =  pitfalls potentials inherent archaeological data research process . ai science emerging discipline attempts uncover , quantitatively \n",
      "Cleaned Token After Stem =  pitfal potenti inher archaeolog data research process . ai scienc emerg disciplin attempt uncov , quantit \n",
      "Cleaned Token Before =  life and health sciences; area studies; energy and engineering; physics; chemistry; history; anthropology; informatics and data science; mathematics; materials\n",
      "Cleaned Token After =  life health sciences ; area studies ; energy engineering ; physics ; chemistry ; history ; anthropology ; informatics data science ; mathematics ; materials \n",
      "Cleaned Token After Stem =  life health scienc ; area studi ; energi engin ; physic ; chemistri ; histori ; anthropolog ; informat data scienc ; mathemat ; materi \n",
      "Cleaned Token Before =  international management (head: prof. horst treiblmaier) department of applied data science (interim management: prof. karl wöber) research institute for new media\n",
      "Cleaned Token After =  international management ( head : prof. horst treiblmaier ) department applied data science ( interim management : prof. karl wöber ) research institute new media \n",
      "Cleaned Token After Stem =  intern manag ( head : prof. horst treiblmaier ) depart appli data scienc ( interim manag : prof. karl wöber ) research institut new media \n",
      "Cleaned Token Before =  19th century with the positivist philosophy of science. since the mid-20th century, the term \"social science\" has come to refer more generally, not just\n",
      "Cleaned Token After =  19th century positivist philosophy science . since mid-20th century , term `` social science '' come refer generally , \n",
      "Cleaned Token After Stem =  19th centuri positivist philosophi scienc . sinc mid-20th centuri , term `` social scienc `` come refer gener , \n",
      "Cleaned Token Before =  data center services encompass all of the services and facility-related components or activities that support the implementation, maintenance, operation\n",
      "Cleaned Token After =  data center services encompass services facility-related components activities support implementation , maintenance , operation \n",
      "Cleaned Token After Stem =  data center servic encompass servic facility-rel compon activ support implement , mainten , oper \n",
      "Cleaned Token Before =  is the central data distribution hub where selected data products are provided to remote science operations sites as needed. jpl is also the central hub\n",
      "Cleaned Token After =  central data distribution hub selected data products provided remote science operations sites needed . jpl also central hub \n",
      "Cleaned Token After Stem =  central data distribut hub select data product provid remot scienc oper site need . jpl also central hub \n",
      "Cleaned Token Before =  anonymous data. first introduced in 2013, unicity is measured by the number of points p needed to uniquely identify an individual in a data set. the fewer\n",
      "Cleaned Token After =  anonymous data . first introduced 2013 , unicity measured number points p needed uniquely identify individual data set . fewer \n",
      "Cleaned Token After Stem =  anonym data . first introduc 2013 , unic measur number point p need uniqu identifi individu data set . fewer \n",
      "Cleaned Token Before =  kavli institute for theoretical sciences research center on fictitious economy and data science cas key laboratory of big data mining and knowledge management\n",
      "Cleaned Token After =  kavli institute theoretical sciences research center fictitious economy data science cas key laboratory big data mining knowledge management \n",
      "Cleaned Token After Stem =  kavli institut theoret scienc research center fictiti economi data scienc ca key laboratori big data mine knowledg manag \n",
      "Cleaned Token Before =  in computer science, concurrency is the ability of different parts or units of a program, algorithm, or problem to be executed out-of-order or at the\n",
      "Cleaned Token After =  computer science , concurrency ability different parts units program , algorithm , problem executed out-of-order \n",
      "Cleaned Token After Stem =  comput scienc , concurr abil differ part unit program , algorithm , problem execut out-of-ord \n",
      "Cleaned Token Before =  academic field that is a cross-disciplinary science using informatics to study the information flows and data management related to irrigation. the field\n",
      "Cleaned Token After =  academic field cross-disciplinary science using informatics study information flows data management related irrigation . field \n",
      "Cleaned Token After Stem =  academ field cross-disciplinari scienc use informat studi inform flow data manag relat irrig . field \n",
      "Cleaned Token Before =  engineering, mathematics, linguistics, and computer science—for the purpose of designing efficient and reliable data transmission methods. this typically involves\n",
      "Cleaned Token After =  engineering , mathematics , linguistics , computer science—for purpose designing efficient reliable data transmission methods . typically involves \n",
      "Cleaned Token After Stem =  engin , mathemat , linguist , comput science—for purpos design effici reliabl data transmiss method . typic involv \n",
      "Cleaned Token Before =  (control) \"cmsc 411 lecture 19, pipelining data forwarding\". university of maryland baltimore county computer science and electrical engineering department\n",
      "Cleaned Token After =  ( control ) `` cmsc 411 lecture 19 , pipelining data forwarding '' . university maryland baltimore county computer science electrical engineering department \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Token After Stem =  ( control ) `` cmsc 411 lectur 19 , pipelin data forward `` . univers maryland baltimor counti comput scienc electr engin depart \n",
      "Cleaned Token Before =  and full professor at rwth aachen university, leading the process and data science (pads) group. his research and teaching interests include information\n",
      "Cleaned Token After =  full professor rwth aachen university , leading process data science ( pads ) group . research teaching interests include information \n",
      "Cleaned Token After Stem =  full professor rwth aachen univers , lead process data scienc ( pad ) group . research teach interest includ inform \n",
      "Cleaned Token Before =  names with the actual locations of the data. while a variable's name, type, and location often remain fixed, the data stored in the location may be changed\n",
      "Cleaned Token After =  names actual locations data . variable 's name , type , location often remain fixed , data stored location may changed \n",
      "Cleaned Token After Stem =  name actual locat data . variabl 's name , type , locat often remain fix , data store locat may chang \n",
      "Cleaned Token Before =  princeton university. fan is interested in statistical theory and methods in data science, finance, economics, risk management, machine learning, computational\n",
      "Cleaned Token After =  princeton university . fan interested statistical theory methods data science , finance , economics , risk management , machine learning , computational \n",
      "Cleaned Token After Stem =  princeton univers . fan interest statist theori method data scienc , financ , econom , risk manag , machin learn , comput \n",
      "Cleaned Token Before =  also refer to: classification of customers, for marketing (as in master data management) or for profitability (e.g. by activity-based costing) classified\n",
      "Cleaned Token After =  also refer : classification customers , marketing ( master data management ) profitability ( e.g . activity-based costing ) classified \n",
      "Cleaned Token After Stem =  also refer : classif custom , market ( master data manag ) profit ( e.g . activity-bas cost ) classifi \n",
      "Cleaned Token Before =  topics in mathematical sciences. in addition to warren weaver hall, the computer science department and center for data science are located at 60 fifth\n",
      "Cleaned Token After =  topics mathematical sciences . addition warren weaver hall , computer science department center data science located 60 fifth \n",
      "Cleaned Token After Stem =  topic mathemat scienc . addit warren weaver hall , comput scienc depart center data scienc locat 60 fifth \n",
      "Cleaned Token Before =  mathematics, science, and reading. it was first performed in 2000 and then repeated every three years. its aim is to provide comparable data with a view\n",
      "Cleaned Token After =  mathematics , science , reading . first performed 2000 repeated every three years . aim provide comparable data view \n",
      "Cleaned Token After Stem =  mathemat , scienc , read . first perform 2000 repeat everi three year . aim provid compar data view \n",
      "Cleaned Token Before =  california, berkeley associate provost for the division of computing, data science, and society and dean of the school of information. she was formerly\n",
      "Cleaned Token After =  california , berkeley associate provost division computing , data science , society dean school information . formerly \n",
      "Cleaned Token After Stem =  california , berkeley associ provost divis comput , data scienc , societi dean school inform . formerli \n",
      "Cleaned Token Before =  bbc science focus (previously bbc focus) is a british monthly magazine about science and technology published in bristol, uk by immediate media company\n",
      "Cleaned Token After =  bbc science focus ( previously bbc focus ) british monthly magazine science technology published bristol , uk immediate media company \n",
      "Cleaned Token After Stem =  bbc scienc focu ( previous bbc focu ) british monthli magazin scienc technolog publish bristol , uk immedi media compani \n",
      "Cleaned Token Before =  university (anu) and csiro’s data61, and a distinguished professor of the anu college of engineering and computer science. she holds the university's inaugural\n",
      "Cleaned Token After =  university ( anu ) csiro ’ data61 , distinguished professor anu college engineering computer science . holds university 's inaugural \n",
      "Cleaned Token After Stem =  univers ( anu ) csiro ’ data61 , distinguish professor anu colleg engin comput scienc . hold univers 's inaugur \n",
      "Cleaned Token Before =  in computer science, a mergeable heap (also called a meldable heap) is an abstract data type, which is a heap supporting a merge operation. a mergeable\n",
      "Cleaned Token After =  computer science , mergeable heap ( also called meldable heap ) abstract data type , heap supporting merge operation . mergeable \n",
      "Cleaned Token After Stem =  comput scienc , mergeabl heap ( also call meldabl heap ) abstract data type , heap support merg oper . mergeabl \n",
      "Cleaned Token Before =  suppressed data. american academy of arts and sciences national digital library program (ndlp) list of members of the national academy of sciences national\n",
      "Cleaned Token After =  suppressed data . american academy arts sciences national digital library program ( ndlp ) list members national academy sciences national \n",
      "Cleaned Token After Stem =  suppress data . american academi art scienc nation digit librari program ( ndlp ) list member nation academi scienc nation \n",
      "Cleaned Token Before =  environmental sciences division (esd) and a contributor to the climate change science institute (ccsi). mercury supports data archiving, data discovery through\n",
      "Cleaned Token After =  environmental sciences division ( esd ) contributor climate change science institute ( ccsi ) . mercury supports data archiving , data discovery \n",
      "Cleaned Token After Stem =  environment scienc divis ( esd ) contributor climat chang scienc institut ( ccsi ) . mercuri support data archiv , data discoveri \n",
      "Cleaned Token Before =  the american association for the advancement of science (aaas) is an american international non-profit organization with the stated goals of promoting\n",
      "Cleaned Token After =  american association advancement science ( aaas ) american international non-profit organization stated goals promoting \n",
      "Cleaned Token After Stem =  american associ advanc scienc ( aaa ) american intern non-profit organ state goal promot \n",
      "Cleaned Token Before =  this page provides supplementary data to the article properties of water. further comprehensive authoritative data can be found at the nist webbook page\n",
      "Cleaned Token After =  page provides supplementary data article properties water . comprehensive authoritative data found nist webbook page \n",
      "Cleaned Token After Stem =  page provid supplementari data articl properti water . comprehens authorit data found nist webbook page \n",
      "Cleaned Token Before =  materials science in science fiction is the study of how materials science is portrayed in works of science fiction. the accuracy of the materials science portrayed\n",
      "Cleaned Token After =  materials science science fiction study materials science portrayed works science fiction . accuracy materials science portrayed \n",
      "Cleaned Token After Stem =  materi scienc scienc fiction studi materi scienc portray work scienc fiction . accuraci materi scienc portray \n",
      "Cleaned Token Before =  march 2020. strategic planning division strategic data and foresight technology division malaysian science and technology information centre (mastic) sti\n",
      "Cleaned Token After =  march 2020. strategic planning division strategic data foresight technology division malaysian science technology information centre ( mastic ) sti \n",
      "Cleaned Token After Stem =  march 2020. strateg plan divis strateg data foresight technolog divis malaysian scienc technolog inform centr ( mastic ) sti \n",
      "Cleaned Token Before =  outline is provided as an overview of and topical guide to formal science: formal science – branches of knowledge that are concerned with formal systems\n",
      "Cleaned Token After =  outline provided overview topical guide formal science : formal science – branches knowledge concerned formal systems \n",
      "Cleaned Token After Stem =  outlin provid overview topic guid formal scienc : formal scienc – branch knowledg concern formal system \n",
      "Cleaned Token Before =  happy science (幸福の科学, kōfuku-no-kagaku), formerly known as the institute for research in human happiness, is a controversial new religious and spiritual\n",
      "Cleaned Token After =  happy science ( 幸福の科学 , kōfuku-no-kagaku ) , formerly known institute research human happiness , controversial new religious spiritual \n",
      "Cleaned Token After Stem =  happi scienc ( 幸福の科学 , kōfuku-no-kagaku ) , formerli known institut research human happi , controversi new religi spiritu \n",
      "Cleaned Token Before =  santanu bhattacharya is the chief data scientist at airtel, a visiting professor at indian institute of science. and a collaborating scientist at the\n",
      "Cleaned Token After =  santanu bhattacharya chief data scientist airtel , visiting professor indian institute science . collaborating scientist \n",
      "Cleaned Token After Stem =  santanu bhattacharya chief data scientist airtel , visit professor indian institut scienc . collabor scientist \n",
      "Cleaned Token Before =  bill nye the science guy is an american half-hour live action science program produced by kcts seattle and mckenna/gottlieb producers. it was substantially\n",
      "Cleaned Token After =  bill nye science guy american half-hour live action science program produced kcts seattle mckenna/gottlieb producers . substantially \n",
      "Cleaned Token After Stem =  bill nye scienc guy american half-hour live action scienc program produc kct seattl mckenna/gottlieb produc . substanti \n",
      "Cleaned Token Before =  communications/ 12th ieee international conference on big data science and engineering (trust com/bigdatase). ieee. pp. 1064–1069. doi:10.1109/trustcom/bigdatase\n",
      "Cleaned Token After =  communications/ 12th ieee international conference big data science engineering ( trust com/bigdatase ) . ieee . pp . 1064–1069 . doi:10.1109/trustcom/bigdatase \n",
      "Cleaned Token After Stem =  communications/ 12th ieee intern confer big data scienc engin ( trust com/bigdatas ) . ieee . pp . 1064–1069 . doi:10.1109/trustcom/bigdatas \n",
      "Cleaned Token Before =  in computer science, a double-ended queue (abbreviated to deque, pronounced deck, like \"cheque\") is an abstract data type that generalizes a queue, for\n",
      "Cleaned Token After =  computer science , double-ended queue ( abbreviated deque , pronounced deck , like `` cheque '' ) abstract data type generalizes queue , \n",
      "Cleaned Token After Stem =  comput scienc , double-end queue ( abbrevi dequ , pronounc deck , like `` chequ `` ) abstract data type gener queue , \n",
      "Cleaned Token Before =  locality. abundances of the elements (data page) atmospheric chemistry clarke number — lists of historical data and terminology list of chemical elements\n",
      "Cleaned Token After =  locality . abundances elements ( data page ) atmospheric chemistry clarke number — lists historical data terminology list chemical elements \n",
      "Cleaned Token After Stem =  local . abund element ( data page ) atmospher chemistri clark number — list histor data terminolog list chemic element \n",
      "Cleaned Token Before =  saitou n, sugawara h, et al. (2002). \"dna data bank of japan (ddbj) for genome scale research in life science\". nucleic acids res. 30 (1): 27–30. doi:10\n",
      "Cleaned Token After =  saitou n , sugawara h , et al . ( 2002 ) . `` dna data bank japan ( ddbj ) genome scale research life science '' . nucleic acids res . 30 ( 1 ) : 27–30 . doi:10 \n",
      "Cleaned Token After Stem =  saitou n , sugawara h , et al . ( 2002 ) . `` dna data bank japan ( ddbj ) genom scale research life scienc `` . nucleic acid re . 30 ( 1 ) : 27–30 . doi:10 \n",
      "Cleaned Token Before =  more specialized degrees, see below. topics (or specializations ) in data science and machine learning are becoming common. the msf-m.fin distinction is\n",
      "Cleaned Token After =  specialized degrees , see . topics ( specializations ) data science machine learning becoming common . msf-m.fin distinction \n",
      "Cleaned Token After Stem =  special degre , see . topic ( special ) data scienc machin learn becom common . msf-m.fin distinct \n",
      "Cleaned Token Before =  data mining, the process of discovering patterns in large data sets, has been used in many applications. since the early 1960s, with the availability of\n",
      "Cleaned Token After =  data mining , process discovering patterns large data sets , used many applications . since early 1960s , availability \n",
      "Cleaned Token After Stem =  data mine , process discov pattern larg data set , use mani applic . sinc earli 1960 , avail \n",
      "Cleaned Token Before =  the model has been instantiated. in practice, this instance usually has a data structure in common with other instances, but the values stored in the instances\n",
      "Cleaned Token After =  model instantiated . practice , instance usually data structure common instances , values stored instances \n",
      "Cleaned Token After Stem =  model instanti . practic , instanc usual data structur common instanc , valu store instanc \n",
      "Cleaned Token Before =  science, statistics and programming, including: the art of r programming the art of debugging with gdb, ddd and eclipse parallel computing for data science:\n",
      "Cleaned Token After =  science , statistics programming , including : art r programming art debugging gdb , ddd eclipse parallel computing data science : \n",
      "Cleaned Token After Stem =  scienc , statist program , includ : art r program art debug gdb , ddd eclips parallel comput data scienc : \n",
      "Cleaned Token Before =  a data science corporate laboratory in makati, metro manila, philippines. situated within the asian institute of management, it is the first data science\n",
      "Cleaned Token After =  data science corporate laboratory makati , metro manila , philippines . situated within asian institute management , first data science \n",
      "Cleaned Token After Stem =  data scienc corpor laboratori makati , metro manila , philippin . situat within asian institut manag , first data scienc \n",
      "Cleaned Token Before =  data politics encompasses the political aspects of data including topics ranging from data activism, open data and open government. the ways in which data\n",
      "Cleaned Token After =  data politics encompasses political aspects data including topics ranging data activism , open data open government . ways data \n",
      "Cleaned Token After Stem =  data polit encompass polit aspect data includ topic rang data activ , open data open govern . way data \n",
      "Cleaned Token Before =  on data science (tds), ieee internet computing, and the transactions on data privacy. she is an associate editor of springer journal in data science and\n",
      "Cleaned Token After =  data science ( tds ) , ieee internet computing , transactions data privacy . associate editor springer journal data science \n",
      "Cleaned Token After Stem =  data scienc ( td ) , ieee internet comput , transact data privaci . associ editor springer journal data scienc \n",
      "Cleaned Token Before =  information science and technology. 36 (1): 3–72. citeseerx 10.1.1.210.6040. doi:10.1002/aris.1440360102. meho, lokman i.; yang, kiduk (2007). \"impact of data sources\n",
      "Cleaned Token After =  information science technology . 36 ( 1 ) : 3–72 . citeseerx 10.1.1.210.6040. doi:10.1002/aris.1440360102 . meho , lokman i. ; yang , kiduk ( 2007 ) . `` impact data sources \n",
      "Cleaned Token After Stem =  inform scienc technolog . 36 ( 1 ) : 3–72 . citeseerx 10.1.1.210.6040. doi:10.1002/aris.1440360102 . meho , lokman i. ; yang , kiduk ( 2007 ) . `` impact data sourc \n",
      "Cleaned Token Before =  al. data grid tools: enabling science on big distributed data venugopal, srikumar; buyya, rajkumar; ramamohanarao, kotagiri. a taxonomy of data grids\n",
      "Cleaned Token After =  al . data grid tools : enabling science big distributed data venugopal , srikumar ; buyya , rajkumar ; ramamohanarao , kotagiri . taxonomy data grids \n",
      "Cleaned Token After Stem =  al . data grid tool : enabl scienc big distribut data venugop , srikumar ; buyya , rajkumar ; ramamohanarao , kotagiri . taxonomi data grid \n",
      "Cleaned Token Before =  needed], data transfer, and data structures. a programmer/software engineer may have a choice of several algorithms, encodings, data types or data structures\n",
      "Cleaned Token After =  needed ] , data transfer , data structures . programmer/software engineer may choice several algorithms , encodings , data types data structures \n",
      "Cleaned Token After Stem =  need ] , data transfer , data structur . programmer/softwar engin may choic sever algorithm , encod , data type data structur \n",
      "Cleaned Token Before =  foundations of computer science. pp. 135–144. doi:10.1109/sfcs.2002.1181890. isbn 0-7695-1822-2. wirth, niklaus (1986), algorithms & data structures, upper\n",
      "Cleaned Token After =  foundations computer science . pp . 135–144 . doi:10.1109/sfcs.2002.1181890 . isbn 0-7695-1822-2. wirth , niklaus ( 1986 ) , algorithms & data structures , upper \n",
      "Cleaned Token After Stem =  foundat comput scienc . pp . 135–144 . doi:10.1109/sfcs.2002.1181890 . isbn 0-7695-1822-2. wirth , niklau ( 1986 ) , algorithm & data structur , upper \n",
      "Cleaned Token Before =  in computer science, tree traversal (also known as tree search and walking the tree) is a form of graph traversal and refers to the process of visiting\n",
      "Cleaned Token After =  computer science , tree traversal ( also known tree search walking tree ) form graph traversal refers process visiting \n",
      "Cleaned Token After Stem =  comput scienc , tree travers ( also known tree search walk tree ) form graph travers refer process visit \n",
      "Cleaned Token Before =  coverage of science in the media: a big data study on the impact of the fukushima disaster\". 2014 ieee international conference on big data (big data). pp. 60–66\n",
      "Cleaned Token After =  coverage science media : big data study impact fukushima disaster '' . 2014 ieee international conference big data ( big data ) . pp . 60–66 \n",
      "Cleaned Token After Stem =  coverag scienc media : big data studi impact fukushima disast `` . 2014 ieee intern confer big data ( big data ) . pp . 60–66 \n",
      "Cleaned Token Before =  special computer file, named /dev/null on unix systems, that discards all data written to it null modem, a specially wired serial communications cable null\n",
      "Cleaned Token After =  special computer file , named /dev/null unix systems , discards data written null modem , specially wired serial communications cable null \n",
      "Cleaned Token After Stem =  special comput file , name /dev/nul unix system , discard data written null modem , special wire serial commun cabl null \n",
      "Cleaned Token Before =  tech in data science and artificial intelligence in iiit naya raipur\". the hans india. \"iiit naya raipur launches b.tech program in data science ai\". united\n",
      "Cleaned Token After =  tech data science artificial intelligence iiit naya raipur '' . hans india . `` iiit naya raipur launches b.tech program data science ai '' . united \n",
      "Cleaned Token After Stem =  tech data scienc artifici intellig iiit naya raipur `` . han india . `` iiit naya raipur launch b.tech program data scienc ai `` . unit \n",
      "Cleaned Token Before =  april 2017: establishment of data science center april 2018: department of science and technology, graduate school of science and technology established\n",
      "Cleaned Token After =  april 2017 : establishment data science center april 2018 : department science technology , graduate school science technology established \n",
      "Cleaned Token After Stem =  april 2017 : establish data scienc center april 2018 : depart scienc technolog , graduat school scienc technolog establish \n",
      "Cleaned Token Before =  supplementary data for aluminium chloride. baker fisher em science akzo nobel (hexahydrate) science stuff (hexahydrate) external sds nist website except\n",
      "Cleaned Token After =  supplementary data aluminium chloride . baker fisher em science akzo nobel ( hexahydrate ) science stuff ( hexahydrate ) external sds nist website except \n",
      "Cleaned Token After Stem =  supplementari data aluminium chlorid . baker fisher em scienc akzo nobel ( hexahydr ) scienc stuff ( hexahydr ) extern sd nist websit except \n",
      "Cleaned Token Before =  developing new insights and understanding of business performance based on data and statistical methods. in contrast, business intelligence traditionally\n",
      "Cleaned Token After =  developing new insights understanding business performance based data statistical methods . contrast , business intelligence traditionally \n",
      "Cleaned Token After Stem =  develop new insight understand busi perform base data statist method . contrast , busi intellig tradit \n",
      "Cleaned Token Before =  operates resources including the open science data cloud (aka osdc), which is a multi-petabyte scientific data sharing resource. the consortium is based\n",
      "Cleaned Token After =  operates resources including open science data cloud ( aka osdc ) , multi-petabyte scientific data sharing resource . consortium based \n",
      "Cleaned Token After Stem =  oper resourc includ open scienc data cloud ( aka osdc ) , multi-petabyt scientif data share resourc . consortium base \n",
      "Cleaned Token Before =  data included in the arda are submitted by the foremost religion scholars and research centers in the world. currently housed in the social science research\n",
      "Cleaned Token After =  data included arda submitted foremost religion scholars research centers world . currently housed social science research \n",
      "Cleaned Token After Stem =  data includ arda submit foremost religion scholar research center world . current hous social scienc research \n",
      "Cleaned Token Before =  biology, and the great betrayal: fraud in science, an examination of the deliberate manipulation of scientific data. horace freeland judson was born on 21\n",
      "Cleaned Token After =  biology , great betrayal : fraud science , examination deliberate manipulation scientific data . horace freeland judson born 21 \n",
      "Cleaned Token After Stem =  biolog , great betray : fraud scienc , examin deliber manipul scientif data . horac freeland judson born 21 \n",
      "Cleaned Token Before =  mathematics, as well as computer science. after graduation, he enrolled in stanford university to acquire a phd in computer science. there he met page, with whom\n",
      "Cleaned Token After =  mathematics , well computer science . graduation , enrolled stanford university acquire phd computer science . met page , \n",
      "Cleaned Token After Stem =  mathemat , well comput scienc . graduat , enrol stanford univers acquir phd comput scienc . met page , \n",
      "Cleaned Token Before =  netscape. may 2015 [9] alteryx acquires clearstory data to accelerate innovation in data science and analytics [10] linkedin profile of tim howes. retrieved\n",
      "Cleaned Token After =  netscape . may 2015 [ 9 ] alteryx acquires clearstory data accelerate innovation data science analytics [ 10 ] linkedin profile tim howes . retrieved \n",
      "Cleaned Token After Stem =  netscap . may 2015 [ 9 ] alteryx acquir clearstori data acceler innov data scienc analyt [ 10 ] linkedin profil tim how . retriev \n",
      "Cleaned Token Before =  industrial science and technology\". archived from the original on 5 may 2006. retrieved 1 february 2007. except where noted otherwise, data relate to standard\n",
      "Cleaned Token After =  industrial science technology '' . archived original 5 may 2006. retrieved 1 february 2007. except noted otherwise , data relate standard \n",
      "Cleaned Token After Stem =  industri scienc technolog `` . archiv origin 5 may 2006. retriev 1 februari 2007. except note otherwis , data relat standard \n",
      "Cleaned Token Before =  measured transmission loss data in a genetic algorithm inversion technique. she served as chief scientist during at-sea data collection operations and\n",
      "Cleaned Token After =  measured transmission loss data genetic algorithm inversion technique . served chief scientist at-sea data collection operations \n",
      "Cleaned Token After Stem =  measur transmiss loss data genet algorithm invers techniqu . serv chief scientist at-sea data collect oper \n",
      "Cleaned Token Before =  available to bs/is students include information & culture, data & society, data analytics/science, and human computer interaction (hci)/user experience (ux)\n",
      "Cleaned Token After =  available bs/is students include information & culture , data & society , data analytics/science , human computer interaction ( hci ) /user experience ( ux ) \n",
      "Cleaned Token After Stem =  avail bs/i student includ inform & cultur , data & societi , data analytics/sci , human comput interact ( hci ) /user experi ( ux ) \n",
      "Cleaned Token Before =  the national academies of sciences) to test the viability and utility of information captured by the drivecam video event data recorder (vedr). also in\n",
      "Cleaned Token After =  national academies sciences ) test viability utility information captured drivecam video event data recorder ( vedr ) . also \n",
      "Cleaned Token After Stem =  nation academi scienc ) test viabil util inform captur drivecam video event data record ( vedr ) . also \n",
      "Cleaned Token Before =  truck and managed the carnegie mellon research cafe. the data truck is a mobile behavioral science lab. the research cafe was a cafe located in downtown\n",
      "Cleaned Token After =  truck managed carnegie mellon research cafe . data truck mobile behavioral science lab . research cafe cafe located downtown \n",
      "Cleaned Token After Stem =  truck manag carnegi mellon research cafe . data truck mobil behavior scienc lab . research cafe cafe locat downtown \n",
      "Cleaned Token Before =  startups are seeing renewed interest from investors with the advent of data science, ai and voice technologies in 2018. lola.com, an ai based travel planning\n",
      "Cleaned Token After =  startups seeing renewed interest investors advent data science , ai voice technologies 2018. lola.com , ai based travel planning \n",
      "Cleaned Token After Stem =  startup see renew interest investor advent data scienc , ai voic technolog 2018. lola.com , ai base travel plan \n",
      "Cleaned Token Before =  carried out, and the federal bureau of investigation does not collect these data either. the annual average number of justifiable homicides alone was previously\n",
      "Cleaned Token After =  carried , federal bureau investigation collect data either . annual average number justifiable homicides alone previously \n",
      "Cleaned Token After Stem =  carri , feder bureau investig collect data either . annual averag number justifi homicid alon previous \n",
      "Cleaned Token Before =  including science, medicine, user experience and design, engineering and patient advocacy. the project is not the first one to aim to collect data on many\n",
      "Cleaned Token After =  including science , medicine , user experience design , engineering patient advocacy . project first one aim collect data many \n",
      "Cleaned Token After Stem =  includ scienc , medicin , user experi design , engin patient advocaci . project first one aim collect data mani \n",
      "Cleaned Token Before =  big science is the 1982 debut album by avant-garde artist laurie anderson and the first of a seven-album deal she signed with warner bros. records. it\n",
      "Cleaned Token After =  big science 1982 debut album avant-garde artist laurie anderson first seven-album deal signed warner bros. records . \n",
      "Cleaned Token After Stem =  big scienc 1982 debut album avant-gard artist lauri anderson first seven-album deal sign warner bros. record . \n",
      "Cleaned Token Before =  aim to summarize a sample, rather than use the data to learn about the population that the sample of data is thought to represent. this generally means\n",
      "Cleaned Token After =  aim summarize sample , rather use data learn population sample data thought represent . generally means \n",
      "Cleaned Token After Stem =  aim summar sampl , rather use data learn popul sampl data thought repres . gener mean \n",
      "Cleaned Token Before =  virologist and a lecturer based at cambridge university. he is also a science radio broadcaster and writer, and presents the naked scientists, a programme\n",
      "Cleaned Token After =  virologist lecturer based cambridge university . also science radio broadcaster writer , presents naked scientists , programme \n",
      "Cleaned Token After Stem =  virologist lectur base cambridg univers . also scienc radio broadcast writer , present nake scientist , programm \n",
      "Cleaned Token Before =  social science research network, is a repository for preprints devoted to the rapid dissemination of scholarly research in the social sciences and humanities\n",
      "Cleaned Token After =  social science research network , repository preprints devoted rapid dissemination scholarly research social sciences humanities \n",
      "Cleaned Token After Stem =  social scienc research network , repositori preprint devot rapid dissemin scholarli research social scienc human \n",
      "Cleaned Token Before =  méthodes d'enquête en sciences humaines et sociales (dime-shs) aims to collect and disseminate data for use in humanities and social sciences research. the max\n",
      "Cleaned Token After =  méthodes d'enquête en sciences humaines et sociales ( dime-shs ) aims collect disseminate data use humanities social sciences research . max \n",
      "Cleaned Token After Stem =  méthode d'enquêt en scienc humain et social ( dime-sh ) aim collect dissemin data use human social scienc research . max \n",
      "Cleaned Token Before =  of large amounts of biological data produced by life science experiments. elixir aims to ensure that biological data is integrated into a federated system\n",
      "Cleaned Token After =  large amounts biological data produced life science experiments . elixir aims ensure biological data integrated federated system \n",
      "Cleaned Token After Stem =  larg amount biolog data produc life scienc experi . elixir aim ensur biolog data integr feder system \n",
      "Cleaned Token Before =  director of the health data science program. onnela is known for his pioneering research using cell phone data in network science. he was awarded the nih\n",
      "Cleaned Token After =  director health data science program . onnela known pioneering research using cell phone data network science . awarded nih \n",
      "Cleaned Token After Stem =  director health data scienc program . onnela known pioneer research use cell phone data network scienc . award nih \n",
      "Cleaned Token Before =  follow its directions. msds from fluka in the sdsdata.org database science stuff table data obtained from crc handbook of chemistry and physics, 44th ed. the\n",
      "Cleaned Token After =  follow directions . msds fluka sdsdata.org database science stuff table data obtained crc handbook chemistry physics , 44th ed . \n",
      "Cleaned Token After Stem =  follow direct . msd fluka sdsdata.org databas scienc stuff tabl data obtain crc handbook chemistri physic , 44th ed . \n",
      "Cleaned Token Before =  geospatial data science cybergis center for advanced digital and spatial studies national center for supercomputing applications computational science data science\n",
      "Cleaned Token After =  geospatial data science cybergis center advanced digital spatial studies national center supercomputing applications computational science data science \n",
      "Cleaned Token After Stem =  geospati data scienc cybergi center advanc digit spatial studi nation center supercomput applic comput scienc data scienc \n",
      "Cleaned Token Before =  high performance computing, and data and computational science. the acm sighpc/intel computational and data science fellowships are part of a 5-year\n",
      "Cleaned Token After =  high performance computing , data computational science . acm sighpc/intel computational data science fellowships part 5-year \n",
      "Cleaned Token After Stem =  high perform comput , data comput scienc . acm sighpc/intel comput data scienc fellowship part 5-year \n",
      "Cleaned Token Before =  in computer science, locality-sensitive hashing (lsh) is an algorithmic technique that hashes similar input items into the same \"buckets\" with high probability\n",
      "Cleaned Token After =  computer science , locality-sensitive hashing ( lsh ) algorithmic technique hashes similar input items `` buckets '' high probability \n",
      "Cleaned Token After Stem =  comput scienc , locality-sensit hash ( lsh ) algorithm techniqu hash similar input item `` bucket `` high probabl \n",
      "Cleaned Token Before =  science campaigns, collecting data on topics such as global built-up surface validation, human impact on forests, global agricultural field-size data\n",
      "Cleaned Token After =  science campaigns , collecting data topics global built-up surface validation , human impact forests , global agricultural field-size data \n",
      "Cleaned Token After Stem =  scienc campaign , collect data topic global built-up surfac valid , human impact forest , global agricultur field-siz data \n",
      "Cleaned Token Before =  digimon data squad, known in japan as digimon savers (デジモンセイバーズ, dejimon seibāzu), is the fifth anime television series in the digimon franchise, produced\n",
      "Cleaned Token After =  digimon data squad , known japan digimon savers ( デジモンセイバーズ , dejimon seibāzu ) , fifth anime television series digimon franchise , produced \n",
      "Cleaned Token After Stem =  digimon data squad , known japan digimon saver ( デジモンセイバーズ , dejimon seibāzu ) , fifth anim televis seri digimon franchis , produc \n",
      "Cleaned Token Before =  by the system development corporation. in computer science, a pointer is a kind of reference. a data primitive (or just primitive) is any datum that can\n",
      "Cleaned Token After =  system development corporation . computer science , pointer kind reference . data primitive ( primitive ) datum \n",
      "Cleaned Token After Stem =  system develop corpor . comput scienc , pointer kind refer . data primit ( primit ) datum \n",
      "Cleaned Token Before =  of the study, data collection, data analysis, discussion of the results, and publication of the manuscript. however, vertical science has its own limitations\n",
      "Cleaned Token After =  study , data collection , data analysis , discussion results , publication manuscript . however , vertical science limitations \n",
      "Cleaned Token After Stem =  studi , data collect , data analysi , discuss result , public manuscript . howev , vertic scienc limit \n",
      "Cleaned Token Before =  the study of mind as well as intellect. there is also a reference to the science of noetics, which covers the field of thinking and knowing, thought and\n",
      "Cleaned Token After =  study mind well intellect . also reference science noetics , covers field thinking knowing , thought \n",
      "Cleaned Token After Stem =  studi mind well intellect . also refer scienc noetic , cover field think know , thought \n",
      "Cleaned Token Before =  the office of science and technology policy (ostp) is a department of the united states government, part of the executive office of the president (eop)\n",
      "Cleaned Token After =  office science technology policy ( ostp ) department united states government , part executive office president ( eop ) \n",
      "Cleaned Token After Stem =  offic scienc technolog polici ( ostp ) depart unit state govern , part execut offic presid ( eop ) \n",
      "Cleaned Token Before =  research data provenance interest group. within computer science, informatics uses the term \"provenance\" to mean the lineage of data, as per data provenance\n",
      "Cleaned Token After =  research data provenance interest group . within computer science , informatics uses term `` provenance '' mean lineage data , per data provenance \n",
      "Cleaned Token After Stem =  research data proven interest group . within comput scienc , informat use term `` proven `` mean lineag data , per data proven \n",
      "Cleaned Token Before =  data shadows refer to the information that a person leaves behind unintentionally while taking part in daily activities such as checking their e-mails\n",
      "Cleaned Token After =  data shadows refer information person leaves behind unintentionally taking part daily activities checking e-mails \n",
      "Cleaned Token After Stem =  data shadow refer inform person leav behind unintent take part daili activ check e-mail \n",
      "Cleaned Token Before =  way. it is maintained by observational health data sciences and informatics consortium. pcornet common data model: first defined in 2014 and used by pcori\n",
      "Cleaned Token After =  way . maintained observational health data sciences informatics consortium . pcornet common data model : first defined 2014 used pcori \n",
      "Cleaned Token After Stem =  way . maintain observ health data scienc informat consortium . pcornet common data model : first defin 2014 use pcori \n",
      "Cleaned Token Before =  analytics (\"the science of analytical reasoning facilitated by visual interactive interfaces\") and visual data analysis: visual data analysis blends highly\n",
      "Cleaned Token After =  analytics ( `` science analytical reasoning facilitated visual interactive interfaces '' ) visual data analysis : visual data analysis blends highly \n",
      "Cleaned Token After Stem =  analyt ( `` scienc analyt reason facilit visual interact interfac `` ) visual data analysi : visual data analysi blend highli \n",
      "Cleaned Token Before =  science in the medieval islamic world was the science developed and practised during the islamic golden age under the umayyads of córdoba, the abbadids\n",
      "Cleaned Token After =  science medieval islamic world science developed practised islamic golden age umayyads córdoba , abbadids \n",
      "Cleaned Token After Stem =  scienc mediev islam world scienc develop practis islam golden age umayyad córdoba , abbadid \n",
      "Cleaned Token Before =  data envelopment analysis (dea) is a nonparametric method in operations research and economics for the estimation of production frontiers. it is used to\n",
      "Cleaned Token After =  data envelopment analysis ( dea ) nonparametric method operations research economics estimation production frontiers . used \n",
      "Cleaned Token After Stem =  data envelop analysi ( dea ) nonparametr method oper research econom estim product frontier . use \n",
      "Cleaned Token Before =  impact of the nasa astrophysics data system digital library\". journal of the american society for information science and technology. 56 (1): 36–45. arxiv:0909\n",
      "Cleaned Token After =  impact nasa astrophysics data system digital library '' . journal american society information science technology . 56 ( 1 ) : 36–45 . arxiv:0909 \n",
      "Cleaned Token After Stem =  impact nasa astrophys data system digit librari `` . journal american societi inform scienc technolog . 56 ( 1 ) : 36–45 . arxiv:0909 \n",
      "Cleaned Token Before =  (doe) environmental system science data infrastructure for a virtual ecosystem (ess-dive) archive. the oceanic trace gas data have been transitioned to\n",
      "Cleaned Token After =  ( doe ) environmental system science data infrastructure virtual ecosystem ( ess-dive ) archive . oceanic trace gas data transitioned \n",
      "Cleaned Token After Stem =  ( doe ) environment system scienc data infrastructur virtual ecosystem ( ess-div ) archiv . ocean trace ga data transit \n",
      "Cleaned Token Before =  the study of data structures and abstraction, but these topics were not covered to the extent that they were covered in ap computer science ab. the microsoft-sponsored\n",
      "Cleaned Token After =  study data structures abstraction , topics covered extent covered ap computer science ab . microsoft-sponsored \n",
      "Cleaned Token After Stem =  studi data structur abstract , topic cover extent cover ap comput scienc ab . microsoft-sponsor \n",
      "Cleaned Token Before =  specific emphasis on particular areas of applied mathematics, applied science, and types of application. see glossary of engineering. the term engineering\n",
      "Cleaned Token After =  specific emphasis particular areas applied mathematics , applied science , types application . see glossary engineering . term engineering \n",
      "Cleaned Token After Stem =  specif emphasi particular area appli mathemat , appli scienc , type applic . see glossari engin . term engin \n",
      "Cleaned Token Before =  interdisciplinary field of study involving the combination of astronomy, data science, machine learning, informatics, and information/communications technologies\n",
      "Cleaned Token After =  interdisciplinary field study involving combination astronomy , data science , machine learning , informatics , information/communications technologies \n",
      "Cleaned Token After Stem =  interdisciplinari field studi involv combin astronomi , data scienc , machin learn , informat , information/commun technolog \n",
      "Cleaned Token Before =  managers and professionals. mtsm also offers a ph.d. degree in business data science. research areas include fintech, innovation management, and the advancement\n",
      "Cleaned Token After =  managers professionals . mtsm also offers ph.d. degree business data science . research areas include fintech , innovation management , advancement \n",
      "Cleaned Token After Stem =  manag profession . mtsm also offer ph.d. degre busi data scienc . research area includ fintech , innov manag , advanc \n",
      "Cleaned Token Before =  groups of data but disappears or reverses when these groups are combined. this result is often encountered in social-science and medical-science statistics\n",
      "Cleaned Token After =  groups data disappears reverses groups combined . result often encountered social-science medical-science statistics \n",
      "Cleaned Token After Stem =  group data disappear revers group combin . result often encount social-sci medical-sci statist \n",
      "Cleaned Token Before =  research-based doctorate in the field of information science. research areas include data science, digital youth, health and well-being, human-computer\n",
      "Cleaned Token After =  research-based doctorate field information science . research areas include data science , digital youth , health well-being , human-computer \n",
      "Cleaned Token After Stem =  research-bas doctor field inform scienc . research area includ data scienc , digit youth , health well-b , human-comput \n",
      "Cleaned Token Before =  in computer science, a term index is a data structure to facilitate fast lookup of terms and clauses in a logic program, deductive database, or automated\n",
      "Cleaned Token After =  computer science , term index data structure facilitate fast lookup terms clauses logic program , deductive database , automated \n",
      "Cleaned Token After Stem =  comput scienc , term index data structur facilit fast lookup term claus logic program , deduct databas , autom \n",
      "Cleaned Token Before =  model, design, specification, standard, algorithm, or policy. in computer science, an implementation is a realization of a technical specification or algorithm\n",
      "Cleaned Token After =  model , design , specification , standard , algorithm , policy . computer science , implementation realization technical specification algorithm \n",
      "Cleaned Token After Stem =  model , design , specif , standard , algorithm , polici . comput scienc , implement realiz technic specif algorithm \n",
      "Cleaned Token Before =  sciences departments at universities and research centers. online options include: a master of science in applied data science, a master of science in\n",
      "Cleaned Token After =  sciences departments universities research centers . online options include : master science applied data science , master science \n",
      "Cleaned Token After Stem =  scienc depart univers research center . onlin option includ : master scienc appli data scienc , master scienc \n",
      "Cleaned Token Before =  szomszor, martin (15 august 2016). \"digital science's grid now available as linked open data\". digital-science.com. retrieved 31 august 2018. \"grid statistics\"\n",
      "Cleaned Token After =  szomszor , martin ( 15 august 2016 ) . `` digital science 's grid available linked open data '' . digital-science.com . retrieved 31 august 2018 . `` grid statistics '' \n",
      "Cleaned Token After Stem =  szomszor , martin ( 15 august 2016 ) . `` digit scienc 's grid avail link open data `` . digital-science.com . retriev 31 august 2018 . `` grid statist `` \n",
      "Cleaned Token Before =  on open science is a document that advocates for \"full open access for all scientific publications\", and endorses an environment where \"data sharing and\n",
      "Cleaned Token After =  open science document advocates `` full open access scientific publications '' , endorses environment `` data sharing \n",
      "Cleaned Token After Stem =  open scienc document advoc `` full open access scientif public `` , endors environ `` data share \n",
      "Cleaned Token Before =  science, as identified by statistician john tukey, comprises situations in which there is a need to draw an inference from a limited sample of data,\n",
      "Cleaned Token After =  science , identified statistician john tukey , comprises situations need draw inference limited sample data , \n",
      "Cleaned Token After Stem =  scienc , identifi statistician john tukey , compris situat need draw infer limit sampl data , \n",
      "Cleaned Token Before =  https://ucsdnews.ucsd.edu/feature/a_campus_hub_for_data_science personal website uc san diego department of cognitive science center for research in language, ucsd\n",
      "Cleaned Token After =  https : //ucsdnews.ucsd.edu/feature/a_campus_hub_for_data_science personal website uc san diego department cognitive science center research language , ucsd \n",
      "Cleaned Token After Stem =  http : //ucsdnews.ucsd.edu/feature/a_campus_hub_for_data_sci person websit uc san diego depart cognit scienc center research languag , ucsd \n",
      "Cleaned Token Before =  science, planetary science, radio astronomy, and to other sectors. oodt is also used within bioinformatics and is a part of the knowledgent big data platform\n",
      "Cleaned Token After =  science , planetary science , radio astronomy , sectors . oodt also used within bioinformatics part knowledgent big data platform \n",
      "Cleaned Token After Stem =  scienc , planetari scienc , radio astronomi , sector . oodt also use within bioinformat part knowledg big data platform \n",
      "Cleaned Token Before =  algorithms and data structures, or concrete, such as open source software packages. notable examples of technology transfer in computer science include: moler\n",
      "Cleaned Token After =  algorithms data structures , concrete , open source software packages . notable examples technology transfer computer science include : moler \n",
      "Cleaned Token After Stem =  algorithm data structur , concret , open sourc softwar packag . notabl exampl technolog transfer comput scienc includ : moler \n",
      "Cleaned Token Before =  bachelor of science (b. sc.): business administration computer games technology data science & artificial intelligence e-commerce computer science it engineering\n",
      "Cleaned Token After =  bachelor science ( b . sc . ) : business administration computer games technology data science & artificial intelligence e-commerce computer science engineering \n",
      "Cleaned Token After Stem =  bachelor scienc ( b . sc . ) : busi administr comput game technolog data scienc & artifici intellig e-commerc comput scienc engin \n",
      "Cleaned Token Before =  problems described by big data and have applications in fields such as machine learning, signal processing and data science. richtarik is the co-inventor\n",
      "Cleaned Token After =  problems described big data applications fields machine learning , signal processing data science . richtarik co-inventor \n",
      "Cleaned Token After Stem =  problem describ big data applic field machin learn , signal process data scienc . richtarik co-inventor \n",
      "Cleaned Token Before =  assumptions in the definitions. for example, if your \"person\" data element tracked characters in a science fiction series that included aliens you may need a more\n",
      "Cleaned Token After =  assumptions definitions . example , `` person '' data element tracked characters science fiction series included aliens may need \n",
      "Cleaned Token After Stem =  assumpt definit . exampl , `` person `` data element track charact scienc fiction seri includ alien may need \n",
      "Cleaned Token Before =  computer science a level set data structure is designed to represent discretely sampled dynamic level sets functions. a common use of this form of data structure\n",
      "Cleaned Token After =  computer science level set data structure designed represent discretely sampled dynamic level sets functions . common use form data structure \n",
      "Cleaned Token After Stem =  comput scienc level set data structur design repres discret sampl dynam level set function . common use form data structur \n",
      "Cleaned Token Before =  data collection system (dcs) is a computer application that facilitates the process of data collection, allowing specific, structured information to be\n",
      "Cleaned Token After =  data collection system ( dcs ) computer application facilitates process data collection , allowing specific , structured information \n",
      "Cleaned Token After Stem =  data collect system ( dc ) comput applic facilit process data collect , allow specif , structur inform \n",
      "Cleaned Token Before =  implicit data structure, and has continued work in this area. he is currently a university professor in the david r. cheriton school of computer science at\n",
      "Cleaned Token After =  implicit data structure , continued work area . currently university professor david r. cheriton school computer science \n",
      "Cleaned Token After Stem =  implicit data structur , continu work area . current univers professor david r. cheriton school comput scienc \n",
      "Cleaned Token Before =  technologies needed in silicon valley, such as artificial intelligence and data science, as stated in the cstu's website. cstu is seeking to be accredited by\n",
      "Cleaned Token After =  technologies needed silicon valley , artificial intelligence data science , stated cstu 's website . cstu seeking accredited \n",
      "Cleaned Token After Stem =  technolog need silicon valley , artifici intellig data scienc , state cstu 's websit . cstu seek accredit \n",
      "Cleaned Token Before =  uncertainty, and responsible data science\", was selected as a distinguished alumna of the uc santa barbara computer science department, was awarded the\n",
      "Cleaned Token After =  uncertainty , responsible data science '' , selected distinguished alumna uc santa barbara computer science department , awarded \n",
      "Cleaned Token After Stem =  uncertainti , respons data scienc `` , select distinguish alumna uc santa barbara comput scienc depart , award \n",
      "Cleaned Token Before =  workforce, gathering data, and teaching others about the issue of diversity related to the field of library and information science. american indian library\n",
      "Cleaned Token After =  workforce , gathering data , teaching others issue diversity related field library information science . american indian library \n",
      "Cleaned Token After Stem =  workforc , gather data , teach other issu divers relat field librari inform scienc . american indian librari \n",
      "Cleaned Token Before =  consumer sciences, is today a subject concerning human development, personal and family finance, housing and interior design, food science and preparation\n",
      "Cleaned Token After =  consumer sciences , today subject concerning human development , personal family finance , housing interior design , food science preparation \n",
      "Cleaned Token After Stem =  consum scienc , today subject concern human develop , person famili financ , hous interior design , food scienc prepar \n",
      "Cleaned Token Before =  uses of the term protocol in a data-commutation context occurs in a memorandum entitled a protocol for use in the npl data communications network written\n",
      "Cleaned Token After =  uses term protocol data-commutation context occurs memorandum entitled protocol use npl data communications network written \n",
      "Cleaned Token After Stem =  use term protocol data-commut context occur memorandum entitl protocol use npl data commun network written \n",
      "Cleaned Token Before =  research, training and knowledge transfer activities in the environmental sciences. nerc began in 1965 when several environmental (mainly geographic) research\n",
      "Cleaned Token After =  research , training knowledge transfer activities environmental sciences . nerc began 1965 several environmental ( mainly geographic ) research \n",
      "Cleaned Token After Stem =  research , train knowledg transfer activ environment scienc . nerc began 1965 sever environment ( mainli geograph ) research \n",
      "Cleaned Token Before =  the collection, interpretation, analysis, and dissemination of data on social science resources, their availability for research and their impact on society;\n",
      "Cleaned Token After =  collection , interpretation , analysis , dissemination data social science resources , availability research impact society ; \n",
      "Cleaned Token After Stem =  collect , interpret , analysi , dissemin data social scienc resourc , avail research impact societi ; \n",
      "Cleaned Token Before =  13 february 2021. \"biontech publishes data on novel mrna vaccine approach to treat autoimmune diseases in science\". biontech. 7 january 2021. retrieved\n",
      "Cleaned Token After =  13 february 2021 . `` biontech publishes data novel mrna vaccine approach treat autoimmune diseases science '' . biontech . 7 january 2021. retrieved \n",
      "Cleaned Token After Stem =  13 februari 2021 . `` biontech publish data novel mrna vaccin approach treat autoimmun diseas scienc `` . biontech . 7 januari 2021. retriev \n",
      "Cleaned Token Before =  enterprise data modeling (edm) is the practice of creating a graphical model of the data used by an enterprise or company. typical outputs of this activity\n",
      "Cleaned Token After =  enterprise data modeling ( edm ) practice creating graphical model data used enterprise company . typical outputs activity \n",
      "Cleaned Token After Stem =  enterpris data model ( edm ) practic creat graphic model data use enterpris compani . typic output activ \n",
      "Cleaned Token Before =  a data jam is a technically oriented workshop exercise where people solve problems using data sets. the events can produce visual data, analytics and applications\n",
      "Cleaned Token After =  data jam technically oriented workshop exercise people solve problems using data sets . events produce visual data , analytics applications \n",
      "Cleaned Token After Stem =  data jam technic orient workshop exercis peopl solv problem use data set . event produc visual data , analyt applic \n",
      "Cleaned Token Before =  multi-dimensional data (such as raster data) in science, engineering, and business. multidimensional expressions (mdx) multidimensional panel data dimension (data warehouse)\n",
      "Cleaned Token After =  multi-dimensional data ( raster data ) science , engineering , business . multidimensional expressions ( mdx ) multidimensional panel data dimension ( data warehouse ) \n",
      "Cleaned Token After Stem =  multi-dimension data ( raster data ) scienc , engin , busi . multidimension express ( mdx ) multidimension panel data dimens ( data warehous ) \n",
      "Cleaned Token Before =  the infrastructure of social science research, icpsr maintains and provides access to a vast archive of social science data for research and instruction\n",
      "Cleaned Token After =  infrastructure social science research , icpsr maintains provides access vast archive social science data research instruction \n",
      "Cleaned Token After Stem =  infrastructur social scienc research , icpsr maintain provid access vast archiv social scienc data research instruct \n",
      "Cleaned Token Before =  it is a measure of the strength of relationship between the methods and data of a class and some unifying purpose or concept served by that class. in\n",
      "Cleaned Token After =  measure strength relationship methods data class unifying purpose concept served class . \n",
      "Cleaned Token After Stem =  measur strength relationship method data class unifi purpos concept serv class . \n",
      "Cleaned Token Before =  in applied statistics and data science at rice university, oxford university, the essex summer school in social science data analysis, and the ipsa summer\n",
      "Cleaned Token After =  applied statistics data science rice university , oxford university , essex summer school social science data analysis , ipsa summer \n",
      "Cleaned Token After Stem =  appli statist data scienc rice univers , oxford univers , essex summer school social scienc data analysi , ipsa summer \n",
      "Cleaned Token Before =  computer science at the university of illinois at urbana-champaign. his research focuses on data mining, data warehousing, database systems, data mining\n",
      "Cleaned Token After =  computer science university illinois urbana-champaign . research focuses data mining , data warehousing , database systems , data mining \n",
      "Cleaned Token After Stem =  comput scienc univers illinoi urbana-champaign . research focus data mine , data wareh , databas system , data mine \n",
      "Cleaned Token Before =  uproar by publishing data from 70,000 okcupid users\". fortune.com. zimmer, michael. \"okcupid study reveals the perils of big-data science\". wired. duportail\n",
      "Cleaned Token After =  uproar publishing data 70,000 okcupid users '' . fortune.com . zimmer , michael . `` okcupid study reveals perils big-data science '' . wired . duportail \n",
      "Cleaned Token After Stem =  uproar publish data 70,000 okcupid user `` . fortune.com . zimmer , michael . `` okcupid studi reveal peril big-data scienc `` . wire . duportail \n",
      "Cleaned Token Before =  journals accepted them. the article and associated data were published in the 4 october 2013 issue of science as open access. the first fee-charging open access\n",
      "Cleaned Token After =  journals accepted . article associated data published 4 october 2013 issue science open access . first fee-charging open access \n",
      "Cleaned Token After Stem =  journal accept . articl associ data publish 4 octob 2013 issu scienc open access . first fee-charg open access \n",
      "Cleaned Token Before =  networks derived from multiparameter single-cell data\". science. 308 (5721): 523–9. doi:10.1126/science.1105809. pmid 15845847. bendall, s. c.; simonds\n",
      "Cleaned Token After =  networks derived multiparameter single-cell data '' . science . 308 ( 5721 ) : 523–9 . doi:10.1126/science.1105809 . pmid 15845847. bendall , s. c. ; simonds \n",
      "Cleaned Token After Stem =  network deriv multiparamet single-cel data `` . scienc . 308 ( 5721 ) : 523–9 . doi:10.1126/science.1105809 . pmid 15845847. bendal , s. c. ; simond \n",
      "Cleaned Token Before =  mathematics and science. for 2019, castillo-chavez was provost visiting professor in the applied mathematics division and data science initiative at brown\n",
      "Cleaned Token After =  mathematics science . 2019 , castillo-chavez provost visiting professor applied mathematics division data science initiative brown \n",
      "Cleaned Token After Stem =  mathemat scienc . 2019 , castillo-chavez provost visit professor appli mathemat divis data scienc initi brown \n",
      "Cleaned Token Before =  and marking data in the public domain for machine-assisted discovery. spreading science knowledge far and wide, new york academy of sciences, 2010 creative\n",
      "Cleaned Token After =  marking data public domain machine-assisted discovery . spreading science knowledge far wide , new york academy sciences , 2010 creative \n",
      "Cleaned Token After Stem =  mark data public domain machine-assist discoveri . spread scienc knowledg far wide , new york academi scienc , 2010 creativ \n",
      "Cleaned Token Before =  botany, also called plant science(s), plant biology or phytology, is the science of plant life and a branch of biology. a botanist, plant scientist or\n",
      "Cleaned Token After =  botany , also called plant science ( ) , plant biology phytology , science plant life branch biology . botanist , plant scientist \n",
      "Cleaned Token After Stem =  botani , also call plant scienc ( ) , plant biolog phytolog , scienc plant life branch biolog . botanist , plant scientist \n",
      "Cleaned Token Before =  computer science computing cybernetics and human knowing data mining and knowledge discovery discrete mathematics & theoretical computer science distributed\n",
      "Cleaned Token After =  computer science computing cybernetics human knowing data mining knowledge discovery discrete mathematics & theoretical computer science distributed \n",
      "Cleaned Token After Stem =  comput scienc comput cybernet human know data mine knowledg discoveri discret mathemat & theoret comput scienc distribut \n",
      "Cleaned Token Before =  peer-reviewed research from a variety of academic disciplines, mainly in science and technology. it has core editorial offices across the united states\n",
      "Cleaned Token After =  peer-reviewed research variety academic disciplines , mainly science technology . core editorial offices across united states \n",
      "Cleaned Token After Stem =  peer-review research varieti academ disciplin , mainli scienc technolog . core editori offic across unit state \n",
      "Cleaned Token Before =  1977, 1986. computational aspects of vlsi, computer science press, 1984 isbn 978-0-914894-95-7 data structures and algorithms (with a. v. aho and j. e\n",
      "Cleaned Token After =  1977 , 1986. computational aspects vlsi , computer science press , 1984 isbn 978-0-914894-95-7 data structures algorithms ( a. v. aho j. e \n",
      "Cleaned Token After Stem =  1977 , 1986. comput aspect vlsi , comput scienc press , 1984 isbn 978-0-914894-95-7 data structur algorithm ( a. v. aho j. e \n",
      "Cleaned Token Before =  (macro and microsemantics) and predefining three semantic entities (actions, data and yielders) to simplify the specification; algebraic semantics is a form\n",
      "Cleaned Token After =  ( macro microsemantics ) predefining three semantic entities ( actions , data yielders ) simplify specification ; algebraic semantics form \n",
      "Cleaned Token After Stem =  ( macro microsemant ) predefin three semant entiti ( action , data yielder ) simplifi specif ; algebra semant form \n",
      "Cleaned Token Before =  lay summary. media related to gilead sciences at wikimedia commons official website business data for gilead sciences: google finance yahoo! finance sec\n",
      "Cleaned Token After =  lay summary . media related gilead sciences wikimedia commons official website business data gilead sciences : google finance yahoo ! finance sec \n",
      "Cleaned Token After Stem =  lay summari . media relat gilead scienc wikimedia common offici websit busi data gilead scienc : googl financ yahoo ! financ sec \n",
      "Cleaned Token Before =  impact open access to scientific publications open science research assessment research careers research data research infrastructures research integrity dedicated\n",
      "Cleaned Token After =  impact open access scientific publications open science research assessment research careers research data research infrastructures research integrity dedicated \n",
      "Cleaned Token After Stem =  impact open access scientif public open scienc research assess research career research data research infrastructur research integr dedic \n",
      "Cleaned Token Before =  he is a professor of computer science at luiss university in rome. he is known for his work in graph algorithms, data structures and algorithm engineering\n",
      "Cleaned Token After =  professor computer science luiss university rome . known work graph algorithms , data structures algorithm engineering \n",
      "Cleaned Token After Stem =  professor comput scienc luiss univers rome . known work graph algorithm , data structur algorithm engin \n",
      "Cleaned Token Before =  gonnet and granted in 1989. his research interests include: algorithms and data structures. his contributions include algorithms for string search such as\n",
      "Cleaned Token After =  gonnet granted 1989. research interests include : algorithms data structures . contributions include algorithms string search \n",
      "Cleaned Token After Stem =  gonnet grant 1989. research interest includ : algorithm data structur . contribut includ algorithm string search \n",
      "Cleaned Token Before =  is a proprietary computer program for interactive scientific graphing and data analysis. it is produced by originlab corporation, and runs on microsoft\n",
      "Cleaned Token After =  proprietary computer program interactive scientific graphing data analysis . produced originlab corporation , runs microsoft \n",
      "Cleaned Token After Stem =  proprietari comput program interact scientif graph data analysi . produc originlab corpor , run microsoft \n",
      "Cleaned Token Before =  google data centers are the large data center facilities google uses to provide their services, which combine large drives, computer nodes organized in\n",
      "Cleaned Token After =  google data centers large data center facilities google uses provide services , combine large drives , computer nodes organized \n",
      "Cleaned Token After Stem =  googl data center larg data center facil googl use provid servic , combin larg drive , comput node organ \n",
      "Cleaned Token Before =  science and key engineering data. on october 3, 2018, the jpl began operating curiosity on its backup computer (side-a). curiosity will store science\n",
      "Cleaned Token After =  science key engineering data . october 3 , 2018 , jpl began operating curiosity backup computer ( side-a ) . curiosity store science \n",
      "Cleaned Token After Stem =  scienc key engin data . octob 3 , 2018 , jpl began oper curios backup comput ( side-a ) . curios store scienc \n",
      "Cleaned Token Before =   artificial intelligence, computational biology, computer networks, data science, human–computer interaction, parallel processing, quantum computing and\n",
      "Cleaned Token After =  artificial intelligence , computational biology , computer networks , data science , human–computer interaction , parallel processing , quantum computing \n",
      "Cleaned Token After Stem =  artifici intellig , comput biolog , comput network , data scienc , human–comput interact , parallel process , quantum comput \n",
      "Cleaned Token Before =  sid the science kid science fair app sid the science kid at imdb sid the science kid: the movie at imdb sid the science kid at the big cartoon database\n",
      "Cleaned Token After =  sid science kid science fair app sid science kid imdb sid science kid : movie imdb sid science kid big cartoon database \n",
      "Cleaned Token After Stem =  sid scienc kid scienc fair app sid scienc kid imdb sid scienc kid : movi imdb sid scienc kid big cartoon databas \n",
      "Cleaned Token Before =  businessman john purdue donated land and money to establish a college of science, technology, and agriculture in his name. the first classes were held on\n",
      "Cleaned Token After =  businessman john purdue donated land money establish college science , technology , agriculture name . first classes held \n",
      "Cleaned Token After Stem =  businessman john purdu donat land money establish colleg scienc , technolog , agricultur name . first class held \n",
      "Cleaned Token Before =  information science. remote sensing is the science of obtaining information about earth features from measurements made at a distance. remotely sensed data comes\n",
      "Cleaned Token After =  information science . remote sensing science obtaining information earth features measurements made distance . remotely sensed data comes \n",
      "Cleaned Token After Stem =  inform scienc . remot sens scienc obtain inform earth featur measur made distanc . remot sens data come \n",
      "Cleaned Token Before =  data quality act: a revolution in the role of science in policy making or a can of worms?\" rick weiss, the washington post, august 16, 2004, \"'data quality'\n",
      "Cleaned Token After =  data quality act : revolution role science policy making worms ? '' rick weiss , washington post , august 16 , 2004 , `` 'data quality ' \n",
      "Cleaned Token After Stem =  data qualiti act : revolut role scienc polici make worm ? `` rick weiss , washington post , august 16 , 2004 , `` 'data qualiti ' \n",
      "Cleaned Token Before =  the import and export of data is the automated or semi-automated input and output of data sets between different software applications. it involves \"translating\"\n",
      "Cleaned Token After =  import export data automated semi-automated input output data sets different software applications . involves `` translating '' \n",
      "Cleaned Token After Stem =  import export data autom semi-autom input output data set differ softwar applic . involv `` translat `` \n",
      "Cleaned Token Before =  information retrieval (ir) is the process of obtaining information system resources that are relevant to an information need from a collection of those\n",
      "Cleaned Token After =  information retrieval ( ir ) process obtaining information system resources relevant information need collection \n",
      "Cleaned Token After Stem =  inform retriev ( ir ) process obtain inform system resourc relev inform need collect \n",
      "Cleaned Token Before =  music information retrieval (mir) is the interdisciplinary science of retrieving information from music. mir is a small but growing field of research with\n",
      "Cleaned Token After =  music information retrieval ( mir ) interdisciplinary science retrieving information music . mir small growing field research \n",
      "Cleaned Token After Stem =  music inform retriev ( mir ) interdisciplinari scienc retriev inform music . mir small grow field research \n",
      "Cleaned Token Before =  in information science and information retrieval, relevance denotes how well a retrieved document or set of documents meets the information need of the\n",
      "Cleaned Token After =  information science information retrieval , relevance denotes well retrieved document set documents meets information need \n",
      "Cleaned Token After Stem =  inform scienc inform retriev , relev denot well retriev document set document meet inform need \n",
      "Cleaned Token Before =  in the context of information retrieval, a thesaurus (plural: \"thesauri\") is a form of controlled vocabulary that seeks to dictate semantic manifestations\n",
      "Cleaned Token After =  context information retrieval , thesaurus ( plural : `` thesauri '' ) form controlled vocabulary seeks dictate semantic manifestations \n",
      "Cleaned Token After Stem =  context inform retriev , thesauru ( plural : `` thesauri `` ) form control vocabulari seek dictat semant manifest \n",
      "Cleaned Token Before =  evaluation measures for an information retrieval system are used to assess how well the search results satisfied the user's query intent. such metrics\n",
      "Cleaned Token After =  evaluation measures information retrieval system used assess well search results satisfied user 's query intent . metrics \n",
      "Cleaned Token After Stem =  evalu measur inform retriev system use assess well search result satisfi user 's queri intent . metric \n",
      "Cleaned Token Before =  in pattern recognition, information retrieval and classification (machine learning), precision (also called positive predictive value) is the fraction\n",
      "Cleaned Token After =  pattern recognition , information retrieval classification ( machine learning ) , precision ( also called positive predictive value ) fraction \n",
      "Cleaned Token After Stem =  pattern recognit , inform retriev classif ( machin learn ) , precis ( also call posit predict valu ) fraction \n",
      "Cleaned Token Before =  ranking of query is one of the fundamental problems in information retrieval (ir), the scientific/engineering discipline behind search engines. given\n",
      "Cleaned Token After =  ranking query one fundamental problems information retrieval ( ir ) , scientific/engineering discipline behind search engines . given \n",
      "Cleaned Token After Stem =  rank queri one fundament problem inform retriev ( ir ) , scientific/engin disciplin behind search engin . given \n",
      "Cleaned Token Before =  the (standard) boolean model of information retrieval (bir) is a classical information retrieval (ir) model and, at the same time, the first and most-adopted\n",
      "Cleaned Token After =  ( standard ) boolean model information retrieval ( bir ) classical information retrieval ( ir ) model , time , first most-adopted \n",
      "Cleaned Token After Stem =  ( standard ) boolean model inform retriev ( bir ) classic inform retriev ( ir ) model , time , first most-adopt \n",
      "Cleaned Token Before =  in cryptography, a private information retrieval (pir) protocol is a protocol that allows a user to retrieve an item from a server in possession of a\n",
      "Cleaned Token After =  cryptography , private information retrieval ( pir ) protocol protocol allows user retrieve item server possession \n",
      "Cleaned Token After Stem =  cryptographi , privat inform retriev ( pir ) protocol protocol allow user retriev item server possess \n",
      "Cleaned Token Before =  cross-language information retrieval (clir) is a subfield of information retrieval dealing with retrieving information written in a language different\n",
      "Cleaned Token After =  cross-language information retrieval ( clir ) subfield information retrieval dealing retrieving information written language different \n",
      "Cleaned Token After Stem =  cross-languag inform retriev ( clir ) subfield inform retriev deal retriev inform written languag differ \n",
      "Cleaned Token Before =  human–computer information retrieval (hcir) is the study and engineering of information retrieval techniques that bring human intelligence into the search\n",
      "Cleaned Token After =  human–computer information retrieval ( hcir ) study engineering information retrieval techniques bring human intelligence search \n",
      "Cleaned Token After Stem =  human–comput inform retriev ( hcir ) studi engin inform retriev techniqu bring human intellig search \n",
      "Cleaned Token Before =  a list of free information retrieval libraries, which are libraries used in software development for performing information retrieval functions. it is\n",
      "Cleaned Token After =  list free information retrieval libraries , libraries used software development performing information retrieval functions . \n",
      "Cleaned Token After Stem =  list free inform retriev librari , librari use softwar develop perform inform retriev function . \n",
      "Cleaned Token Before =  content-based image retrieval, also known as query by image content (qbic) and content-based visual information retrieval (cbvir), is the application\n",
      "Cleaned Token After =  content-based image retrieval , also known query image content ( qbic ) content-based visual information retrieval ( cbvir ) , application \n",
      "Cleaned Token After Stem =  content-bas imag retriev , also known queri imag content ( qbic ) content-bas visual inform retriev ( cbvir ) , applic \n",
      "Cleaned Token Before =  literature analysis and retrieval system online, or medlars online) is a bibliographic database of life sciences and biomedical information. it includes bibliographic\n",
      "Cleaned Token After =  literature analysis retrieval system online , medlars online ) bibliographic database life sciences biomedical information . includes bibliographic \n",
      "Cleaned Token After Stem =  literatur analysi retriev system onlin , medlar onlin ) bibliograph databas life scienc biomed inform . includ bibliograph \n",
      "Cleaned Token Before =  legal information retrieval is the science of information retrieval applied to legal text, including legislation, case law, and scholarly works. accurate\n",
      "Cleaned Token After =  legal information retrieval science information retrieval applied legal text , including legislation , case law , scholarly works . accurate \n",
      "Cleaned Token After Stem =  legal inform retriev scienc inform retriev appli legal text , includ legisl , case law , scholarli work . accur \n",
      "Cleaned Token Before =  in information retrieval, dwell time denotes the time which a user spends viewing a document after clicking a link on a search engine results page (serp)\n",
      "Cleaned Token After =  information retrieval , dwell time denotes time user spends viewing document clicking link search engine results page ( serp ) \n",
      "Cleaned Token After Stem =  inform retriev , dwell time denot time user spend view document click link search engin result page ( serp ) \n",
      "Cleaned Token Before =  multimedia information retrieval (mmir or mir) is a research discipline of computer science that aims at extracting semantic information from multimedia\n",
      "Cleaned Token After =  multimedia information retrieval ( mmir mir ) research discipline computer science aims extracting semantic information multimedia \n",
      "Cleaned Token After Stem =  multimedia inform retriev ( mmir mir ) research disciplin comput scienc aim extract semant inform multimedia \n",
      "Cleaned Token Before =  (system for the mechanical analysis and retrieval of text) information retrieval system is an information retrieval system developed at cornell university\n",
      "Cleaned Token After =  ( system mechanical analysis retrieval text ) information retrieval system information retrieval system developed cornell university \n",
      "Cleaned Token After Stem =  ( system mechan analysi retriev text ) inform retriev system inform retriev system develop cornel univers \n",
      "Cleaned Token Before =  center for intelligent information retrieval (ciir) is a research center at the department of computer science, university of massachusetts amherst. it\n",
      "Cleaned Token After =  center intelligent information retrieval ( ciir ) research center department computer science , university massachusetts amherst . \n",
      "Cleaned Token After Stem =  center intellig inform retriev ( ciir ) research center depart comput scienc , univers massachusett amherst . \n",
      "Cleaned Token Before =  temporal information retrieval (t-ir) is an emerging area of research related to the field of information retrieval (ir) and a considerable number of sub-areas\n",
      "Cleaned Token After =  temporal information retrieval ( t-ir ) emerging area research related field information retrieval ( ir ) considerable number sub-areas \n",
      "Cleaned Token After Stem =  tempor inform retriev ( t-ir ) emerg area research relat field inform retriev ( ir ) consider number sub-area \n",
      "Cleaned Token Before =  cognitive models of information retrieval rest on the mix of areas such as cognitive science, human-computer interaction, information retrieval, and library\n",
      "Cleaned Token After =  cognitive models information retrieval rest mix areas cognitive science , human-computer interaction , information retrieval , library \n",
      "Cleaned Token After Stem =  cognit model inform retriev rest mix area cognit scienc , human-comput interact , inform retriev , librari \n",
      "Cleaned Token Before =  an information retrieval (ir) query language is a query language used to make queries into search index. a query language is formally defined in a context-free\n",
      "Cleaned Token After =  information retrieval ( ir ) query language query language used make queries search index . query language formally defined context-free \n",
      "Cleaned Token After Stem =  inform retriev ( ir ) queri languag queri languag use make queri search index . queri languag formal defin context-fre \n",
      "Cleaned Token Before =  information retrieval knowledge retrieval medical retrieval music information retrieval text retrieval the process of recalling information that is stored\n",
      "Cleaned Token After =  information retrieval knowledge retrieval medical retrieval music information retrieval text retrieval process recalling information stored \n",
      "Cleaned Token After Stem =  inform retriev knowledg retriev medic retriev music inform retriev text retriev process recal inform store \n",
      "Cleaned Token Before =  association for computing machinery's special interest group on information retrieval. the scope of the group's specialty is the theory and application\n",
      "Cleaned Token After =  association computing machinery 's special interest group information retrieval . scope group 's specialty theory application \n",
      "Cleaned Token After Stem =  associ comput machineri 's special interest group inform retriev . scope group 's specialti theori applic \n",
      "Cleaned Token Before =  geographic information retrieval (gir) or geographical information retrieval systems are search tools for searching the web, enterprise documents, and\n",
      "Cleaned Token After =  geographic information retrieval ( gir ) geographical information retrieval systems search tools searching web , enterprise documents , \n",
      "Cleaned Token After Stem =  geograph inform retriev ( gir ) geograph inform retriev system search tool search web , enterpris document , \n",
      "Cleaned Token Before =  collection, classification, manipulation, storage, retrieval, movement, dissemination, and protection of information. practitioners within and outside the field\n",
      "Cleaned Token After =  collection , classification , manipulation , storage , retrieval , movement , dissemination , protection information . practitioners within outside field \n",
      "Cleaned Token After Stem =  collect , classif , manipul , storag , retriev , movement , dissemin , protect inform . practition within outsid field \n",
      "Cleaned Token Before =  several different sources, databases, and formats into a uniform information model and retrieval system which can efficiently retrieve that relevant references\n",
      "Cleaned Token After =  several different sources , databases , formats uniform information model retrieval system efficiently retrieve relevant references \n",
      "Cleaned Token After Stem =  sever differ sourc , databas , format uniform inform model retriev system effici retriev relev refer \n",
      "Cleaned Token Before =  on information retrieval (ecir) is the main european research conference for the presentation of new results in the field of information retrieval (ir)\n",
      "Cleaned Token After =  information retrieval ( ecir ) main european research conference presentation new results field information retrieval ( ir ) \n",
      "Cleaned Token After Stem =  inform retriev ( ecir ) main european research confer present new result field inform retriev ( ir ) \n",
      "Cleaned Token Before =  descriptions of an information need to a few words. document retrieval is sometimes referred to as, or as a branch of, text retrieval. text retrieval is a branch\n",
      "Cleaned Token After =  descriptions information need words . document retrieval sometimes referred , branch , text retrieval . text retrieval branch \n",
      "Cleaned Token After Stem =  descript inform need word . document retriev sometim refer , branch , text retriev . text retriev branch \n",
      "Cleaned Token Before =   roediger, iii (2008) lent support to the idea that practicing information retrieval is integral to learning. they had college students study 40 pairs\n",
      "Cleaned Token After =  roediger , iii ( 2008 ) lent support idea practicing information retrieval integral learning . college students study 40 pairs \n",
      "Cleaned Token After Stem =  roedig , iii ( 2008 ) lent support idea practic inform retriev integr learn . colleg student studi 40 pair \n",
      "Cleaned Token Before =  documentation. when information scientists from 1964 entered library schools, they brought with them competencies in relation to information retrieval in subject\n",
      "Cleaned Token After =  documentation . information scientists 1964 entered library schools , brought competencies relation information retrieval subject \n",
      "Cleaned Token After Stem =  document . inform scientist 1964 enter librari school , brought compet relat inform retriev subject \n",
      "Cleaned Token Before =  adversarial information retrieval (adversarial ir) is a topic in information retrieval related to strategies for working with a data source where some\n",
      "Cleaned Token After =  adversarial information retrieval ( adversarial ir ) topic information retrieval related strategies working data source \n",
      "Cleaned Token After Stem =  adversari inform retriev ( adversari ir ) topic inform retriev relat strategi work data sourc \n",
      "Cleaned Token Before =  contexts. information seeking is related to, but different from, information retrieval (ir). traditionally, ir tools have been designed for ir professionals\n",
      "Cleaned Token After =  contexts . information seeking related , different , information retrieval ( ir ) . traditionally , ir tools designed ir professionals \n",
      "Cleaned Token After Stem =  context . inform seek relat , differ , inform retriev ( ir ) . tradit , ir tool design ir profession \n",
      "Cleaned Token Before =  nf-squared databases. pick was originally implemented as the generalized information retrieval language system (girls) on an ibm system/360 in 1965 by don nelson\n",
      "Cleaned Token After =  nf-squared databases . pick originally implemented generalized information retrieval language system ( girls ) ibm system/360 1965 nelson \n",
      "Cleaned Token After Stem =  nf-squar databas . pick origin implement gener inform retriev languag system ( girl ) ibm system/360 1965 nelson \n",
      "Cleaned Token Before =  information retrieval, intelligence gathering, plagiarism detection, pattern recognition, anomaly detection and even art creation. often information can\n",
      "Cleaned Token After =  information retrieval , intelligence gathering , plagiarism detection , pattern recognition , anomaly detection even art creation . often information \n",
      "Cleaned Token After Stem =  inform retriev , intellig gather , plagiar detect , pattern recognit , anomali detect even art creation . often inform \n",
      "Cleaned Token Before =  in information retrieval, okapi bm25 (bm is an abbreviation of best matching) is a ranking function used by search engines to estimate the relevance of\n",
      "Cleaned Token After =  information retrieval , okapi bm25 ( bm abbreviation best matching ) ranking function used search engines estimate relevance \n",
      "Cleaned Token After Stem =  inform retriev , okapi bm25 ( bm abbrevi best match ) rank function use search engin estim relev \n",
      "Cleaned Token Before =  the stanford physics information retrieval system (spires) is a database management system developed by stanford university. it is used by universities\n",
      "Cleaned Token After =  stanford physics information retrieval system ( spires ) database management system developed stanford university . used universities \n",
      "Cleaned Token After Stem =  stanford physic inform retriev system ( spire ) databas manag system develop stanford univers . use univers \n",
      "Cleaned Token Before =  the information retrieval facility (irf), founded 2006 and located in vienna, austria, was a research platform for networking and collaboration for professionals\n",
      "Cleaned Token After =  information retrieval facility ( irf ) , founded 2006 located vienna , austria , research platform networking collaboration professionals \n",
      "Cleaned Token After Stem =  inform retriev facil ( irf ) , found 2006 locat vienna , austria , research platform network collabor profession \n",
      "Cleaned Token Before =  kernel can also be applied to image representation for classification or retrieval problems. currently, the most popular bag-of-visual-words representation\n",
      "Cleaned Token After =  kernel also applied image representation classification retrieval problems . currently , popular bag-of-visual-words representation \n",
      "Cleaned Token After Stem =  kernel also appli imag represent classif retriev problem . current , popular bag-of-visual-word represent \n",
      "Cleaned Token Before =  an image retrieval system is a computer system for browsing, searching and retrieving images from a large database of digital images. most traditional\n",
      "Cleaned Token After =  image retrieval system computer system browsing , searching retrieving images large database digital images . traditional \n",
      "Cleaned Token After Stem =  imag retriev system comput system brows , search retriev imag larg databas digit imag . tradit \n",
      "Cleaned Token Before =  'information technology' was appropriate to describe the convergence of technologies with application in the vast field of data storage, retrieval, processing\n",
      "Cleaned Token After =  'information technology ' appropriate describe convergence technologies application vast field data storage , retrieval , processing \n",
      "Cleaned Token After Stem =  'inform technolog ' appropri describ converg technolog applic vast field data storag , retriev , process \n",
      "Cleaned Token Before =  the information retrieval specialist group (irsg) or bcs-irsg is a specialist group of the british computer society concerned with supporting communication\n",
      "Cleaned Token After =  information retrieval specialist group ( irsg ) bcs-irsg specialist group british computer society concerned supporting communication \n",
      "Cleaned Token After Stem =  inform retriev specialist group ( irsg ) bcs-irsg specialist group british comput societi concern support commun \n",
      "Cleaned Token Before =  holes, information retrieval, intelligence gathering, plagiarism detection, pattern recognition, anomaly detection and even art creation. information theory\n",
      "Cleaned Token After =  holes , information retrieval , intelligence gathering , plagiarism detection , pattern recognition , anomaly detection even art creation . information theory \n",
      "Cleaned Token After Stem =  hole , inform retriev , intellig gather , plagiar detect , pattern recognit , anomali detect even art creation . inform theori \n",
      "Cleaned Token Before =  the international journal of multimedia information retrieval is a quarterly peer-reviewed scientific journal published by springer science+business media\n",
      "Cleaned Token After =  international journal multimedia information retrieval quarterly peer-reviewed scientific journal published springer science+business media \n",
      "Cleaned Token After Stem =  intern journal multimedia inform retriev quarterli peer-review scientif journal publish springer science+busi media \n",
      "Cleaned Token Before =  in information retrieval, tf–idf, tf*idf, or tfidf, short for term frequency–inverse document frequency, is a numerical statistic that is intended to\n",
      "Cleaned Token After =  information retrieval , tf–idf , tf * idf , tfidf , short term frequency–inverse document frequency , numerical statistic intended \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Token After Stem =  inform retriev , tf–idf , tf * idf , tfidf , short term frequency–invers document frequenc , numer statist intend \n",
      "Cleaned Token Before =  and to reconstruct the input with significantly lower information loss. information retrieval benefits particularly from dimensionality reduction in\n",
      "Cleaned Token After =  reconstruct input significantly lower information loss . information retrieval benefits particularly dimensionality reduction \n",
      "Cleaned Token After Stem =  reconstruct input significantli lower inform loss . inform retriev benefit particularli dimension reduct \n",
      "Cleaned Token Before =  dictionary setups in dictionarybased cross-language information retrieval. department of information studies university of tampere. pp. 55–63. citeseerx 10\n",
      "Cleaned Token After =  dictionary setups dictionarybased cross-language information retrieval . department information studies university tampere . pp . 55–63 . citeseerx 10 \n",
      "Cleaned Token After Stem =  dictionari setup dictionarybas cross-languag inform retriev . depart inform studi univers tamper . pp . 55–63 . citeseerx 10 \n",
      "Cleaned Token Before =  correct value lies at a given confidence level (e.g., 95%). in information retrieval, the positive predictive value is called precision, and sensitivity\n",
      "Cleaned Token After =  correct value lies given confidence level ( e.g. , 95 % ) . information retrieval , positive predictive value called precision , sensitivity \n",
      "Cleaned Token After Stem =  correct valu lie given confid level ( e.g . , 95 % ) . inform retriev , posit predict valu call precis , sensit \n",
      "Cleaned Token Before =  collecting, parsing, and storing of data to facilitate fast and accurate information retrieval. index design incorporates interdisciplinary concepts from linguistics\n",
      "Cleaned Token After =  collecting , parsing , storing data facilitate fast accurate information retrieval . index design incorporates interdisciplinary concepts linguistics \n",
      "Cleaned Token After Stem =  collect , pars , store data facilit fast accur inform retriev . index design incorpor interdisciplinari concept linguist \n",
      "Cleaned Token Before =  development of large-scale information retrieval applications. terrier was developed by members of the information retrieval research group, department\n",
      "Cleaned Token After =  development large-scale information retrieval applications . terrier developed members information retrieval research group , department \n",
      "Cleaned Token After Stem =  develop large-scal inform retriev applic . terrier develop member inform retriev research group , depart \n",
      "Cleaned Token Before =  knowledge retrieval seeks to return information in a structured form, consistent with human cognitive processes as opposed to simple lists of data items\n",
      "Cleaned Token After =  knowledge retrieval seeks return information structured form , consistent human cognitive processes opposed simple lists data items \n",
      "Cleaned Token After Stem =  knowledg retriev seek return inform structur form , consist human cognit process oppos simpl list data item \n",
      "Cleaned Token Before =  a concept search (or conceptual search) is an automated information retrieval method that is used to search electronically stored unstructured text (for\n",
      "Cleaned Token After =  concept search ( conceptual search ) automated information retrieval method used search electronically stored unstructured text ( \n",
      "Cleaned Token After Stem =  concept search ( conceptu search ) autom inform retriev method use search electron store unstructur text ( \n",
      "Cleaned Token Before =  the international society for music information retrieval (ismir) is an international forum for research on the organization of music-related data. it\n",
      "Cleaned Token After =  international society music information retrieval ( ismir ) international forum research organization music-related data . \n",
      "Cleaned Token After Stem =  intern societi music inform retriev ( ismir ) intern forum research organ music-rel data . \n",
      "Cleaned Token Before =  information seeking and information retrieval, but it also aims to understand why people seek information and how they use it. the term 'information behavior'\n",
      "Cleaned Token After =  information seeking information retrieval , also aims understand people seek information use . term 'information behavior ' \n",
      "Cleaned Token After Stem =  inform seek inform retriev , also aim understand peopl seek inform use . term 'inform behavior ' \n",
      "Cleaned Token Before =  the process of reformulating a given query to improve retrieval performance in information retrieval operations, particularly in the context of query understanding\n",
      "Cleaned Token After =  process reformulating given query improve retrieval performance information retrieval operations , particularly context query understanding \n",
      "Cleaned Token After Stem =  process reformul given queri improv retriev perform inform retriev oper , particularli context queri understand \n",
      "Cleaned Token Before =  sample image that it will then base its search upon; in terms of information retrieval, the sample image is what formulates a search query. in particular\n",
      "Cleaned Token After =  sample image base search upon ; terms information retrieval , sample image formulates search query . particular \n",
      "Cleaned Token After Stem =  sampl imag base search upon ; term inform retriev , sampl imag formul search queri . particular \n",
      "Cleaned Token Before =  the text retrieval conference (trec) is an ongoing series of workshops focusing on a list of different information retrieval (ir) research areas, or tracks\n",
      "Cleaned Token After =  text retrieval conference ( trec ) ongoing series workshops focusing list different information retrieval ( ir ) research areas , tracks \n",
      "Cleaned Token After Stem =  text retriev confer ( trec ) ongo seri workshop focus list differ inform retriev ( ir ) research area , track \n",
      "Cleaned Token Before =  patent application information retrieval (pair) is an online service provided by the united states patent and trademark office to allow users to see the\n",
      "Cleaned Token After =  patent application information retrieval ( pair ) online service provided united states patent trademark office allow users see \n",
      "Cleaned Token After Stem =  patent applic inform retriev ( pair ) onlin servic provid unit state patent trademark offic allow user see \n",
      "Cleaned Token Before =  wide area information server (wais) is a client–server text searching system that uses the ansi standard z39.50 information retrieval service definition\n",
      "Cleaned Token After =  wide area information server ( wais ) client–server text searching system uses ansi standard z39.50 information retrieval service definition \n",
      "Cleaned Token After Stem =  wide area inform server ( wai ) client–serv text search system use ansi standard z39.50 inform retriev servic definit \n",
      "Cleaned Token Before =  parsing, optical character recognition, handwriting recognition, information retrieval and other applications. in speech recognition, sounds are matched\n",
      "Cleaned Token After =  parsing , optical character recognition , handwriting recognition , information retrieval applications . speech recognition , sounds matched \n",
      "Cleaned Token After Stem =  pars , optic charact recognit , handwrit recognit , inform retriev applic . speech recognit , sound match \n",
      "Cleaned Token Before =  while values close to 0 represent very dissimilar documents. an information retrieval technique using latent semantic structure was patented in 1988 (us\n",
      "Cleaned Token After =  values close 0 represent dissimilar documents . information retrieval technique using latent semantic structure patented 1988 ( us \n",
      "Cleaned Token After Stem =  valu close 0 repres dissimilar document . inform retriev techniqu use latent semant structur patent 1988 ( us \n",
      "Cleaned Token Before =  used in information filtering, information retrieval, indexing and relevancy rankings. its first use was in the smart information retrieval system. documents\n",
      "Cleaned Token After =  used information filtering , information retrieval , indexing relevancy rankings . first use smart information retrieval system . documents \n",
      "Cleaned Token After Stem =  use inform filter , inform retriev , index relev rank . first use smart inform retriev system . document \n",
      "Cleaned Token Before =  information retrieval needs hjørland, birger (1997). information seeking and subject representation. an activity-theoretical approach to information science\n",
      "Cleaned Token After =  information retrieval needs hjørland , birger ( 1997 ) . information seeking subject representation . activity-theoretical approach information science \n",
      "Cleaned Token After Stem =  inform retriev need hjørland , birger ( 1997 ) . inform seek subject represent . activity-theoret approach inform scienc \n",
      "Cleaned Token Before =  the european summer school in information retrieval (essir) is a scientific event founded in 1990, which starts off a series of summer schools to provide\n",
      "Cleaned Token After =  european summer school information retrieval ( essir ) scientific event founded 1990 , starts series summer schools provide \n",
      "Cleaned Token After Stem =  european summer school inform retriev ( essir ) scientif event found 1990 , start seri summer school provid \n",
      "Cleaned Token Before =  textbooks randomized algorithms with rajeev motwani and introduction to information retrieval. raghavan's mother, amba raghavan, taught physics and maths at st\n",
      "Cleaned Token After =  textbooks randomized algorithms rajeev motwani introduction information retrieval . raghavan 's mother , amba raghavan , taught physics maths st \n",
      "Cleaned Token After Stem =  textbook random algorithm rajeev motwani introduct inform retriev . raghavan 's mother , amba raghavan , taught physic math st \n",
      "Cleaned Token Before =  reinforcement learning, in the construction of ranking models for information retrieval systems. training data consists of lists of items with some partial\n",
      "Cleaned Token After =  reinforcement learning , construction ranking models information retrieval systems . training data consists lists items partial \n",
      "Cleaned Token After Stem =  reinforc learn , construct rank model inform retriev system . train data consist list item partial \n",
      "Cleaned Token Before =  of health maintain the database as part of the entrez system of information retrieval. from 1971 to 1997, online access to the medline database had been\n",
      "Cleaned Token After =  health maintain database part entrez system information retrieval . 1971 1997 , online access medline database \n",
      "Cleaned Token After Stem =  health maintain databas part entrez system inform retriev . 1971 1997 , onlin access medlin databas \n",
      "Cleaned Token Before =  an information system (is) is a formal, sociotechnical, organizational system designed to collect, process, store, and distribute information. in a sociotechnical\n",
      "Cleaned Token After =  information system ( ) formal , sociotechnical , organizational system designed collect , process , store , distribute information . sociotechnical \n",
      "Cleaned Token After Stem =  inform system ( ) formal , sociotechn , organiz system design collect , process , store , distribut inform . sociotechn \n",
      "Cleaned Token Before =  library and information science researchers, and to some extent among computer science researchers specializing in information retrieval. faceted search\n",
      "Cleaned Token After =  library information science researchers , extent among computer science researchers specializing information retrieval . faceted search \n",
      "Cleaned Token After Stem =  librari inform scienc research , extent among comput scienc research special inform retriev . facet search \n",
      "Cleaned Token Before =  discounted cumulative gain (dcg) is a measure of ranking quality. in information retrieval, it is often used to measure effectiveness of web search engine\n",
      "Cleaned Token After =  discounted cumulative gain ( dcg ) measure ranking quality . information retrieval , often used measure effectiveness web search engine \n",
      "Cleaned Token After Stem =  discount cumul gain ( dcg ) measur rank qualiti . inform retriev , often use measur effect web search engin \n",
      "Cleaned Token Before =  accessed remotely via computer networks. these information retrieval systems are able to exchange information with each other through interoperability and\n",
      "Cleaned Token After =  accessed remotely via computer networks . information retrieval systems able exchange information interoperability \n",
      "Cleaned Token After Stem =  access remot via comput network . inform retriev system abl exchang inform interoper \n",
      "Cleaned Token Before =  d j {\\displaystyle d_{j}} . it is discordant if they disagree. information retrieval quality is usually evaluated by the following three measurements:\n",
      "Cleaned Token After =  j { \\displaystyle d_ { j } } . discordant disagree . information retrieval quality usually evaluated following three measurements : \n",
      "Cleaned Token After Stem =  j { \\displaystyl d_ { j } } . discord disagre . inform retriev qualiti usual evalu follow three measur : \n",
      "Cleaned Token Before =  analysis\" (pdf). proceedings of the international conference on music information retrieval: 625–636. ellis, daniel p.w.; poliner, graham (2007). \"identifying\n",
      "Cleaned Token After =  analysis '' ( pdf ) . proceedings international conference music information retrieval : 625–636 . ellis , daniel p.w . ; poliner , graham ( 2007 ) . `` identifying \n",
      "Cleaned Token After Stem =  analysi `` ( pdf ) . proceed intern confer music inform retriev : 625–636 . elli , daniel p.w . ; polin , graham ( 2007 ) . `` identifi \n",
      "Cleaned Token Before =  they omit one of the words \"electronic\" or \"voting\", or even both. information retrieval web search engine web query classification taxonomy for search engines\n",
      "Cleaned Token After =  omit one words `` electronic '' `` voting '' , even . information retrieval web search engine web query classification taxonomy search engines \n",
      "Cleaned Token After Stem =  omit one word `` electron `` `` vote `` , even . inform retriev web search engin web queri classif taxonomi search engin \n",
      "Cleaned Token Before =  the query likelihood model is a language model used in information retrieval. a language model is constructed for each document in the collection. it\n",
      "Cleaned Token After =  query likelihood model language model used information retrieval . language model constructed document collection . \n",
      "Cleaned Token After Stem =  queri likelihood model languag model use inform retriev . languag model construct document collect . \n",
      "Cleaned Token Before =  in machine learning and information retrieval, the cluster hypothesis is an assumption about the nature of the data handled in those fields, which takes\n",
      "Cleaned Token After =  machine learning information retrieval , cluster hypothesis assumption nature data handled fields , takes \n",
      "Cleaned Token After Stem =  machin learn inform retriev , cluster hypothesi assumpt natur data handl field , take \n",
      "Cleaned Token Before =  normalisation by and large did not help retrieval performance. once the attention of the information retrieval field moved to languages other than english\n",
      "Cleaned Token After =  normalisation large help retrieval performance . attention information retrieval field moved languages english \n",
      "Cleaned Token After Stem =  normalis larg help retriev perform . attent inform retriev field move languag english \n",
      "Cleaned Token Before =  research, including computer vision, document analysis, and music information retrieval. it is relevant for practicing musicians and composers that could\n",
      "Cleaned Token After =  research , including computer vision , document analysis , music information retrieval . relevant practicing musicians composers could \n",
      "Cleaned Token After Stem =  research , includ comput vision , document analysi , music inform retriev . relev practic musician compos could \n",
      "Cleaned Token Before =  commonly used in high-dimensional positive spaces. for example, in information retrieval and text mining, each term is notionally assigned a different dimension\n",
      "Cleaned Token After =  commonly used high-dimensional positive spaces . example , information retrieval text mining , term notionally assigned different dimension \n",
      "Cleaned Token After Stem =  commonli use high-dimension posit space . exampl , inform retriev text mine , term notion assign differ dimens \n",
      "Cleaned Token Before =  the clearinghouse for networked information discovery and retrieval or cnidr was an organization funded by the u.s. national science foundation from 1993\n",
      "Cleaned Token After =  clearinghouse networked information discovery retrieval cnidr organization funded u.s. national science foundation 1993 \n",
      "Cleaned Token After Stem =  clearinghous network inform discoveri retriev cnidr organ fund u.s. nation scienc foundat 1993 \n",
      "Cleaned Token Before =  was the iso international standard for monolingual thesauri for information retrieval, first published in 1974 and revised in 1986. the official title\n",
      "Cleaned Token After =  iso international standard monolingual thesauri information retrieval , first published 1974 revised 1986. official title \n",
      "Cleaned Token After Stem =  iso intern standard monolingu thesauri inform retriev , first publish 1974 revis 1986. offici titl \n",
      "Cleaned Token Before =  roots in information retrieval and information filtering research. to create a user profile, the system mostly focuses on two types of information: 1. a\n",
      "Cleaned Token After =  roots information retrieval information filtering research . create user profile , system mostly focuses two types information : 1. \n",
      "Cleaned Token After Stem =  root inform retriev inform filter research . creat user profil , system mostli focus two type inform : 1 . \n",
      "Cleaned Token Before =  unwieldy amounts of data and information. several technologies applicable to the general area are information retrieval, text mining, machine translation\n",
      "Cleaned Token After =  unwieldy amounts data information . several technologies applicable general area information retrieval , text mining , machine translation \n",
      "Cleaned Token After Stem =  unwieldi amount data inform . sever technolog applic gener area inform retriev , text mine , machin translat \n",
      "Cleaned Token Before =   and whether that solution is guaranteed to be optimal. though information retrieval algorithms must be fast, the quality of ranking, and whether good\n",
      "Cleaned Token After =  whether solution guaranteed optimal . though information retrieval algorithms must fast , quality ranking , whether good \n",
      "Cleaned Token After Stem =  whether solut guarante optim . though inform retriev algorithm must fast , qualiti rank , whether good \n",
      "Cleaned Token Before =  in information retrieval systems which stemmed from the smart information retrieval system which was developed 1960-1964. like many other retrieval systems\n",
      "Cleaned Token After =  information retrieval systems stemmed smart information retrieval system developed 1960-1964. like many retrieval systems \n",
      "Cleaned Token After Stem =  inform retriev system stem smart inform retriev system develop 1960-1964. like mani retriev system \n",
      "Cleaned Token Before =  the information age (also known as the computer age, digital age, or new media age) is a historical period that began in the mid-20th century, characterized\n",
      "Cleaned Token After =  information age ( also known computer age , digital age , new media age ) historical period began mid-20th century , characterized \n",
      "Cleaned Token After Stem =  inform age ( also known comput age , digit age , new media age ) histor period began mid-20th centuri , character \n",
      "Cleaned Token Before =  a metasearch engine (or search aggregator) is an online information retrieval tool that uses the data of a web search engine to produce its own results\n",
      "Cleaned Token After =  metasearch engine ( search aggregator ) online information retrieval tool uses data web search engine produce results \n",
      "Cleaned Token After Stem =  metasearch engin ( search aggreg ) onlin inform retriev tool use data web search engin produc result \n",
      "Cleaned Token Before =  information science to web design which considers, for example, issues of classification and information retrieval. in the big ia view, information architecture\n",
      "Cleaned Token After =  information science web design considers , example , issues classification information retrieval . big ia view , information architecture \n",
      "Cleaned Token After Stem =  inform scienc web design consid , exampl , issu classif inform retriev . big ia view , inform architectur \n",
      "Cleaned Token Before =  beyond its transmission, storage and display. the discipline of information retrieval (ir) has developed automatic methods, typically of a statistical\n",
      "Cleaned Token After =  beyond transmission , storage display . discipline information retrieval ( ir ) developed automatic methods , typically statistical \n",
      "Cleaned Token After Stem =  beyond transmiss , storag display . disciplin inform retriev ( ir ) develop automat method , typic statist \n",
      "Cleaned Token Before =  answering (qa) is a computer science discipline within the fields of information retrieval and natural language processing (nlp), which is concerned with building\n",
      "Cleaned Token After =  answering ( qa ) computer science discipline within fields information retrieval natural language processing ( nlp ) , concerned building \n",
      "Cleaned Token After Stem =  answer ( qa ) comput scienc disciplin within field inform retriev natur languag process ( nlp ) , concern build \n",
      "Cleaned Token Before =  boolean information retrieval\". commun. acm. acm. 26 (11): 1022. doi:10.1145/182.358466. hdl:1813/6351. s2cid 207180535. information retrieval: implementing\n",
      "Cleaned Token After =  boolean information retrieval '' . commun . acm . acm . 26 ( 11 ) : 1022. doi:10.1145/182.358466 . hdl:1813/6351 . s2cid 207180535. information retrieval : implementing \n",
      "Cleaned Token After Stem =  boolean inform retriev `` . commun . acm . acm . 26 ( 11 ) : 1022. doi:10.1145/182.358466 . hdl:1813/6351 . s2cid 207180535. inform retriev : implement \n",
      "Cleaned Token Before =  an index term, subject term, subject heading, or descriptor, in information retrieval, is a term that captures the essence of the topic of a document\n",
      "Cleaned Token After =  index term , subject term , subject heading , descriptor , information retrieval , term captures essence topic document \n",
      "Cleaned Token After Stem =  index term , subject term , subject head , descriptor , inform retriev , term captur essenc topic document \n",
      "Cleaned Token Before =  25964-1:2011 information and documentation -- thesauri and interoperability with other vocabularies -- part 1: thesauri for information retrieval \"iso 25964-1:2011\n",
      "Cleaned Token After =  25964-1:2011 information documentation -- thesauri interoperability vocabularies -- part 1 : thesauri information retrieval `` iso 25964-1:2011 \n",
      "Cleaned Token After Stem =  25964-1:2011 inform document -- thesauri interoper vocabulari -- part 1 : thesauri inform retriev `` iso 25964-1:2011 \n",
      "Cleaned Token Before =  xml retrieval, or xml information retrieval, is the content-based retrieval of documents structured with xml (extensible markup language). as such it\n",
      "Cleaned Token After =  xml retrieval , xml information retrieval , content-based retrieval documents structured xml ( extensible markup language ) . \n",
      "Cleaned Token After Stem =  xml retriev , xml inform retriev , content-bas retriev document structur xml ( extens markup languag ) . \n",
      "Cleaned Token Before =  contributions to the field of information retrieval and is presented in memory of dr tony kent, a past fellow of the institute of information scientists (iis), who\n",
      "Cleaned Token After =  contributions field information retrieval presented memory dr tony kent , past fellow institute information scientists ( iis ) , \n",
      "Cleaned Token After Stem =  contribut field inform retriev present memori dr toni kent , past fellow institut inform scientist ( ii ) , \n",
      "Cleaned Token Before =  as probabilistic latent semantic indexing (plsi, especially in information retrieval circles) is a statistical technique for the analysis of two-mode\n",
      "Cleaned Token After =  probabilistic latent semantic indexing ( plsi , especially information retrieval circles ) statistical technique analysis two-mode \n",
      "Cleaned Token After Stem =  probabilist latent semant index ( plsi , especi inform retriev circl ) statist techniqu analysi two-mod \n",
      "Cleaned Token Before =  a telephone. mfccs are also increasingly finding uses in music information retrieval applications such as genre classification, audio similarity measures\n",
      "Cleaned Token After =  telephone . mfccs also increasingly finding uses music information retrieval applications genre classification , audio similarity measures \n",
      "Cleaned Token After Stem =  telephon . mfcc also increasingli find use music inform retriev applic genr classif , audio similar measur \n",
      "Cleaned Token Before =  also refer to: search engine (computing), an information retrieval system designed to help find information stored on a computer system enterprise search\n",
      "Cleaned Token After =  also refer : search engine ( computing ) , information retrieval system designed help find information stored computer system enterprise search \n",
      "Cleaned Token After Stem =  also refer : search engin ( comput ) , inform retriev system design help find inform store comput system enterpris search \n",
      "Cleaned Token Before =  evaluation (information retrieval evaluation) aims to develop measures of database retrieval performance that shall be comparable across all information retrieval\n",
      "Cleaned Token After =  evaluation ( information retrieval evaluation ) aims develop measures database retrieval performance shall comparable across information retrieval \n",
      "Cleaned Token After Stem =  evalu ( inform retriev evalu ) aim develop measur databas retriev perform shall compar across inform retriev \n",
      "Cleaned Token Before =  search on text and knowledge bases\". foundations and trends in information retrieval. 10 (2–3): 119–271. doi:10.1561/1500000032. retrieved 1 december\n",
      "Cleaned Token After =  search text knowledge bases '' . foundations trends information retrieval . 10 ( 2–3 ) : 119–271 . doi:10.1561/1500000032 . retrieved 1 december \n",
      "Cleaned Token After Stem =  search text knowledg base `` . foundat trend inform retriev . 10 ( 2–3 ) : 119–271 . doi:10.1561/1500000032 . retriev 1 decemb \n",
      "Cleaned Token Before =  now outside the field of ai proper, in pattern recognition and information retrieval. neural networks research had been abandoned by ai and computer\n",
      "Cleaned Token After =  outside field ai proper , pattern recognition information retrieval . neural networks research abandoned ai computer \n",
      "Cleaned Token After Stem =  outsid field ai proper , pattern recognit inform retriev . neural network research abandon ai comput \n",
      "Cleaned Token Before =  1994), was an american computer scientist known for his work in information retrieval and for the programming language trac. mooers was a native of minneapolis\n",
      "Cleaned Token After =  1994 ) , american computer scientist known work information retrieval programming language trac . mooers native minneapolis \n",
      "Cleaned Token After Stem =  1994 ) , american comput scientist known work inform retriev program languag trac . mooer nativ minneapoli \n",
      "Cleaned Token Before =  bit 0. in the mathematical study of computer security, the private information retrieval problem can be modeled as one in which a client, communicating with\n",
      "Cleaned Token After =  bit 0. mathematical study computer security , private information retrieval problem modeled one client , communicating \n",
      "Cleaned Token After Stem =  bit 0. mathemat studi comput secur , privat inform retriev problem model one client , commun \n",
      "Cleaned Token Before =  the overlap coefficient, or szymkiewicz–simpson coefficient, is a similarity measure that measures the overlap between two finite sets. it is related to\n",
      "Cleaned Token After =  overlap coefficient , szymkiewicz–simpson coefficient , similarity measure measures overlap two finite sets . related \n",
      "Cleaned Token After Stem =  overlap coeffici , szymkiewicz–simpson coeffici , similar measur measur overlap two finit set . relat \n",
      "Cleaned Token Before =  and organize web-based information. web content mining is differentiated from two different points of view: information retrieval view and database view\n",
      "Cleaned Token After =  organize web-based information . web content mining differentiated two different points view : information retrieval view database view \n",
      "Cleaned Token After Stem =  organ web-bas inform . web content mine differenti two differ point view : inform retriev view databas view \n",
      "Cleaned Token Before =  in natural language processing and information retrieval, cluster labeling is the problem of picking descriptive, human-readable labels for the clusters\n",
      "Cleaned Token After =  natural language processing information retrieval , cluster labeling problem picking descriptive , human-readable labels clusters \n",
      "Cleaned Token After Stem =  natur languag process inform retriev , cluster label problem pick descript , human-read label cluster \n",
      "Cleaned Token Before =  database – that is organized in a way that facilitates local or remote information retrieval and is able to process many continual queries over a long period\n",
      "Cleaned Token After =  database – organized way facilitates local remote information retrieval able process many continual queries long period \n",
      "Cleaned Token After Stem =  databas – organ way facilit local remot inform retriev abl process mani continu queri long period \n",
      "Cleaned Token Before =  (icr), machine translation and similar applications improve retrieval in information retrieval systems when it is hoped to find similar \"documents\" (a term\n",
      "Cleaned Token After =  ( icr ) , machine translation similar applications improve retrieval information retrieval systems hoped find similar `` documents '' ( term \n",
      "Cleaned Token After Stem =  ( icr ) , machin translat similar applic improv retriev inform retriev system hope find similar `` document `` ( term \n",
      "Cleaned Token Before =  and information systems. broadly, query languages can be classified according to whether they are database query languages or information retrieval query\n",
      "Cleaned Token After =  information systems . broadly , query languages classified according whether database query languages information retrieval query \n",
      "Cleaned Token After Stem =  inform system . broadli , queri languag classifi accord whether databas queri languag inform retriev queri \n",
      "Cleaned Token Before =  relevance feedback is a feature of some information retrieval systems. the idea behind relevance feedback is to take the results that are initially returned\n",
      "Cleaned Token After =  relevance feedback feature information retrieval systems . idea behind relevance feedback take results initially returned \n",
      "Cleaned Token After Stem =  relev feedback featur inform retriev system . idea behind relev feedback take result initi return \n",
      "Cleaned Token Before =  viewdata is a videotex implementation. it is a type of information retrieval service in which a subscriber can access a remote database via a common carrier\n",
      "Cleaned Token After =  viewdata videotex implementation . type information retrieval service subscriber access remote database via common carrier \n",
      "Cleaned Token After Stem =  viewdata videotex implement . type inform retriev servic subscrib access remot databas via common carrier \n",
      "Cleaned Token Before =  elicitation psychographic filtering recommendation system relevance (information retrieval) reputation system robust collaborative filtering similarity search\n",
      "Cleaned Token After =  elicitation psychographic filtering recommendation system relevance ( information retrieval ) reputation system robust collaborative filtering similarity search \n",
      "Cleaned Token After Stem =  elicit psychograph filter recommend system relev ( inform retriev ) reput system robust collabor filter similar search \n",
      "Cleaned Token Before =  a search engine is an information retrieval system designed to help find information stored on a computer system. the search results are usually presented\n",
      "Cleaned Token After =  search engine information retrieval system designed help find information stored computer system . search results usually presented \n",
      "Cleaned Token After Stem =  search engin inform retriev system design help find inform store comput system . search result usual present \n",
      "Cleaned Token Before =  strategies. ismir 2004 – 5th international conference on music information retrieval. joan serra, emilia gomez, perfecto herrera, and xavier serra chroma\n",
      "Cleaned Token After =  strategies . ismir 2004 – 5th international conference music information retrieval . joan serra , emilia gomez , perfecto herrera , xavier serra chroma \n",
      "Cleaned Token After Stem =  strategi . ismir 2004 – 5th intern confer music inform retriev . joan serra , emilia gomez , perfecto herrera , xavier serra chroma \n",
      "Cleaned Token Before =  integration of information from mixed sources dissolving ambiguities in corporate terminology improving information retrieval thereby reducing information overload\n",
      "Cleaned Token After =  integration information mixed sources dissolving ambiguities corporate terminology improving information retrieval thereby reducing information overload \n",
      "Cleaned Token After Stem =  integr inform mix sourc dissolv ambigu corpor terminolog improv inform retriev therebi reduc inform overload \n",
      "Cleaned Token Before =  they are for information retrieval. this is a method similar to tf-idf but it deals with finding keywords suitable for information retrieval and ones that\n",
      "Cleaned Token After =  information retrieval . method similar tf-idf deals finding keywords suitable information retrieval ones \n",
      "Cleaned Token After Stem =  inform retriev . method similar tf-idf deal find keyword suitabl inform retriev one \n",
      "Cleaned Token Before =  human-computer interaction, information science, artificial intelligence, database management and information retrieval. pim relates to but differs from\n",
      "Cleaned Token After =  human-computer interaction , information science , artificial intelligence , database management information retrieval . pim relates differs \n",
      "Cleaned Token After Stem =  human-comput interact , inform scienc , artifici intellig , databas manag inform retriev . pim relat differ \n",
      "Cleaned Token Before =  and methods of information retrieval. based on the research done during development, and in order to support both information retrieval and browsing, history\n",
      "Cleaned Token After =  methods information retrieval . based research done development , order support information retrieval browsing , history \n",
      "Cleaned Token After Stem =  method inform retriev . base research done develop , order support inform retriev brows , histori \n",
      "Cleaned Token Before =  termed \"sensitivity\". the f-score is often used in the field of information retrieval for measuring search, document classification, and query classification\n",
      "Cleaned Token After =  termed `` sensitivity '' . f-score often used field information retrieval measuring search , document classification , query classification \n",
      "Cleaned Token After Stem =  term `` sensit `` . f-score often use field inform retriev measur search , document classif , queri classif \n",
      "Cleaned Token Before =  dictionary. the number sign or hash symbol, '#', has long been used in information technology to highlight specific pieces of text. in 1970, the number\n",
      "Cleaned Token After =  dictionary . number sign hash symbol , ' # ' , long used information technology highlight specific pieces text . 1970 , number \n",
      "Cleaned Token After Stem =  dictionari . number sign hash symbol , ' # ' , long use inform technolog highlight specif piec text . 1970 , number \n",
      "Cleaned Token Before =  experiments, which were founded in the 1950s, and the trec experiments (text retrieval conferences) starting in 1992. it was the cranfield experiments, which\n",
      "Cleaned Token After =  experiments , founded 1950s , trec experiments ( text retrieval conferences ) starting 1992. cranfield experiments , \n",
      "Cleaned Token After Stem =  experi , found 1950 , trec experi ( text retriev confer ) start 1992. cranfield experi , \n",
      "Cleaned Token Before =  institute for scientific information and the inventor of important information retrieval tools such as current contents and the science citation index. the\n",
      "Cleaned Token After =  institute scientific information inventor important information retrieval tools current contents science citation index . \n",
      "Cleaned Token After Stem =  institut scientif inform inventor import inform retriev tool current content scienc citat index . \n",
      "Cleaned Token Before =  of which are journal articles. the academic knowledge api offers information retrieval from the underlying database using rest endpoints for advanced research\n",
      "Cleaned Token After =  journal articles . academic knowledge api offers information retrieval underlying database using rest endpoints advanced research \n",
      "Cleaned Token After Stem =  journal articl . academ knowledg api offer inform retriev underli databas use rest endpoint advanc research \n",
      "Cleaned Token Before =  field.\" from 2008, to recognize her achievements in the fields of information retrieval (ir) and natural language processing (nlp), the karen spärck jones\n",
      "Cleaned Token After =  field . '' 2008 , recognize achievements fields information retrieval ( ir ) natural language processing ( nlp ) , karen spärck jones \n",
      "Cleaned Token After Stem =  field . `` 2008 , recogn achiev field inform retriev ( ir ) natur languag process ( nlp ) , karen spärck jone \n",
      "Cleaned Token Before =  prabhakar raghavan; hinrich schütze (2008). an introduction to information retrieval. cambridge university press. isbn 978-0-521-86571-5. haghighat,\n",
      "Cleaned Token After =  prabhakar raghavan ; hinrich schütze ( 2008 ) . introduction information retrieval . cambridge university press . isbn 978-0-521-86571-5. haghighat , \n",
      "Cleaned Token After Stem =  prabhakar raghavan ; hinrich schütze ( 2008 ) . introduct inform retriev . cambridg univers press . isbn 978-0-521-86571-5. haghighat , \n",
      "Cleaned Token Before =  simplifying representation used in natural language processing and information retrieval (ir). in this model, a text (such as a sentence or a document) is\n",
      "Cleaned Token After =  simplifying representation used natural language processing information retrieval ( ir ) . model , text ( sentence document ) \n",
      "Cleaned Token After Stem =  simplifi represent use natur languag process inform retriev ( ir ) . model , text ( sentenc document ) \n",
      "Cleaned Token Before =  iso 25964 information and documentation - thesauri and interoperability with other vocabularies part 1: thesauri for information retrieval [published\n",
      "Cleaned Token After =  iso 25964 information documentation - thesauri interoperability vocabularies part 1 : thesauri information retrieval [ published \n",
      "Cleaned Token After Stem =  iso 25964 inform document - thesauri interoper vocabulari part 1 : thesauri inform retriev [ publish \n",
      "Cleaned Token Before =  the international society for music information retrieval or international symposium on music information retrieval (ismir) the turkish city of i̇zmir a\n",
      "Cleaned Token After =  international society music information retrieval international symposium music information retrieval ( ismir ) turkish city i̇zmir \n",
      "Cleaned Token After Stem =  intern societi music inform retriev intern symposium music inform retriev ( ismir ) turkish citi i̇zmir \n",
      "Cleaned Token Before =  inspired by vannevar bush's 1930s vision of the microfilm-based information retrieval and management \"memex\" system described in his 1945 essay \"as we\n",
      "Cleaned Token After =  inspired vannevar bush 's 1930s vision microfilm-based information retrieval management `` memex '' system described 1945 essay `` \n",
      "Cleaned Token After Stem =  inspir vannevar bush 's 1930 vision microfilm-bas inform retriev manag `` memex `` system describ 1945 essay `` \n",
      "Cleaned Token Before =  theoretical constructs of information searching and information retrieval. journal of the american society for information sciences and technology. 61(8)\n",
      "Cleaned Token After =  theoretical constructs information searching information retrieval . journal american society information sciences technology . 61 ( 8 ) \n",
      "Cleaned Token After Stem =  theoret construct inform search inform retriev . journal american societi inform scienc technolog . 61 ( 8 ) \n",
      "Cleaned Token Before =  cranfield experiments were a series of experimental studies in information retrieval conducted by cyril w. cleverdon at the college of aeronautics at\n",
      "Cleaned Token After =  cranfield experiments series experimental studies information retrieval conducted cyril w. cleverdon college aeronautics \n",
      "Cleaned Token After Stem =  cranfield experi seri experiment studi inform retriev conduct cyril w. cleverdon colleg aeronaut \n",
      "Cleaned Token Before =  classifiers. in a bag of words model of natural language processing and information retrieval, the data consists of the number of occurrences of each word in\n",
      "Cleaned Token After =  classifiers . bag words model natural language processing information retrieval , data consists number occurrences word \n",
      "Cleaned Token After Stem =  classifi . bag word model natur languag process inform retriev , data consist number occurr word \n",
      "Cleaned Token Before =  involves information retrieval, lexical analysis to study word frequency distributions, pattern recognition, tagging/annotation, information extraction\n",
      "Cleaned Token After =  involves information retrieval , lexical analysis study word frequency distributions , pattern recognition , tagging/annotation , information extraction \n",
      "Cleaned Token After Stem =  involv inform retriev , lexic analysi studi word frequenc distribut , pattern recognit , tagging/annot , inform extract \n",
      "Cleaned Token Before =  publication has been seen as a method of reducing costs associated with information retrieval in research, as universities typically pay to subscribe for access\n",
      "Cleaned Token After =  publication seen method reducing costs associated information retrieval research , universities typically pay subscribe access \n",
      "Cleaned Token After Stem =  public seen method reduc cost associ inform retriev research , univers typic pay subscrib access \n",
      "Cleaned Token Before =  derandomization, theory of fault tolerant computation, and private information retrieval schemes. locally decodable codes are especially useful for data\n",
      "Cleaned Token After =  derandomization , theory fault tolerant computation , private information retrieval schemes . locally decodable codes especially useful data \n",
      "Cleaned Token After Stem =  derandom , theori fault toler comput , privat inform retriev scheme . local decod code especi use data \n",
      "Cleaned Token Before =  sets x and y of keywords used in information retrieval, the coefficient may be defined as twice the shared information (intersection) over the sum of cardinalities :\n",
      "Cleaned Token After =  sets x keywords used information retrieval , coefficient may defined twice shared information ( intersection ) sum cardinalities : \n",
      "Cleaned Token After Stem =  set x keyword use inform retriev , coeffici may defin twice share inform ( intersect ) sum cardin : \n",
      "Cleaned Token Before =  context to mean a different metric originating from the field of information retrieval (see below). in psychometrics and psychophysics, the term accuracy\n",
      "Cleaned Token After =  context mean different metric originating field information retrieval ( see ) . psychometrics psychophysics , term accuracy \n",
      "Cleaned Token After Stem =  context mean differ metric origin field inform retriev ( see ) . psychometr psychophys , term accuraci \n",
      "Cleaned Token Before =  information security, sometimes shortened to infosec, is the practice of protecting information by mitigating information risks. it is part of information\n",
      "Cleaned Token After =  information security , sometimes shortened infosec , practice protecting information mitigating information risks . part information \n",
      "Cleaned Token After Stem =  inform secur , sometim shorten infosec , practic protect inform mitig inform risk . part inform \n",
      "Cleaned Token Before =  pointwise mutual information. proceedings of kdir 2011 : kdir- international conference on knowledge discovery and information retrieval, paris, october\n",
      "Cleaned Token After =  pointwise mutual information . proceedings kdir 2011 : kdir- international conference knowledge discovery information retrieval , paris , october \n",
      "Cleaned Token After Stem =  pointwis mutual inform . proceed kdir 2011 : kdir- intern confer knowledg discoveri inform retriev , pari , octob \n",
      "Cleaned Token Before =  that allow entry, storage and retrieval of large quantities of information and provides ways to manage how that information is organized. because of the\n",
      "Cleaned Token After =  allow entry , storage retrieval large quantities information provides ways manage information organized . \n",
      "Cleaned Token After Stem =  allow entri , storag retriev larg quantiti inform provid way manag inform organ . \n",
      "Cleaned Token Before =  analysis, collection, classification, manipulation, storage, retrieval and dissemination of information. practitioners within the field study the application\n",
      "Cleaned Token After =  analysis , collection , classification , manipulation , storage , retrieval dissemination information . practitioners within field study application \n",
      "Cleaned Token After Stem =  analysi , collect , classif , manipul , storag , retriev dissemin inform . practition within field studi applic \n",
      "Cleaned Token Before =  was created in 2008 by the british computer society (bcs) and its information retrieval specialist group (bcs irsg), which is sponsored by microsoft research\n",
      "Cleaned Token After =  created 2008 british computer society ( bcs ) information retrieval specialist group ( bcs irsg ) , sponsored microsoft research \n",
      "Cleaned Token After Stem =  creat 2008 british comput societi ( bc ) inform retriev specialist group ( bc irsg ) , sponsor microsoft research \n",
      "Cleaned Token Before =  online analytical processing. the name \"trex\" stands for text retrieval and information extraction, but it is not a registered trademark of sap and is\n",
      "Cleaned Token After =  online analytical processing . name `` trex '' stands text retrieval information extraction , registered trademark sap \n",
      "Cleaned Token After Stem =  onlin analyt process . name `` trex `` stand text retriev inform extract , regist trademark sap \n",
      "Cleaned Token Before =  search engine is an information retrieval software program that discovers, crawls, transforms and stores information for retrieval and presentation in\n",
      "Cleaned Token After =  search engine information retrieval software program discovers , crawls , transforms stores information retrieval presentation \n",
      "Cleaned Token After Stem =  search engin inform retriev softwar program discov , crawl , transform store inform retriev present \n",
      "Cleaned Token Before =  framework for probabilistic models to come. it is a formalism of information retrieval useful to derive ranking functions used by search engines and web\n",
      "Cleaned Token After =  framework probabilistic models come . formalism information retrieval useful derive ranking functions used search engines web \n",
      "Cleaned Token After Stem =  framework probabilist model come . formal inform retriev use deriv rank function use search engin web \n",
      "Cleaned Token Before =  effect.[citation needed] spreading activation can also be applied in information retrieval, by means of a network of nodes representing documents and terms\n",
      "Cleaned Token After =  effect . [ citation needed ] spreading activation also applied information retrieval , means network nodes representing documents terms \n",
      "Cleaned Token After Stem =  effect . [ citat need ] spread activ also appli inform retriev , mean network node repres document term \n",
      "Cleaned Token Before =  synchronization tasks have been studied extensively within the field of music information retrieval. in the following, we give some pointers to related tasks. depending\n",
      "Cleaned Token After =  synchronization tasks studied extensively within field music information retrieval . following , give pointers related tasks . depending \n",
      "Cleaned Token After Stem =  synchron task studi extens within field music inform retriev . follow , give pointer relat task . depend \n",
      "Cleaned Token Before =  h5 is a privately held company specializing in information retrieval systems for the legal industry, with offices in san francisco and new york city.\n",
      "Cleaned Token After =  h5 privately held company specializing information retrieval systems legal industry , offices san francisco new york city . \n",
      "Cleaned Token After Stem =  h5 privat held compani special inform retriev system legal industri , offic san francisco new york citi . \n",
      "Cleaned Token Before =  in natural language processing and information retrieval, explicit semantic analysis (esa) is a vectoral representation of text (individual words or entire\n",
      "Cleaned Token After =  natural language processing information retrieval , explicit semantic analysis ( esa ) vectoral representation text ( individual words entire \n",
      "Cleaned Token After Stem =  natur languag process inform retriev , explicit semant analysi ( esa ) vector represent text ( individu word entir \n",
      "Cleaned Token Before =  linear memor\". proceedings of the international conference on music information retrieval (ismir). silva, d. f., batista, g. e. a. p. a. (2015). speeding\n",
      "Cleaned Token After =  linear memor '' . proceedings international conference music information retrieval ( ismir ) . silva , d. f. , batista , g. e. a. p. . ( 2015 ) . speeding \n",
      "Cleaned Token After Stem =  linear memor `` . proceed intern confer music inform retriev ( ismir ) . silva , d. f. , batista , g. e. a. p. . ( 2015 ) . speed \n",
      "Cleaned Token Before =  to improve performance. hans peter luhn, one of the pioneers in information retrieval, is credited with coining the phrase and using the concept. the\n",
      "Cleaned Token After =  improve performance . hans peter luhn , one pioneers information retrieval , credited coining phrase using concept . \n",
      "Cleaned Token After Stem =  improv perform . han peter luhn , one pioneer inform retriev , credit coin phrase use concept . \n",
      "Cleaned Token Before =  dirk lewandowski (born 1973) is a german professor of information research and information retrieval at the hamburg university of applied sciences, germany\n",
      "Cleaned Token After =  dirk lewandowski ( born 1973 ) german professor information research information retrieval hamburg university applied sciences , germany \n",
      "Cleaned Token After Stem =  dirk lewandowski ( born 1973 ) german professor inform research inform retriev hamburg univers appli scienc , germani \n",
      "Cleaned Token Before =  intranets that let users combine their efforts in information retrieval (ir) activities, share information resources collaboratively using knowledge tags\n",
      "Cleaned Token After =  intranets let users combine efforts information retrieval ( ir ) activities , share information resources collaboratively using knowledge tags \n",
      "Cleaned Token After Stem =  intranet let user combin effort inform retriev ( ir ) activ , share inform resourc collabor use knowledg tag \n",
      "Cleaned Token Before =  information retrieval group. he is one of the founders of modern information retrieval and the author of the seminal monograph information retrieval and\n",
      "Cleaned Token After =  information retrieval group . one founders modern information retrieval author seminal monograph information retrieval \n",
      "Cleaned Token After Stem =  inform retriev group . one founder modern inform retriev author semin monograph inform retriev \n",
      "Cleaned Token Before =  potential alternative metric. information retrieval question answering e.m. voorhees (1999). \"proceedings of the 8th text retrieval conference\" (pdf). trec-8\n",
      "Cleaned Token After =  potential alternative metric . information retrieval question answering e.m. voorhees ( 1999 ) . `` proceedings 8th text retrieval conference '' ( pdf ) . trec-8 \n",
      "Cleaned Token After Stem =  potenti altern metric . inform retriev question answer e.m. voorhe ( 1999 ) . `` proceed 8th text retriev confer `` ( pdf ) . trec-8 \n",
      "Cleaned Token Before =  in text retrieval, full-text search refers to techniques for searching a single computer-stored document or a collection in a full-text database. full-text\n",
      "Cleaned Token After =  text retrieval , full-text search refers techniques searching single computer-stored document collection full-text database . full-text \n",
      "Cleaned Token After Stem =  text retriev , full-text search refer techniqu search singl computer-stor document collect full-text databas . full-text \n",
      "Cleaned Token Before =   retrieved 2020-05-27. goh, dion; foo, schubert (2007). social information retrieval systems: emerging technologies and applications for searching the\n",
      "Cleaned Token After =  retrieved 2020-05-27. goh , dion ; foo , schubert ( 2007 ) . social information retrieval systems : emerging technologies applications searching \n",
      "Cleaned Token After Stem =  retriev 2020-05-27. goh , dion ; foo , schubert ( 2007 ) . social inform retriev system : emerg technolog applic search \n",
      "Cleaned Token Before =  of information retrieval during his time, and \"the father of information retrieval\". his group at cornell developed the smart information retrieval system\n",
      "Cleaned Token After =  information retrieval time , `` father information retrieval '' . group cornell developed smart information retrieval system \n",
      "Cleaned Token After Stem =  inform retriev time , `` father inform retriev `` . group cornel develop smart inform retriev system \n",
      "Cleaned Token Before =  the auspices of nist for the purpose of evaluating systems for information retrieval and related technologies in the genomics domain. the trec genomics\n",
      "Cleaned Token After =  auspices nist purpose evaluating systems information retrieval related technologies genomics domain . trec genomics \n",
      "Cleaned Token After Stem =  auspic nist purpos evalu system inform retriev relat technolog genom domain . trec genom \n",
      "Cleaned Token Before =  the webometrics ranking of business schools, also known as ranking web of business schools, is a ranking system for the world's business schools based\n",
      "Cleaned Token After =  webometrics ranking business schools , also known ranking web business schools , ranking system world 's business schools based \n",
      "Cleaned Token After Stem =  webometr rank busi school , also known rank web busi school , rank system world 's busi school base \n",
      "Cleaned Token Before =  latter notion of oblivious transfer is a strengthening of private information retrieval, in which the database is not kept private. claude crépeau showed\n",
      "Cleaned Token After =  latter notion oblivious transfer strengthening private information retrieval , database kept private . claude crépeau showed \n",
      "Cleaned Token After Stem =  latter notion oblivi transfer strengthen privat inform retriev , databas kept privat . claud crépeau show \n",
      "Cleaned Token Before =  made in relation to information retrieval and the interpretation of the observation is used commonly throughout the information profession both within\n",
      "Cleaned Token After =  made relation information retrieval interpretation observation used commonly throughout information profession within \n",
      "Cleaned Token After Stem =  made relat inform retriev interpret observ use commonli throughout inform profess within \n",
      "Cleaned Token Before =  that a good value reported by this method does not imply the best information retrieval.[citation needed] given n dimensional points, let ci be a cluster\n",
      "Cleaned Token After =  good value reported method imply best information retrieval . [ citation needed ] given n dimensional points , let ci cluster \n",
      "Cleaned Token After Stem =  good valu report method impli best inform retriev . [ citat need ] given n dimension point , let ci cluster \n",
      "Cleaned Token Before =  association for computing machinery (acm) special interest group on information retrieval (sigir) every three years to an individual who has made \"significant\n",
      "Cleaned Token After =  association computing machinery ( acm ) special interest group information retrieval ( sigir ) every three years individual made `` significant \n",
      "Cleaned Token After Stem =  associ comput machineri ( acm ) special interest group inform retriev ( sigir ) everi three year individu made `` signific \n",
      "Cleaned Token Before =  articles) within a field of knowledge. subject indexing is used in information retrieval especially to create bibliographic indexes to retrieve documents\n",
      "Cleaned Token After =  articles ) within field knowledge . subject indexing used information retrieval especially create bibliographic indexes retrieve documents \n",
      "Cleaned Token After Stem =  articl ) within field knowledg . subject index use inform retriev especi creat bibliograph index retriev document \n",
      "Cleaned Token Before =  in many fields, including pattern recognition, image analysis, information retrieval, bioinformatics, data compression, computer graphics and machine\n",
      "Cleaned Token After =  many fields , including pattern recognition , image analysis , information retrieval , bioinformatics , data compression , computer graphics machine \n",
      "Cleaned Token After Stem =  mani field , includ pattern recognit , imag analysi , inform retriev , bioinformat , data compress , comput graphic machin \n",
      "Cleaned Token Before =  from, say, 1–5 for \"very poor\" through \"excellent\"), as well as in information retrieval. in machine learning, ordinal regression may also be called ranking\n",
      "Cleaned Token After =  , say , 1–5 `` poor '' `` excellent '' ) , well information retrieval . machine learning , ordinal regression may also called ranking \n",
      "Cleaned Token After Stem =  , say , 1–5 `` poor `` `` excel `` ) , well inform retriev . machin learn , ordin regress may also call rank \n",
      "Cleaned Token Before =  representing queries to information retrieval systems such as search engines, bibliographic catalogs and museum collection information. based on the semantics\n",
      "Cleaned Token After =  representing queries information retrieval systems search engines , bibliographic catalogs museum collection information . based semantics \n",
      "Cleaned Token After Stem =  repres queri inform retriev system search engin , bibliograph catalog museum collect inform . base semant \n",
      "Cleaned Token Before =  of users.) $ find . -name 'my*' -type f -ls this prints extended file information. $ find / -name myfile -type f -print this searches every directory for\n",
      "Cleaned Token After =  users . ) $ find . -name 'my * ' -type f -ls prints extended file information . $ find / -name myfile -type f -print searches every directory \n",
      "Cleaned Token After Stem =  user . ) $ find . -name 'mi * ' -type f -l print extend file inform . $ find / -name myfil -type f -print search everi directori \n",
      "Cleaned Token Before =  in industry, deciding whether a specification has been met; in information retrieval, deciding whether a page should be in the result set of a search\n",
      "Cleaned Token After =  industry , deciding whether specification met ; information retrieval , deciding whether page result set search \n",
      "Cleaned Token After Stem =  industri , decid whether specif met ; inform retriev , decid whether page result set search \n",
      "Cleaned Token Before =  services differ from current search engines based on traditional information retrieval that return lists of documents based on their relevance to the query\n",
      "Cleaned Token After =  services differ current search engines based traditional information retrieval return lists documents based relevance query \n",
      "Cleaned Token After Stem =  servic differ current search engin base tradit inform retriev return list document base relev queri \n",
      "Cleaned Token Before =  in linguistic morphology and information retrieval, stemming is the process of reducing inflected (or sometimes derived) words to their word stem, base\n",
      "Cleaned Token After =  linguistic morphology information retrieval , stemming process reducing inflected ( sometimes derived ) words word stem , base \n",
      "Cleaned Token After Stem =  linguist morpholog inform retriev , stem process reduc inflect ( sometim deriv ) word word stem , base \n",
      "Cleaned Token Before =  may not matter for some applications. in fact, when used within information retrieval systems, stemming improves query recall accuracy, or true positive\n",
      "Cleaned Token After =  may matter applications . fact , used within information retrieval systems , stemming improves query recall accuracy , true positive \n",
      "Cleaned Token After Stem =  may matter applic . fact , use within inform retriev system , stem improv queri recal accuraci , true posit \n",
      "Cleaned Token Before =  any such kind of information retrieval (ir) programs. multisearch is an emerging feature of automated search and information retrieval systems which combines\n",
      "Cleaned Token After =  kind information retrieval ( ir ) programs . multisearch emerging feature automated search information retrieval systems combines \n",
      "Cleaned Token After Stem =  kind inform retriev ( ir ) program . multisearch emerg featur autom search inform retriev system combin \n",
      "Cleaned Token Before =  interaction between humans and information retrieval systems. belkin is best known for his work on human-centered information retrieval and the hypothesis of anomalous\n",
      "Cleaned Token After =  interaction humans information retrieval systems . belkin best known work human-centered information retrieval hypothesis anomalous \n",
      "Cleaned Token After Stem =  interact human inform retriev system . belkin best known work human-cent inform retriev hypothesi anomal \n",
      "Cleaned Token Before =   according to its literature, it was \"the world's first online information retrieval system to be used globally with materially significant databases\"\n",
      "Cleaned Token After =  according literature , `` world 's first online information retrieval system used globally materially significant databases '' \n",
      "Cleaned Token After Stem =  accord literatur , `` world 's first onlin inform retriev system use global materi signific databas `` \n",
      "Cleaned Token Before =  controlled vocabularies provide a way to organize knowledge for subsequent retrieval. they are used in subject indexing schemes, subject headings, thesauri\n",
      "Cleaned Token After =  controlled vocabularies provide way organize knowledge subsequent retrieval . used subject indexing schemes , subject headings , thesauri \n",
      "Cleaned Token After Stem =  control vocabulari provid way organ knowledg subsequ retriev . use subject index scheme , subject head , thesauri \n",
      "Cleaned Token Before =  indexing, audio analytics, speech analytics, word spotting, and information retrieval. audio indexing, however, is mostly used to describe the pre-process\n",
      "Cleaned Token After =  indexing , audio analytics , speech analytics , word spotting , information retrieval . audio indexing , however , mostly used describe pre-process \n",
      "Cleaned Token After Stem =  index , audio analyt , speech analyt , word spot , inform retriev . audio index , howev , mostli use describ pre-process \n",
      "Cleaned Token Before =  influencing interaction with multimedia information.\" in proceedings of theseus/imageclef workshop on visual information retrieval evaluation, pp. 8-11. 2009. amigó\n",
      "Cleaned Token After =  influencing interaction multimedia information . '' proceedings theseus/imageclef workshop visual information retrieval evaluation , pp . 8-11 . 2009. amigó \n",
      "Cleaned Token After Stem =  influenc interact multimedia inform . `` proceed theseus/imageclef workshop visual inform retriev evalu , pp . 8-11 . 2009. amigó \n",
      "Cleaned Token Before =  this is a list of publicly available content-based image retrieval (cbir) engines. these image search engines look at the content (pixels) of images in\n",
      "Cleaned Token After =  list publicly available content-based image retrieval ( cbir ) engines . image search engines look content ( pixels ) images \n",
      "Cleaned Token After Stem =  list publicli avail content-bas imag retriev ( cbir ) engin . imag search engin look content ( pixel ) imag \n",
      "Cleaned Token Before =  in computer science and information science, an ontology encompasses a representation, formal naming and definition of the categories, properties and\n",
      "Cleaned Token After =  computer science information science , ontology encompasses representation , formal naming definition categories , properties \n",
      "Cleaned Token After Stem =  comput scienc inform scienc , ontolog encompass represent , formal name definit categori , properti \n",
      "Cleaned Token Before =  moreover, entity linking has been used to improve the performance of information retrieval systems and to improve search performance on digital libraries.\n",
      "Cleaned Token After =  moreover , entity linking used improve performance information retrieval systems improve search performance digital libraries . \n",
      "Cleaned Token After Stem =  moreov , entiti link use improv perform inform retriev system improv search perform digit librari . \n",
      "Cleaned Token Before =  the positive predictive value, the two are numerically equal. in information retrieval, the ppv statistic is often called the precision. the positive predictive\n",
      "Cleaned Token After =  positive predictive value , two numerically equal . information retrieval , ppv statistic often called precision . positive predictive \n",
      "Cleaned Token After Stem =  posit predict valu , two numer equal . inform retriev , ppv statist often call precis . posit predict \n",
      "Cleaned Token Before =  δp'). markedness and informedness correspond to different directions of information flow and generalize youden's j statistic, the δ {\\displaystyle \\delta\n",
      "Cleaned Token After =  δp ' ) . markedness informedness correspond different directions information flow generalize youden 's j statistic , δ { \\displaystyle \\delta \n",
      "Cleaned Token After Stem =  δp ' ) . marked informed correspond differ direct inform flow gener youden 's j statist , δ { \\displaystyl \\delta \n",
      "Cleaned Token Before =  quantum information science is an interdisciplinary field that seeks to understand the analysis, processing, and transmission of information using quantum\n",
      "Cleaned Token After =  quantum information science interdisciplinary field seeks understand analysis , processing , transmission information using quantum \n",
      "Cleaned Token After Stem =  quantum inform scienc interdisciplinari field seek understand analysi , process , transmiss inform use quantum \n",
      "Cleaned Token Before =  web research for the social sciences. synthesis lectures on information concepts, retrieval, and services. 1. morgan & claypool. pp. 1–116. doi:10\n",
      "Cleaned Token After =  web research social sciences . synthesis lectures information concepts , retrieval , services . 1. morgan & claypool . pp . 1–116 . doi:10 \n",
      "Cleaned Token After Stem =  web research social scienc . synthesi lectur inform concept , retriev , servic . 1. morgan & claypool . pp . 1–116 . doi:10 \n",
      "Cleaned Token Before =  fuzzy retrieval techniques are based on the extended boolean model and the fuzzy set theory. there are two classical fuzzy retrieval models: mixed min\n",
      "Cleaned Token After =  fuzzy retrieval techniques based extended boolean model fuzzy set theory . two classical fuzzy retrieval models : mixed min \n",
      "Cleaned Token After Stem =  fuzzi retriev techniqu base extend boolean model fuzzi set theori . two classic fuzzi retriev model : mix min \n",
      "Cleaned Token Before =   journal of multimedia list of search engines multimedia multimedia information retrieval search engine indexing streaming media video search engine\n",
      "Cleaned Token After =  journal multimedia list search engines multimedia multimedia information retrieval search engine indexing streaming media video search engine \n",
      "Cleaned Token After Stem =  journal multimedia list search engin multimedia multimedia inform retriev search engin index stream media video search engin \n",
      "Cleaned Token Before =  task of keyword extraction is an important problem in text mining, information retrieval and natural language processing. keyword assignment methods can\n",
      "Cleaned Token After =  task keyword extraction important problem text mining , information retrieval natural language processing . keyword assignment methods \n",
      "Cleaned Token After Stem =  task keyword extract import problem text mine , inform retriev natur languag process . keyword assign method \n",
      "Cleaned Token Before =  rutkowski, semantic compression for specialised information retrieval systems, advances in intelligent information and database systems, vol. 283, p. 111-121\n",
      "Cleaned Token After =  rutkowski , semantic compression specialised information retrieval systems , advances intelligent information database systems , vol . 283 , p. 111-121 \n",
      "Cleaned Token After Stem =  rutkowski , semant compress specialis inform retriev system , advanc intellig inform databas system , vol . 283 , p. 111-121 \n",
      "Cleaned Token Before =  metaphor text mining chen, ran; hongfei lin & zhihao yang (2011). \"passage retrieval based hidden knowledge discovery from biomedical literature.\" expert systems\n",
      "Cleaned Token After =  metaphor text mining chen , ran ; hongfei lin & zhihao yang ( 2011 ) . `` passage retrieval based hidden knowledge discovery biomedical literature . '' expert systems \n",
      "Cleaned Token After Stem =  metaphor text mine chen , ran ; hongfei lin & zhihao yang ( 2011 ) . `` passag retriev base hidden knowledg discoveri biomed literatur . `` expert system \n",
      "Cleaned Token Before =  space model is a generalization of the vector space model used in information retrieval. wong et al. presented an analysis of the problems that the pairwise\n",
      "Cleaned Token After =  space model generalization vector space model used information retrieval . wong et al . presented analysis problems pairwise \n",
      "Cleaned Token After Stem =  space model gener vector space model use inform retriev . wong et al . present analysi problem pairwis \n",
      "Cleaned Token Before =  and expressive differentiable programming\" (pdf), advances in neural information processing systems 31, curran associates, inc., pp. 10201–10212, retrieved\n",
      "Cleaned Token After =  expressive differentiable programming '' ( pdf ) , advances neural information processing systems 31 , curran associates , inc. , pp . 10201–10212 , retrieved \n",
      "Cleaned Token After Stem =  express differenti program `` ( pdf ) , advanc neural inform process system 31 , curran associ , inc. , pp . 10201–10212 , retriev \n",
      "Cleaned Token Before =  with combining hierarchical and non-hierarchical tagging to aid in information retrieval. others are combining top-down and bottom-up tagging, including\n",
      "Cleaned Token After =  combining hierarchical non-hierarchical tagging aid information retrieval . others combining top-down bottom-up tagging , including \n",
      "Cleaned Token After Stem =  combin hierarch non-hierarch tag aid inform retriev . other combin top-down bottom-up tag , includ \n",
      "Cleaned Token Before =  applications in automatic document organization, topic extraction and fast information retrieval or filtering. document clustering involves the use of descriptors\n",
      "Cleaned Token After =  applications automatic document organization , topic extraction fast information retrieval filtering . document clustering involves use descriptors \n",
      "Cleaned Token After Stem =  applic automat document organ , topic extract fast inform retriev filter . document cluster involv use descriptor \n",
      "Cleaned Token Before =  known for her work in document retrieval, information retrieval, and natural language processing. she works in the retrieval group at the national institute\n",
      "Cleaned Token After =  known work document retrieval , information retrieval , natural language processing . works retrieval group national institute \n",
      "Cleaned Token After Stem =  known work document retriev , inform retriev , natur languag process . work retriev group nation institut \n",
      "Cleaned Token Before =  do not. \"crawling\" (a human by-eye search) is not necessary to find information stored in a database because the data is already structured. indexing\n",
      "Cleaned Token After =  . `` crawling '' ( human by-eye search ) necessary find information stored database data already structured . indexing \n",
      "Cleaned Token After Stem =  . `` crawl `` ( human by-ey search ) necessari find inform store databas data alreadi structur . index \n",
      "Cleaned Token Before =  for the stored information resources. since the 1970s these metadata are in machine-readable form and are indexed by information retrieval tools, such as\n",
      "Cleaned Token After =  stored information resources . since 1970s metadata machine-readable form indexed information retrieval tools , \n",
      "Cleaned Token After Stem =  store inform resourc . sinc 1970 metadata machine-read form index inform retriev tool , \n",
      "Cleaned Token Before =  different chosen methods. the engine also provides different multistage retrieval, as well as a single text index baseline to be able to compare all the\n",
      "Cleaned Token After =  different chosen methods . engine also provides different multistage retrieval , well single text index baseline able compare \n",
      "Cleaned Token After Stem =  differ chosen method . engin also provid differ multistag retriev , well singl text index baselin abl compar \n",
      "Cleaned Token Before =  image retrieval. a visual search engine searches images, patterns based on an algorithm which it could recognize and gives relative information based\n",
      "Cleaned Token After =  image retrieval . visual search engine searches images , patterns based algorithm could recognize gives relative information based \n",
      "Cleaned Token After Stem =  imag retriev . visual search engin search imag , pattern base algorithm could recogn give rel inform base \n",
      "Cleaned Token Before =  an information society is a society where the usage, creation, distribution, manipulation and integration of information is a significant activity. its\n",
      "Cleaned Token After =  information society society usage , creation , distribution , manipulation integration information significant activity . \n",
      "Cleaned Token After Stem =  inform societi societi usag , creation , distribut , manipul integr inform signific activ . \n",
      "Cleaned Token Before =  \"document clustering of scientific texts using citation contexts\". information retrieval. springer. 13 (2): 101–131. doi:10.1007/s10791-009-9108-x. needs\n",
      "Cleaned Token After =  `` document clustering scientific texts using citation contexts '' . information retrieval . springer . 13 ( 2 ) : 101–131 . doi:10.1007/s10791-009-9108-x . needs \n",
      "Cleaned Token After Stem =  `` document cluster scientif text use citat context `` . inform retriev . springer . 13 ( 2 ) : 101–131 . doi:10.1007/s10791-009-9108-x . need \n",
      "Cleaned Token Before =  minnesota duluth: umd was the turning point in my life. studying information retrieval with don crouch and then don recommending that i move to cornell\n",
      "Cleaned Token After =  minnesota duluth : umd turning point life . studying information retrieval crouch recommending move cornell \n",
      "Cleaned Token After Stem =  minnesota duluth : umd turn point life . studi inform retriev crouch recommend move cornel \n",
      "Cleaned Token Before =  librarianship information retrieval information school information scientist international society for knowledge organization (isko) library and information science\n",
      "Cleaned Token After =  librarianship information retrieval information school information scientist international society knowledge organization ( isko ) library information science \n",
      "Cleaned Token After Stem =  librarianship inform retriev inform school inform scientist intern societi knowledg organ ( isko ) librari inform scienc \n",
      "Cleaned Token Before =  library systems. the organization of knowledge for efficient retrieval of relevant information is also a major research goal of library science. being interdisciplinary\n",
      "Cleaned Token After =  library systems . organization knowledge efficient retrieval relevant information also major research goal library science . interdisciplinary \n",
      "Cleaned Token After Stem =  librari system . organ knowledg effici retriev relev inform also major research goal librari scienc . interdisciplinari \n",
      "Cleaned Token Before =  broader definition, voice search includes open-domain keyword query on any information on the internet, for example in google voice search, cortana, siri and\n",
      "Cleaned Token After =  broader definition , voice search includes open-domain keyword query information internet , example google voice search , cortana , siri \n",
      "Cleaned Token After Stem =  broader definit , voic search includ open-domain keyword queri inform internet , exampl googl voic search , cortana , siri \n",
      "Cleaned Token Before =  activities than typical information retrieval, such as investigating, evaluating, comparing, and synthesizing, where new information is sought in a defined\n",
      "Cleaned Token After =  activities typical information retrieval , investigating , evaluating , comparing , synthesizing , new information sought defined \n",
      "Cleaned Token After Stem =  activ typic inform retriev , investig , evalu , compar , synthes , new inform sought defin \n",
      "Cleaned Token Before =  recall in memory refers to the mental process of retrieval of information from the past. along with encoding and storage, it is one of the three core processes\n",
      "Cleaned Token After =  recall memory refers mental process retrieval information past . along encoding storage , one three core processes \n",
      "Cleaned Token After Stem =  recal memori refer mental process retriev inform past . along encod storag , one three core process \n",
      "Cleaned Token Before =  neural information processing systems: 451–457. liu, tie-yan (2009). \"learning to rank for information retrieval\". foundations and trends in information retrieval\n",
      "Cleaned Token After =  neural information processing systems : 451–457 . liu , tie-yan ( 2009 ) . `` learning rank information retrieval '' . foundations trends information retrieval \n",
      "Cleaned Token After Stem =  neural inform process system : 451–457 . liu , tie-yan ( 2009 ) . `` learn rank inform retriev `` . foundat trend inform retriev \n",
      "Cleaned Token Before =  along with query-dependent factors traditionally associated with information retrieval algorithms. also, the rich functionality of enterprise search uis\n",
      "Cleaned Token After =  along query-dependent factors traditionally associated information retrieval algorithms . also , rich functionality enterprise search uis \n",
      "Cleaned Token After Stem =  along query-depend factor tradit associ inform retriev algorithm . also , rich function enterpris search ui \n",
      "Cleaned Token Before =  (pdf). information retrieval and data science group. information retrieval and data science group. retrieved 27 august 2018. \"usc irds - information retrieval\n",
      "Cleaned Token After =  ( pdf ) . information retrieval data science group . information retrieval data science group . retrieved 27 august 2018 . `` usc irds - information retrieval \n",
      "Cleaned Token After Stem =  ( pdf ) . inform retriev data scienc group . inform retriev data scienc group . retriev 27 august 2018 . `` usc ird - inform retriev \n",
      "Cleaned Token Before =  data tier is queried by the logic or business tier when information is needed using a data retrieval language like sql. in a search-oriented architecture\n",
      "Cleaned Token After =  data tier queried logic business tier information needed using data retrieval language like sql . search-oriented architecture \n",
      "Cleaned Token After Stem =  data tier queri logic busi tier inform need use data retriev languag like sql . search-ori architectur \n",
      "Cleaned Token Before =  with his former ph.d. advisor gaston gonnet, information retrieval. co-author of modern information retrieval addison wesley, isbn 0-201-39829-x, first edition\n",
      "Cleaned Token After =  former ph.d. advisor gaston gonnet , information retrieval . co-author modern information retrieval addison wesley , isbn 0-201-39829-x , first edition \n",
      "Cleaned Token After Stem =  former ph.d. advisor gaston gonnet , inform retriev . co-author modern inform retriev addison wesley , isbn 0-201-39829-x , first edit \n",
      "Cleaned Token Before =  and wikipedia are examples of new forms of the encyclopedia as information retrieval becomes simpler. the method of production for an encyclopedia historically\n",
      "Cleaned Token After =  wikipedia examples new forms encyclopedia information retrieval becomes simpler . method production encyclopedia historically \n",
      "Cleaned Token After Stem =  wikipedia exampl new form encyclopedia inform retriev becom simpler . method product encyclopedia histor \n",
      "Cleaned Token Before =  foreign language reading aid foreign language writing aid information extraction information retrieval language and communication technologies language technology\n",
      "Cleaned Token After =  foreign language reading aid foreign language writing aid information extraction information retrieval language communication technologies language technology \n",
      "Cleaned Token After Stem =  foreign languag read aid foreign languag write aid inform extract inform retriev languag commun technolog languag technolog \n",
      "Cleaned Token Before =  technique that aids information retention or retrieval (remembering) in the human memory. mnemonics make use of elaborative encoding, retrieval cues, and imagery\n",
      "Cleaned Token After =  technique aids information retention retrieval ( remembering ) human memory . mnemonics make use elaborative encoding , retrieval cues , imagery \n",
      "Cleaned Token After Stem =  techniqu aid inform retent retriev ( rememb ) human memori . mnemon make use elabor encod , retriev cue , imageri \n",
      "Cleaned Token Before =  the internet is rooted in the .arpa top-level domain. although the informational rfc 1912 (section 2.1) recommends that \"every internet-reachable host\n",
      "Cleaned Token After =  internet rooted .arpa top-level domain . although informational rfc 1912 ( section 2.1 ) recommends `` every internet-reachable host \n",
      "Cleaned Token After Stem =  internet root .arpa top-level domain . although inform rfc 1912 ( section 2.1 ) recommend `` everi internet-reach host \n",
      "Cleaned Token Before =  to-be-remembered information. the effect is also sometimes referred to as retrieval practice, practice testing, or test-enhanced learning. retrieval practice\n",
      "Cleaned Token After =  to-be-remembered information . effect also sometimes referred retrieval practice , practice testing , test-enhanced learning . retrieval practice \n",
      "Cleaned Token After Stem =  to-be-rememb inform . effect also sometim refer retriev practic , practic test , test-enhanc learn . retriev practic \n",
      "Cleaned Token Before =  04.007. portfolio theory of information retrieval july 11th, 2009 (2009-07-11). \"portfolio theory of information retrieval | dr. jun wang's home page\"\n",
      "Cleaned Token After =  04.007. portfolio theory information retrieval july 11th , 2009 ( 2009-07-11 ) . `` portfolio theory information retrieval | dr. jun wang 's home page '' \n",
      "Cleaned Token After Stem =  04.007. portfolio theori inform retriev juli 11th , 2009 ( 2009-07-11 ) . `` portfolio theori inform retriev | dr. jun wang 's home page `` \n",
      "Cleaned Token Before =  argument mining, or argumentation mining, is a research area within the natural-language processing field. the goal of argument mining is the automatic\n",
      "Cleaned Token After =  argument mining , argumentation mining , research area within natural-language processing field . goal argument mining automatic \n",
      "Cleaned Token After Stem =  argument mine , argument mine , research area within natural-languag process field . goal argument mine automat \n",
      "Cleaned Token Before =  libraries informatics (academic field) information management information retrieval information science information systems internet search engines and libraries\n",
      "Cleaned Token After =  libraries informatics ( academic field ) information management information retrieval information science information systems internet search engines libraries \n",
      "Cleaned Token After Stem =  librari informat ( academ field ) inform manag inform retriev inform scienc inform system internet search engin librari \n",
      "Cleaned Token Before =  the interchange of cultural heritage information iso 23950 information and documentation – information retrieval (z39.50) – application service definition\n",
      "Cleaned Token After =  interchange cultural heritage information iso 23950 information documentation – information retrieval ( z39.50 ) – application service definition \n",
      "Cleaned Token After Stem =  interchang cultur heritag inform iso 23950 inform document – inform retriev ( z39.50 ) – applic servic definit \n",
      "Cleaned Token Before =  an automated storage and retrieval system (asrs or as/rs) consists of a variety of computer-controlled systems for automatically placing and retrieving\n",
      "Cleaned Token After =  automated storage retrieval system ( asrs as/rs ) consists variety computer-controlled systems automatically placing retrieving \n",
      "Cleaned Token After Stem =  autom storag retriev system ( asr as/r ) consist varieti computer-control system automat place retriev \n",
      "Cleaned Token Before =  xapian is a free and open-source probabilistic information retrieval library, released under the gnu general public license (gpl). it is a full-text search\n",
      "Cleaned Token After =  xapian free open-source probabilistic information retrieval library , released gnu general public license ( gpl ) . full-text search \n",
      "Cleaned Token After Stem =  xapian free open-sourc probabilist inform retriev librari , releas gnu gener public licens ( gpl ) . full-text search \n",
      "Cleaned Token Before =  technology used in computer storage devices smart information retrieval system, an information retrieval system developed at cornell university in the 1960s\n",
      "Cleaned Token After =  technology used computer storage devices smart information retrieval system , information retrieval system developed cornell university 1960s \n",
      "Cleaned Token After Stem =  technolog use comput storag devic smart inform retriev system , inform retriev system develop cornel univers 1960 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Token Before =  another document. computer-assisted plagiarism detection (capd) is an information retrieval (ir) task supported by specialized ir systems, which is referred\n",
      "Cleaned Token After =  another document . computer-assisted plagiarism detection ( capd ) information retrieval ( ir ) task supported specialized ir systems , referred \n",
      "Cleaned Token After Stem =  anoth document . computer-assist plagiar detect ( capd ) inform retriev ( ir ) task support special ir system , refer \n",
      "Cleaned Token Before =  encounters in a geographically distributed community. serendipitous information retrieval : an academic research publication by elaine g. toms programming\n",
      "Cleaned Token After =  encounters geographically distributed community . serendipitous information retrieval : academic research publication elaine g. toms programming \n",
      "Cleaned Token After Stem =  encount geograph distribut commun . serendipit inform retriev : academ research public elain g. tom program \n",
      "Cleaned Token Before =  the binary independence model (bim) is a probabilistic information retrieval technique that makes some simple assumptions to make the estimation of document/query\n",
      "Cleaned Token After =  binary independence model ( bim ) probabilistic information retrieval technique makes simple assumptions make estimation document/query \n",
      "Cleaned Token After Stem =  binari independ model ( bim ) probabilist inform retriev techniqu make simpl assumpt make estim document/queri \n",
      "Cleaned Token Before =  compound-term processing, in information-retrieval, is search result matching on the basis of compound terms. compound terms are built by combining two\n",
      "Cleaned Token After =  compound-term processing , information-retrieval , search result matching basis compound terms . compound terms built combining two \n",
      "Cleaned Token After Stem =  compound-term process , information-retriev , search result match basi compound term . compound term built combin two \n",
      "Cleaned Token Before =  algorithm has applications in bioinformatics, web scraping, and information retrieval. the ruzzo–tompa algorithm has been used in bioinformatics tools\n",
      "Cleaned Token After =  algorithm applications bioinformatics , web scraping , information retrieval . ruzzo–tompa algorithm used bioinformatics tools \n",
      "Cleaned Token After Stem =  algorithm applic bioinformat , web scrape , inform retriev . ruzzo–tompa algorithm use bioinformat tool \n",
      "Cleaned Token Before =  1108/eb024320. cove, j.f.; walsh, b.c. (1988). \"online text retrieval via browsing\". information processing & management. 24: 31–37. doi:10.1016/0306-4573(88)90075-1\n",
      "Cleaned Token After =  1108/eb024320 . cove , j.f . ; walsh , b.c . ( 1988 ) . `` online text retrieval via browsing '' . information processing & management . 24 : 31–37 . doi:10.1016/0306-4573 ( 88 ) 90075-1 \n",
      "Cleaned Token After Stem =  1108/eb024320 . cove , j.f . ; walsh , b.c . ( 1988 ) . `` onlin text retriev via brows `` . inform process & manag . 24 : 31–37 . doi:10.1016/0306-4573 ( 88 ) 90075-1 \n",
      "Cleaned Token Before =  lemur project is a collaboration between the center for intelligent information retrieval at the university of massachusetts amherst and the language technologies\n",
      "Cleaned Token After =  lemur project collaboration center intelligent information retrieval university massachusetts amherst language technologies \n",
      "Cleaned Token After Stem =  lemur project collabor center intellig inform retriev univers massachusett amherst languag technolog \n",
      "Cleaned Token Before =  similarity measure for real-valued vectors, used in (among other fields) information retrieval to score the similarity of documents in the vector space model.\n",
      "Cleaned Token After =  similarity measure real-valued vectors , used ( among fields ) information retrieval score similarity documents vector space model . \n",
      "Cleaned Token After Stem =  similar measur real-valu vector , use ( among field ) inform retriev score similar document vector space model . \n",
      "Cleaned Token Before =  information management (im) concerns a cycle of organizational activity: the acquisition of information from one or more sources, the custodianship and\n",
      "Cleaned Token After =  information management ( im ) concerns cycle organizational activity : acquisition information one sources , custodianship \n",
      "Cleaned Token After Stem =  inform manag ( im ) concern cycl organiz activ : acquisit inform one sourc , custodianship \n",
      "Cleaned Token Before =  visual words, as used in image retrieval systems, refer to small parts of an image which carry some kind of information related to the features (such as\n",
      "Cleaned Token After =  visual words , used image retrieval systems , refer small parts image carry kind information related features ( \n",
      "Cleaned Token After Stem =  visual word , use imag retriev system , refer small part imag carri kind inform relat featur ( \n",
      "Cleaned Token Before =  bedeutung normierter terminologien in zeiten moderner sprach- und information-retrieval-technologien\" (pdf; 205 kb) [1] abi-technik, de gruyter, berlin\n",
      "Cleaned Token After =  bedeutung normierter terminologien zeiten moderner sprach- und information-retrieval-technologien '' ( pdf ; 205 kb ) [ 1 ] abi-technik , de gruyter , berlin \n",
      "Cleaned Token After Stem =  bedeutung normiert terminologien zeiten modern sprach- und information-retrieval-technologien `` ( pdf ; 205 kb ) [ 1 ] abi-technik , de gruyter , berlin \n",
      "Cleaned Token Before =  in mathematics and signal processing, the constant-q transform, simply known as cqt transforms a data series to the frequency domain. it is related to\n",
      "Cleaned Token After =  mathematics signal processing , constant-q transform , simply known cqt transforms data series frequency domain . related \n",
      "Cleaned Token After Stem =  mathemat signal process , constant-q transform , simpli known cqt transform data seri frequenc domain . relat \n",
      "Cleaned Token Before =  music information processing and retrieval. the work is performed at the international music information retrieval systems evaluation laboratory (imirsel)\n",
      "Cleaned Token After =  music information processing retrieval . work performed international music information retrieval systems evaluation laboratory ( imirsel ) \n",
      "Cleaned Token After Stem =  music inform process retriev . work perform intern music inform retriev system evalu laboratori ( imirsel ) \n",
      "Cleaned Token Before =  topical guide to search engines. search engine – information retrieval system designed to help find information stored on a computer system. the search results\n",
      "Cleaned Token After =  topical guide search engines . search engine – information retrieval system designed help find information stored computer system . search results \n",
      "Cleaned Token After Stem =  topic guid search engin . search engin – inform retriev system design help find inform store comput system . search result \n",
      "Cleaned Token Before =  information-theoretic security. private information retrieval with multiple databases can be achieved with information-theoretic privacy for the user's query. reductions\n",
      "Cleaned Token After =  information-theoretic security . private information retrieval multiple databases achieved information-theoretic privacy user 's query . reductions \n",
      "Cleaned Token After Stem =  information-theoret secur . privat inform retriev multipl databas achiev information-theoret privaci user 's queri . reduct \n",
      "Cleaned Token Before =  retrievalware is an enterprise search engine emphasizing natural language processing and semantic networks which was commercially available from 1992\n",
      "Cleaned Token After =  retrievalware enterprise search engine emphasizing natural language processing semantic networks commercially available 1992 \n",
      "Cleaned Token After Stem =  retrievalwar enterpris search engin emphas natur languag process semant network commerci avail 1992 \n",
      "Cleaned Token Before =  (2008). \"comparing citation contexts for information retrieval\". proceedings of the 17th acm conference on information and knowledge mining - cikm '08. pp\n",
      "Cleaned Token After =  ( 2008 ) . `` comparing citation contexts information retrieval '' . proceedings 17th acm conference information knowledge mining - cikm '08 . pp \n",
      "Cleaned Token After Stem =  ( 2008 ) . `` compar citat context inform retriev `` . proceed 17th acm confer inform knowledg mine - cikm '08 . pp \n",
      "Cleaned Token Before =  or peripheral device is an auxiliary device used to put information into and get information out of the computer. the term peripheral device refers to\n",
      "Cleaned Token After =  peripheral device auxiliary device used put information get information computer . term peripheral device refers \n",
      "Cleaned Token After Stem =  peripher devic auxiliari devic use put inform get inform comput . term peripher devic refer \n",
      "Cleaned Token Before =   semi-supervised learning, and clustering, and it also affects information retrieval. in a 2012 survey, zimek et al. identified the following problems\n",
      "Cleaned Token After =  semi-supervised learning , clustering , also affects information retrieval . 2012 survey , zimek et al . identified following problems \n",
      "Cleaned Token After Stem =  semi-supervis learn , cluster , also affect inform retriev . 2012 survey , zimek et al . identifi follow problem \n",
      "Cleaned Token Before =  of the ellipse from a focus. in computer science, specifically information retrieval and machine learning, the harmonic mean of the precision (true positives\n",
      "Cleaned Token After =  ellipse focus . computer science , specifically information retrieval machine learning , harmonic mean precision ( true positives \n",
      "Cleaned Token After Stem =  ellips focu . comput scienc , specif inform retriev machin learn , harmon mean precis ( true posit \n",
      "Cleaned Token Before =   he worked for lockheed in the 1960s, was put in charge of its information retrieval lab, and from his work created a system that became known as dialog\n",
      "Cleaned Token After =  worked lockheed 1960s , put charge information retrieval lab , work created system became known dialog \n",
      "Cleaned Token After Stem =  work lockhe 1960 , put charg inform retriev lab , work creat system becam known dialog \n",
      "Cleaned Token Before =  documents. this conundrum of natural language processing (nlp) and information retrieval (ir) on the web – and data bases in general – can be addressed using\n",
      "Cleaned Token After =  documents . conundrum natural language processing ( nlp ) information retrieval ( ir ) web – data bases general – addressed using \n",
      "Cleaned Token After Stem =  document . conundrum natur languag process ( nlp ) inform retriev ( ir ) web – data base gener – address use \n",
      "Cleaned Token Before =  jaxsta is an australian tech start-up seeking to become the world’s most comprehensive source of official music credits. according to a 2018 report in\n",
      "Cleaned Token After =  jaxsta australian tech start-up seeking become world ’ comprehensive source official music credits . according 2018 report \n",
      "Cleaned Token After Stem =  jaxsta australian tech start-up seek becom world ’ comprehens sourc offici music credit . accord 2018 report \n",
      "Cleaned Token Before =   classification, cataloging, bibliometrics, online information retrieval, information management, among others. it covers about 560 core journals, 50\n",
      "Cleaned Token After =  classification , cataloging , bibliometrics , online information retrieval , information management , among others . covers 560 core journals , 50 \n",
      "Cleaned Token After Stem =  classif , catalog , bibliometr , onlin inform retriev , inform manag , among other . cover 560 core journal , 50 \n",
      "Cleaned Token Before =  historical development and present state‐of‐the‐art of mechanized information retrieval systems\". american documentation. 12 (2): 108–110. doi:10.1002/asi\n",
      "Cleaned Token After =  historical development present state‐of‐the‐art mechanized information retrieval systems '' . american documentation . 12 ( 2 ) : 108–110 . doi:10.1002/asi \n",
      "Cleaned Token After Stem =  histor develop present state‐of‐the‐art mechan inform retriev system `` . american document . 12 ( 2 ) : 108–110 . doi:10.1002/asi \n",
      "Cleaned Token Before =  language). these technologies formally represent the meaning involved in information. for example, ontology can describe concepts, relationships between things\n",
      "Cleaned Token After =  language ) . technologies formally represent meaning involved information . example , ontology describe concepts , relationships things \n",
      "Cleaned Token After Stem =  languag ) . technolog formal repres mean involv inform . exampl , ontolog describ concept , relationship thing \n",
      "Cleaned Token Before =  like the text search, image search is an information retrieval system designed to help to find information on the internet and it allows the user to\n",
      "Cleaned Token After =  like text search , image search information retrieval system designed help find information internet allows user \n",
      "Cleaned Token After Stem =  like text search , imag search inform retriev system design help find inform internet allow user \n",
      "Cleaned Token Before =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion\n",
      "Cleaned Token After =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion \n",
      "Cleaned Token After Stem =  digit librari comput platform digit market world wide web inform retriev secur cryptographi formal method secur servic intrus \n",
      "Cleaned Token Before =  straightforward applications of natural language processing include information retrieval, text mining, question answering and machine translation. many current\n",
      "Cleaned Token After =  straightforward applications natural language processing include information retrieval , text mining , question answering machine translation . many current \n",
      "Cleaned Token After Stem =  straightforward applic natur languag process includ inform retriev , text mine , question answer machin translat . mani current \n",
      "Cleaned Token Before =  recall may refer to: recall (bugle call), a signal to stop recall (information retrieval), a statistical measure recall (journal), an academic journal about\n",
      "Cleaned Token After =  recall may refer : recall ( bugle call ) , signal stop recall ( information retrieval ) , statistical measure recall ( journal ) , academic journal \n",
      "Cleaned Token After Stem =  recal may refer : recal ( bugl call ) , signal stop recal ( inform retriev ) , statist measur recal ( journal ) , academ journal \n",
      "Cleaned Token Before =  second (qps) is a common measure of the amount of search traffic an information retrieval system, such as a search engine or a database, receives during one\n",
      "Cleaned Token After =  second ( qps ) common measure amount search traffic information retrieval system , search engine database , receives one \n",
      "Cleaned Token After Stem =  second ( qp ) common measur amount search traffic inform retriev system , search engin databas , receiv one \n",
      "Cleaned Token Before =  in statistical data analysis, signal processing, image analysis, information retrieval, bioinformatics, data compression, computer graphics and machine\n",
      "Cleaned Token After =  statistical data analysis , signal processing , image analysis , information retrieval , bioinformatics , data compression , computer graphics machine \n",
      "Cleaned Token After Stem =  statist data analysi , signal process , imag analysi , inform retriev , bioinformat , data compress , comput graphic machin \n",
      "Cleaned Token Before =  international acm sigir conference on research and development in information retrieval, p. 284, doi:10.1145/1148170.1148222, isbn 978-1595933690. charikar\n",
      "Cleaned Token After =  international acm sigir conference research development information retrieval , p. 284 , doi:10.1145/1148170.1148222 , isbn 978-1595933690. charikar \n",
      "Cleaned Token After Stem =  intern acm sigir confer research develop inform retriev , p. 284 , doi:10.1145/1148170.1148222 , isbn 978-1595933690. charikar \n",
      "Cleaned Token Before =  harshness (also called raucousness), in music information retrieval, is a non-contextual low-level audio descriptors (nlds) that represents one dimension\n",
      "Cleaned Token After =  harshness ( also called raucousness ) , music information retrieval , non-contextual low-level audio descriptors ( nlds ) represents one dimension \n",
      "Cleaned Token After Stem =  harsh ( also call raucous ) , music inform retriev , non-contextu low-level audio descriptor ( nld ) repres one dimens \n",
      "Cleaned Token Before =  algorithms with a focus on data structures, algorithmic game theory, information retrieval, search algorithms and web data mining. she is married to thomas\n",
      "Cleaned Token After =  algorithms focus data structures , algorithmic game theory , information retrieval , search algorithms web data mining . married thomas \n",
      "Cleaned Token After Stem =  algorithm focu data structur , algorithm game theori , inform retriev , search algorithm web data mine . marri thoma \n",
      "Cleaned Token Before =  passed the concept on to j. c. r. licklider at the inaugural unesco information processing conference in paris that year. mccarthy was instrumental in\n",
      "Cleaned Token After =  passed concept j. c. r. licklider inaugural unesco information processing conference paris year . mccarthy instrumental \n",
      "Cleaned Token After Stem =  pass concept j. c. r. licklid inaugur unesco inform process confer pari year . mccarthi instrument \n",
      "Cleaned Token Before =  searching or information retrieval (ir), information gathering, and information sharing. beyond that, cis can extend to collaborative information synthesis\n",
      "Cleaned Token After =  searching information retrieval ( ir ) , information gathering , information sharing . beyond , cis extend collaborative information synthesis \n",
      "Cleaned Token After Stem =  search inform retriev ( ir ) , inform gather , inform share . beyond , ci extend collabor inform synthesi \n",
      "Cleaned Token Before =  intervals, repetition spacing, repetition scheduling, spaced retrieval and expanded retrieval. over the years, techniques and tests have been formed to better\n",
      "Cleaned Token After =  intervals , repetition spacing , repetition scheduling , spaced retrieval expanded retrieval . years , techniques tests formed better \n",
      "Cleaned Token After Stem =  interv , repetit space , repetit schedul , space retriev expand retriev . year , techniqu test form better \n",
      "Cleaned Token Before =  justia is an american website specializing in legal information retrieval. it was founded in 2003 by tim stanley, formerly of findlaw, and is one of the\n",
      "Cleaned Token After =  justia american website specializing legal information retrieval . founded 2003 tim stanley , formerly findlaw , one \n",
      "Cleaned Token After Stem =  justia american websit special legal inform retriev . found 2003 tim stanley , formerli findlaw , one \n",
      "Cleaned Token Before =  comprehensive model of information seeking, or cmis, is a theoretical construct designed to predict how people will seek information. it was first developed\n",
      "Cleaned Token After =  comprehensive model information seeking , cmis , theoretical construct designed predict people seek information . first developed \n",
      "Cleaned Token After Stem =  comprehens model inform seek , cmi , theoret construct design predict peopl seek inform . first develop \n",
      "Cleaned Token Before =  database system modifying the database structure, as necessary, from information given by application developers enrolling users and maintaining system\n",
      "Cleaned Token After =  database system modifying database structure , necessary , information given application developers enrolling users maintaining system \n",
      "Cleaned Token After Stem =  databas system modifi databas structur , necessari , inform given applic develop enrol user maintain system \n",
      "Cleaned Token Before =  in the field of information retrieval, divergence from randomness, one of the first models, is one type of probabilistic model. it is basically used to\n",
      "Cleaned Token After =  field information retrieval , divergence randomness , one first models , one type probabilistic model . basically used \n",
      "Cleaned Token After Stem =  field inform retriev , diverg random , one first model , one type probabilist model . basic use \n",
      "Cleaned Token Before =  both. pdas are used in various contexts (e.g. phonetics, music information retrieval, speech coding, musical performance systems) and so there may be\n",
      "Cleaned Token After =  . pdas used various contexts ( e.g . phonetics , music information retrieval , speech coding , musical performance systems ) may \n",
      "Cleaned Token After Stem =  . pda use variou context ( e.g . phonet , music inform retriev , speech code , music perform system ) may \n",
      "Cleaned Token Before =  the ibm storage and information retrieval system, better known by the acronym stairs, was a program providing storage and online free-text search of text\n",
      "Cleaned Token After =  ibm storage information retrieval system , better known acronym stairs , program providing storage online free-text search text \n",
      "Cleaned Token After Stem =  ibm storag inform retriev system , better known acronym stair , program provid storag onlin free-text search text \n",
      "Cleaned Token Before =   computer science, and information science—for example in the areas of topology, chemical graph theory, information retrieval and data mining in the chemical\n",
      "Cleaned Token After =  computer science , information science—for example areas topology , chemical graph theory , information retrieval data mining chemical \n",
      "Cleaned Token After Stem =  comput scienc , inform science—for exampl area topolog , chemic graph theori , inform retriev data mine chemic \n",
      "Cleaned Token Before =  empirical linguistics, cognitive science, artificial intelligence, information retrieval, and machine learning. nltk has been used successfully as a teaching\n",
      "Cleaned Token After =  empirical linguistics , cognitive science , artificial intelligence , information retrieval , machine learning . nltk used successfully teaching \n",
      "Cleaned Token After Stem =  empir linguist , cognit scienc , artifici intellig , inform retriev , machin learn . nltk use success teach \n",
      "Cleaned Token Before =  image. this application of computer vision techniques is used in image retrieval systems to organize and locate images of interest from a database. this\n",
      "Cleaned Token After =  image . application computer vision techniques used image retrieval systems organize locate images interest database . \n",
      "Cleaned Token After Stem =  imag . applic comput vision techniqu use imag retriev system organ locat imag interest databas . \n",
      "Cleaned Token Before =  dog\" or \"dog * * house\". compound term processing edit distance information retrieval search engine search engine indexing - how texts are indexed to\n",
      "Cleaned Token After =  dog '' `` dog * * house '' . compound term processing edit distance information retrieval search engine search engine indexing - texts indexed \n",
      "Cleaned Token After Stem =  dog `` `` dog * * hous `` . compound term process edit distanc inform retriev search engin search engin index - text index \n",
      "Cleaned Token Before =  algorithms for searching and processing information in documents and databases; closely related to information retrieval. compiler theory – theory of compiler\n",
      "Cleaned Token After =  algorithms searching processing information documents databases ; closely related information retrieval . compiler theory – theory compiler \n",
      "Cleaned Token After Stem =  algorithm search process inform document databas ; close relat inform retriev . compil theori – theori compil \n",
      "Cleaned Token Before =  overcome the drawbacks of the boolean model that has been used in information retrieval. the boolean model doesn't consider term weights in queries, and\n",
      "Cleaned Token After =  overcome drawbacks boolean model used information retrieval . boolean model n't consider term weights queries , \n",
      "Cleaned Token After Stem =  overcom drawback boolean model use inform retriev . boolean model n't consid term weight queri , \n",
      "Cleaned Token Before =   type private industry enterprise search internet search information technology information access open source software founded 2007 headquarters san\n",
      "Cleaned Token After =  type private industry enterprise search internet search information technology information access open source software founded 2007 headquarters san \n",
      "Cleaned Token After Stem =  type privat industri enterpris search internet search inform technolog inform access open sourc softwar found 2007 headquart san \n",
      "Cleaned Token Before =  operated by processing users' responses to scripts. using almost no information about human thought or emotion, the doctor script sometimes provided\n",
      "Cleaned Token After =  operated processing users ' responses scripts . using almost information human thought emotion , doctor script sometimes provided \n",
      "Cleaned Token After Stem =  oper process user ' respons script . use almost inform human thought emot , doctor script sometim provid \n",
      "Cleaned Token Before =  functions are to maintain an underlying framework for testing information retrieval systems and to create repositories of data for researchers to use in developing\n",
      "Cleaned Token After =  functions maintain underlying framework testing information retrieval systems create repositories data researchers use developing \n",
      "Cleaned Token After Stem =  function maintain underli framework test inform retriev system creat repositori data research use develop \n",
      "Cleaned Token Before =  application of technology to the organization, storage, retrieval, and dissemination of information.\" legal informatics therefore, pertains to the application\n",
      "Cleaned Token After =  application technology organization , storage , retrieval , dissemination information . '' legal informatics therefore , pertains application \n",
      "Cleaned Token After Stem =  applic technolog organ , storag , retriev , dissemin inform . `` legal informat therefor , pertain applic \n",
      "Cleaned Token Before =  in research communities (for example, earth sciences, astronomy, business, and government), subsetting is the process of retrieving just the parts of large\n",
      "Cleaned Token After =  research communities ( example , earth sciences , astronomy , business , government ) , subsetting process retrieving parts large \n",
      "Cleaned Token After Stem =  research commun ( exampl , earth scienc , astronomi , busi , govern ) , subset process retriev part larg \n",
      "Cleaned Token Before =  brs/search is a full-text database and information retrieval system. brs/search uses a fully inverted indexing system to store, locate, and retrieve unstructured\n",
      "Cleaned Token After =  brs/search full-text database information retrieval system . brs/search uses fully inverted indexing system store , locate , retrieve unstructured \n",
      "Cleaned Token After Stem =  brs/search full-text databas inform retriev system . brs/search use fulli invert index system store , locat , retriev unstructur \n",
      "Cleaned Token Before =   m. & smyth, b. (2007). \"information recovery and discovery in collaborative web search\". advances in information retrieval. lecture notes in computer\n",
      "Cleaned Token After =  m. & smyth , b . ( 2007 ) . `` information recovery discovery collaborative web search '' . advances information retrieval . lecture notes computer \n",
      "Cleaned Token After Stem =  m. & smyth , b . ( 2007 ) . `` inform recoveri discoveri collabor web search `` . advanc inform retriev . lectur note comput \n",
      "Cleaned Token Before =   that allows the information to be processed by a machine. such machine readable descriptions can facilitate information retrieval, display, design,\n",
      "Cleaned Token After =  allows information processed machine . machine readable descriptions facilitate information retrieval , display , design , \n",
      "Cleaned Token After Stem =  allow inform process machin . machin readabl descript facilit inform retriev , display , design , \n",
      "Cleaned Token Before =  scientist and electrical engineer noted for his research on multimedia information retrieval, computer vision, machine learning, and signal processing. he is\n",
      "Cleaned Token After =  scientist electrical engineer noted research multimedia information retrieval , computer vision , machine learning , signal processing . \n",
      "Cleaned Token After Stem =  scientist electr engin note research multimedia inform retriev , comput vision , machin learn , signal process . \n",
      "Cleaned Token Before =  single webpage, as indexed by google tf-idf – a statistic used in information retrieval and text mining \"sipping wikipedia\" (pdf). courses.cms.caltech.edu\n",
      "Cleaned Token After =  single webpage , indexed google tf-idf – statistic used information retrieval text mining `` sipping wikipedia '' ( pdf ) . courses.cms.caltech.edu \n",
      "Cleaned Token After Stem =  singl webpag , index googl tf-idf – statist use inform retriev text mine `` sip wikipedia `` ( pdf ) . courses.cms.caltech.edu \n",
      "Cleaned Token Before =  decide what topic will be investigated and how to proceed. some information retrieval may occur at this point, resulting in multiple rounds of query reformulation\n",
      "Cleaned Token After =  decide topic investigated proceed . information retrieval may occur point , resulting multiple rounds query reformulation \n",
      "Cleaned Token After Stem =  decid topic investig proceed . inform retriev may occur point , result multipl round queri reformul \n",
      "Cleaned Token Before =  is a senior staff research scientist at google, specializing in information retrieval, machine learning, and computational linguistics, and a senior member\n",
      "Cleaned Token After =  senior staff research scientist google , specializing information retrieval , machine learning , computational linguistics , senior member \n",
      "Cleaned Token After Stem =  senior staff research scientist googl , special inform retriev , machin learn , comput linguist , senior member \n",
      "Cleaned Token Before =  privacy and the power of the algorithm\". international journal of law and information technology. 23: 261–289. retrieved 2016-08-03. keeshin, jeremy (2011-08-18)\n",
      "Cleaned Token After =  privacy power algorithm '' . international journal law information technology . 23 : 261–289 . retrieved 2016-08-03. keeshin , jeremy ( 2011-08-18 ) \n",
      "Cleaned Token After Stem =  privaci power algorithm `` . intern journal law inform technolog . 23 : 261–289 . retriev 2016-08-03. keeshin , jeremi ( 2011-08-18 ) \n",
      "Cleaned Token Before =  pre-war information retrieval specialists of continental europe, the 'documentalists,' largely disregarded by post-war information retrieval specialists\n",
      "Cleaned Token After =  pre-war information retrieval specialists continental europe , 'documentalists , ' largely disregarded post-war information retrieval specialists \n",
      "Cleaned Token After Stem =  pre-war inform retriev specialist continent europ , 'documentalist , ' larg disregard post-war inform retriev specialist \n",
      "Cleaned Token Before =  geographic information systems, crc press, pp. 212–214, isbn 978-1-4822-2314-9 zhang, jin (2007), visualization for information retrieval, springer,\n",
      "Cleaned Token After =  geographic information systems , crc press , pp . 212–214 , isbn 978-1-4822-2314-9 zhang , jin ( 2007 ) , visualization information retrieval , springer , \n",
      "Cleaned Token After Stem =  geograph inform system , crc press , pp . 212–214 , isbn 978-1-4822-2314-9 zhang , jin ( 2007 ) , visual inform retriev , springer , \n",
      "Cleaned Token Before =  study of computational systems, especially those for data storage and retrieval. according to acm europe and informatics europe, informatics is synonymous\n",
      "Cleaned Token After =  study computational systems , especially data storage retrieval . according acm europe informatics europe , informatics synonymous \n",
      "Cleaned Token After Stem =  studi comput system , especi data storag retriev . accord acm europ informat europ , informat synonym \n",
      "Cleaned Token Before =  an american computer scientist, famous for his contributions to information retrieval and several textbooks. he was son of dr. roy korfhage who was a\n",
      "Cleaned Token After =  american computer scientist , famous contributions information retrieval several textbooks . son dr. roy korfhage \n",
      "Cleaned Token After Stem =  american comput scientist , famou contribut inform retriev sever textbook . son dr. roy korfhag \n",
      "Cleaned Token Before =  com \"globalspec, inc. company profile - view globalspec, inc. company information\". bizjournals.com. archived from the original on february 10, 2009. retrieved\n",
      "Cleaned Token After =  com `` globalspec , inc. company profile - view globalspec , inc. company information '' . bizjournals.com . archived original february 10 , 2009. retrieved \n",
      "Cleaned Token After Stem =  com `` globalspec , inc. compani profil - view globalspec , inc. compani inform `` . bizjournals.com . archiv origin februari 10 , 2009. retriev \n",
      "Cleaned Token Before =  services in release of information department (roi), record retrieval and health information management. three out of five hospitals and more than 16,000\n",
      "Cleaned Token After =  services release information department ( roi ) , record retrieval health information management . three five hospitals 16,000 \n",
      "Cleaned Token After Stem =  servic releas inform depart ( roi ) , record retriev health inform manag . three five hospit 16,000 \n",
      "Cleaned Token Before =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion\n",
      "Cleaned Token After =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion \n",
      "Cleaned Token After Stem =  digit librari comput platform digit market world wide web inform retriev secur cryptographi formal method secur servic intrus \n",
      "Cleaned Token Before =  application software to be suited to fit the personalized web page or information appliance. current open data standards on the web include: attention\n",
      "Cleaned Token After =  application software suited fit personalized web page information appliance . current open data standards web include : attention \n",
      "Cleaned Token After Stem =  applic softwar suit fit person web page inform applianc . current open data standard web includ : attent \n",
      "Cleaned Token Before =  statistics population statistics psychometrics spatial statistics cartography environmental statistics geographic information system geostatistics kriging\n",
      "Cleaned Token After =  statistics population statistics psychometrics spatial statistics cartography environmental statistics geographic information system geostatistics kriging \n",
      "Cleaned Token After Stem =  statist popul statist psychometr spatial statist cartographi environment statist geograph inform system geostatist krige \n",
      "Cleaned Token Before =  contents. they all aim at variants of the vector space model for information retrieval on text collections. keyword stuffing involves the calculated placement\n",
      "Cleaned Token After =  contents . aim variants vector space model information retrieval text collections . keyword stuffing involves calculated placement \n",
      "Cleaned Token After Stem =  content . aim variant vector space model inform retriev text collect . keyword stuf involv calcul placement \n",
      "Cleaned Token Before =  search by sound is the retrieval of information based on audio input. there are a handful of applications, specifically for mobile devices that utilize\n",
      "Cleaned Token After =  search sound retrieval information based audio input . handful applications , specifically mobile devices utilize \n",
      "Cleaned Token After Stem =  search sound retriev inform base audio input . hand applic , specif mobil devic util \n",
      "Cleaned Token Before =  donna k. harman is an american information retrieval researcher. she is a group leader in the retrieval group at the national institute of standards and\n",
      "Cleaned Token After =  donna k. harman american information retrieval researcher . group leader retrieval group national institute standards \n",
      "Cleaned Token After Stem =  donna k. harman american inform retriev research . group leader retriev group nation institut standard \n",
      "Cleaned Token Before =  of information retrieval was developed by calvin mooers in 1947. calvin mooers invented zatocoding at m.i.t., a mechanical information retrieval system\n",
      "Cleaned Token After =  information retrieval developed calvin mooers 1947. calvin mooers invented zatocoding m.i.t. , mechanical information retrieval system \n",
      "Cleaned Token After Stem =  inform retriev develop calvin mooer 1947. calvin mooer invent zatocod m.i.t . , mechan inform retriev system \n",
      "Cleaned Token Before =  science, and the founding leader of the centre for information retrieval, faculty of information technology, university of pannonia, veszprém, hungary\n",
      "Cleaned Token After =  science , founding leader centre information retrieval , faculty information technology , university pannonia , veszprém , hungary \n",
      "Cleaned Token After Stem =  scienc , found leader centr inform retriev , faculti inform technolog , univers pannonia , veszprém , hungari \n",
      "Cleaned Token Before =  selecting them rather than typing in their names. in the context of information retrieval, qbe has a somewhat different meaning. the user can submit a document\n",
      "Cleaned Token After =  selecting rather typing names . context information retrieval , qbe somewhat different meaning . user submit document \n",
      "Cleaned Token After Stem =  select rather type name . context inform retriev , qbe somewhat differ mean . user submit document \n",
      "Cleaned Token Before =  management, knowledge organization, information seeking, information retrieval, human information behaviour, and digital literacy. the main audience for the journal\n",
      "Cleaned Token After =  management , knowledge organization , information seeking , information retrieval , human information behaviour , digital literacy . main audience journal \n",
      "Cleaned Token After Stem =  manag , knowledg organ , inform seek , inform retriev , human inform behaviour , digit literaci . main audienc journal \n",
      "Cleaned Token Before =  professor susan dumais – information retrieval jon michael dunn – founding dean of indiana university school of informatics, information based logics especially\n",
      "Cleaned Token After =  professor susan dumais – information retrieval jon michael dunn – founding dean indiana university school informatics , information based logics especially \n",
      "Cleaned Token After Stem =  professor susan dumai – inform retriev jon michael dunn – found dean indiana univers school informat , inform base logic especi \n",
      "Cleaned Token Before =  value has been widely used in both speech recognition and music information retrieval, being a key feature to classify percussive sounds. zcr is defined\n",
      "Cleaned Token After =  value widely used speech recognition music information retrieval , key feature classify percussive sounds . zcr defined \n",
      "Cleaned Token After Stem =  valu wide use speech recognit music inform retriev , key featur classifi percuss sound . zcr defin \n",
      "Cleaned Token Before =  sound) to encode digital information, and that also demodulates such a carrier signal to decode the transmitted information. used (for example) when a\n",
      "Cleaned Token After =  sound ) encode digital information , also demodulates carrier signal decode transmitted information . used ( example ) \n",
      "Cleaned Token After Stem =  sound ) encod digit inform , also demodul carrier signal decod transmit inform . use ( exampl ) \n",
      "Cleaned Token Before =  geological prospecting institute. he began his career working on information retrieval technologies in 1990 at arkadia company, where he headed their software\n",
      "Cleaned Token After =  geological prospecting institute . began career working information retrieval technologies 1990 arkadia company , headed software \n",
      "Cleaned Token After Stem =  geolog prospect institut . began career work inform retriev technolog 1990 arkadia compani , head softwar \n",
      "Cleaned Token Before =  articles in the field of information and computational sciences. the journal was founded as information storage and retrieval in 1963, in 1975, the journal\n",
      "Cleaned Token After =  articles field information computational sciences . journal founded information storage retrieval 1963 , 1975 , journal \n",
      "Cleaned Token After Stem =  articl field inform comput scienc . journal found inform storag retriev 1963 , 1975 , journal \n",
      "Cleaned Token Before =  computer scientist who is best known for his work on the evaluation of information retrieval systems. cyril cleverdon was born in bristol, england. he worked\n",
      "Cleaned Token After =  computer scientist best known work evaluation information retrieval systems . cyril cleverdon born bristol , england . worked \n",
      "Cleaned Token After Stem =  comput scientist best known work evalu inform retriev system . cyril cleverdon born bristol , england . work \n",
      "Cleaned Token Before =  artificial intelligence mobile computing quantum computing search, information retrieval, and knowledge management security and privacy social media social\n",
      "Cleaned Token After =  artificial intelligence mobile computing quantum computing search , information retrieval , knowledge management security privacy social media social \n",
      "Cleaned Token After Stem =  artifici intellig mobil comput quantum comput search , inform retriev , knowledg manag secur privaci social media social \n",
      "Cleaned Token Before =  wide area information server (wais) dynix koha openurl opensearch cql: the contextual query language: specifications sru: search/retrieval via url, standards\n",
      "Cleaned Token After =  wide area information server ( wais ) dynix koha openurl opensearch cql : contextual query language : specifications sru : search/retrieval via url , standards \n",
      "Cleaned Token After Stem =  wide area inform server ( wai ) dynix koha openurl opensearch cql : contextu queri languag : specif sru : search/retriev via url , standard \n",
      "Cleaned Token Before =  to a degree of precision at least sufficient for the purpose of information retrieval. the term statistical semantics was first used by warren weaver\n",
      "Cleaned Token After =  degree precision least sufficient purpose information retrieval . term statistical semantics first used warren weaver \n",
      "Cleaned Token After Stem =  degre precis least suffici purpos inform retriev . term statist semant first use warren weaver \n",
      "Cleaned Token Before =  2002, \"perhaps visual representations will begin to predominate in information retrieval when they show things that we can not see in the ordered list. the\n",
      "Cleaned Token After =  2002 , `` perhaps visual representations begin predominate information retrieval show things see ordered list . \n",
      "Cleaned Token After Stem =  2002 , `` perhap visual represent begin predomin inform retriev show thing see order list . \n",
      "Cleaned Token Before =  protocols. karger has conducted research in the area of information retrieval and personal information management. this work has focused on new interfaces\n",
      "Cleaned Token After =  protocols . karger conducted research area information retrieval personal information management . work focused new interfaces \n",
      "Cleaned Token After Stem =  protocol . karger conduct research area inform retriev person inform manag . work focus new interfac \n",
      "Cleaned Token Before =  automatic data analysis techniques has grown considerably, music information retrieval sound recognition speech segmentation automatic music transcription\n",
      "Cleaned Token After =  automatic data analysis techniques grown considerably , music information retrieval sound recognition speech segmentation automatic music transcription \n",
      "Cleaned Token After Stem =  automat data analysi techniqu grown consider , music inform retriev sound recognit speech segment automat music transcript \n",
      "Cleaned Token Before =   corporations, etc.) were invited to participate in the annual information retrieval, topic detection and tracking, automatic content extraction, and\n",
      "Cleaned Token After =  corporations , etc . ) invited participate annual information retrieval , topic detection tracking , automatic content extraction , \n",
      "Cleaned Token After Stem =  corpor , etc . ) invit particip annual inform retriev , topic detect track , automat content extract , \n",
      "Cleaned Token Before =  (link) bobbie johnson (may 21, 2009). \"where does wolfram alpha get its information?\". the guardian. retrieved march 8, 2013. \"about wolfram|alpha: making\n",
      "Cleaned Token After =  ( link ) bobbie johnson ( may 21 , 2009 ) . `` wolfram alpha get information ? '' . guardian . retrieved march 8 , 2013 . `` wolfram|alpha : making \n",
      "Cleaned Token After Stem =  ( link ) bobbi johnson ( may 21 , 2009 ) . `` wolfram alpha get inform ? `` . guardian . retriev march 8 , 2013 . `` wolfram|alpha : make \n",
      "Cleaned Token Before =  content search system for microsoft's web server software, internet information services.[citation needed] its origins, however, date further back to\n",
      "Cleaned Token After =  content search system microsoft 's web server software , internet information services . [ citation needed ] origins , however , date back \n",
      "Cleaned Token After Stem =  content search system microsoft 's web server softwar , internet inform servic . [ citat need ] origin , howev , date back \n",
      "Cleaned Token Before =  focus and intent. working memory serves as an encoding and retrieval processor. information in the form of stimuli is encoded in accordance with explicit\n",
      "Cleaned Token After =  focus intent . working memory serves encoding retrieval processor . information form stimuli encoded accordance explicit \n",
      "Cleaned Token After Stem =  focu intent . work memori serv encod retriev processor . inform form stimuli encod accord explicit \n",
      "Cleaned Token Before =  classified and the only way to access them is to be promoted to information retrieval. he has previously turned down a promotion arranged by his mother\n",
      "Cleaned Token After =  classified way access promoted information retrieval . previously turned promotion arranged mother \n",
      "Cleaned Token After Stem =  classifi way access promot inform retriev . previous turn promot arrang mother \n",
      "Cleaned Token Before =  together. relational database concepts of computer science and information retrieval concepts of digital libraries are important for understanding biological\n",
      "Cleaned Token After =  together . relational database concepts computer science information retrieval concepts digital libraries important understanding biological \n",
      "Cleaned Token After Stem =  togeth . relat databas concept comput scienc inform retriev concept digit librari import understand biolog \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, information retrieval. version: 27 april 2006. https://web.archive\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval . version : 27 april 2006. https : //web.archive \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev . version : 27 april 2006. http : //web.arch \n",
      "Cleaned Token Before =  bookmarking systems (pdf). fourth international workshop on adversarial information retrieval on the web. archived from the original (pdf) on 2008-06-05. benjamin\n",
      "Cleaned Token After =  bookmarking systems ( pdf ) . fourth international workshop adversarial information retrieval web . archived original ( pdf ) 2008-06-05. benjamin \n",
      "Cleaned Token After Stem =  bookmark system ( pdf ) . fourth intern workshop adversari inform retriev web . archiv origin ( pdf ) 2008-06-05. benjamin \n",
      "Cleaned Token Before =  technical reports on natural-language processing, autonomous information agents, information retrieval, and expert systems. he is also one of the authors of\n",
      "Cleaned Token After =  technical reports natural-language processing , autonomous information agents , information retrieval , expert systems . also one authors \n",
      "Cleaned Token After Stem =  technic report natural-languag process , autonom inform agent , inform retriev , expert system . also one author \n",
      "Cleaned Token Before =  unrelated but commonly used combination of basic statistics from information retrieval is the f-score, being a (possibly weighted) harmonic mean of recall\n",
      "Cleaned Token After =  unrelated commonly used combination basic statistics information retrieval f-score , ( possibly weighted ) harmonic mean recall \n",
      "Cleaned Token After Stem =  unrel commonli use combin basic statist inform retriev f-score , ( possibl weight ) harmon mean recal \n",
      "Cleaned Token Before =  opinion on information retrieval systems. he aimed efforts of his cc №1 scientists at their development. creation of information retrieval systems became\n",
      "Cleaned Token After =  opinion information retrieval systems . aimed efforts cc №1 scientists development . creation information retrieval systems became \n",
      "Cleaned Token After Stem =  opinion inform retriev system . aim effort cc №1 scientist develop . creation inform retriev system becam \n",
      "Cleaned Token Before =  ease with which information can be found or retrieved using an information system, specifically a search engine or information retrieval system. a document\n",
      "Cleaned Token After =  ease information found retrieved using information system , specifically search engine information retrieval system . document \n",
      "Cleaned Token After Stem =  eas inform found retriev use inform system , specif search engin inform retriev system . document \n",
      "Cleaned Token Before =  porting and extracting data files and objects. it can hold and store information both temporarily and permanently and can be internal or external to a\n",
      "Cleaned Token After =  porting extracting data files objects . hold store information temporarily permanently internal external \n",
      "Cleaned Token After Stem =  port extract data file object . hold store inform temporarili perman intern extern \n",
      "Cleaned Token Before =  phase retrieval is the process of algorithmically finding solutions to the phase problem. given a complex signal f ( k ) {\\displaystyle f(k)} , of amplitude\n",
      "Cleaned Token After =  phase retrieval process algorithmically finding solutions phase problem . given complex signal f ( k ) { \\displaystyle f ( k ) } , amplitude \n",
      "Cleaned Token After Stem =  phase retriev process algorithm find solut phase problem . given complex signal f ( k ) { \\displaystyl f ( k ) } , amplitud \n",
      "Cleaned Token Before =  hospitals. this integration is able to provide increased efficiency of retrieval of images. it has also been used as a separate software package and can\n",
      "Cleaned Token After =  hospitals . integration able provide increased efficiency retrieval images . also used separate software package \n",
      "Cleaned Token After Stem =  hospit . integr abl provid increas effici retriev imag . also use separ softwar packag \n",
      "Cleaned Token Before =  school. in 1997, lanzone co-founded etour, an early provider of information retrieval and cost-per-lead services on the web. by 1998, etour had become\n",
      "Cleaned Token After =  school . 1997 , lanzone co-founded etour , early provider information retrieval cost-per-lead services web . 1998 , etour become \n",
      "Cleaned Token After Stem =  school . 1997 , lanzon co-found etour , earli provid inform retriev cost-per-lead servic web . 1998 , etour becom \n",
      "Cleaned Token Before =  these directories are often created by phone phreakers by collecting the information available via the publicly accessible directories and then providing\n",
      "Cleaned Token After =  directories often created phone phreakers collecting information available via publicly accessible directories providing \n",
      "Cleaned Token After Stem =  directori often creat phone phreaker collect inform avail via publicli access directori provid \n",
      "Cleaned Token Before =  scientific literature and additional data derived from automatic information retrieval methods such as text mining. it provides a web-based user interface\n",
      "Cleaned Token After =  scientific literature additional data derived automatic information retrieval methods text mining . provides web-based user interface \n",
      "Cleaned Token After Stem =  scientif literatur addit data deriv automat inform retriev method text mine . provid web-bas user interfac \n",
      "Cleaned Token Before =  characterise the text (or its author). in this context, unlike for information retrieval, the observed occurrence patterns of the most common words are more\n",
      "Cleaned Token After =  characterise text ( author ) . context , unlike information retrieval , observed occurrence patterns common words \n",
      "Cleaned Token After Stem =  characteris text ( author ) . context , unlik inform retriev , observ occurr pattern common word \n",
      "Cleaned Token Before =  agrep (approximate grep) is an open-source approximate string matching program, developed by udi manber and sun wu between 1988 and 1991, for use with\n",
      "Cleaned Token After =  agrep ( approximate grep ) open-source approximate string matching program , developed udi manber sun wu 1988 1991 , use \n",
      "Cleaned Token After Stem =  agrep ( approxim grep ) open-sourc approxim string match program , develop udi manber sun wu 1988 1991 , use \n",
      "Cleaned Token Before =  california in 1951. maron is best known for his work on probabilistic information retrieval which he published together with his friend and colleague lary kuhns\n",
      "Cleaned Token After =  california 1951. maron best known work probabilistic information retrieval published together friend colleague lary kuhns \n",
      "Cleaned Token After Stem =  california 1951. maron best known work probabilist inform retriev publish togeth friend colleagu lari kuhn \n",
      "Cleaned Token Before =  tube.\" michael buckland concluded that bush's 1945 vision for an information retrieval machine is unhistorically viewed in relation to the subsequent development\n",
      "Cleaned Token After =  tube . '' michael buckland concluded bush 's 1945 vision information retrieval machine unhistorically viewed relation subsequent development \n",
      "Cleaned Token After Stem =  tube . `` michael buckland conclud bush 's 1945 vision inform retriev machin unhistor view relat subsequ develop \n",
      "Cleaned Token Before =  medical literature retrieval or medical document retrieval is an activity that uses professional methods for medical research papers retrieval, report and other\n",
      "Cleaned Token After =  medical literature retrieval medical document retrieval activity uses professional methods medical research papers retrieval , report \n",
      "Cleaned Token After Stem =  medic literatur retriev medic document retriev activ use profession method medic research paper retriev , report \n",
      "Cleaned Token Before =  knautz, k., soubusta, s., & stock, w.g. (2010). tag clusters as information retrieval interfaces archived 2011-07-17 at the wayback machine. proceedings\n",
      "Cleaned Token After =  knautz , k. , soubusta , s. , & stock , w.g . ( 2010 ) . tag clusters information retrieval interfaces archived 2011-07-17 wayback machine . proceedings \n",
      "Cleaned Token After Stem =  knautz , k. , soubusta , s. , & stock , w.g . ( 2010 ) . tag cluster inform retriev interfac archiv 2011-07-17 wayback machin . proceed \n",
      "Cleaned Token Before =  the process of interactively searching for and retrieving requested information via a computer from databases that are online. interactive searches became\n",
      "Cleaned Token After =  process interactively searching retrieving requested information via computer databases online . interactive searches became \n",
      "Cleaned Token After Stem =  process interact search retriev request inform via comput databas onlin . interact search becam \n",
      "Cleaned Token Before =  modularization and information hiding. note that information hiding was first presented in a different paper of the same author – \"information distributions\n",
      "Cleaned Token After =  modularization information hiding . note information hiding first presented different paper author – `` information distributions \n",
      "Cleaned Token After Stem =  modular inform hide . note inform hide first present differ paper author – `` inform distribut \n",
      "Cleaned Token Before =  as a way to formally define a query and document relationship in information retrieval. this formalization is a logical implication with an attached measure\n",
      "Cleaned Token After =  way formally define query document relationship information retrieval . formalization logical implication attached measure \n",
      "Cleaned Token After Stem =  way formal defin queri document relationship inform retriev . formal logic implic attach measur \n",
      "Cleaned Token Before =  blurring the lines between document stores. some search engines (aka information retrieval) systems like elasticsearch provide enough of the core operations\n",
      "Cleaned Token After =  blurring lines document stores . search engines ( aka information retrieval ) systems like elasticsearch provide enough core operations \n",
      "Cleaned Token After Stem =  blur line document store . search engin ( aka inform retriev ) system like elasticsearch provid enough core oper \n",
      "Cleaned Token Before =  openbook opensearchserver pubget q-go quixey sci-hub singlepoint smart information retrieval system sparrho svensk mediedatabas swiftype thunderstone software\n",
      "Cleaned Token After =  openbook opensearchserver pubget q-go quixey sci-hub singlepoint smart information retrieval system sparrho svensk mediedatabas swiftype thunderstone software \n",
      "Cleaned Token After Stem =  openbook opensearchserv pubget q-go quixey sci-hub singlepoint smart inform retriev system sparrho svensk mediedataba swiftyp thunderston softwar \n",
      "Cleaned Token Before =  \"almost human: interview with a chatbot\". new scientist. reed business information ltd. mike elgan (2013-03-09). \"smart apps think (so you don't have to)\"\n",
      "Cleaned Token After =  `` almost human : interview chatbot '' . new scientist . reed business information ltd. mike elgan ( 2013-03-09 ) . `` smart apps think ( n't ) '' \n",
      "Cleaned Token After Stem =  `` almost human : interview chatbot `` . new scientist . reed busi inform ltd. mike elgan ( 2013-03-09 ) . `` smart app think ( n't ) `` \n",
      "Cleaned Token Before =  moved into the field of information retrieval and search engines after taking two outside classes from the university's information and library science department\n",
      "Cleaned Token After =  moved field information retrieval search engines taking two outside classes university 's information library science department \n",
      "Cleaned Token After Stem =  move field inform retriev search engin take two outsid class univers 's inform librari scienc depart \n",
      "Cleaned Token Before =  superstar soccer, a sports video game series information-seeking support system, in information retrieval is-3 (disambiguation) this disambiguation page\n",
      "Cleaned Token After =  superstar soccer , sports video game series information-seeking support system , information retrieval is-3 ( disambiguation ) disambiguation page \n",
      "Cleaned Token After Stem =  superstar soccer , sport video game seri information-seek support system , inform retriev is-3 ( disambigu ) disambigu page \n",
      "Cleaned Token Before =  trip is a free clinical search engine. its primary function is to help clinicians identify the best available evidence with which to answer clinical questions\n",
      "Cleaned Token After =  trip free clinical search engine . primary function help clinicians identify best available evidence answer clinical questions \n",
      "Cleaned Token After Stem =  trip free clinic search engin . primari function help clinician identifi best avail evid answer clinic question \n",
      "Cleaned Token Before =  a corpus for linguistic research in computational linguistics, information retrieval and natural language processing. in particular, it commonly serves\n",
      "Cleaned Token After =  corpus linguistic research computational linguistics , information retrieval natural language processing . particular , commonly serves \n",
      "Cleaned Token After Stem =  corpu linguist research comput linguist , inform retriev natur languag process . particular , commonli serv \n",
      "Cleaned Token Before =  set theoretic data structure and retrieval language\". sigir forum. acm special interest group on information retrieval. 7 (4): 45–55. winter 1972. doi:10\n",
      "Cleaned Token After =  set theoretic data structure retrieval language '' . sigir forum . acm special interest group information retrieval . 7 ( 4 ) : 45–55 . winter 1972. doi:10 \n",
      "Cleaned Token After Stem =  set theoret data structur retriev languag `` . sigir forum . acm special interest group inform retriev . 7 ( 4 ) : 45–55 . winter 1972. doi:10 \n",
      "Cleaned Token Before =  amherst whose work focuses on information retrieval. he is the founder of the center for intelligent information retrieval and served as the editor-in-chief\n",
      "Cleaned Token After =  amherst whose work focuses information retrieval . founder center intelligent information retrieval served editor-in-chief \n",
      "Cleaned Token After Stem =  amherst whose work focus inform retriev . founder center intellig inform retriev serv editor-in-chief \n",
      "Cleaned Token Before =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion\n",
      "Cleaned Token After =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion \n",
      "Cleaned Token After Stem =  digit librari comput platform digit market world wide web inform retriev secur cryptographi formal method secur servic intrus \n",
      "Cleaned Token Before =  algorithms to detect abnormal access to data (e.g., databases or information retrieval systems) or abnormal email exchange, honeypots for detecting authorized\n",
      "Cleaned Token After =  algorithms detect abnormal access data ( e.g. , databases information retrieval systems ) abnormal email exchange , honeypots detecting authorized \n",
      "Cleaned Token After Stem =  algorithm detect abnorm access data ( e.g . , databas inform retriev system ) abnorm email exchang , honeypot detect author \n",
      "Cleaned Token Before =  host configuration protocol (dhcp) to assign networking configuration information to network hosts. authentication servers identify and authenticate users\n",
      "Cleaned Token After =  host configuration protocol ( dhcp ) assign networking configuration information network hosts . authentication servers identify authenticate users \n",
      "Cleaned Token After Stem =  host configur protocol ( dhcp ) assign network configur inform network host . authent server identifi authent user \n",
      "Cleaned Token Before =  information retrieval with database and information systems query language, a computer language used to make queries into databases and information systems\n",
      "Cleaned Token After =  information retrieval database information systems query language , computer language used make queries databases information systems \n",
      "Cleaned Token After Stem =  inform retriev databas inform system queri languag , comput languag use make queri databas inform system \n",
      "Cleaned Token Before =  content and data, to automate the delivery of relevant, personalized information. coveo provides solutions[buzzword] for ecommerce, customer service,\n",
      "Cleaned Token After =  content data , automate delivery relevant , personalized information . coveo provides solutions [ buzzword ] ecommerce , customer service , \n",
      "Cleaned Token After Stem =  content data , autom deliveri relev , person inform . coveo provid solut [ buzzword ] ecommerc , custom servic , \n",
      "Cleaned Token Before =  general principle that matching the encoding contexts of information at recall assists in the retrieval of episodic memories. it provides a framework for understanding\n",
      "Cleaned Token After =  general principle matching encoding contexts information recall assists retrieval episodic memories . provides framework understanding \n",
      "Cleaned Token After Stem =  gener principl match encod context inform recal assist retriev episod memori . provid framework understand \n",
      "Cleaned Token Before =  damerau stated that in an investigation of spelling errors for an information-retrieval system, more than 80% were a result of a single error of one of\n",
      "Cleaned Token After =  damerau stated investigation spelling errors information-retrieval system , 80 % result single error one \n",
      "Cleaned Token After Stem =  damerau state investig spell error information-retriev system , 80 % result singl error one \n",
      "Cleaned Token Before =  and alertness. the third primary application of neurohacking is information retrieval from the brain. this typically involves the use of a brain-machine\n",
      "Cleaned Token After =  alertness . third primary application neurohacking information retrieval brain . typically involves use brain-machine \n",
      "Cleaned Token After Stem =  alert . third primari applic neurohack inform retriev brain . typic involv use brain-machin \n",
      "Cleaned Token Before =  opposed to searching the internet. these tools are designed to find information on the user's pc, including web browser history, e-mail archives, text\n",
      "Cleaned Token After =  opposed searching internet . tools designed find information user 's pc , including web browser history , e-mail archives , text \n",
      "Cleaned Token After Stem =  oppos search internet . tool design find inform user 's pc , includ web browser histori , e-mail archiv , text \n",
      "Cleaned Token Before =  marec is intended as raw material for research in areas such as information retrieval, natural language processing or machine translation, which require\n",
      "Cleaned Token After =  marec intended raw material research areas information retrieval , natural language processing machine translation , require \n",
      "Cleaned Token After Stem =  marec intend raw materi research area inform retriev , natur languag process machin translat , requir \n",
      "Cleaned Token Before =  contact with an active filter medium. dwell time (gnss) dwell time (information retrieval), the time a user remains at a search result after a click dwell\n",
      "Cleaned Token After =  contact active filter medium . dwell time ( gnss ) dwell time ( information retrieval ) , time user remains search result click dwell \n",
      "Cleaned Token After Stem =  contact activ filter medium . dwell time ( gnss ) dwell time ( inform retriev ) , time user remain search result click dwell \n",
      "Cleaned Token Before =  michael s. lew (born 19 april 1965) is a scientist in multimedia information search and retrieval at leiden university, netherlands. he has published over a\n",
      "Cleaned Token After =  michael s. lew ( born 19 april 1965 ) scientist multimedia information search retrieval leiden university , netherlands . published \n",
      "Cleaned Token After Stem =  michael s. lew ( born 19 april 1965 ) scientist multimedia inform search retriev leiden univers , netherland . publish \n",
      "Cleaned Token Before =  challenges: automatic speech recognition, machine translation, and information retrieval. the focus of the program was on recognizing speech in mandarin\n",
      "Cleaned Token After =  challenges : automatic speech recognition , machine translation , information retrieval . focus program recognizing speech mandarin \n",
      "Cleaned Token After Stem =  challeng : automat speech recognit , machin translat , inform retriev . focu program recogn speech mandarin \n",
      "Cleaned Token Before =  he worked on profiling tools, microprocessor architecture, and information retrieval. much of his work was completed in close collaboration with sanjay\n",
      "Cleaned Token After =  worked profiling tools , microprocessor architecture , information retrieval . much work completed close collaboration sanjay \n",
      "Cleaned Token After Stem =  work profil tool , microprocessor architectur , inform retriev . much work complet close collabor sanjay \n",
      "Cleaned Token Before =  and open-source software portal enterprise search information extraction list of information retrieval libraries text mining \"welcome to apache lucene\"\n",
      "Cleaned Token After =  open-source software portal enterprise search information extraction list information retrieval libraries text mining `` welcome apache lucene '' \n",
      "Cleaned Token After Stem =  open-sourc softwar portal enterpris search inform extract list inform retriev librari text mine `` welcom apach lucen `` \n",
      "Cleaned Token Before =  dynatext is an sgml publishing tool. it was introduced in 1990, and was the first system to handle arbitrarily large sgml documents, and to render them\n",
      "Cleaned Token After =  dynatext sgml publishing tool . introduced 1990 , first system handle arbitrarily large sgml documents , render \n",
      "Cleaned Token After Stem =  dynatext sgml publish tool . introduc 1990 , first system handl arbitrarili larg sgml document , render \n",
      "Cleaned Token Before =   in proceedings, acm conference on research and development in information retrieval sigir'95, pages 74–82, seattle, washington, july 1995. [6] c.-y\n",
      "Cleaned Token After =  proceedings , acm conference research development information retrieval sigir'95 , pages 74–82 , seattle , washington , july 1995 . [ 6 ] c.-y \n",
      "Cleaned Token After Stem =  proceed , acm confer research develop inform retriev sigir'95 , page 74–82 , seattl , washington , juli 1995 . [ 6 ] c.-i \n",
      "Cleaned Token Before =  and usable by content management systems, other web crawlers, and information retrieval systems. the standalone tika was founded by jérôme charron, chris\n",
      "Cleaned Token After =  usable content management systems , web crawlers , information retrieval systems . standalone tika founded jérôme charron , chris \n",
      "Cleaned Token After Stem =  usabl content manag system , web crawler , inform retriev system . standalon tika found jérôme charron , chri \n",
      "Cleaned Token Before =  computationally private information retrieval with polylogarithmic communication, where it was used in a private information retrieval scheme. the phi-hiding\n",
      "Cleaned Token After =  computationally private information retrieval polylogarithmic communication , used private information retrieval scheme . phi-hiding \n",
      "Cleaned Token After Stem =  comput privat inform retriev polylogarithm commun , use privat inform retriev scheme . phi-hid \n",
      "Cleaned Token Before =  concept hierarchies are crucial components for many applications of information retrieval, natural language processing and knowledge management. building\n",
      "Cleaned Token After =  concept hierarchies crucial components many applications information retrieval , natural language processing knowledge management . building \n",
      "Cleaned Token After Stem =  concept hierarchi crucial compon mani applic inform retriev , natur languag process knowledg manag . build \n",
      "Cleaned Token Before =  application of a column-oriented database storage system with focus on information-retrieval in biology in 1969. clinical data from patient records with many\n",
      "Cleaned Token After =  application column-oriented database storage system focus information-retrieval biology 1969. clinical data patient records many \n",
      "Cleaned Token After Stem =  applic column-ori databas storag system focu information-retriev biolog 1969. clinic data patient record mani \n",
      "Cleaned Token Before =  humans transfer information among the different memory stores. some prominent process used in transferring information are coding, retrieval, and perception\n",
      "Cleaned Token After =  humans transfer information among different memory stores . prominent process used transferring information coding , retrieval , perception \n",
      "Cleaned Token After Stem =  human transfer inform among differ memori store . promin process use transfer inform code , retriev , percept \n",
      "Cleaned Token Before =  content-based image retrieval document supervised learning, unsupervised learning document retrieval document clustering information retrieval knowledge organization\n",
      "Cleaned Token After =  content-based image retrieval document supervised learning , unsupervised learning document retrieval document clustering information retrieval knowledge organization \n",
      "Cleaned Token After Stem =  content-bas imag retriev document supervis learn , unsupervis learn document retriev document cluster inform retriev knowledg organ \n",
      "Cleaned Token Before =  of the regular interrogation of filesystems even when no user needs information) and absolute accuracy (since the database does not update in real time)\n",
      "Cleaned Token After =  regular interrogation filesystems even user needs information ) absolute accuracy ( since database update real time ) \n",
      "Cleaned Token After Stem =  regular interrog filesystem even user need inform ) absolut accuraci ( sinc databas updat real time ) \n",
      "Cleaned Token Before =  classical computers. the study of quantum computing is a subfield of quantum information science. it is likely to expand in the next few years as the field shifts\n",
      "Cleaned Token After =  classical computers . study quantum computing subfield quantum information science . likely expand next years field shifts \n",
      "Cleaned Token After Stem =  classic comput . studi quantum comput subfield quantum inform scienc . like expand next year field shift \n",
      "Cleaned Token Before =  with an overall goal to extract information (with intelligent methods) from a data set and transform the information into a comprehensible structure for\n",
      "Cleaned Token After =  overall goal extract information ( intelligent methods ) data set transform information comprehensible structure \n",
      "Cleaned Token After Stem =  overal goal extract inform ( intellig method ) data set transform inform comprehens structur \n",
      "Cleaned Token Before =  software take care of describing data structures for storing the data and retrieval procedures for answering queries. most relational databases use the sql\n",
      "Cleaned Token After =  software take care describing data structures storing data retrieval procedures answering queries . relational databases use sql \n",
      "Cleaned Token After Stem =  softwar take care describ data structur store data retriev procedur answer queri . relat databas use sql \n",
      "Cleaned Token Before =  of mis systems: retrieval and dissemination are dependent on technology hardware and software. potential for inaccurate information. enterprise systems—also\n",
      "Cleaned Token After =  mis systems : retrieval dissemination dependent technology hardware software . potential inaccurate information . enterprise systems—also \n",
      "Cleaned Token After Stem =  mi system : retriev dissemin depend technolog hardwar softwar . potenti inaccur inform . enterpris systems—also \n",
      "Cleaned Token Before =  paraphrases. applications of paraphrasing are varied including information retrieval, question answering, text summarization, and plagiarism detection\n",
      "Cleaned Token After =  paraphrases . applications paraphrasing varied including information retrieval , question answering , text summarization , plagiarism detection \n",
      "Cleaned Token After Stem =  paraphras . applic paraphras vari includ inform retriev , question answer , text summar , plagiar detect \n",
      "Cleaned Token Before =  international acm sigir conference on research and development in information retrieval (sigir-05). pp. 601–602. archived from the original (pdf) on 2007-09-28\n",
      "Cleaned Token After =  international acm sigir conference research development information retrieval ( sigir-05 ) . pp . 601–602 . archived original ( pdf ) 2007-09-28 \n",
      "Cleaned Token After Stem =  intern acm sigir confer research develop inform retriev ( sigir-05 ) . pp . 601–602 . archiv origin ( pdf ) 2007-09-28 \n",
      "Cleaned Token Before =  multi-million page corpus for the persian language. the siren - security information retrieval and extraction engine. the project wiki contains a list of videos\n",
      "Cleaned Token After =  multi-million page corpus persian language . siren - security information retrieval extraction engine . project wiki contains list videos \n",
      "Cleaned Token After Stem =  multi-million page corpu persian languag . siren - secur inform retriev extract engin . project wiki contain list video \n",
      "Cleaned Token Before =  provide resources and information relevant to small and medium accounting practices. it now includes resources and information for accountants in all\n",
      "Cleaned Token After =  provide resources information relevant small medium accounting practices . includes resources information accountants \n",
      "Cleaned Token After Stem =  provid resourc inform relev small medium account practic . includ resourc inform account \n",
      "Cleaned Token Before =  film), a canadian documentary film ibm stairs, ibm \"storage and information retrieval system\" software stairs (video game) house of stairs (disambiguation)\n",
      "Cleaned Token After =  film ) , canadian documentary film ibm stairs , ibm `` storage information retrieval system '' software stairs ( video game ) house stairs ( disambiguation ) \n",
      "Cleaned Token After Stem =  film ) , canadian documentari film ibm stair , ibm `` storag inform retriev system `` softwar stair ( video game ) hous stair ( disambigu ) \n",
      "Cleaned Token Before =  organizations outside of libraries began developing more sophisticated information retrieval systems. web search engines like google and popular e-commerce websites\n",
      "Cleaned Token After =  organizations outside libraries began developing sophisticated information retrieval systems . web search engines like google popular e-commerce websites \n",
      "Cleaned Token After Stem =  organ outsid librari began develop sophist inform retriev system . web search engin like googl popular e-commerc websit \n",
      "Cleaned Token Before =  enfermagem. 2007;15(3):508–511. boudin f, nie j-y, dawes m. clinical information retrieval using document and pico structure. in: human language technologies:\n",
      "Cleaned Token After =  enfermagem . 2007 ; 15 ( 3 ) :508–511 . boudin f , nie j-y , dawes m. clinical information retrieval using document pico structure . : human language technologies : \n",
      "Cleaned Token After Stem =  enfermagem . 2007 ; 15 ( 3 ) :508–511 . boudin f , nie j-i , daw m. clinic inform retriev use document pico structur . : human languag technolog : \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, and information retrieval. version: 1 june 2007. retrieved 2007-11-04. dimitri, m. 1987. enciclopedia\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval . version : 1 june 2007. retrieved 2007-11-04. dimitri , m. 1987. enciclopedia \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev . version : 1 june 2007. retriev 2007-11-04. dimitri , m. 1987. enciclopedia \n",
      "Cleaned Token Before =  relationship database marketing handwriting recognition information retrieval learning to rank information extraction object recognition in computer vision optical\n",
      "Cleaned Token After =  relationship database marketing handwriting recognition information retrieval learning rank information extraction object recognition computer vision optical \n",
      "Cleaned Token After Stem =  relationship databas market handwrit recognit inform retriev learn rank inform extract object recognit comput vision optic \n",
      "Cleaned Token Before =  many fields – including data mining (in particular web mining), information retrieval, pattern recognition, predictive analytics, the semantic web, web\n",
      "Cleaned Token After =  many fields – including data mining ( particular web mining ) , information retrieval , pattern recognition , predictive analytics , semantic web , web \n",
      "Cleaned Token After Stem =  mani field – includ data mine ( particular web mine ) , inform retriev , pattern recognit , predict analyt , semant web , web \n",
      "Cleaned Token Before =  picture(s) used for its prediction. the heightened flexibility of information retrieval means that b-frames typically require fewer bits for encoding than\n",
      "Cleaned Token After =  picture ( ) used prediction . heightened flexibility information retrieval means b-frames typically require fewer bits encoding \n",
      "Cleaned Token After Stem =  pictur ( ) use predict . heighten flexibl inform retriev mean b-frame typic requir fewer bit encod \n",
      "Cleaned Token Before =  the philosophy of information (pi) is a branch of philosophy that studies topics relevant to information processing, representational system and consciousness\n",
      "Cleaned Token After =  philosophy information ( pi ) branch philosophy studies topics relevant information processing , representational system consciousness \n",
      "Cleaned Token After Stem =  philosophi inform ( pi ) branch philosophi studi topic relev inform process , represent system conscious \n",
      "Cleaned Token Before =  pubpsych is a vertical open access information retrieval system for psychological resources, coordinated by the research support organization leibniz\n",
      "Cleaned Token After =  pubpsych vertical open access information retrieval system psychological resources , coordinated research support organization leibniz \n",
      "Cleaned Token After Stem =  pubpsych vertic open access inform retriev system psycholog resourc , coordin research support organ leibniz \n",
      "Cleaned Token Before =  negative search is the elimination of information which is not relevant from a mass of content in order to present to a user a range of relevant content\n",
      "Cleaned Token After =  negative search elimination information relevant mass content order present user range relevant content \n",
      "Cleaned Token After Stem =  neg search elimin inform relev mass content order present user rang relev content \n",
      "Cleaned Token Before =  information retrieval. delta – description language for taxonomy. june 2009. national hardwood and lumber association american hardwood information center\n",
      "Cleaned Token After =  information retrieval . delta – description language taxonomy . june 2009. national hardwood lumber association american hardwood information center \n",
      "Cleaned Token After Stem =  inform retriev . delta – descript languag taxonomi . june 2009. nation hardwood lumber associ american hardwood inform center \n",
      "Cleaned Token Before =  framework\" (pdf). proceedings of the international society for music information retrieval. october: 293–298. retrieved 31 march 2015. cs1 maint: discouraged\n",
      "Cleaned Token After =  framework '' ( pdf ) . proceedings international society music information retrieval . october : 293–298 . retrieved 31 march 2015. cs1 maint : discouraged \n",
      "Cleaned Token After Stem =  framework `` ( pdf ) . proceed intern societi music inform retriev . octob : 293–298 . retriev 31 march 2015. cs1 maint : discourag \n",
      "Cleaned Token Before =  intuitive graphical visualisation. kleio is a faceted semantic information retrieval system over medline abstracts. europe pmc evidencefinder europe\n",
      "Cleaned Token After =  intuitive graphical visualisation . kleio faceted semantic information retrieval system medline abstracts . europe pmc evidencefinder europe \n",
      "Cleaned Token After Stem =  intuit graphic visualis . kleio facet semant inform retriev system medlin abstract . europ pmc evidencefind europ \n",
      "Cleaned Token Before =  ness computing was a personal search company. it was acquired by opentable in march 2014 and was shut down later that year. it was founded in october 2009\n",
      "Cleaned Token After =  ness computing personal search company . acquired opentable march 2014 shut later year . founded october 2009 \n",
      "Cleaned Token After Stem =  ness comput person search compani . acquir opent march 2014 shut later year . found octob 2009 \n",
      "Cleaned Token Before =  of electrical and electronics engineers, other computer science and information science awards, and a list of computer science competitions. the top\n",
      "Cleaned Token After =  electrical electronics engineers , computer science information science awards , list computer science competitions . top \n",
      "Cleaned Token After Stem =  electr electron engin , comput scienc inform scienc award , list comput scienc competit . top \n",
      "Cleaned Token Before =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion\n",
      "Cleaned Token After =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion \n",
      "Cleaned Token After Stem =  digit librari comput platform digit market world wide web inform retriev secur cryptographi formal method secur servic intrus \n",
      "Cleaned Token Before =  dtsearch corp. is a software company which specializes in text retrieval software. it was founded in 1991, and is headquartered in bethesda, maryland\n",
      "Cleaned Token After =  dtsearch corp. software company specializes text retrieval software . founded 1991 , headquartered bethesda , maryland \n",
      "Cleaned Token After Stem =  dtsearch corp. softwar compani special text retriev softwar . found 1991 , headquart bethesda , maryland \n",
      "Cleaned Token Before =  2019. baeza-yates, ricardo; ribeiro-neto, berthier (2010). modern information retrieval: the concepts and technology behind search. addison-wesley/acm press\n",
      "Cleaned Token After =  2019. baeza-yates , ricardo ; ribeiro-neto , berthier ( 2010 ) . modern information retrieval : concepts technology behind search . addison-wesley/acm press \n",
      "Cleaned Token After Stem =  2019. baeza-y , ricardo ; ribeiro-neto , berthier ( 2010 ) . modern inform retriev : concept technolog behind search . addison-wesley/acm press \n",
      "Cleaned Token Before =  information center. 25 september 2000. retrieved 4 may 2021. \"administrative measures on internet information services\". china internet information center\n",
      "Cleaned Token After =  information center . 25 september 2000. retrieved 4 may 2021 . `` administrative measures internet information services '' . china internet information center \n",
      "Cleaned Token After Stem =  inform center . 25 septemb 2000. retriev 4 may 2021 . `` administr measur internet inform servic `` . china internet inform center \n",
      "Cleaned Token Before =  cybersecurity or information technology security (it security) is the protection of computer systems and networks from information disclosure, theft\n",
      "Cleaned Token After =  cybersecurity information technology security ( security ) protection computer systems networks information disclosure , theft \n",
      "Cleaned Token After Stem =  cybersecur inform technolog secur ( secur ) protect comput system network inform disclosur , theft \n",
      "Cleaned Token Before =  published in proceedings to the 2010 acm special interest group on information retrieval conference, the authors present research on predicting escalations\n",
      "Cleaned Token After =  published proceedings 2010 acm special interest group information retrieval conference , authors present research predicting escalations \n",
      "Cleaned Token After Stem =  publish proceed 2010 acm special interest group inform retriev confer , author present research predict escal \n",
      "Cleaned Token Before =  waterloo, 1982. as a researcher, he is known for his projects in information retrieval and recommendation systems. in 2011, he received the scientific\n",
      "Cleaned Token After =  waterloo , 1982. researcher , known projects information retrieval recommendation systems . 2011 , received scientific \n",
      "Cleaned Token After Stem =  waterloo , 1982. research , known project inform retriev recommend system . 2011 , receiv scientif \n",
      "Cleaned Token Before =  since the early years of the 21st century he has worked mainly in information retrieval. his work is supported by grants from the nederlandse organisatie\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Token After =  since early years 21st century worked mainly information retrieval . work supported grants nederlandse organisatie \n",
      "Cleaned Token After Stem =  sinc earli year 21st centuri work mainli inform retriev . work support grant nederlands organisati \n",
      "Cleaned Token Before =  the number of digits that carry real information about a measurement precision and recall, in information retrieval: the percentage of relevant documents\n",
      "Cleaned Token After =  number digits carry real information measurement precision recall , information retrieval : percentage relevant documents \n",
      "Cleaned Token After Stem =  number digit carri real inform measur precis recal , inform retriev : percentag relev document \n",
      "Cleaned Token Before =  general productivity and information retrieval, including email, calendar, contacts, the stock market and weather information. however, public demand and\n",
      "Cleaned Token After =  general productivity information retrieval , including email , calendar , contacts , stock market weather information . however , public demand \n",
      "Cleaned Token After Stem =  gener product inform retriev , includ email , calendar , contact , stock market weather inform . howev , public demand \n",
      "Cleaned Token Before =  software, inc. was a software company specializing in visualization, information retrieval and natural language processing. it was bought by business objects\n",
      "Cleaned Token After =  software , inc. software company specializing visualization , information retrieval natural language processing . bought business objects \n",
      "Cleaned Token After Stem =  softwar , inc. softwar compani special visual , inform retriev natur languag process . bought busi object \n",
      "Cleaned Token Before =  hashing, and other security mechanisms in your design to ensure that information collected from a potential attacker won't allow access. another key feature\n",
      "Cleaned Token After =  hashing , security mechanisms design ensure information collected potential attacker wo n't allow access . another key feature \n",
      "Cleaned Token After Stem =  hash , secur mechan design ensur inform collect potenti attack wo n't allow access . anoth key featur \n",
      "Cleaned Token Before =  may differ depending on the situation: searching: users expect information retrieval systems to be able to have correct case sensitivity depending on\n",
      "Cleaned Token After =  may differ depending situation : searching : users expect information retrieval systems able correct case sensitivity depending \n",
      "Cleaned Token After Stem =  may differ depend situat : search : user expect inform retriev system abl correct case sensit depend \n",
      "Cleaned Token Before =  vocabulary and syntax that enables powerful content indexing and information retrieval in large collections. since 1991, the udc has been owned and managed\n",
      "Cleaned Token After =  vocabulary syntax enables powerful content indexing information retrieval large collections . since 1991 , udc owned managed \n",
      "Cleaned Token After Stem =  vocabulari syntax enabl power content index inform retriev larg collect . sinc 1991 , udc own manag \n",
      "Cleaned Token Before =  uspto's electronic filing system. duty of candor patent application information retrieval (pair) mpep 2129 iv, citing riverwood int'l corp. v. r.a. jones\n",
      "Cleaned Token After =  uspto 's electronic filing system . duty candor patent application information retrieval ( pair ) mpep 2129 iv , citing riverwood int ' l corp. v. r.a. jones \n",
      "Cleaned Token After Stem =  uspto 's electron file system . duti candor patent applic inform retriev ( pair ) mpep 2129 iv , cite riverwood int ' l corp. v. r.a. jone \n",
      "Cleaned Token Before =  problem in information retrieval. zhao and callan (2010) were perhaps the first to quantitatively study the vocabulary mismatch problem in a retrieval setting\n",
      "Cleaned Token After =  problem information retrieval . zhao callan ( 2010 ) perhaps first quantitatively study vocabulary mismatch problem retrieval setting \n",
      "Cleaned Token After Stem =  problem inform retriev . zhao callan ( 2010 ) perhap first quantit studi vocabulari mismatch problem retriev set \n",
      "Cleaned Token Before =  information systems to be opened to 'outside' correspondents not just for transaction processing but also for e-messaging and information retrieval and\n",
      "Cleaned Token After =  information systems opened 'outside ' correspondents transaction processing also e-messaging information retrieval \n",
      "Cleaned Token After Stem =  inform system open 'outsid ' correspond transact process also e-messag inform retriev \n",
      "Cleaned Token Before =  the precise retrieval of subsets of the information on the web, real-time trend analysis, and meta-level analysis of the available information of the web\n",
      "Cleaned Token After =  precise retrieval subsets information web , real-time trend analysis , meta-level analysis available information web \n",
      "Cleaned Token After Stem =  precis retriev subset inform web , real-tim trend analysi , meta-level analysi avail inform web \n",
      "Cleaned Token Before =  society for information science and technology, 58 (5): 702–709, doi:10.1002/asi.20524. heaps, harold stanley (1978), information retrieval: computational\n",
      "Cleaned Token After =  society information science technology , 58 ( 5 ) : 702–709 , doi:10.1002/asi.20524 . heaps , harold stanley ( 1978 ) , information retrieval : computational \n",
      "Cleaned Token After Stem =  societi inform scienc technolog , 58 ( 5 ) : 702–709 , doi:10.1002/asi.20524 . heap , harold stanley ( 1978 ) , inform retriev : comput \n",
      "Cleaned Token Before =  cancellation, or identify and categorize audio content through music information retrieval or acoustic fingerprint. architectural acoustics is the science\n",
      "Cleaned Token After =  cancellation , identify categorize audio content music information retrieval acoustic fingerprint . architectural acoustics science \n",
      "Cleaned Token After Stem =  cancel , identifi categor audio content music inform retriev acoust fingerprint . architectur acoust scienc \n",
      "Cleaned Token Before =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion\n",
      "Cleaned Token After =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion \n",
      "Cleaned Token After Stem =  digit librari comput platform digit market world wide web inform retriev secur cryptographi formal method secur servic intrus \n",
      "Cleaned Token Before =  important role in the transfer of information from short-term memory to long-term memory during encoding and retrieval stages. these stages do not need\n",
      "Cleaned Token After =  important role transfer information short-term memory long-term memory encoding retrieval stages . stages need \n",
      "Cleaned Token After Stem =  import role transfer inform short-term memori long-term memori encod retriev stage . stage need \n",
      "Cleaned Token Before =  provides us with a new technique for directly aggregating uncertain information with uncertain weights via owa mechanism in soft decision making and\n",
      "Cleaned Token After =  provides us new technique directly aggregating uncertain information uncertain weights via owa mechanism soft decision making \n",
      "Cleaned Token After Stem =  provid us new techniqu directli aggreg uncertain inform uncertain weight via owa mechan soft decis make \n",
      "Cleaned Token Before =  equivalent of screen burn information retrieval, the science of searching for information in or as documents or databases information revolution, one of the\n",
      "Cleaned Token After =  equivalent screen burn information retrieval , science searching information documents databases information revolution , one \n",
      "Cleaned Token After Stem =  equival screen burn inform retriev , scienc search inform document databas inform revolut , one \n",
      "Cleaned Token Before =  ibm omnifind was an enterprise search platform from ibm. it did come in several packages adapted to different business needs, including omnifind enterprise\n",
      "Cleaned Token After =  ibm omnifind enterprise search platform ibm . come several packages adapted different business needs , including omnifind enterprise \n",
      "Cleaned Token After Stem =  ibm omnifind enterpris search platform ibm . come sever packag adapt differ busi need , includ omnifind enterpris \n",
      "Cleaned Token Before =  electronics engineers (ieee) in 2016 for contributions to multimedia information retrieval. \"2016 elevated fellow\" (pdf). ieee fellows directory. qi tian homepage\n",
      "Cleaned Token After =  electronics engineers ( ieee ) 2016 contributions multimedia information retrieval . `` 2016 elevated fellow '' ( pdf ) . ieee fellows directory . qi tian homepage \n",
      "Cleaned Token After Stem =  electron engin ( ieee ) 2016 contribut multimedia inform retriev . `` 2016 elev fellow `` ( pdf ) . ieee fellow directori . qi tian homepag \n",
      "Cleaned Token Before =  health informatics, information retrieval, information systems, knowledge and information management, as well as libraries and information society. such is\n",
      "Cleaned Token After =  health informatics , information retrieval , information systems , knowledge information management , well libraries information society . \n",
      "Cleaned Token After Stem =  health informat , inform retriev , inform system , knowledg inform manag , well librari inform societi . \n",
      "Cleaned Token Before =  that are considered semantically equivalent for the purposes of information retrieval. these data elements are frequently found in different metadata\n",
      "Cleaned Token After =  considered semantically equivalent purposes information retrieval . data elements frequently found different metadata \n",
      "Cleaned Token After Stem =  consid semant equival purpos inform retriev . data element frequent found differ metadata \n",
      "Cleaned Token Before =  connected. memory is a site of storage and enables the retrieval and encoding of information, which is essential for the process of learning. learning\n",
      "Cleaned Token After =  connected . memory site storage enables retrieval encoding information , essential process learning . learning \n",
      "Cleaned Token After Stem =  connect . memori site storag enabl retriev encod inform , essenti process learn . learn \n",
      "Cleaned Token Before =  application:andrcs marzal and enrique vidal mccowan et al. 2005: on the use of information retrieval measures for speech recognition evaluation hunt, m.j., 1990: figures\n",
      "Cleaned Token After =  application : andrcs marzal enrique vidal mccowan et al . 2005 : use information retrieval measures speech recognition evaluation hunt , m.j. , 1990 : figures \n",
      "Cleaned Token After Stem =  applic : andrc marzal enriqu vidal mccowan et al . 2005 : use inform retriev measur speech recognit evalu hunt , m.j. , 1990 : figur \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, information retrieval. https://web.archive.org/web/20070103200438/http://delta-intkey\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval . https : //web.archive.org/web/20070103200438/http : //delta-intkey \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev . http : //web.archive.org/web/20070103200438/http : //delta-intkey \n",
      "Cleaned Token Before =  post–production and audio editing. music information retrieval: this application domain focuses on retrieval technologies for music (both audio and symbolic\n",
      "Cleaned Token After =  post–production audio editing . music information retrieval : application domain focuses retrieval technologies music ( audio symbolic \n",
      "Cleaned Token After Stem =  post–product audio edit . music inform retriev : applic domain focus retriev technolog music ( audio symbol \n",
      "Cleaned Token Before =  international acm sigir conference on research and development in information retrieval: 1329–1338. doi:10.1145/3397271.3401129. hdl:10138/328471. s2cid 220730163\n",
      "Cleaned Token After =  international acm sigir conference research development information retrieval : 1329–1338 . doi:10.1145/3397271.3401129 . hdl:10138/328471 . s2cid 220730163 \n",
      "Cleaned Token After Stem =  intern acm sigir confer research develop inform retriev : 1329–1338 . doi:10.1145/3397271.3401129 . hdl:10138/328471 . s2cid 220730163 \n",
      "Cleaned Token Before =  chemrefer is a service that allows searching of freely available and full-text chemical and pharmaceutical literature that is published by authoritative\n",
      "Cleaned Token After =  chemrefer service allows searching freely available full-text chemical pharmaceutical literature published authoritative \n",
      "Cleaned Token After Stem =  chemref servic allow search freeli avail full-text chemic pharmaceut literatur publish authorit \n",
      "Cleaned Token Before =   corporations, etc.) were invited to participate in the annual information retrieval, topic detection and tracking, automatic content extraction, and\n",
      "Cleaned Token After =  corporations , etc . ) invited participate annual information retrieval , topic detection tracking , automatic content extraction , \n",
      "Cleaned Token After Stem =  corpor , etc . ) invit particip annual inform retriev , topic detect track , automat content extract , \n",
      "Cleaned Token Before =  and mahmoud r. hejazi, an object oriented ontology interface for information retrieval purposes in telecommunication domain, international symposium on\n",
      "Cleaned Token After =  mahmoud r. hejazi , object oriented ontology interface information retrieval purposes telecommunication domain , international symposium \n",
      "Cleaned Token After Stem =  mahmoud r. hejazi , object orient ontolog interfac inform retriev purpos telecommun domain , intern symposium \n",
      "Cleaned Token Before =  zumasys.com. \"ongroup\". www.ongroup.com. nelson, don (1965). \"general information retrieval language and system (girls)\" (pdf). cite journal requires |journal=\n",
      "Cleaned Token After =  zumasys.com . `` ongroup '' . www.ongroup.com . nelson , ( 1965 ) . `` general information retrieval language system ( girls ) '' ( pdf ) . cite journal requires |journal= \n",
      "Cleaned Token After Stem =  zumasys.com . `` ongroup `` . www.ongroup.com . nelson , ( 1965 ) . `` gener inform retriev languag system ( girl ) `` ( pdf ) . cite journal requir |journal= \n",
      "Cleaned Token Before =  as a result of public procurement contracts. list of information retrieval libraries information extraction \"elasticsearch releases\". retrieved 2 december\n",
      "Cleaned Token After =  result public procurement contracts . list information retrieval libraries information extraction `` elasticsearch releases '' . retrieved 2 december \n",
      "Cleaned Token After Stem =  result public procur contract . list inform retriev librari inform extract `` elasticsearch releas `` . retriev 2 decemb \n",
      "Cleaned Token Before =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion\n",
      "Cleaned Token After =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion \n",
      "Cleaned Token After Stem =  digit librari comput platform digit market world wide web inform retriev secur cryptographi formal method secur servic intrus \n",
      "Cleaned Token Before =  informatics information architecture information consultant (aka information broker) information literacy information retrieval information science (outline)\n",
      "Cleaned Token After =  informatics information architecture information consultant ( aka information broker ) information literacy information retrieval information science ( outline ) \n",
      "Cleaned Token After Stem =  informat inform architectur inform consult ( aka inform broker ) inform literaci inform retriev inform scienc ( outlin ) \n",
      "Cleaned Token Before =  portal open semantic framework search oriented architecture list of information retrieval libraries \"news\". apache foundation. retrieved 12 february 2021\n",
      "Cleaned Token After =  portal open semantic framework search oriented architecture list information retrieval libraries `` news '' . apache foundation . retrieved 12 february 2021 \n",
      "Cleaned Token After Stem =  portal open semant framework search orient architectur list inform retriev librari `` news `` . apach foundat . retriev 12 februari 2021 \n",
      "Cleaned Token Before =  the best results for constituency parsing, sentiment analysis, information retrieval, spoken language understanding, machine translation, contextual\n",
      "Cleaned Token After =  best results constituency parsing , sentiment analysis , information retrieval , spoken language understanding , machine translation , contextual \n",
      "Cleaned Token After Stem =  best result constitu pars , sentiment analysi , inform retriev , spoken languag understand , machin translat , contextu \n",
      "Cleaned Token Before =  which are not in their original combinations\". for the purpose of information retrieval, the author citation and year appended to the scientific name, e\n",
      "Cleaned Token After =  original combinations '' . purpose information retrieval , author citation year appended scientific name , e \n",
      "Cleaned Token After Stem =  origin combin `` . purpos inform retriev , author citat year append scientif name , e \n",
      "Cleaned Token Before =  mathematical music theory, computer music, systematic musicology, music information retrieval, computational musicology, digital musicology, sound and music computing\n",
      "Cleaned Token After =  mathematical music theory , computer music , systematic musicology , music information retrieval , computational musicology , digital musicology , sound music computing \n",
      "Cleaned Token After Stem =  mathemat music theori , comput music , systemat musicolog , music inform retriev , comput musicolog , digit musicolog , sound music comput \n",
      "Cleaned Token Before =  virtual reference services, information retrieval, information extraction, and knowledge representation. social information seeking is often materialized\n",
      "Cleaned Token After =  virtual reference services , information retrieval , information extraction , knowledge representation . social information seeking often materialized \n",
      "Cleaned Token After Stem =  virtual refer servic , inform retriev , inform extract , knowledg represent . social inform seek often materi \n",
      "Cleaned Token Before =  architectures index term, also known as a \"descriptor\" in information retrieval file descriptor, an abstract key for accessing a file in chemistry: molecular\n",
      "Cleaned Token After =  architectures index term , also known `` descriptor '' information retrieval file descriptor , abstract key accessing file chemistry : molecular \n",
      "Cleaned Token After Stem =  architectur index term , also known `` descriptor `` inform retriev file descriptor , abstract key access file chemistri : molecular \n",
      "Cleaned Token Before =  belief networks\". proceedings of the international society for music information retrieval conference: 339–344. jamieson, a.r.; giger, m.l.; drukker, k.; lui\n",
      "Cleaned Token After =  belief networks '' . proceedings international society music information retrieval conference : 339–344 . jamieson , a.r . ; giger , m.l . ; drukker , k. ; lui \n",
      "Cleaned Token After Stem =  belief network `` . proceed intern societi music inform retriev confer : 339–344 . jamieson , a.r . ; giger , m.l . ; drukker , k. ; lui \n",
      "Cleaned Token Before =  a search appliance is a type of computer which is attached to a corporate network for the purpose of indexing the content shared across that network in\n",
      "Cleaned Token After =  search appliance type computer attached corporate network purpose indexing content shared across network \n",
      "Cleaned Token After Stem =  search applianc type comput attach corpor network purpos index content share across network \n",
      "Cleaned Token Before =  college park. retrieved october 14, 2018. \"nist to develop cloud roadmap\". informationweek. november 5, 2010. computing initiative seeks to remove barriers\n",
      "Cleaned Token After =  college park . retrieved october 14 , 2018 . `` nist develop cloud roadmap '' . informationweek . november 5 , 2010. computing initiative seeks remove barriers \n",
      "Cleaned Token After Stem =  colleg park . retriev octob 14 , 2018 . `` nist develop cloud roadmap `` . informationweek . novemb 5 , 2010. comput initi seek remov barrier \n",
      "Cleaned Token Before =   computer graphics studies the manipulation of visual and geometric information using computational techniques. it focuses on the mathematical and computational\n",
      "Cleaned Token After =  computer graphics studies manipulation visual geometric information using computational techniques . focuses mathematical computational \n",
      "Cleaned Token After Stem =  comput graphic studi manipul visual geometr inform use comput techniqu . focus mathemat comput \n",
      "Cleaned Token Before =  integration of the measures inside specific applications such the information retrieval, recommender systems, natural language processing, etc. the concept\n",
      "Cleaned Token After =  integration measures inside specific applications information retrieval , recommender systems , natural language processing , etc . concept \n",
      "Cleaned Token After Stem =  integr measur insid specif applic inform retriev , recommend system , natur languag process , etc . concept \n",
      "Cleaned Token Before =  source trustworthiness using similarity measures typically used in information retrieval. source trustworthiness is computed as the cosine similarity (or\n",
      "Cleaned Token After =  source trustworthiness using similarity measures typically used information retrieval . source trustworthiness computed cosine similarity ( \n",
      "Cleaned Token After Stem =  sourc trustworthi use similar measur typic use inform retriev . sourc trustworthi comput cosin similar ( \n",
      "Cleaned Token Before =   machine learning, computational advertising, data mining, and information retrieval. he was named a fellow of the institute of electrical and electronics\n",
      "Cleaned Token After =  machine learning , computational advertising , data mining , information retrieval . named fellow institute electrical electronics \n",
      "Cleaned Token After Stem =  machin learn , comput advertis , data mine , inform retriev . name fellow institut electr electron \n",
      "Cleaned Token Before =  cross-linguistic automatic information machine (exclaim) was an integrated tool for cross-language information retrieval (clir), created at the university\n",
      "Cleaned Token After =  cross-linguistic automatic information machine ( exclaim ) integrated tool cross-language information retrieval ( clir ) , created university \n",
      "Cleaned Token After Stem =  cross-linguist automat inform machin ( exclaim ) integr tool cross-languag inform retriev ( clir ) , creat univers \n",
      "Cleaned Token Before =  ethics in mathematics false positive paradox family-wise error rate information retrieval performance measures neyman–pearson lemma null hypothesis probability\n",
      "Cleaned Token After =  ethics mathematics false positive paradox family-wise error rate information retrieval performance measures neyman–pearson lemma null hypothesis probability \n",
      "Cleaned Token After Stem =  ethic mathemat fals posit paradox family-wis error rate inform retriev perform measur neyman–pearson lemma null hypothesi probabl \n",
      "Cleaned Token Before =  systems being considered for the processing, storage and retrieval of sensitive or classified information. network services include offerings such as file sharing\n",
      "Cleaned Token After =  systems considered processing , storage retrieval sensitive classified information . network services include offerings file sharing \n",
      "Cleaned Token After Stem =  system consid process , storag retriev sensit classifi inform . network servic includ offer file share \n",
      "Cleaned Token Before =  still leads today. maristella agosti's research interests cover information retrieval, user engagement, databases, digital cultural heritage and data\n",
      "Cleaned Token After =  still leads today . maristella agosti 's research interests cover information retrieval , user engagement , databases , digital cultural heritage data \n",
      "Cleaned Token After Stem =  still lead today . maristella agosti 's research interest cover inform retriev , user engag , databas , digit cultur heritag data \n",
      "Cleaned Token Before =  relevant information resources\", though it appears to have been first coined in a public context referring to the web and information retrieval by alkis\n",
      "Cleaned Token After =  relevant information resources '' , though appears first coined public context referring web information retrieval alkis \n",
      "Cleaned Token After Stem =  relev inform resourc `` , though appear first coin public context refer web inform retriev alki \n",
      "Cleaned Token Before =  range of topics from theoretical studies of algorithms, computation and information to the practical issues of implementing computational systems in hardware\n",
      "Cleaned Token After =  range topics theoretical studies algorithms , computation information practical issues implementing computational systems hardware \n",
      "Cleaned Token After Stem =  rang topic theoret studi algorithm , comput inform practic issu implement comput system hardwar \n",
      "Cleaned Token Before =  automatically, specifically for google analytics. adversarial information retrieval – information retrieval strategies in datasets spam in blogs – form of spamdexing\n",
      "Cleaned Token After =  automatically , specifically google analytics . adversarial information retrieval – information retrieval strategies datasets spam blogs – form spamdexing \n",
      "Cleaned Token After Stem =  automat , specif googl analyt . adversari inform retriev – inform retriev strategi dataset spam blog – form spamdex \n",
      "Cleaned Token Before =  the ministry of peace (war and foreign affairs) . the ministry of information retrieval features in the film brazil. the ministry of social coherence appears\n",
      "Cleaned Token After =  ministry peace ( war foreign affairs ) . ministry information retrieval features film brazil . ministry social coherence appears \n",
      "Cleaned Token After Stem =  ministri peac ( war foreign affair ) . ministri inform retriev featur film brazil . ministri social coher appear \n",
      "Cleaned Token Before =  in information retrieval applications. unl is designed to establish a simple foundation for representing the most central aspects of information and\n",
      "Cleaned Token After =  information retrieval applications . unl designed establish simple foundation representing central aspects information \n",
      "Cleaned Token After Stem =  inform retriev applic . unl design establish simpl foundat repres central aspect inform \n",
      "Cleaned Token Before =  about library cataloging, classification, metadata, indexing, information retrieval, information management, and other topics related to library cataloging\n",
      "Cleaned Token After =  library cataloging , classification , metadata , indexing , information retrieval , information management , topics related library cataloging \n",
      "Cleaned Token After Stem =  librari catalog , classif , metadata , index , inform retriev , inform manag , topic relat librari catalog \n",
      "Cleaned Token Before =  instances of cryptographic information in a card; use of the cryptographic information; retrieval of the cryptographic information; cross-referencing of the\n",
      "Cleaned Token After =  instances cryptographic information card ; use cryptographic information ; retrieval cryptographic information ; cross-referencing \n",
      "Cleaned Token After Stem =  instanc cryptograph inform card ; use cryptograph inform ; retriev cryptograph inform ; cross-referenc \n",
      "Cleaned Token Before =  lead to the testing effect, which aids long-term memory through information retrieval and feedback. some theories consider sleep to be an important factor\n",
      "Cleaned Token After =  lead testing effect , aids long-term memory information retrieval feedback . theories consider sleep important factor \n",
      "Cleaned Token After Stem =  lead test effect , aid long-term memori inform retriev feedback . theori consid sleep import factor \n",
      "Cleaned Token Before =  with which information is processed. perceptual fluency is the ease of processing stimuli based on manipulations to perceptual quality. retrieval fluency\n",
      "Cleaned Token After =  information processed . perceptual fluency ease processing stimuli based manipulations perceptual quality . retrieval fluency \n",
      "Cleaned Token After Stem =  inform process . perceptu fluenci eas process stimuli base manipul perceptu qualiti . retriev fluenci \n",
      "Cleaned Token Before =  search results\". in goh, dion hoe-lian; foo, schubert (eds.). social information retrieval systems. igi global research collection. hershey, pennsylvania:\n",
      "Cleaned Token After =  search results '' . goh , dion hoe-lian ; foo , schubert ( eds. ) . social information retrieval systems . igi global research collection . hershey , pennsylvania : \n",
      "Cleaned Token After Stem =  search result `` . goh , dion hoe-lian ; foo , schubert ( ed . ) . social inform retriev system . igi global research collect . hershey , pennsylvania : \n",
      "Cleaned Token Before =  robertson is a british computer scientist. he is known for his work on information retrieval and the okapi bm25 weighting model. after completing his undergraduate\n",
      "Cleaned Token After =  robertson british computer scientist . known work information retrieval okapi bm25 weighting model . completing undergraduate \n",
      "Cleaned Token After Stem =  robertson british comput scientist . known work inform retriev okapi bm25 weight model . complet undergradu \n",
      "Cleaned Token Before =  possible by the power of the new ibm 360 computers. this kind of information retrieval was then in the very early stages in terms of what was technically\n",
      "Cleaned Token After =  possible power new ibm 360 computers . kind information retrieval early stages terms technically \n",
      "Cleaned Token After Stem =  possibl power new ibm 360 comput . kind inform retriev earli stage term technic \n",
      "Cleaned Token Before =  a senior programmer working on spell checkers and multilingual information retrieval tools. after his retirement from ibm in 1996, zamora established\n",
      "Cleaned Token After =  senior programmer working spell checkers multilingual information retrieval tools . retirement ibm 1996 , zamora established \n",
      "Cleaned Token After Stem =  senior programm work spell checker multilingu inform retriev tool . retir ibm 1996 , zamora establish \n",
      "Cleaned Token Before =  patterns in large data sets information retrieval – area of study concerned with searching for documents, for information within documents, and for metadata\n",
      "Cleaned Token After =  patterns large data sets information retrieval – area study concerned searching documents , information within documents , metadata \n",
      "Cleaned Token After Stem =  pattern larg data set inform retriev – area studi concern search document , inform within document , metadata \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, information retrieval. https://web.archive.org/web/20070103200438/http://delta-intkey\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval . https : //web.archive.org/web/20070103200438/http : //delta-intkey \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev . http : //web.archive.org/web/20070103200438/http : //delta-intkey \n",
      "Cleaned Token Before =  interaction with multimedia information.\" in proceedings of theseus/image clef workshop on visual information retrieval evaluation, pp. 8-11. 2009. gibbs\n",
      "Cleaned Token After =  interaction multimedia information . '' proceedings theseus/image clef workshop visual information retrieval evaluation , pp . 8-11 . 2009. gibbs \n",
      "Cleaned Token After Stem =  interact multimedia inform . `` proceed theseus/imag clef workshop visual inform retriev evalu , pp . 8-11 . 2009. gibb \n",
      "Cleaned Token Before =  television information retrieval service developed in the united kingdom in the early 1970s. it offers a range of text-based information, typically including\n",
      "Cleaned Token After =  television information retrieval service developed united kingdom early 1970s . offers range text-based information , typically including \n",
      "Cleaned Token After Stem =  televis inform retriev servic develop unit kingdom earli 1970 . offer rang text-bas inform , typic includ \n",
      "Cleaned Token Before =  respectively. david parnas introduced the key concept of modularity and information hiding in 1972 to help programmers deal with the ever-increasing complexity\n",
      "Cleaned Token After =  respectively . david parnas introduced key concept modularity information hiding 1972 help programmers deal ever-increasing complexity \n",
      "Cleaned Token After Stem =  respect . david parna introduc key concept modular inform hide 1972 help programm deal ever-increas complex \n",
      "Cleaned Token Before =  eyewitnesses and victims about what they remember from a crime scene. using four retrievals, the primary focus of the cognitive interview is to make witnesses and\n",
      "Cleaned Token After =  eyewitnesses victims remember crime scene . using four retrievals , primary focus cognitive interview make witnesses \n",
      "Cleaned Token After Stem =  eyewit victim rememb crime scene . use four retriev , primari focu cognit interview make wit \n",
      "Cleaned Token Before =  with similar meanings. thesaurus may also refer to: thesaurus (information retrieval), a form of controlled vocabulary that seeks to dictate semantic\n",
      "Cleaned Token After =  similar meanings . thesaurus may also refer : thesaurus ( information retrieval ) , form controlled vocabulary seeks dictate semantic \n",
      "Cleaned Token After Stem =  similar mean . thesauru may also refer : thesauru ( inform retriev ) , form control vocabulari seek dictat semant \n",
      "Cleaned Token Before =  a champion list, also called top doc or fancy list is a precomputed list sometimes used with the vector space model to avoid computing relevancy rankings\n",
      "Cleaned Token After =  champion list , also called top doc fancy list precomputed list sometimes used vector space model avoid computing relevancy rankings \n",
      "Cleaned Token After Stem =  champion list , also call top doc fanci list precomput list sometim use vector space model avoid comput relev rank \n",
      "Cleaned Token Before =  for information and communication technologies - audiovisual media group. bilvideo-7: mpeg-7 compatible, distributed video indexing and retrieval system\n",
      "Cleaned Token After =  information communication technologies - audiovisual media group . bilvideo-7 : mpeg-7 compatible , distributed video indexing retrieval system \n",
      "Cleaned Token After Stem =  inform commun technolog - audiovisu media group . bilvideo-7 : mpeg-7 compat , distribut video index retriev system \n",
      "Cleaned Token Before =  is not common in general-purpose systems, as it requires additional information in order to schedule a task: namely a bound or worst-case estimate for\n",
      "Cleaned Token After =  common general-purpose systems , requires additional information order schedule task : namely bound worst-case estimate \n",
      "Cleaned Token After Stem =  common general-purpos system , requir addit inform order schedul task : name bound worst-cas estim \n",
      "Cleaned Token Before =  exhibit good fit to experimental fading channel measurements in information retrieval to model dwell times on web pages. in general insurance to model\n",
      "Cleaned Token After =  exhibit good fit experimental fading channel measurements information retrieval model dwell times web pages . general insurance model \n",
      "Cleaned Token After Stem =  exhibit good fit experiment fade channel measur inform retriev model dwell time web page . gener insur model \n",
      "Cleaned Token Before =  a communication engine is a tool that sends user requests to several other communication protocols and/or databases and aggregates the results into a single\n",
      "Cleaned Token After =  communication engine tool sends user requests several communication protocols and/or databases aggregates results single \n",
      "Cleaned Token After Stem =  commun engin tool send user request sever commun protocol and/or databas aggreg result singl \n",
      "Cleaned Token Before =  museums and archives to highlight digital collections; and by other information retrieval projects. the university of virginia began developing blacklight\n",
      "Cleaned Token After =  museums archives highlight digital collections ; information retrieval projects . university virginia began developing blacklight \n",
      "Cleaned Token After Stem =  museum archiv highlight digit collect ; inform retriev project . univers virginia began develop blacklight \n",
      "Cleaned Token Before =  tunebot at northwestern university comprehensive list of music information retrieval systems (apparently last updated ca 2003) at the wayback machine\n",
      "Cleaned Token After =  tunebot northwestern university comprehensive list music information retrieval systems ( apparently last updated ca 2003 ) wayback machine \n",
      "Cleaned Token After Stem =  tunebot northwestern univers comprehens list music inform retriev system ( appar last updat ca 2003 ) wayback machin \n",
      "Cleaned Token Before =  generation of semantic space models is the vector space model for information retrieval. such vector space models for words and their distributional data\n",
      "Cleaned Token After =  generation semantic space models vector space model information retrieval . vector space models words distributional data \n",
      "Cleaned Token After Stem =  gener semant space model vector space model inform retriev . vector space model word distribut data \n",
      "Cleaned Token Before =  how the real surroundings look in some way. ar systems layer virtual information over a camera live feed into a headset or smartglasses or through a mobile\n",
      "Cleaned Token After =  real surroundings look way . ar systems layer virtual information camera live feed headset smartglasses mobile \n",
      "Cleaned Token After Stem =  real surround look way . ar system layer virtual inform camera live feed headset smartglass mobil \n",
      "Cleaned Token Before =  irf may refer to: impulse response function information retrieval facility initial reaction force or internal response force immediate response force\n",
      "Cleaned Token After =  irf may refer : impulse response function information retrieval facility initial reaction force internal response force immediate response force \n",
      "Cleaned Token After Stem =  irf may refer : impuls respons function inform retriev facil initi reaction forc intern respons forc immedi respons forc \n",
      "Cleaned Token Before =  an american computer scientist who is a leader in the field of information retrieval, and has been a significant contributor to microsoft's search technologies\n",
      "Cleaned Token After =  american computer scientist leader field information retrieval , significant contributor microsoft 's search technologies \n",
      "Cleaned Token After Stem =  american comput scientist leader field inform retriev , signific contributor microsoft 's search technolog \n",
      "Cleaned Token Before =  enable document browsing by providing a short summary, improve information retrieval (if documents have keyphrases assigned, a user could search by keyphrase\n",
      "Cleaned Token After =  enable document browsing providing short summary , improve information retrieval ( documents keyphrases assigned , user could search keyphrase \n",
      "Cleaned Token After Stem =  enabl document brows provid short summari , improv inform retriev ( document keyphras assign , user could search keyphras \n",
      "Cleaned Token Before =  development in information retrieval. acm, 2015 ganesan, kavita; zhai, chengxiang (2012). \"opinion-based entity ranking\". information retrieval. 15 (2): 116–150\n",
      "Cleaned Token After =  development information retrieval . acm , 2015 ganesan , kavita ; zhai , chengxiang ( 2012 ) . `` opinion-based entity ranking '' . information retrieval . 15 ( 2 ) : 116–150 \n",
      "Cleaned Token After Stem =  develop inform retriev . acm , 2015 ganesan , kavita ; zhai , chengxiang ( 2012 ) . `` opinion-bas entiti rank `` . inform retriev . 15 ( 2 ) : 116–150 \n",
      "Cleaned Token Before =  association for computing machinery in 2017 \"for contributions to information retrieval and text data mining\". \"chengxiang (\"cheng\") zhai\". http://sifaka\n",
      "Cleaned Token After =  association computing machinery 2017 `` contributions information retrieval text data mining '' . `` chengxiang ( `` cheng '' ) zhai '' . http : //sifaka \n",
      "Cleaned Token After Stem =  associ comput machineri 2017 `` contribut inform retriev text data mine `` . `` chengxiang ( `` cheng `` ) zhai `` . http : //sifaka \n",
      "Cleaned Token Before =  retrieval-induced forgetting (rif) is a memory phenomenon where remembering causes forgetting of other information in memory. the phenomenon was first\n",
      "Cleaned Token After =  retrieval-induced forgetting ( rif ) memory phenomenon remembering causes forgetting information memory . phenomenon first \n",
      "Cleaned Token After Stem =  retrieval-induc forget ( rif ) memori phenomenon rememb caus forget inform memori . phenomenon first \n",
      "Cleaned Token Before =  victim's data. cryptovirology also encompasses the use of private information retrieval (pir) to allow cryptoviruses to search for and steal host data without\n",
      "Cleaned Token After =  victim 's data . cryptovirology also encompasses use private information retrieval ( pir ) allow cryptoviruses search steal host data without \n",
      "Cleaned Token After Stem =  victim 's data . cryptovirolog also encompass use privat inform retriev ( pir ) allow cryptovirus search steal host data without \n",
      "Cleaned Token Before =  that is used to structure, plan, and control the process of developing information systems. a wide variety of such frameworks has evolved over the years\n",
      "Cleaned Token After =  used structure , plan , control process developing information systems . wide variety frameworks evolved years \n",
      "Cleaned Token After Stem =  use structur , plan , control process develop inform system . wide varieti framework evolv year \n",
      "Cleaned Token Before =  (apocynaceae): descriptions, illustrations, identification, and information retrieval version: 21 september 2000. phillips, roger (1997). the random house\n",
      "Cleaned Token After =  ( apocynaceae ) : descriptions , illustrations , identification , information retrieval version : 21 september 2000. phillips , roger ( 1997 ) . random house \n",
      "Cleaned Token After Stem =  ( apocynacea ) : descript , illustr , identif , inform retriev version : 21 septemb 2000. phillip , roger ( 1997 ) . random hous \n",
      "Cleaned Token Before =  recognition, digital audio editors, online music search engines, music information retrieval and cognitive issues in music. because music informatics is an emerging\n",
      "Cleaned Token After =  recognition , digital audio editors , online music search engines , music information retrieval cognitive issues music . music informatics emerging \n",
      "Cleaned Token After Stem =  recognit , digit audio editor , onlin music search engin , music inform retriev cognit issu music . music informat emerg \n",
      "Cleaned Token Before =  of over 90 government and industry initiatives on \"green icts\", i.e. information and communication technologies, the environment and climate change. the\n",
      "Cleaned Token After =  90 government industry initiatives `` green icts '' , i.e . information communication technologies , environment climate change . \n",
      "Cleaned Token After Stem =  90 govern industri initi `` green ict `` , i.e . inform commun technolog , environ climat chang . \n",
      "Cleaned Token Before =  this act is performed by a computer program. information retrieval – cross-language information retrieval – machine translation (mt) – aims to automatically\n",
      "Cleaned Token After =  act performed computer program . information retrieval – cross-language information retrieval – machine translation ( mt ) – aims automatically \n",
      "Cleaned Token After Stem =  act perform comput program . inform retriev – cross-languag inform retriev – machin translat ( mt ) – aim automat \n",
      "Cleaned Token Before =  proceedings of the 25th international symposium on string processing and information retrieval (spire). lecture notes in computer science. 11147. springer. pp\n",
      "Cleaned Token After =  proceedings 25th international symposium string processing information retrieval ( spire ) . lecture notes computer science . 11147. springer . pp \n",
      "Cleaned Token After Stem =  proceed 25th intern symposium string process inform retriev ( spire ) . lectur note comput scienc . 11147. springer . pp \n",
      "Cleaned Token Before =  ieee solid-state circuits magazine, winter 2009, ieee xplore japan, information processing society of. \"shima masatoshi-computer museum\". museum.ipsj\n",
      "Cleaned Token After =  ieee solid-state circuits magazine , winter 2009 , ieee xplore japan , information processing society . `` shima masatoshi-computer museum '' . museum.ipsj \n",
      "Cleaned Token After Stem =  ieee solid-st circuit magazin , winter 2009 , ieee xplore japan , inform process societi . `` shima masatoshi-comput museum `` . museum.ipsj \n",
      "Cleaned Token Before =  poliqarp is an open source search engine designed to process text corpora, among others the national corpus of polish created at the institute of computer\n",
      "Cleaned Token After =  poliqarp open source search engine designed process text corpora , among others national corpus polish created institute computer \n",
      "Cleaned Token After Stem =  poliqarp open sourc search engin design process text corpora , among other nation corpu polish creat institut comput \n",
      "Cleaned Token Before =  pistor data structures for an integrated data base management and information retrieval system kent, william (february 1983). \"a simple guide to five normal\n",
      "Cleaned Token After =  pistor data structures integrated data base management information retrieval system kent , william ( february 1983 ) . `` simple guide five normal \n",
      "Cleaned Token After Stem =  pistor data structur integr data base manag inform retriev system kent , william ( februari 1983 ) . `` simpl guid five normal \n",
      "Cleaned Token Before =  energy physics (hep). it is the successor of the stanford physics information retrieval system (spires) database, the main literature database for high\n",
      "Cleaned Token After =  energy physics ( hep ) . successor stanford physics information retrieval system ( spires ) database , main literature database high \n",
      "Cleaned Token After Stem =  energi physic ( hep ) . successor stanford physic inform retriev system ( spire ) databas , main literatur databas high \n",
      "Cleaned Token Before =  other taxonomic identifier - for efficient data management and information retrieval as required. today, taxonomic databases are routinely used for the\n",
      "Cleaned Token After =  taxonomic identifier - efficient data management information retrieval required . today , taxonomic databases routinely used \n",
      "Cleaned Token After Stem =  taxonom identifi - effici data manag inform retriev requir . today , taxonom databas routin use \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, information retrieval. http://delta-intkey.com media related to oxalidaceae at wikimedia\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval . http : //delta-intkey.com media related oxalidaceae wikimedia \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev . http : //delta-intkey.com media relat oxalidacea wikimedia \n",
      "Cleaned Token Before =  hinrich (2008). \"vector space classification\". introduction to information retrieval. cambridge university press. tibshirani, robert; hastie, trevor;\n",
      "Cleaned Token After =  hinrich ( 2008 ) . `` vector space classification '' . introduction information retrieval . cambridge university press . tibshirani , robert ; hastie , trevor ; \n",
      "Cleaned Token After Stem =  hinrich ( 2008 ) . `` vector space classif `` . introduct inform retriev . cambridg univers press . tibshirani , robert ; hasti , trevor ; \n",
      "Cleaned Token Before =  search/retrieve via url (sru) is a standard search protocol for internet search queries, utilizing contextual query language (cql), a standard query syntax\n",
      "Cleaned Token After =  search/retrieve via url ( sru ) standard search protocol internet search queries , utilizing contextual query language ( cql ) , standard query syntax \n",
      "Cleaned Token After Stem =  search/retriev via url ( sru ) standard search protocol internet search queri , util contextu queri languag ( cql ) , standard queri syntax \n",
      "Cleaned Token Before =  memory capacity, latency (latency is the amount of time that it takes for information from one node to travel to the source) and throughput. sometimes other\n",
      "Cleaned Token After =  memory capacity , latency ( latency amount time takes information one node travel source ) throughput . sometimes \n",
      "Cleaned Token After Stem =  memori capac , latenc ( latenc amount time take inform one node travel sourc ) throughput . sometim \n",
      "Cleaned Token Before =  browsing. the user goal of web browsing web interactions is for information retrieval through users' traversal of ad-hoc, user-driven, sequence of hypermedia\n",
      "Cleaned Token After =  browsing . user goal web browsing web interactions information retrieval users ' traversal ad-hoc , user-driven , sequence hypermedia \n",
      "Cleaned Token After Stem =  brows . user goal web brows web interact inform retriev user ' travers ad-hoc , user-driven , sequenc hypermedia \n",
      "Cleaned Token Before =  geographic information retrieval (gir) has emerged as an academic community interested in technical aspects of helping people find information about places\n",
      "Cleaned Token After =  geographic information retrieval ( gir ) emerged academic community interested technical aspects helping people find information places \n",
      "Cleaned Token After Stem =  geograph inform retriev ( gir ) emerg academ commun interest technic aspect help peopl find inform place \n",
      "Cleaned Token Before =  integrated circuits are usually large enough to include identifying information. four common sections are the manufacturer's name or logo, the part number\n",
      "Cleaned Token After =  integrated circuits usually large enough include identifying information . four common sections manufacturer 's name logo , part number \n",
      "Cleaned Token After Stem =  integr circuit usual larg enough includ identifi inform . four common section manufactur 's name logo , part number \n",
      "Cleaned Token Before =  statistics have also been used as a method for term weighting in information retrieval. the method is one of a collection of dfr (\"divergence from randomness\")\n",
      "Cleaned Token After =  statistics also used method term weighting information retrieval . method one collection dfr ( `` divergence randomness '' ) \n",
      "Cleaned Token After Stem =  statist also use method term weight inform retriev . method one collect dfr ( `` diverg random `` ) \n",
      "Cleaned Token Before =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion\n",
      "Cleaned Token After =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion \n",
      "Cleaned Token After Stem =  digit librari comput platform digit market world wide web inform retriev secur cryptographi formal method secur servic intrus \n",
      "Cleaned Token Before =  discussion of issues relating to knowledge organisation systems, information retrieval and the semantic web. anyone may participate informally in the development\n",
      "Cleaned Token After =  discussion issues relating knowledge organisation systems , information retrieval semantic web . anyone may participate informally development \n",
      "Cleaned Token After Stem =  discuss issu relat knowledg organis system , inform retriev semant web . anyon may particip inform develop \n",
      "Cleaned Token Before =  historical note: the past thirty years in information retrieval salton, gerard journal of the american society for information science (1986-1998); sep 1987; 38\n",
      "Cleaned Token After =  historical note : past thirty years information retrieval salton , gerard journal american society information science ( 1986-1998 ) ; sep 1987 ; 38 \n",
      "Cleaned Token After Stem =  histor note : past thirti year inform retriev salton , gerard journal american societi inform scienc ( 1986-1998 ) ; sep 1987 ; 38 \n",
      "Cleaned Token Before =  categorization classification (general theory) document classification information retrieval knowledge organization library management library of congress subject\n",
      "Cleaned Token After =  categorization classification ( general theory ) document classification information retrieval knowledge organization library management library congress subject \n",
      "Cleaned Token After Stem =  categor classif ( gener theori ) document classif inform retriev knowledg organ librari manag librari congress subject \n",
      "Cleaned Token Before =  discrimination is a way to rank keywords in how useful they are for information retrieval. word sense discrimination is the automatic identification of the\n",
      "Cleaned Token After =  discrimination way rank keywords useful information retrieval . word sense discrimination automatic identification \n",
      "Cleaned Token After Stem =  discrimin way rank keyword use inform retriev . word sens discrimin automat identif \n",
      "Cleaned Token Before =  intermediate-range ballistic missile okapi bm25, a ranking function in information retrieval this disambiguation page lists articles associated with the same\n",
      "Cleaned Token After =  intermediate-range ballistic missile okapi bm25 , ranking function information retrieval disambiguation page lists articles associated \n",
      "Cleaned Token After Stem =  intermediate-rang ballist missil okapi bm25 , rank function inform retriev disambigu page list articl associ \n",
      "Cleaned Token Before =  com/rare-technologies/gensim written in python operating system linux, windows, macos type information retrieval license lgpl website radimrehurek.com/gensim/\n",
      "Cleaned Token After =  com/rare-technologies/gensim written python operating system linux , windows , macos type information retrieval license lgpl website radimrehurek.com/gensim/ \n",
      "Cleaned Token After Stem =  com/rare-technologies/gensim written python oper system linux , window , maco type inform retriev licens lgpl websit radimrehurek.com/gensim/ \n",
      "Cleaned Token Before =  terms of the gpl license. free and open-source software portal information retrieval (ir) zetta rmit university at trec 2004 (pdf) - b. billerbeck, a\n",
      "Cleaned Token After =  terms gpl license . free open-source software portal information retrieval ( ir ) zetta rmit university trec 2004 ( pdf ) - b. billerbeck , \n",
      "Cleaned Token After Stem =  term gpl licens . free open-sourc softwar portal inform retriev ( ir ) zetta rmit univers trec 2004 ( pdf ) - b. billerbeck , \n",
      "Cleaned Token Before =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion\n",
      "Cleaned Token After =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion \n",
      "Cleaned Token After Stem =  digit librari comput platform digit market world wide web inform retriev secur cryptographi formal method secur servic intrus \n",
      "Cleaned Token Before =  into one of the major forums for research on database management, information retrieval, and knowledge management. the conference is noted for its interdisciplinarity\n",
      "Cleaned Token After =  one major forums research database management , information retrieval , knowledge management . conference noted interdisciplinarity \n",
      "Cleaned Token After Stem =  one major forum research databas manag , inform retriev , knowledg manag . confer note interdisciplinar \n",
      "Cleaned Token Before =  lesk worked for the smart information retrieval system project, wrote much of its retrieval code and did many of the retrieval experiments, as well as obtaining\n",
      "Cleaned Token After =  lesk worked smart information retrieval system project , wrote much retrieval code many retrieval experiments , well obtaining \n",
      "Cleaned Token After Stem =  lesk work smart inform retriev system project , wrote much retriev code mani retriev experi , well obtain \n",
      "Cleaned Token Before =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion\n",
      "Cleaned Token After =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion \n",
      "Cleaned Token After Stem =  digit librari comput platform digit market world wide web inform retriev secur cryptographi formal method secur servic intrus \n",
      "Cleaned Token Before =  three dimensions: 1) encoding, 2) storage, and 3) retrieval. this is how viewers get presented information into their heads. messages can be processed under\n",
      "Cleaned Token After =  three dimensions : 1 ) encoding , 2 ) storage , 3 ) retrieval . viewers get presented information heads . messages processed \n",
      "Cleaned Token After Stem =  three dimens : 1 ) encod , 2 ) storag , 3 ) retriev . viewer get present inform head . messag process \n",
      "Cleaned Token Before =  concept searching limited is a software company that specializes in information retrieval software. it has products for enterprise search, taxonomy management\n",
      "Cleaned Token After =  concept searching limited software company specializes information retrieval software . products enterprise search , taxonomy management \n",
      "Cleaned Token After Stem =  concept search limit softwar compani special inform retriev softwar . product enterpris search , taxonomi manag \n",
      "Cleaned Token Before =  difficult it is to transform them into each other. it can be used in information retrieval and data mining for cluster analysis. we assume that the objects\n",
      "Cleaned Token After =  difficult transform . used information retrieval data mining cluster analysis . assume objects \n",
      "Cleaned Token After Stem =  difficult transform . use inform retriev data mine cluster analysi . assum object \n",
      "Cleaned Token Before =  and it continues to do so as the system grows and evolves. many information retrieval techniques used by packages such as spss were initially developed\n",
      "Cleaned Token After =  continues system grows evolves . many information retrieval techniques used packages spss initially developed \n",
      "Cleaned Token After Stem =  continu system grow evolv . mani inform retriev techniqu use packag spss initi develop \n",
      "Cleaned Token Before =  and brian d. davison: \"cloaking and redirection: a preliminary study\". workshop on adversarial information retrieval on the web, chiba, japan, 2005.\n",
      "Cleaned Token After =  brian d. davison : `` cloaking redirection : preliminary study '' . workshop adversarial information retrieval web , chiba , japan , 2005 . \n",
      "Cleaned Token After Stem =  brian d. davison : `` cloak redirect : preliminari studi `` . workshop adversari inform retriev web , chiba , japan , 2005 . \n",
      "Cleaned Token Before =  \"order-preserving minimal perfect hash functions and information retrieval\" (pdf), acm transactions on information systems, new york, ny, usa: acm, 9 (3): 281–308\n",
      "Cleaned Token After =  `` order-preserving minimal perfect hash functions information retrieval '' ( pdf ) , acm transactions information systems , new york , ny , usa : acm , 9 ( 3 ) : 281–308 \n",
      "Cleaned Token After Stem =  `` order-preserv minim perfect hash function inform retriev `` ( pdf ) , acm transact inform system , new york , ny , usa : acm , 9 ( 3 ) : 281–308 \n",
      "Cleaned Token Before =  ; raghavan, prabhakar; schütze, hinrich (2008). introduction to information retrieval. new york: cambridge university press. isbn 978-0521865715. oclc 190786122\n",
      "Cleaned Token After =  ; raghavan , prabhakar ; schütze , hinrich ( 2008 ) . introduction information retrieval . new york : cambridge university press . isbn 978-0521865715. oclc 190786122 \n",
      "Cleaned Token After Stem =  ; raghavan , prabhakar ; schütze , hinrich ( 2008 ) . introduct inform retriev . new york : cambridg univers press . isbn 978-0521865715. oclc 190786122 \n",
      "Cleaned Token Before =  a wide range of areas including information retrieval (ir) with a particular focus on how people access information from mobile devices (mhcir). he has\n",
      "Cleaned Token After =  wide range areas including information retrieval ( ir ) particular focus people access information mobile devices ( mhcir ) . \n",
      "Cleaned Token After Stem =  wide rang area includ inform retriev ( ir ) particular focu peopl access inform mobil devic ( mhcir ) . \n",
      "Cleaned Token Before =  acquisition, knowledge engineering, scientific citation patterns, information retrieval, and data visualization. pathfinder networks are potentially applicable\n",
      "Cleaned Token After =  acquisition , knowledge engineering , scientific citation patterns , information retrieval , data visualization . pathfinder networks potentially applicable \n",
      "Cleaned Token After Stem =  acquisit , knowledg engin , scientif citat pattern , inform retriev , data visual . pathfind network potenti applic \n",
      "Cleaned Token Before =  ; raghavan, prabhakar; schütze, hinrich (2008). introduction to information retrieval. cambridge university press. pp. 308–314. francois-lavet, vincent;\n",
      "Cleaned Token After =  ; raghavan , prabhakar ; schütze , hinrich ( 2008 ) . introduction information retrieval . cambridge university press . pp . 308–314 . francois-lavet , vincent ; \n",
      "Cleaned Token After Stem =  ; raghavan , prabhakar ; schütze , hinrich ( 2008 ) . introduct inform retriev . cambridg univers press . pp . 308–314 . francois-lavet , vincent ; \n",
      "Cleaned Token Before =  moodagent (ai based emotion keyed playlist generator and app) music information retrieval software effect processor sound recorder (windows) impromptu (programming\n",
      "Cleaned Token After =  moodagent ( ai based emotion keyed playlist generator app ) music information retrieval software effect processor sound recorder ( windows ) impromptu ( programming \n",
      "Cleaned Token After Stem =  moodag ( ai base emot key playlist gener app ) music inform retriev softwar effect processor sound record ( window ) impromptu ( program \n",
      "Cleaned Token Before =  networks are used in specialized information retrieval tasks, such as plagiarism detection. they provide information on hierarchical relations in order\n",
      "Cleaned Token After =  networks used specialized information retrieval tasks , plagiarism detection . provide information hierarchical relations order \n",
      "Cleaned Token After Stem =  network use special inform retriev task , plagiar detect . provid inform hierarch relat order \n",
      "Cleaned Token Before =  system that ibm built to apply advanced natural language processing, information retrieval, knowledge representation, automated reasoning, and machine learning\n",
      "Cleaned Token After =  system ibm built apply advanced natural language processing , information retrieval , knowledge representation , automated reasoning , machine learning \n",
      "Cleaned Token After Stem =  system ibm built appli advanc natur languag process , inform retriev , knowledg represent , autom reason , machin learn \n",
      "Cleaned Token Before =  scientist known for her research in human-computer interaction and information retrieval. she is particularly known for the work she has done on personalized\n",
      "Cleaned Token After =  scientist known research human-computer interaction information retrieval . particularly known work done personalized \n",
      "Cleaned Token After Stem =  scientist known research human-comput interact inform retriev . particularli known work done person \n",
      "Cleaned Token Before =  tradition of science has been for publications to contain sufficient information to allow fellow researchers to replicate and therefore test the research\n",
      "Cleaned Token After =  tradition science publications contain sufficient information allow fellow researchers replicate therefore test research \n",
      "Cleaned Token After Stem =  tradit scienc public contain suffici inform allow fellow research replic therefor test research \n",
      "Cleaned Token Before =  prabhakar; schütze, hinrich (7 july 2008). \"w-shingling\". introduction to information retrieval. cambridge university press. isbn 978-1-139-47210-4.\n",
      "Cleaned Token After =  prabhakar ; schütze , hinrich ( 7 july 2008 ) . `` w-shingling '' . introduction information retrieval . cambridge university press . isbn 978-1-139-47210-4 . \n",
      "Cleaned Token After Stem =  prabhakar ; schütze , hinrich ( 7 juli 2008 ) . `` w-shingl `` . introduct inform retriev . cambridg univers press . isbn 978-1-139-47210-4 . \n",
      "Cleaned Token Before =  spanning information retrieval, multimedia computing, hci, and smart environments. fxpal's mission was to provide fuji xerox a digital information technology\n",
      "Cleaned Token After =  spanning information retrieval , multimedia computing , hci , smart environments . fxpal 's mission provide fuji xerox digital information technology \n",
      "Cleaned Token After Stem =  span inform retriev , multimedia comput , hci , smart environ . fxpal 's mission provid fuji xerox digit inform technolog \n",
      "Cleaned Token Before =  teaching, development and promotion of library classification and information retrieval, principally as a major figure in the british school of facet analysis\n",
      "Cleaned Token After =  teaching , development promotion library classification information retrieval , principally major figure british school facet analysis \n",
      "Cleaned Token After Stem =  teach , develop promot librari classif inform retriev , princip major figur british school facet analysi \n",
      "Cleaned Token Before =  data retrieval means obtaining data from a database management system such as odbms. in this case, it is considered that data is represented in a structured\n",
      "Cleaned Token After =  data retrieval means obtaining data database management system odbms . case , considered data represented structured \n",
      "Cleaned Token After Stem =  data retriev mean obtain data databas manag system odbm . case , consid data repres structur \n",
      "Cleaned Token Before =  soon became manager of the information retrieval research division. his introduction to the field of documentation/information science came in 1947 when\n",
      "Cleaned Token After =  soon became manager information retrieval research division . introduction field documentation/information science came 1947 \n",
      "Cleaned Token After Stem =  soon becam manag inform retriev research divis . introduct field documentation/inform scienc came 1947 \n",
      "Cleaned Token Before =  conference on information and knowledge management ecir - european conference on information retrieval ecis - european conference on information systems er\n",
      "Cleaned Token After =  conference information knowledge management ecir - european conference information retrieval ecis - european conference information systems er \n",
      "Cleaned Token After Stem =  confer inform knowledg manag ecir - european confer inform retriev eci - european confer inform system er \n",
      "Cleaned Token Before =  censorship is the suppression of speech, public communication, or other information. this may be done on the basis that such material is considered objectionable\n",
      "Cleaned Token After =  censorship suppression speech , public communication , information . may done basis material considered objectionable \n",
      "Cleaned Token After Stem =  censorship suppress speech , public commun , inform . may done basi materi consid objection \n",
      "Cleaned Token Before =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion\n",
      "Cleaned Token After =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion \n",
      "Cleaned Token After Stem =  digit librari comput platform digit market world wide web inform retriev secur cryptographi formal method secur servic intrus \n",
      "Cleaned Token Before =  an integration with apache solr / lucene to provide a complete information retrieval environment, a classification and categorisation system on the basis\n",
      "Cleaned Token After =  integration apache solr / lucene provide complete information retrieval environment , classification categorisation system basis \n",
      "Cleaned Token After Stem =  integr apach solr / lucen provid complet inform retriev environ , classif categoris system basi \n",
      "Cleaned Token Before =  ethernet infinity engine, a video game engine information extraction, a type of information retrieval intellimouse explorer, a brand of mouse by microsoft\n",
      "Cleaned Token After =  ethernet infinity engine , video game engine information extraction , type information retrieval intellimouse explorer , brand mouse microsoft \n",
      "Cleaned Token After Stem =  ethernet infin engin , video game engin inform extract , type inform retriev intellimous explor , brand mous microsoft \n",
      "Cleaned Token Before =  information bottleneck method. proceedings of the 23rd annual international acm sigir conference on research and development in information retrieval\n",
      "Cleaned Token After =  information bottleneck method . proceedings 23rd annual international acm sigir conference research development information retrieval \n",
      "Cleaned Token After Stem =  inform bottleneck method . proceed 23rd annual intern acm sigir confer research develop inform retriev \n",
      "Cleaned Token Before =   in fuhr, norbert (hrsg.), informatik-fachberichte information retrieval (bd. 289, s. 64-77). berlin etc.: springer-verlag, 1991b. konopásek\n",
      "Cleaned Token After =  fuhr , norbert ( hrsg . ) , informatik-fachberichte information retrieval ( bd . 289 , s. 64-77 ) . berlin etc . : springer-verlag , 1991b . konopásek \n",
      "Cleaned Token After Stem =  fuhr , norbert ( hrsg . ) , informatik-fachbericht inform retriev ( bd . 289 , s. 64-77 ) . berlin etc . : springer-verlag , 1991b . konopásek \n",
      "Cleaned Token Before =  data preservation and access network partners program announcements & information\". national science foundation. september 28, 2007. retrieved october\n",
      "Cleaned Token After =  data preservation access network partners program announcements & information '' . national science foundation . september 28 , 2007. retrieved october \n",
      "Cleaned Token After Stem =  data preserv access network partner program announc & inform `` . nation scienc foundat . septemb 28 , 2007. retriev octob \n",
      "Cleaned Token Before =  information retrieval tool developed at technical university of lisbon which can be used as a search engine or as evaluation system for information retrieval\n",
      "Cleaned Token After =  information retrieval tool developed technical university lisbon used search engine evaluation system information retrieval \n",
      "Cleaned Token After Stem =  inform retriev tool develop technic univers lisbon use search engin evalu system inform retriev \n",
      "Cleaned Token Before =  construction for image retrieval in specialist domains. in sebastiani, f. (ed.). proceedings of the 25th european conference on information retrieval research (ecir-03)\n",
      "Cleaned Token After =  construction image retrieval specialist domains . sebastiani , f . ( ed. ) . proceedings 25th european conference information retrieval research ( ecir-03 ) \n",
      "Cleaned Token After Stem =  construct imag retriev specialist domain . sebastiani , f . ( ed . ) . proceed 25th european confer inform retriev research ( ecir-03 ) \n",
      "Cleaned Token Before =  through their web queries. document classification web search query information retrieval query expansion naive bayes classifier support vector machines meta\n",
      "Cleaned Token After =  web queries . document classification web search query information retrieval query expansion naive bayes classifier support vector machines meta \n",
      "Cleaned Token After Stem =  web queri . document classif web search queri inform retriev queri expans naiv bay classifi support vector machin meta \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, and information retrieval. retrieved 30 december 2014. \"flowering plant families, uh botany\"\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval . retrieved 30 december 2014 . `` flowering plant families , uh botany '' \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev . retriev 30 decemb 2014 . `` flower plant famili , uh botani `` \n",
      "Cleaned Token Before =  of the world: descriptions, illustrations, identification, and information retrieval; including synonyms, morphology, anatomy, physiology, phytochemistry\n",
      "Cleaned Token After =  world : descriptions , illustrations , identification , information retrieval ; including synonyms , morphology , anatomy , physiology , phytochemistry \n",
      "Cleaned Token After Stem =  world : descript , illustr , identif , inform retriev ; includ synonym , morpholog , anatomi , physiolog , phytochemistri \n",
      "Cleaned Token Before =  collection, classification, manipulation, storage, retrieval, movement, dissemination, and protection of information. interlibrary loan or interloan – a service\n",
      "Cleaned Token After =  collection , classification , manipulation , storage , retrieval , movement , dissemination , protection information . interlibrary loan interloan – service \n",
      "Cleaned Token After Stem =  collect , classif , manipul , storag , retriev , movement , dissemin , protect inform . interlibrari loan interloan – servic \n",
      "Cleaned Token Before =  march 2014. ricardo baeza-yates and berthier ribeiro-neto, modern information retrieval, acm press, 1999. bowman, lisa m (29 january 2002). \"have you googlewhacked\n",
      "Cleaned Token After =  march 2014. ricardo baeza-yates berthier ribeiro-neto , modern information retrieval , acm press , 1999. bowman , lisa ( 29 january 2002 ) . `` googlewhacked \n",
      "Cleaned Token After Stem =  march 2014. ricardo baeza-y berthier ribeiro-neto , modern inform retriev , acm press , 1999. bowman , lisa ( 29 januari 2002 ) . `` googlewhack \n",
      "Cleaned Token Before =  algorithm\". in proceedings of the international symposium on music information retrieval (ismir), baltimore, md. kinder, lucy (17 september 2012). \"shazam\n",
      "Cleaned Token After =  algorithm '' . proceedings international symposium music information retrieval ( ismir ) , baltimore , md . kinder , lucy ( 17 september 2012 ) . `` shazam \n",
      "Cleaned Token After Stem =  algorithm `` . proceed intern symposium music inform retriev ( ismir ) , baltimor , md . kinder , luci ( 17 septemb 2012 ) . `` shazam \n",
      "Cleaned Token Before =  software testing is an investigation conducted to provide stakeholders with information about the quality of the software product or service under test. software\n",
      "Cleaned Token After =  software testing investigation conducted provide stakeholders information quality software product service test . software \n",
      "Cleaned Token After Stem =  softwar test investig conduct provid stakehold inform qualiti softwar product servic test . softwar \n",
      "Cleaned Token Before =   amir and a. turpin and a. moffat (ed.). string processing and information retrieval, proc. spire. lecture notes in computer science. 5280. springer\n",
      "Cleaned Token After =  amir a. turpin a. moffat ( ed. ) . string processing information retrieval , proc . spire . lecture notes computer science . 5280. springer \n",
      "Cleaned Token After Stem =  amir a. turpin a. moffat ( ed . ) . string process inform retriev , proc . spire . lectur note comput scienc . 5280. springer \n",
      "Cleaned Token Before =  disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimization, multi-agent systems, swarm intelligence\n",
      "Cleaned Token After =  disciplines , game theory , control theory , operations research , information theory , simulation-based optimization , multi-agent systems , swarm intelligence \n",
      "Cleaned Token After Stem =  disciplin , game theori , control theori , oper research , inform theori , simulation-bas optim , multi-ag system , swarm intellig \n",
      "Cleaned Token Before =  international acm sigir conference on research and development in information retrieval, 1197-1200. woo, hyekyung; cho, youngtae; shim, eunyoung; lee, jong-koo;\n",
      "Cleaned Token After =  international acm sigir conference research development information retrieval , 1197-1200. woo , hyekyung ; cho , youngtae ; shim , eunyoung ; lee , jong-koo ; \n",
      "Cleaned Token After Stem =  intern acm sigir confer research develop inform retriev , 1197-1200. woo , hyekyung ; cho , youngta ; shim , eunyoung ; lee , jong-koo ; \n",
      "Cleaned Token Before =  preskill considered information retrieval from evaporating black holes. their study of a black hole's retention time for quantum information before it is revealed\n",
      "Cleaned Token After =  preskill considered information retrieval evaporating black holes . study black hole 's retention time quantum information revealed \n",
      "Cleaned Token After Stem =  preskil consid inform retriev evapor black hole . studi black hole 's retent time quantum inform reveal \n",
      "Cleaned Token Before =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion\n",
      "Cleaned Token After =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion \n",
      "Cleaned Token After Stem =  digit librari comput platform digit market world wide web inform retriev secur cryptographi formal method secur servic intrus \n",
      "Cleaned Token Before =  automatic indexing information architecture search engine optimization site map web navigation web search engine information retrieval beyond book indexing:\n",
      "Cleaned Token After =  automatic indexing information architecture search engine optimization site map web navigation web search engine information retrieval beyond book indexing : \n",
      "Cleaned Token After Stem =  automat index inform architectur search engin optim site map web navig web search engin inform retriev beyond book index : \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, and information retrieval\". 14 december 2000. archived from the original on 2014-08-02. \"flowering\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval '' . 14 december 2000. archived original 2014-08-02 . `` flowering \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev `` . 14 decemb 2000. archiv origin 2014-08-02 . `` flower \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, and information retrieval. retrieved 2007-08-27. v.h. heywood, r.k. brummit,a. culham, o.\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval . retrieved 2007-08-27. v.h . heywood , r.k. brummit , . culham , . \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev . retriev 2007-08-27. v.h . heywood , r.k. brummit , . culham , . \n",
      "Cleaned Token Before =  theory standard model (mathematical formulation) stanford physics information retrieval system timeline of particle physics unparticle physics tetraquark\n",
      "Cleaned Token After =  theory standard model ( mathematical formulation ) stanford physics information retrieval system timeline particle physics unparticle physics tetraquark \n",
      "Cleaned Token After Stem =  theori standard model ( mathemat formul ) stanford physic inform retriev system timelin particl physic unparticl physic tetraquark \n",
      "Cleaned Token Before =  preview them on the same page.[citation needed] munax has since shut down.[citation needed] search by sound music information retrieval video search engine\n",
      "Cleaned Token After =  preview page . [ citation needed ] munax since shut . [ citation needed ] search sound music information retrieval video search engine \n",
      "Cleaned Token After Stem =  preview page . [ citat need ] munax sinc shut . [ citat need ] search sound music inform retriev video search engin \n",
      "Cleaned Token Before =  listing by adding their websites' social media fan pages and contact information based on which businesses' google maps location will be generated accordingly\n",
      "Cleaned Token After =  listing adding websites ' social media fan pages contact information based businesses ' google maps location generated accordingly \n",
      "Cleaned Token After Stem =  list ad websit ' social media fan page contact inform base busi ' googl map locat gener accordingli \n",
      "Cleaned Token Before =  many users to anonymize what came from whom private information retrieval—get database information without server knowing which item was requested commitment\n",
      "Cleaned Token After =  many users anonymize came private information retrieval—get database information without server knowing item requested commitment \n",
      "Cleaned Token After Stem =  mani user anonym came privat inform retrieval—get databas inform without server know item request commit \n",
      "Cleaned Token Before =  screw. scribner, 2000. norman, jeremy. \"renaissance information retrieval device\". historyofinformation.com. john considine: 'the ramellian bookwheel'. in:\n",
      "Cleaned Token After =  screw . scribner , 2000. norman , jeremy . `` renaissance information retrieval device '' . historyofinformation.com . john considine : 'the ramellian bookwheel ' . : \n",
      "Cleaned Token After Stem =  screw . scribner , 2000. norman , jeremi . `` renaiss inform retriev devic `` . historyofinformation.com . john considin : 'the ramellian bookwheel ' . : \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Token Before =  reporting system (cpars), accessible through the past performance information retrieval system (ppirs) until the two systems were merged on 15 january 2019\n",
      "Cleaned Token After =  reporting system ( cpars ) , accessible past performance information retrieval system ( ppirs ) two systems merged 15 january 2019 \n",
      "Cleaned Token After Stem =  report system ( cpar ) , access past perform inform retriev system ( ppir ) two system merg 15 januari 2019 \n",
      "Cleaned Token Before =  toms is a canadian information scientist working in human–computer interaction and known for her research on information retrieval, usability of web sites\n",
      "Cleaned Token After =  toms canadian information scientist working human–computer interaction known research information retrieval , usability web sites \n",
      "Cleaned Token After Stem =  tom canadian inform scientist work human–comput interact known research inform retriev , usabl web site \n",
      "Cleaned Token Before =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion\n",
      "Cleaned Token After =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion \n",
      "Cleaned Token After Stem =  digit librari comput platform digit market world wide web inform retriev secur cryptographi formal method secur servic intrus \n",
      "Cleaned Token Before =  types of relations and processes in physical, biological, social and information systems. many practical problems can be represented by graphs. emphasizing\n",
      "Cleaned Token After =  types relations processes physical , biological , social information systems . many practical problems represented graphs . emphasizing \n",
      "Cleaned Token After Stem =  type relat process physic , biolog , social inform system . mani practic problem repres graph . emphas \n",
      "Cleaned Token Before =  to measure a myriad of things in the physical world and act on this information through monitoring and control systems. these motes are completely self-contained\n",
      "Cleaned Token After =  measure myriad things physical world act information monitoring control systems . motes completely self-contained \n",
      "Cleaned Token After Stem =  measur myriad thing physic world act inform monitor control system . mote complet self-contain \n",
      "Cleaned Token Before =  brought deep expertise in distributed systems, database design, and information retrieval to his role as chief scientist at metaweb. john giannandrea, formerly\n",
      "Cleaned Token After =  brought deep expertise distributed systems , database design , information retrieval role chief scientist metaweb . john giannandrea , formerly \n",
      "Cleaned Token After Stem =  brought deep expertis distribut system , databas design , inform retriev role chief scientist metaweb . john giannandrea , formerli \n",
      "Cleaned Token Before =  lightroom cc\". helpx.adobe.com. retrieved 2017-11-30. multimedia information retrieval and management: technological fundamentals and applications by david\n",
      "Cleaned Token After =  lightroom cc '' . helpx.adobe.com . retrieved 2017-11-30. multimedia information retrieval management : technological fundamentals applications david \n",
      "Cleaned Token After Stem =  lightroom cc `` . helpx.adobe.com . retriev 2017-11-30. multimedia inform retriev manag : technolog fundament applic david \n",
      "Cleaned Token Before =  performance measurement (factory production) prf asap information retrieval misc reports & retrievals system parameters or business rules transaction effects\n",
      "Cleaned Token After =  performance measurement ( factory production ) prf asap information retrieval misc reports & retrievals system parameters business rules transaction effects \n",
      "Cleaned Token After Stem =  perform measur ( factori product ) prf asap inform retriev misc report & retriev system paramet busi rule transact effect \n",
      "Cleaned Token Before =  leading figure in the early development of automated information retrieval systems and information science. a \"documentalist\", she was particularly known\n",
      "Cleaned Token After =  leading figure early development automated information retrieval systems information science . `` documentalist '' , particularly known \n",
      "Cleaned Token After Stem =  lead figur earli develop autom inform retriev system inform scienc . `` documentalist `` , particularli known \n",
      "Cleaned Token Before =   burke joined the staff of the national archives in 1967 as an information retrieval specialist, after holding previous positions at the university of\n",
      "Cleaned Token After =  burke joined staff national archives 1967 information retrieval specialist , holding previous positions university \n",
      "Cleaned Token After Stem =  burk join staff nation archiv 1967 inform retriev specialist , hold previou posit univers \n",
      "Cleaned Token Before =  accounting software provides many benefits such as speed up the information retrieval process, bring efficiency in bank reconciliation process, automatically\n",
      "Cleaned Token After =  accounting software provides many benefits speed information retrieval process , bring efficiency bank reconciliation process , automatically \n",
      "Cleaned Token After Stem =  account softwar provid mani benefit speed inform retriev process , bring effici bank reconcili process , automat \n",
      "Cleaned Token Before =  developed by data. however, data had also been working on a full-text information retrieval system for the u.s. air force, and by 1967 had adapted this product\n",
      "Cleaned Token After =  developed data . however , data also working full-text information retrieval system u.s. air force , 1967 adapted product \n",
      "Cleaned Token After Stem =  develop data . howev , data also work full-text inform retriev system u.s. air forc , 1967 adapt product \n",
      "Cleaned Token Before =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion\n",
      "Cleaned Token After =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion \n",
      "Cleaned Token After Stem =  digit librari comput platform digit market world wide web inform retriev secur cryptographi formal method secur servic intrus \n",
      "Cleaned Token Before =  selection and the result merging process in distributed information retrieval\". information sciences. 336: 115–128. doi:10.1016/j.ins.2015.12.012. lawrence\n",
      "Cleaned Token After =  selection result merging process distributed information retrieval '' . information sciences . 336 : 115–128 . doi:10.1016/j.ins.2015.12.012 . lawrence \n",
      "Cleaned Token After Stem =  select result merg process distribut inform retriev `` . inform scienc . 336 : 115–128 . doi:10.1016/j.ins.2015.12.012 . lawrenc \n",
      "Cleaned Token Before =  phynd (find) is a lan-indexing search engine used to facilitate peer-to-peer file sharing over a local-area network. it was developed by rensselaer polytechnic\n",
      "Cleaned Token After =  phynd ( find ) lan-indexing search engine used facilitate peer-to-peer file sharing local-area network . developed rensselaer polytechnic \n",
      "Cleaned Token After Stem =  phynd ( find ) lan-index search engin use facilit peer-to-p file share local-area network . develop renssela polytechn \n",
      "Cleaned Token Before =  ; shavitt y.; weinsberg e.; weinsberg u. (2014). \"peer-to-peer information retrieval using shared-content clustering\" (pdf). knowl inf syst. 39 (2):\n",
      "Cleaned Token After =  ; shavitt y. ; weinsberg e. ; weinsberg u . ( 2014 ) . `` peer-to-peer information retrieval using shared-content clustering '' ( pdf ) . knowl inf syst . 39 ( 2 ) : \n",
      "Cleaned Token After Stem =  ; shavitt y. ; weinsberg e. ; weinsberg u . ( 2014 ) . `` peer-to-p inform retriev use shared-cont cluster `` ( pdf ) . knowl inf syst . 39 ( 2 ) : \n",
      "Cleaned Token Before =  ptx is a unix utility, named after the permuted index algorithm which it uses to produce a search or concordance report in the keyword in context (kwic)\n",
      "Cleaned Token After =  ptx unix utility , named permuted index algorithm uses produce search concordance report keyword context ( kwic ) \n",
      "Cleaned Token After Stem =  ptx unix util , name permut index algorithm use produc search concord report keyword context ( kwic ) \n",
      "Cleaned Token Before =  relational database data management data mining information architecture information management information retrieval knowledge management multimedia, hypermedia\n",
      "Cleaned Token After =  relational database data management data mining information architecture information management information retrieval knowledge management multimedia , hypermedia \n",
      "Cleaned Token After Stem =  relat databas data manag data mine inform architectur inform manag inform retriev knowledg manag multimedia , hypermedia \n",
      "Cleaned Token Before =  generalization by reducing the information content of a concept or an observable phenomenon, typically in order to retain only information which is relevant for\n",
      "Cleaned Token After =  generalization reducing information content concept observable phenomenon , typically order retain information relevant \n",
      "Cleaned Token After Stem =  gener reduc inform content concept observ phenomenon , typic order retain inform relev \n",
      "Cleaned Token Before =  enterprise search micro focus idol lookeen server enterprise search autonomy information connectivity coveo connectors ses 11.2.2.2 datasheet - oracle what connectors\n",
      "Cleaned Token After =  enterprise search micro focus idol lookeen server enterprise search autonomy information connectivity coveo connectors ses 11.2.2.2 datasheet - oracle connectors \n",
      "Cleaned Token After Stem =  enterpris search micro focu idol lookeen server enterpris search autonomi inform connect coveo connector se 11.2.2.2 datasheet - oracl connector \n",
      "Cleaned Token Before =  retrieval, video information retrieval, video segmentation, face recognition, and cross-language information retrieval. the lycos search engine was an\n",
      "Cleaned Token After =  retrieval , video information retrieval , video segmentation , face recognition , cross-language information retrieval . lycos search engine \n",
      "Cleaned Token After Stem =  retriev , video inform retriev , video segment , face recognit , cross-languag inform retriev . lyco search engin \n",
      "Cleaned Token Before =  analysis (emdsa) is an important and effective tool in many multimedia information retrieval and pattern recognition applications. however, the computational\n",
      "Cleaned Token After =  analysis ( emdsa ) important effective tool many multimedia information retrieval pattern recognition applications . however , computational \n",
      "Cleaned Token After Stem =  analysi ( emdsa ) import effect tool mani multimedia inform retriev pattern recognit applic . howev , comput \n",
      "Cleaned Token Before =  1995. from 1995 to 2006, chevsky worked on question answering and information-retrieval technologies at ask jeeves (now ask.com). subsequently, he served\n",
      "Cleaned Token After =  1995. 1995 2006 , chevsky worked question answering information-retrieval technologies ask jeeves ( ask.com ) . subsequently , served \n",
      "Cleaned Token After Stem =  1995 . 1995 2006 , chevski work question answer information-retriev technolog ask jeev ( ask.com ) . subsequ , serv \n",
      "Cleaned Token Before =  1960s), and a priori knowledge. similarity is relevant also in music information retrieval. finally, musical similarity can be extended to the comparison between\n",
      "Cleaned Token After =  1960s ) , priori knowledge . similarity relevant also music information retrieval . finally , musical similarity extended comparison \n",
      "Cleaned Token After Stem =  1960 ) , priori knowledg . similar relev also music inform retriev . final , music similar extend comparison \n",
      "Cleaned Token Before =  rank, an algorithm used in the construction of ranking models for information retrieval systems litre (or liter), a metric unit of volume load task register\n",
      "Cleaned Token After =  rank , algorithm used construction ranking models information retrieval systems litre ( liter ) , metric unit volume load task register \n",
      "Cleaned Token After Stem =  rank , algorithm use construct rank model inform retriev system litr ( liter ) , metric unit volum load task regist \n",
      "Cleaned Token Before =  dda&t(q&a)823180 ddg 51 as of december 31, 2011 defense acquisition management information retrieval (damir)\" (pdf). 11 may 2012. archived from the original (pdf) on\n",
      "Cleaned Token After =  dda & ( q & ) 823180 ddg 51 december 31 , 2011 defense acquisition management information retrieval ( damir ) '' ( pdf ) . 11 may 2012. archived original ( pdf ) \n",
      "Cleaned Token After Stem =  dda & ( q & ) 823180 ddg 51 decemb 31 , 2011 defens acquisit manag inform retriev ( damir ) `` ( pdf ) . 11 may 2012. archiv origin ( pdf ) \n",
      "Cleaned Token Before =  solomonoff, ray j. \"a formal theory of inductive inference. part ii.\" information and control 7.2 (1964): 224–254. marr, bernard. \"a short history of machine\n",
      "Cleaned Token After =  solomonoff , ray j . `` formal theory inductive inference . part ii . '' information control 7.2 ( 1964 ) : 224–254 . marr , bernard . `` short history machine \n",
      "Cleaned Token After Stem =  solomonoff , ray j . `` formal theori induct infer . part ii . `` inform control 7.2 ( 1964 ) : 224–254 . marr , bernard . `` short histori machin \n",
      "Cleaned Token Before =  he-drum ( 何鼓 ) is a membranophone instrument designed by he xuntian. the instrument is single headed of cow skin, with a septangle shape. composer he xuntian\n",
      "Cleaned Token After =  he-drum ( 何鼓 ) membranophone instrument designed xuntian . instrument single headed cow skin , septangle shape . composer xuntian \n",
      "Cleaned Token After Stem =  he-drum ( 何鼓 ) membranophon instrument design xuntian . instrument singl head cow skin , septangl shape . compos xuntian \n",
      "Cleaned Token Before =  network, these influential vertices might be good users for spreading information or to target in a viral marketing campaign. when the query vertices belong\n",
      "Cleaned Token After =  network , influential vertices might good users spreading information target viral marketing campaign . query vertices belong \n",
      "Cleaned Token After Stem =  network , influenti vertic might good user spread inform target viral market campaign . queri vertic belong \n",
      "Cleaned Token Before =  corpus and created the first persian text collection suitable for information retrieval evaluation tasks. this corpus was created by crawling the online\n",
      "Cleaned Token After =  corpus created first persian text collection suitable information retrieval evaluation tasks . corpus created crawling online \n",
      "Cleaned Token After Stem =  corpu creat first persian text collect suitabl inform retriev evalu task . corpu creat crawl onlin \n",
      "Cleaned Token Before =  is a generalization of latent semantic analysis. in information retrieval, lsa enables retrieval on the basis of conceptual content, instead of merely\n",
      "Cleaned Token After =  generalization latent semantic analysis . information retrieval , lsa enables retrieval basis conceptual content , instead merely \n",
      "Cleaned Token After Stem =  gener latent semant analysi . inform retriev , lsa enabl retriev basi conceptu content , instead mere \n",
      "Cleaned Token Before =  zylab is a developer of software for e-discovery, information risk management, email management, records, contract, and document management, knowledge\n",
      "Cleaned Token After =  zylab developer software e-discovery , information risk management , email management , records , contract , document management , knowledge \n",
      "Cleaned Token After Stem =  zylab develop softwar e-discoveri , inform risk manag , email manag , record , contract , document manag , knowledg \n",
      "Cleaned Token Before =  of the 4th acm workshop on geographical information retrieval. workshop on geographic information retrieval, november 09, 2007, lisbon, portugal. retrieved\n",
      "Cleaned Token After =  4th acm workshop geographical information retrieval . workshop geographic information retrieval , november 09 , 2007 , lisbon , portugal . retrieved \n",
      "Cleaned Token After Stem =  4th acm workshop geograph inform retriev . workshop geograph inform retriev , novemb 09 , 2007 , lisbon , portug . retriev \n",
      "Cleaned Token Before =  researching collaborative systems, evolutionary algorithms and information retrieval. camp co-founded stumbleupon in 2002. it was the first web-discovery\n",
      "Cleaned Token After =  researching collaborative systems , evolutionary algorithms information retrieval . camp co-founded stumbleupon 2002. first web-discovery \n",
      "Cleaned Token After Stem =  research collabor system , evolutionari algorithm inform retriev . camp co-found stumbleupon 2002. first web-discoveri \n",
      "Cleaned Token Before =  a \"process\" taking one group to another, in a way that carries along information about the structure of the first group into the second group. the study\n",
      "Cleaned Token After =  `` process '' taking one group another , way carries along information structure first group second group . study \n",
      "Cleaned Token After Stem =  `` process `` take one group anoth , way carri along inform structur first group second group . studi \n",
      "Cleaned Token Before =  looping time variable, systems of logic, and interaction with the audio information received from winamp or other applicable media player's fast fourier\n",
      "Cleaned Token After =  looping time variable , systems logic , interaction audio information received winamp applicable media player 's fast fourier \n",
      "Cleaned Token After Stem =  loop time variabl , system logic , interact audio inform receiv winamp applic media player 's fast fourier \n",
      "Cleaned Token Before =  christopher; najork, marc. \"web crawling\" (pdf). foundations and trends in information retrieval. patil, yugandhara; patil, sonal (2016). \"review of web crawlers\n",
      "Cleaned Token After =  christopher ; najork , marc . `` web crawling '' ( pdf ) . foundations trends information retrieval . patil , yugandhara ; patil , sonal ( 2016 ) . `` review web crawlers \n",
      "Cleaned Token After Stem =  christoph ; najork , marc . `` web crawl `` ( pdf ) . foundat trend inform retriev . patil , yugandhara ; patil , sonal ( 2016 ) . `` review web crawler \n",
      "Cleaned Token Before =  computing machinery \"for contributions to industrial leadership and to information retrieval and web search.\" bort, julie (july 8, 2014), 22 of the most powerful\n",
      "Cleaned Token After =  computing machinery `` contributions industrial leadership information retrieval web search . '' bort , julie ( july 8 , 2014 ) , 22 powerful \n",
      "Cleaned Token After Stem =  comput machineri `` contribut industri leadership inform retriev web search . `` bort , juli ( juli 8 , 2014 ) , 22 power \n",
      "Cleaned Token Before =  health information-seeking behaviour (hisb), also known as health information seeking, health seeking behaviour or health information behaviour, refers\n",
      "Cleaned Token After =  health information-seeking behaviour ( hisb ) , also known health information seeking , health seeking behaviour health information behaviour , refers \n",
      "Cleaned Token After Stem =  health information-seek behaviour ( hisb ) , also known health inform seek , health seek behaviour health inform behaviour , refer \n",
      "Cleaned Token Before =  of oldenburg, germany. her main research interests are semantic information retrieval, intelligent user-interfaces and mobile systems. boll is a member\n",
      "Cleaned Token After =  oldenburg , germany . main research interests semantic information retrieval , intelligent user-interfaces mobile systems . boll member \n",
      "Cleaned Token After Stem =  oldenburg , germani . main research interest semant inform retriev , intellig user-interfac mobil system . boll member \n",
      "Cleaned Token Before =  conducts research in the areas of speech processing, computer vision, information retrieval, biometric authentication, multimodal interaction and machine learning\n",
      "Cleaned Token After =  conducts research areas speech processing , computer vision , information retrieval , biometric authentication , multimodal interaction machine learning \n",
      "Cleaned Token After Stem =  conduct research area speech process , comput vision , inform retriev , biometr authent , multimod interact machin learn \n",
      "Cleaned Token Before =  fellow of the aaas. his research centers on the role of information systems for storage and retrieval in a wide range of applications, with particular emphasis\n",
      "Cleaned Token After =  fellow aaas . research centers role information systems storage retrieval wide range applications , particular emphasis \n",
      "Cleaned Token After Stem =  fellow aaa . research center role inform system storag retriev wide rang applic , particular emphasi \n",
      "Cleaned Token Before =  and application areas include storage, data compression, music information retrieval, speech processing, localization, acoustic detection, transmission\n",
      "Cleaned Token After =  application areas include storage , data compression , music information retrieval , speech processing , localization , acoustic detection , transmission \n",
      "Cleaned Token After Stem =  applic area includ storag , data compress , music inform retriev , speech process , local , acoust detect , transmiss \n",
      "Cleaned Token Before =  triplestore or rdf store is a purpose-built database for the storage and retrieval of triples through semantic queries. a triple is a data entity composed\n",
      "Cleaned Token After =  triplestore rdf store purpose-built database storage retrieval triples semantic queries . triple data entity composed \n",
      "Cleaned Token After Stem =  triplestor rdf store purpose-built databas storag retriev tripl semant queri . tripl data entiti compos \n",
      "Cleaned Token Before =  dictionaries are used to control machine translations or cross-lingual information retrieval (clir) the content is usually multilingual and usually of huge size\n",
      "Cleaned Token After =  dictionaries used control machine translations cross-lingual information retrieval ( clir ) content usually multilingual usually huge size \n",
      "Cleaned Token After Stem =  dictionari use control machin translat cross-lingu inform retriev ( clir ) content usual multilingu usual huge size \n",
      "Cleaned Token Before =  onwards). the families of flowering plants: descriptions, illustrations, identification, information retrieval. published by delta-intkey (2002-06-18)\n",
      "Cleaned Token After =  onwards ) . families flowering plants : descriptions , illustrations , identification , information retrieval . published delta-intkey ( 2002-06-18 ) \n",
      "Cleaned Token After Stem =  onward ) . famili flower plant : descript , illustr , identif , inform retriev . publish delta-intkey ( 2002-06-18 ) \n",
      "Cleaned Token Before =  achievements with early online retrieval systems, including evaluation studies of medlars. he published broadly in library and information science over a period\n",
      "Cleaned Token After =  achievements early online retrieval systems , including evaluation studies medlars . published broadly library information science period \n",
      "Cleaned Token After Stem =  achiev earli onlin retriev system , includ evalu studi medlar . publish broadli librari inform scienc period \n",
      "Cleaned Token Before =  been used for a number of purposes in information systems, including word-sense disambiguation, information retrieval, automatic text classification, automatic\n",
      "Cleaned Token After =  used number purposes information systems , including word-sense disambiguation , information retrieval , automatic text classification , automatic \n",
      "Cleaned Token After Stem =  use number purpos inform system , includ word-sens disambigu , inform retriev , automat text classif , automat \n",
      "Cleaned Token Before =  addresses. they are also used for inverted indexes of text documents in information retrieval. radix trees support insertion, deletion, and searching operations\n",
      "Cleaned Token After =  addresses . also used inverted indexes text documents information retrieval . radix trees support insertion , deletion , searching operations \n",
      "Cleaned Token After Stem =  address . also use invert index text document inform retriev . radix tree support insert , delet , search oper \n",
      "Cleaned Token Before =  devices that help in arrangements of linear systems such as books and information retrieval systems. since phylogenetic relationships are complex and non-linear\n",
      "Cleaned Token After =  devices help arrangements linear systems books information retrieval systems . since phylogenetic relationships complex non-linear \n",
      "Cleaned Token After Stem =  devic help arrang linear system book inform retriev system . sinc phylogenet relationship complex non-linear \n",
      "Cleaned Token Before =  interface standard (wcs) defines web-based retrieval of coverages – that is, digital geospatial information representing space/time-varying phenomena.\n",
      "Cleaned Token After =  interface standard ( wcs ) defines web-based retrieval coverages – , digital geospatial information representing space/time-varying phenomena . \n",
      "Cleaned Token After Stem =  interfac standard ( wc ) defin web-bas retriev coverag – , digit geospati inform repres space/time-vari phenomena . \n",
      "Cleaned Token Before =   retrieved 2012-03-20 goodair, christine & welsh anne (2008). “information retrieval and terminology”. in addiction 103(4) p. 695. doi: 10.1111/j.1360-0443\n",
      "Cleaned Token After =  retrieved 2012-03-20 goodair , christine & welsh anne ( 2008 ) . “ information retrieval terminology ” . addiction 103 ( 4 ) p. 695. doi : 10.1111/j.1360-0443 \n",
      "Cleaned Token After Stem =  retriev 2012-03-20 goodair , christin & welsh ann ( 2008 ) . “ inform retriev terminolog ” . addict 103 ( 4 ) p. 695. doi : 10.1111/j.1360-0443 \n",
      "Cleaned Token Before =  hirschman l (2008). \"linking genes to literature: text mining, information extraction, and retrieval applications for biology\". genome biology. 9 suppl 2 (suppl\n",
      "Cleaned Token After =  hirschman l ( 2008 ) . `` linking genes literature : text mining , information extraction , retrieval applications biology '' . genome biology . 9 suppl 2 ( suppl \n",
      "Cleaned Token After Stem =  hirschman l ( 2008 ) . `` link gene literatur : text mine , inform extract , retriev applic biolog `` . genom biolog . 9 suppl 2 ( suppl \n",
      "Cleaned Token Before =  noting the nature of the reactions question answering, a type of information retrieval qa (cuneiform), a sign in cuneiform writing qa (cyrillic), a character\n",
      "Cleaned Token After =  noting nature reactions question answering , type information retrieval qa ( cuneiform ) , sign cuneiform writing qa ( cyrillic ) , character \n",
      "Cleaned Token After Stem =  note natur reaction question answer , type inform retriev qa ( cuneiform ) , sign cuneiform write qa ( cyril ) , charact \n",
      "Cleaned Token Before =  and information retrieval, digital libraries, web services, knowledge and information management and extraction, machine learning, and information and\n",
      "Cleaned Token After =  information retrieval , digital libraries , web services , knowledge information management extraction , machine learning , information \n",
      "Cleaned Token After Stem =  inform retriev , digit librari , web servic , knowledg inform manag extract , machin learn , inform \n",
      "Cleaned Token Before =  2008: proceedings of the 9th international conference on music information retrieval. drexel university, philadelphia, pennsylvania. pp. 363–368 at 365\n",
      "Cleaned Token After =  2008 : proceedings 9th international conference music information retrieval . drexel university , philadelphia , pennsylvania . pp . 363–368 365 \n",
      "Cleaned Token After Stem =  2008 : proceed 9th intern confer music inform retriev . drexel univers , philadelphia , pennsylvania . pp . 363–368 365 \n",
      "Cleaned Token Before =  tatum (surname) tatum (music), a subdivision of a beat in music information retrieval tatum, a brand name of the sfn group, a temporary work agency uss\n",
      "Cleaned Token After =  tatum ( surname ) tatum ( music ) , subdivision beat music information retrieval tatum , brand name sfn group , temporary work agency uss \n",
      "Cleaned Token After Stem =  tatum ( surnam ) tatum ( music ) , subdivis beat music inform retriev tatum , brand name sfn group , temporari work agenc uss \n",
      "Cleaned Token Before =  pianist. as a computer scientist, nassar was among the architects of information retrieval software for the world wide web and was the creator of isearch,\n",
      "Cleaned Token After =  pianist . computer scientist , nassar among architects information retrieval software world wide web creator isearch , \n",
      "Cleaned Token After Stem =  pianist . comput scientist , nassar among architect inform retriev softwar world wide web creator isearch , \n",
      "Cleaned Token Before =  owa operators provides a technique for directly aggregating uncertain information with uncertain weights via owa mechanism in soft decision making and\n",
      "Cleaned Token After =  owa operators provides technique directly aggregating uncertain information uncertain weights via owa mechanism soft decision making \n",
      "Cleaned Token After Stem =  owa oper provid techniqu directli aggreg uncertain inform uncertain weight via owa mechan soft decis make \n",
      "Cleaned Token Before =  dallwitz (1992 onwards). the families of flowering plants: descriptions, illustrations, identification, information retrieval. http://delta-intkey.com\n",
      "Cleaned Token After =  dallwitz ( 1992 onwards ) . families flowering plants : descriptions , illustrations , identification , information retrieval . http : //delta-intkey.com \n",
      "Cleaned Token After Stem =  dallwitz ( 1992 onward ) . famili flower plant : descript , illustr , identif , inform retriev . http : //delta-intkey.com \n",
      "Cleaned Token Before =  it covered the study of multimedia algorithms and applications, information retrieval, artificial intelligence, multimedia compression, statistical inference\n",
      "Cleaned Token After =  covered study multimedia algorithms applications , information retrieval , artificial intelligence , multimedia compression , statistical inference \n",
      "Cleaned Token After Stem =  cover studi multimedia algorithm applic , inform retriev , artifici intellig , multimedia compress , statist infer \n",
      "Cleaned Token Before =  content which is specifically designed to satisfy algorithms for maximal retrieval by automated search engines which is known as seo (search engine optimization)\n",
      "Cleaned Token After =  content specifically designed satisfy algorithms maximal retrieval automated search engines known seo ( search engine optimization ) \n",
      "Cleaned Token After Stem =  content specif design satisfi algorithm maxim retriev autom search engin known seo ( search engin optim ) \n",
      "Cleaned Token Before =  international acm sigir conference on research and development in information retrieval (sigir '94), 3–12. new york, springer-verlag, 1994. j. c. platt\n",
      "Cleaned Token After =  international acm sigir conference research development information retrieval ( sigir '94 ) , 3–12 . new york , springer-verlag , 1994. j. c. platt \n",
      "Cleaned Token After Stem =  intern acm sigir confer research develop inform retriev ( sigir '94 ) , 3–12 . new york , springer-verlag , 1994. j. c. platt \n",
      "Cleaned Token Before =  together natively. language-independent specification cross-language information retrieval, referring to natural languages, not programming languages language\n",
      "Cleaned Token After =  together natively . language-independent specification cross-language information retrieval , referring natural languages , programming languages language \n",
      "Cleaned Token After Stem =  togeth nativ . language-independ specif cross-languag inform retriev , refer natur languag , program languag languag \n",
      "Cleaned Token Before =  computing machinery (acm) international conference on multimedia information retrieval (philadelphia, march 2010), a program committee vice chair for the\n",
      "Cleaned Token After =  computing machinery ( acm ) international conference multimedia information retrieval ( philadelphia , march 2010 ) , program committee vice chair \n",
      "Cleaned Token After Stem =  comput machineri ( acm ) intern confer multimedia inform retriev ( philadelphia , march 2010 ) , program committe vice chair \n",
      "Cleaned Token Before =  single request (in request–response architectures) or a query (in information retrieval), either a single stage of handling, or the whole system-wide handling\n",
      "Cleaned Token After =  single request ( request–response architectures ) query ( information retrieval ) , either single stage handling , whole system-wide handling \n",
      "Cleaned Token After Stem =  singl request ( request–respons architectur ) queri ( inform retriev ) , either singl stage handl , whole system-wid handl \n",
      "Cleaned Token Before =  analytics is a process of information extraction whose goal is to automatically extract structured or semistructured information from noisy unstructured\n",
      "Cleaned Token After =  analytics process information extraction whose goal automatically extract structured semistructured information noisy unstructured \n",
      "Cleaned Token After Stem =  analyt process inform extract whose goal automat extract structur semistructur inform noisi unstructur \n",
      "Cleaned Token Before =  services, the library provides services of international online information retrieval, various types of e-resources searching, interlibrary loans, document\n",
      "Cleaned Token After =  services , library provides services international online information retrieval , various types e-resources searching , interlibrary loans , document \n",
      "Cleaned Token After Stem =  servic , librari provid servic intern onlin inform retriev , variou type e-resourc search , interlibrari loan , document \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, and information retrieval. version: 21 march 2010. delta-intkey.com. caratini, roger. la vie\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval . version : 21 march 2010. delta-intkey.com . caratini , roger . la vie \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev . version : 21 march 2010. delta-intkey.com . caratini , roger . la vie \n",
      "Cleaned Token Before =  implementation was released as through the special interest group on information retrieval of the association for computing machinery in 2017 and won the best\n",
      "Cleaned Token After =  implementation released special interest group information retrieval association computing machinery 2017 best \n",
      "Cleaned Token After Stem =  implement releas special interest group inform retriev associ comput machineri 2017 best \n",
      "Cleaned Token Before =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion\n",
      "Cleaned Token After =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion \n",
      "Cleaned Token After Stem =  digit librari comput platform digit market world wide web inform retriev secur cryptographi formal method secur servic intrus \n",
      "Cleaned Token Before =  from boolean logic to switching circuits and automata: towards modern information technology. springer. isbn 978-3-642-11681-0. boolean algebra chapter\n",
      "Cleaned Token After =  boolean logic switching circuits automata : towards modern information technology . springer . isbn 978-3-642-11681-0. boolean algebra chapter \n",
      "Cleaned Token After Stem =  boolean logic switch circuit automata : toward modern inform technolog . springer . isbn 978-3-642-11681-0. boolean algebra chapter \n",
      "Cleaned Token Before =  bioindicator biomarker biosignature molecular marker multimedia information retrieval \"remote heartbeat monitor will outperform current technology\". university\n",
      "Cleaned Token After =  bioindicator biomarker biosignature molecular marker multimedia information retrieval `` remote heartbeat monitor outperform current technology '' . university \n",
      "Cleaned Token After Stem =  bioindic biomark biosignatur molecular marker multimedia inform retriev `` remot heartbeat monitor outperform current technolog `` . univers \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, and information retrieval\". 20 june 2017. retrieved 9 july 2017. valente, luis m.; britton\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval '' . 20 june 2017. retrieved 9 july 2017. valente , luis m. ; britton \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev `` . 20 june 2017. retriev 9 juli 2017. valent , lui m. ; britton \n",
      "Cleaned Token Before =  metric for image retrieval\". international journal of computer vision. 40 (2): 99–121. doi:10.1023/a:1026543900054. s2cid 14106275. information theoretical\n",
      "Cleaned Token After =  metric image retrieval '' . international journal computer vision . 40 ( 2 ) : 99–121 . doi:10.1023/a:1026543900054. s2cid 14106275. information theoretical \n",
      "Cleaned Token After Stem =  metric imag retriev `` . intern journal comput vision . 40 ( 2 ) : 99–121 . doi:10.1023/a:1026543900054. s2cid 14106275. inform theoret \n",
      "Cleaned Token Before =  negative rate into account and, therefore, are more suited to information retrieval and information extraction evaluation where the true negatives are innumerable\n",
      "Cleaned Token After =  negative rate account , therefore , suited information retrieval information extraction evaluation true negatives innumerable \n",
      "Cleaned Token After Stem =  neg rate account , therefor , suit inform retriev inform extract evalu true neg innumer \n",
      "Cleaned Token Before =  the crisp (computer retrieval of information on scientific projects) system at nih has been replaced by the report expenditures and results (reporter)\n",
      "Cleaned Token After =  crisp ( computer retrieval information scientific projects ) system nih replaced report expenditures results ( reporter ) \n",
      "Cleaned Token After Stem =  crisp ( comput retriev inform scientif project ) system nih replac report expenditur result ( report ) \n",
      "Cleaned Token Before =  evaluation methods he made other research contributions in the area of information retrieval, anaphora resolution and automatic abstracting. christopher d paice\n",
      "Cleaned Token After =  evaluation methods made research contributions area information retrieval , anaphora resolution automatic abstracting . christopher paice \n",
      "Cleaned Token After Stem =  evalu method made research contribut area inform retriev , anaphora resolut automat abstract . christoph paic \n",
      "Cleaned Token Before =  item features in recommender systems, most of them are from the information retrieval domain like tf–idf, okapi bm25, only a few have been developed specifically\n",
      "Cleaned Token After =  item features recommender systems , information retrieval domain like tf–idf , okapi bm25 , developed specifically \n",
      "Cleaned Token After Stem =  item featur recommend system , inform retriev domain like tf–idf , okapi bm25 , develop specif \n",
      "Cleaned Token Before =  metric called mahalanobis distance. similarity learning is used in information retrieval for learning to rank, in face verification or face identification\n",
      "Cleaned Token After =  metric called mahalanobis distance . similarity learning used information retrieval learning rank , face verification face identification \n",
      "Cleaned Token After Stem =  metric call mahalanobi distanc . similar learn use inform retriev learn rank , face verif face identif \n",
      "Cleaned Token Before =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion\n",
      "Cleaned Token After =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion \n",
      "Cleaned Token After Stem =  digit librari comput platform digit market world wide web inform retriev secur cryptographi formal method secur servic intrus \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, and information retrieval archived 13 december 2010 at the wayback machine. version: 4 march\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval archived 13 december 2010 wayback machine . version : 4 march \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev archiv 13 decemb 2010 wayback machin . version : 4 march \n",
      "Cleaned Token Before =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion\n",
      "Cleaned Token After =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion \n",
      "Cleaned Token After Stem =  digit librari comput platform digit market world wide web inform retriev secur cryptographi formal method secur servic intrus \n",
      "Cleaned Token Before =  searched. the greenpilot portal integrates various scientifically relevant information resources under a uniform search interface. these resources are diverse\n",
      "Cleaned Token After =  searched . greenpilot portal integrates various scientifically relevant information resources uniform search interface . resources diverse \n",
      "Cleaned Token After Stem =  search . greenpilot portal integr variou scientif relev inform resourc uniform search interfac . resourc divers \n",
      "Cleaned Token Before =  inventors hall of fame old patent office building patent application information retrieval (pair) patent model patent office patent office professional association\n",
      "Cleaned Token After =  inventors hall fame old patent office building patent application information retrieval ( pair ) patent model patent office patent office professional association \n",
      "Cleaned Token After Stem =  inventor hall fame old patent offic build patent applic inform retriev ( pair ) patent model patent offic patent offic profession associ \n",
      "Cleaned Token Before =   retrieved 20 may 2008. masinter, larry (1993). \"collaborative information retrieval: gopher from moo\". citeseerx 10.1.1.198.5779. cite journal requires\n",
      "Cleaned Token After =  retrieved 20 may 2008. masinter , larry ( 1993 ) . `` collaborative information retrieval : gopher moo '' . citeseerx 10.1.1.198.5779. cite journal requires \n",
      "Cleaned Token After Stem =  retriev 20 may 2008. masint , larri ( 1993 ) . `` collabor inform retriev : gopher moo `` . citeseerx 10.1.1.198.5779. cite journal requir \n",
      "Cleaned Token Before =  clir may refer to: council on library and information resources, usa cross-language information retrieval calling line identification restriction, one\n",
      "Cleaned Token After =  clir may refer : council library information resources , usa cross-language information retrieval calling line identification restriction , one \n",
      "Cleaned Token After Stem =  clir may refer : council librari inform resourc , usa cross-languag inform retriev call line identif restrict , one \n",
      "Cleaned Token Before =  measures such as precision and recall, commonly used in the field of information retrieval, are typical ways of quantifying the response of a speech analytics\n",
      "Cleaned Token After =  measures precision recall , commonly used field information retrieval , typical ways quantifying response speech analytics \n",
      "Cleaned Token After Stem =  measur precis recal , commonli use field inform retriev , typic way quantifi respons speech analyt \n",
      "Cleaned Token Before =  quintal research group after it secured a patent for a \"computerized information retrieval system\" in 2008. on march 17, 2018, the united states appeals court\n",
      "Cleaned Token After =  quintal research group secured patent `` computerized information retrieval system '' 2008. march 17 , 2018 , united states appeals court \n",
      "Cleaned Token After Stem =  quintal research group secur patent `` computer inform retriev system `` 2008. march 17 , 2018 , unit state appeal court \n",
      "Cleaned Token Before =  information creation may refer to: information retrieval content creation this disambiguation page lists articles associated with the title information\n",
      "Cleaned Token After =  information creation may refer : information retrieval content creation disambiguation page lists articles associated title information \n",
      "Cleaned Token After Stem =  inform creation may refer : inform retriev content creation disambigu page list articl associ titl inform \n",
      "Cleaned Token Before =  of computer science working on natural language processing and information retrieval. he previously served as a university of michigan computer science\n",
      "Cleaned Token After =  computer science working natural language processing information retrieval . previously served university michigan computer science \n",
      "Cleaned Token After Stem =  comput scienc work natur languag process inform retriev . previous serv univers michigan comput scienc \n",
      "Cleaned Token Before =  intelligence, and some software developers focus on the practical aspect, information retrieval. chatbot competitions focus on the turing test or more specific\n",
      "Cleaned Token After =  intelligence , software developers focus practical aspect , information retrieval . chatbot competitions focus turing test specific \n",
      "Cleaned Token After Stem =  intellig , softwar develop focu practic aspect , inform retriev . chatbot competit focu ture test specif \n",
      "Cleaned Token Before =  humans to expertise areas, and as such is a sub-problem of expertise retrieval (the other problem being expertise profiling). it can be argued that human\n",
      "Cleaned Token After =  humans expertise areas , sub-problem expertise retrieval ( problem expertise profiling ) . argued human \n",
      "Cleaned Token After Stem =  human expertis area , sub-problem expertis retriev ( problem expertis profil ) . argu human \n",
      "Cleaned Token Before =  methods of data transmission. it is now a large field of study, part of information theory. discrete geometry (also called combinatorial geometry) also began\n",
      "Cleaned Token After =  methods data transmission . large field study , part information theory . discrete geometry ( also called combinatorial geometry ) also began \n",
      "Cleaned Token After Stem =  method data transmiss . larg field studi , part inform theori . discret geometri ( also call combinatori geometri ) also began \n",
      "Cleaned Token Before =  areas of ontology-based reasoning include, but are not limited to, information retrieval, automated scene interpretation, and knowledge discovery. an ontology\n",
      "Cleaned Token After =  areas ontology-based reasoning include , limited , information retrieval , automated scene interpretation , knowledge discovery . ontology \n",
      "Cleaned Token After Stem =  area ontology-bas reason includ , limit , inform retriev , autom scene interpret , knowledg discoveri . ontolog \n",
      "Cleaned Token Before =  usability engineering handheld devices human–computer information retrieval information retrieval internet and the world wide web multimedia software agents\n",
      "Cleaned Token After =  usability engineering handheld devices human–computer information retrieval information retrieval internet world wide web multimedia software agents \n",
      "Cleaned Token After Stem =  usabl engin handheld devic human–comput inform retriev inform retriev internet world wide web multimedia softwar agent \n",
      "Cleaned Token Before =  from previous work on systems by using abstract algebra to describe information systems rather than differential calculus to describe material systems\n",
      "Cleaned Token After =  previous work systems using abstract algebra describe information systems rather differential calculus describe material systems \n",
      "Cleaned Token After Stem =  previou work system use abstract algebra describ inform system rather differenti calculu describ materi system \n",
      "Cleaned Token Before =  databases contextual query language (or common query language), for information retrieval cassandra query language, for apache cassandra classora query language\n",
      "Cleaned Token After =  databases contextual query language ( common query language ) , information retrieval cassandra query language , apache cassandra classora query language \n",
      "Cleaned Token After Stem =  databas contextu queri languag ( common queri languag ) , inform retriev cassandra queri languag , apach cassandra classora queri languag \n",
      "Cleaned Token Before =  that assists the human memory with information retention or retrieval by making abstract or impersonal information more accessible and meaningful, and\n",
      "Cleaned Token After =  assists human memory information retention retrieval making abstract impersonal information accessible meaningful , \n",
      "Cleaned Token After Stem =  assist human memori inform retent retriev make abstract imperson inform access meaning , \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, and information retrieval\". delta – description language for taxonomy. archived from the original\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval '' . delta – description language taxonomy . archived original \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev `` . delta – descript languag taxonomi . archiv origin \n",
      "Cleaned Token Before =  via metrics but is a subjective assessment that requires judgmental information to be applied to give a level of confidence, whilst reliability can be\n",
      "Cleaned Token After =  via metrics subjective assessment requires judgmental information applied give level confidence , whilst reliability \n",
      "Cleaned Token After Stem =  via metric subject assess requir judgment inform appli give level confid , whilst reliabl \n",
      "Cleaned Token Before =  hidden markov model r. baeza-yates and b. ribeiro-neto. \"modern information retrieval\", second edition, addison-wesley, 2011. zhiyuan chen, bing liu,\n",
      "Cleaned Token After =  hidden markov model r. baeza-yates b. ribeiro-neto . `` modern information retrieval '' , second edition , addison-wesley , 2011. zhiyuan chen , bing liu , \n",
      "Cleaned Token After Stem =  hidden markov model r. baeza-y b. ribeiro-neto . `` modern inform retriev `` , second edit , addison-wesley , 2011. zhiyuan chen , bing liu , \n",
      "Cleaned Token Before =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion\n",
      "Cleaned Token After =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion \n",
      "Cleaned Token After Stem =  digit librari comput platform digit market world wide web inform retriev secur cryptographi formal method secur servic intrus \n",
      "Cleaned Token Before =  isbn 978-1-55860-539-8 page 41-48 milestones in computer science and information technology by edwin d. reilly 2003 isbn 1-57356-521-0 page 65 \"mikhail\n",
      "Cleaned Token After =  isbn 978-1-55860-539-8 page 41-48 milestones computer science information technology edwin d. reilly 2003 isbn 1-57356-521-0 page 65 `` mikhail \n",
      "Cleaned Token After Stem =  isbn 978-1-55860-539-8 page 41-48 mileston comput scienc inform technolog edwin d. reilli 2003 isbn 1-57356-521-0 page 65 `` mikhail \n",
      "Cleaned Token Before =  probabilistisches indexing und retrieval, fachinformationszentrum karlsruhe fuhr, norbert (2012), \"salton award lecture: information retrieval as engineering science\"\n",
      "Cleaned Token After =  probabilistisches indexing und retrieval , fachinformationszentrum karlsruhe fuhr , norbert ( 2012 ) , `` salton award lecture : information retrieval engineering science '' \n",
      "Cleaned Token After Stem =  probabilistisch index und retriev , fachinformationszentrum karlsruh fuhr , norbert ( 2012 ) , `` salton award lectur : inform retriev engin scienc `` \n",
      "Cleaned Token Before =  in a broad range of areas, including: neural networks multimedia information retrieval genetic design computational linguistics speech recognition web-browser\n",
      "Cleaned Token After =  broad range areas , including : neural networks multimedia information retrieval genetic design computational linguistics speech recognition web-browser \n",
      "Cleaned Token After Stem =  broad rang area , includ : neural network multimedia inform retriev genet design comput linguist speech recognit web-brows \n",
      "Cleaned Token Before =  sci-tech research and patent information, offers a wide array of databases, the fiz autodoc full-text delivery service, and retrieval, analysis, and visualization\n",
      "Cleaned Token After =  sci-tech research patent information , offers wide array databases , fiz autodoc full-text delivery service , retrieval , analysis , visualization \n",
      "Cleaned Token After Stem =  sci-tech research patent inform , offer wide array databas , fiz autodoc full-text deliveri servic , retriev , analysi , visual \n",
      "Cleaned Token Before =  evolution, research issues, perspectives\". string processing and information retrieval. lncs. springer-verlag. 2000: 481–486. doi:10.1007/3-540-45735-6_1\n",
      "Cleaned Token After =  evolution , research issues , perspectives '' . string processing information retrieval . lncs . springer-verlag . 2000 : 481–486 . doi:10.1007/3-540-45735-6_1 \n",
      "Cleaned Token After Stem =  evolut , research issu , perspect `` . string process inform retriev . lnc . springer-verlag . 2000 : 481–486 . doi:10.1007/3-540-45735-6_1 \n",
      "Cleaned Token Before =  programming class (philosophy) formal semantics (linguistics) information extraction information retrieval question answering semantic analysis (linguistics) semantic\n",
      "Cleaned Token After =  programming class ( philosophy ) formal semantics ( linguistics ) information extraction information retrieval question answering semantic analysis ( linguistics ) semantic \n",
      "Cleaned Token After Stem =  program class ( philosophi ) formal semant ( linguist ) inform extract inform retriev question answer semant analysi ( linguist ) semant \n",
      "Cleaned Token Before =  expressed as an xml schema document for use by the distributed generic information retrieval (digir) protocol. a tdwg task group was created to revise the darwin\n",
      "Cleaned Token After =  expressed xml schema document use distributed generic information retrieval ( digir ) protocol . tdwg task group created revise darwin \n",
      "Cleaned Token After Stem =  express xml schema document use distribut gener inform retriev ( digir ) protocol . tdwg task group creat revis darwin \n",
      "Cleaned Token Before =  international contexts. research of information-seeking activity, information retrieval systems, and information structures are core interests. these\n",
      "Cleaned Token After =  international contexts . research information-seeking activity , information retrieval systems , information structures core interests . \n",
      "Cleaned Token After Stem =  intern context . research information-seek activ , inform retriev system , inform structur core interest . \n",
      "Cleaned Token Before =  domain-specific languages can help to shift the development of business information systems from traditional software developers to the typically larger\n",
      "Cleaned Token After =  domain-specific languages help shift development business information systems traditional software developers typically larger \n",
      "Cleaned Token After Stem =  domain-specif languag help shift develop busi inform system tradit softwar develop typic larger \n",
      "Cleaned Token Before =  computer vision/computer graphics, vlsi and communication, databases, information retrieval and algorithms. located in salt lake sector-i, kolkata. the institute\n",
      "Cleaned Token After =  computer vision/computer graphics , vlsi communication , databases , information retrieval algorithms . located salt lake sector-i , kolkata . institute \n",
      "Cleaned Token After Stem =  comput vision/comput graphic , vlsi commun , databas , inform retriev algorithm . locat salt lake sector-i , kolkata . institut \n",
      "Cleaned Token Before =  conversational agent that utilizes natural language processing (nlp), information retrieval (ir) and automatic learning. because the bot poses as a young female\n",
      "Cleaned Token After =  conversational agent utilizes natural language processing ( nlp ) , information retrieval ( ir ) automatic learning . bot poses young female \n",
      "Cleaned Token After Stem =  convers agent util natur languag process ( nlp ) , inform retriev ( ir ) automat learn . bot pose young femal \n",
      "Cleaned Token Before =  international acm sigir conference on research and development in information retrieval. (reprinted in acm sigir forum, vol. 51, no. 2, pp. 148-159. acm\n",
      "Cleaned Token After =  international acm sigir conference research development information retrieval . ( reprinted acm sigir forum , vol . 51 , . 2 , pp . 148-159. acm \n",
      "Cleaned Token After Stem =  intern acm sigir confer research develop inform retriev . ( reprint acm sigir forum , vol . 51 , . 2 , pp . 148-159. acm \n",
      "Cleaned Token Before =  for example, databases use b-tree indexes for small percentages of data retrieval and compilers and databases use dynamic hash tables as look up tables\n",
      "Cleaned Token After =  example , databases use b-tree indexes small percentages data retrieval compilers databases use dynamic hash tables look tables \n",
      "Cleaned Token After Stem =  exampl , databas use b-tree index small percentag data retriev compil databas use dynam hash tabl look tabl \n",
      "Cleaned Token Before =  proceedings of the 12th international conference, string processing and information retrieval (spire 2005). 3772/2005. pp. 91–102. doi:10.1007/11575832_11.\n",
      "Cleaned Token After =  proceedings 12th international conference , string processing information retrieval ( spire 2005 ) . 3772/2005 . pp . 91–102 . doi:10.1007/11575832_11 . \n",
      "Cleaned Token After Stem =  proceed 12th intern confer , string process inform retriev ( spire 2005 ) . 3772/2005 . pp . 91–102 . doi:10.1007/11575832_11 . \n",
      "Cleaned Token Before =  nature.[citation needed] lawrence's research interests include information retrieval, digital libraries, and machine learning. he has published over\n",
      "Cleaned Token After =  nature . [ citation needed ] lawrence 's research interests include information retrieval , digital libraries , machine learning . published \n",
      "Cleaned Token After Stem =  natur . [ citat need ] lawrenc 's research interest includ inform retriev , digit librari , machin learn . publish \n",
      "Cleaned Token Before =  arctic archipelago: descriptions, illustrations, identification, and information retrieval. version: 29 april 2003. \"archived copy\". archived from the original\n",
      "Cleaned Token After =  arctic archipelago : descriptions , illustrations , identification , information retrieval . version : 29 april 2003 . `` archived copy '' . archived original \n",
      "Cleaned Token After Stem =  arctic archipelago : descript , illustr , identif , inform retriev . version : 29 april 2003 . `` archiv copi `` . archiv origin \n",
      "Cleaned Token Before =  independence model, a probabilistic information retrieval technique blade inspection method for helicopters building information modeling, within construction\n",
      "Cleaned Token After =  independence model , probabilistic information retrieval technique blade inspection method helicopters building information modeling , within construction \n",
      "Cleaned Token After Stem =  independ model , probabilist inform retriev techniqu blade inspect method helicopt build inform model , within construct \n",
      "Cleaned Token Before =  targets in a cued-memory task, memory relies on the retrieval of structural-perceptual information about the targets. when the items are presented in a\n",
      "Cleaned Token After =  targets cued-memory task , memory relies retrieval structural-perceptual information targets . items presented \n",
      "Cleaned Token After Stem =  target cued-memori task , memori reli retriev structural-perceptu inform target . item present \n",
      "Cleaned Token Before =  scientist associated with northwestern university who specializes in information retrieval, computational social science, and human–computer interaction. she\n",
      "Cleaned Token After =  scientist associated northwestern university specializes information retrieval , computational social science , human–computer interaction . \n",
      "Cleaned Token After Stem =  scientist associ northwestern univers special inform retriev , comput social scienc , human–comput interact . \n",
      "Cleaned Token Before =  proceedings of the first international workshop on adversarial information retrieval on the web (airweb), 2005 in the 14th international world wide web\n",
      "Cleaned Token After =  proceedings first international workshop adversarial information retrieval web ( airweb ) , 2005 14th international world wide web \n",
      "Cleaned Token After Stem =  proceed first intern workshop adversari inform retriev web ( airweb ) , 2005 14th intern world wide web \n",
      "Cleaned Token Before =  typically collected by direct observations.in machine learning and information retrieval, \"ground truth\" is the preferred term even when classifications\n",
      "Cleaned Token After =  typically collected direct observations.in machine learning information retrieval , `` ground truth '' preferred term even classifications \n",
      "Cleaned Token After Stem =  typic collect direct observations.in machin learn inform retriev , `` ground truth `` prefer term even classif \n",
      "Cleaned Token Before =   mahidol university. his best known work is buddhist scripture information retrieval (budsir), the first computerized buddhist scripture of the world\n",
      "Cleaned Token After =  mahidol university . best known work buddhist scripture information retrieval ( budsir ) , first computerized buddhist scripture world \n",
      "Cleaned Token After Stem =  mahidol univers . best known work buddhist scriptur inform retriev ( budsir ) , first computer buddhist scriptur world \n",
      "Cleaned Token Before =  \"fluency heuristic: a model of how the mind exploits a by-product of information retrieval\". journal of experimental psychology: learning, memory, and cognition\n",
      "Cleaned Token After =  `` fluency heuristic : model mind exploits by-product information retrieval '' . journal experimental psychology : learning , memory , cognition \n",
      "Cleaned Token After Stem =  `` fluenci heurist : model mind exploit by-product inform retriev `` . journal experiment psycholog : learn , memori , cognit \n",
      "Cleaned Token Before =  unknown zettair october 2009 enterprise search list of search engine software list of search appliance vendors dmoz category information retrieval/fulltext\n",
      "Cleaned Token After =  unknown zettair october 2009 enterprise search list search engine software list search appliance vendors dmoz category information retrieval/fulltext \n",
      "Cleaned Token After Stem =  unknown zettair octob 2009 enterpris search list search engin softwar list search applianc vendor dmoz categori inform retrieval/fulltext \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, information retrieval. die agaven agavaceae in bodd – botanical dermatology database media\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval . die agaven agavaceae bodd – botanical dermatology database media \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev . die agaven agavacea bodd – botan dermatolog databas media \n",
      "Cleaned Token Before =  concentrating on artificial intelligence, natural language processing, information retrieval and software engineering, including the books artificial intelligence:\n",
      "Cleaned Token After =  concentrating artificial intelligence , natural language processing , information retrieval software engineering , including books artificial intelligence : \n",
      "Cleaned Token After Stem =  concentr artifici intellig , natur languag process , inform retriev softwar engin , includ book artifici intellig : \n",
      "Cleaned Token Before =  programming language designed for creating stemming algorithms for use in information retrieval. the snowball compiler translates a snowball script (a .sbl file)\n",
      "Cleaned Token After =  programming language designed creating stemming algorithms use information retrieval . snowball compiler translates snowball script ( .sbl file ) \n",
      "Cleaned Token After Stem =  program languag design creat stem algorithm use inform retriev . snowbal compil translat snowbal script ( .sbl file ) \n",
      "Cleaned Token Before =  period, an archaeological assemblage in the persian gulf private information retrieval, without revealing what was retrieved prosopographia imperii romani\n",
      "Cleaned Token After =  period , archaeological assemblage persian gulf private information retrieval , without revealing retrieved prosopographia imperii romani \n",
      "Cleaned Token After Stem =  period , archaeolog assemblag persian gulf privat inform retriev , without reveal retriev prosopographia imperii romani \n",
      "Cleaned Token Before =  these enormous collections led to a great expansion in the field of information retrieval. in the us, the aeronautical collection was first sent to us army\n",
      "Cleaned Token After =  enormous collections led great expansion field information retrieval . us , aeronautical collection first sent us army \n",
      "Cleaned Token After Stem =  enorm collect led great expans field inform retriev . us , aeronaut collect first sent us armi \n",
      "Cleaned Token Before =  spectral music, minimalist music, music theory, fractals, music information retrieval, sound synthesis etc. alain bancquart brian ferneyhough joshua fineberg\n",
      "Cleaned Token After =  spectral music , minimalist music , music theory , fractals , music information retrieval , sound synthesis etc . alain bancquart brian ferneyhough joshua fineberg \n",
      "Cleaned Token After Stem =  spectral music , minimalist music , music theori , fractal , music inform retriev , sound synthesi etc . alain bancquart brian ferneyhough joshua fineberg \n",
      "Cleaned Token Before =  fellow 2020, for his research and contributions to the area of information retrieval. his research has been cited more than 20,000 times (april 2021)\n",
      "Cleaned Token After =  fellow 2020 , research contributions area information retrieval . research cited 20,000 times ( april 2021 ) \n",
      "Cleaned Token After Stem =  fellow 2020 , research contribut area inform retriev . research cite 20,000 time ( april 2021 ) \n",
      "Cleaned Token Before =  computer sciences of music (including sound and music computing, music information retrieval, and computing in musicology). these subdisciplines and paradigms\n",
      "Cleaned Token After =  computer sciences music ( including sound music computing , music information retrieval , computing musicology ) . subdisciplines paradigms \n",
      "Cleaned Token After Stem =  comput scienc music ( includ sound music comput , music inform retriev , comput musicolog ) . subdisciplin paradigm \n",
      "Cleaned Token Before =  both digital and traditional artists use many sources of electronic information and programs to create their work. given the parallels between visual\n",
      "Cleaned Token After =  digital traditional artists use many sources electronic information programs create work . given parallels visual \n",
      "Cleaned Token After Stem =  digit tradit artist use mani sourc electron inform program creat work . given parallel visual \n",
      "Cleaned Token Before =  machine from the human end, whilst the machine simultaneously feeds back information that aids the operators' decision-making process. examples of this broad\n",
      "Cleaned Token After =  machine human end , whilst machine simultaneously feeds back information aids operators ' decision-making process . examples broad \n",
      "Cleaned Token After Stem =  machin human end , whilst machin simultan feed back inform aid oper ' decision-mak process . exampl broad \n",
      "Cleaned Token Before =  'information technology' was appropriate to describe the convergence of technologies with application in the broad field of data storage, retrieval, processing\n",
      "Cleaned Token After =  'information technology ' appropriate describe convergence technologies application broad field data storage , retrieval , processing \n",
      "Cleaned Token After Stem =  'inform technolog ' appropri describ converg technolog applic broad field data storag , retriev , process \n",
      "Cleaned Token Before =  inputs to receive commands to perform certain functions. in terms of information retrieval, the tool can respond either verbally or by displaying its findings\n",
      "Cleaned Token After =  inputs receive commands perform certain functions . terms information retrieval , tool respond either verbally displaying findings \n",
      "Cleaned Token After Stem =  input receiv command perform certain function . term inform retriev , tool respond either verbal display find \n",
      "Cleaned Token Before =   under appropriate assumptions, certain two-player games of perfect information are determined from the start in the sense that one player must have\n",
      "Cleaned Token After =  appropriate assumptions , certain two-player games perfect information determined start sense one player must \n",
      "Cleaned Token After Stem =  appropri assumpt , certain two-play game perfect inform determin start sens one player must \n",
      "Cleaned Token Before =  melucci, massimo; toni, bourama (2019). quantum-like models for information retrieval and decision-making. cham, switzerland: springer nature. p. 65.\n",
      "Cleaned Token After =  melucci , massimo ; toni , bourama ( 2019 ) . quantum-like models information retrieval decision-making . cham , switzerland : springer nature . p. 65 . \n",
      "Cleaned Token After Stem =  melucci , massimo ; toni , bourama ( 2019 ) . quantum-lik model inform retriev decision-mak . cham , switzerland : springer natur . p. 65 . \n",
      "Cleaned Token Before =  chomsky hierarchy (1956). \"three models for the description of language\". information theory, ire transactions on. ieee. 2 (3): 113–124. doi:10.1109/tit.1956\n",
      "Cleaned Token After =  chomsky hierarchy ( 1956 ) . `` three models description language '' . information theory , ire transactions . ieee . 2 ( 3 ) : 113–124 . doi:10.1109/tit.1956 \n",
      "Cleaned Token After Stem =  chomski hierarchi ( 1956 ) . `` three model descript languag `` . inform theori , ire transact . ieee . 2 ( 3 ) : 113–124 . doi:10.1109/tit.1956 \n",
      "Cleaned Token Before =  \"banque\"—that is, 'financial bank' or \"rive\"—that is, 'edge of river'). in information retrieval, a sense inventory is not necessarily required, because it is enough\n",
      "Cleaned Token After =  `` banque '' —that , 'financial bank ' `` rive '' —that , 'edge river ' ) . information retrieval , sense inventory necessarily required , enough \n",
      "Cleaned Token After Stem =  `` banqu `` —that , 'financi bank ' `` rive `` —that , 'edg river ' ) . inform retriev , sens inventori necessarili requir , enough \n",
      "Cleaned Token Before =  port, an ipv6 transition technology mean average precision, in information retrieval message access profile, a bluetooth profile for exchange of messages\n",
      "Cleaned Token After =  port , ipv6 transition technology mean average precision , information retrieval message access profile , bluetooth profile exchange messages \n",
      "Cleaned Token After Stem =  port , ipv6 transit technolog mean averag precis , inform retriev messag access profil , bluetooth profil exchang messag \n",
      "Cleaned Token Before =  that allows two or more entities of a communications system to transmit information via any kind of variation of a physical quantity. the protocol defines\n",
      "Cleaned Token After =  allows two entities communications system transmit information via kind variation physical quantity . protocol defines \n",
      "Cleaned Token After Stem =  allow two entiti commun system transmit inform via kind variat physic quantiti . protocol defin \n",
      "Cleaned Token Before =  information retrieval by metabrowsing. journal of the american society for information science and technology . retrieved on 2007-01-24. information retrieval\n",
      "Cleaned Token After =  information retrieval metabrowsing . journal american society information science technology . retrieved 2007-01-24. information retrieval \n",
      "Cleaned Token After Stem =  inform retriev metabrows . journal american societi inform scienc technolog . retriev 2007-01-24. inform retriev \n",
      "Cleaned Token Before =  arctic archipelago: descriptions, illustrations, identification, and information retrieval. version: 29 april 2003. retrieved 11-22-2011. hedysarum alpinum\n",
      "Cleaned Token After =  arctic archipelago : descriptions , illustrations , identification , information retrieval . version : 29 april 2003. retrieved 11-22-2011. hedysarum alpinum \n",
      "Cleaned Token After Stem =  arctic archipelago : descript , illustr , identif , inform retriev . version : 29 april 2003. retriev 11-22-2011. hedysarum alpinum \n",
      "Cleaned Token Before =  retrieved 21 november 2010. kobayashi, m. & takeda, k. (2000). \"information retrieval on the web\". acm computing surveys. 32 (2): 144–173. citeseerx 10\n",
      "Cleaned Token After =  retrieved 21 november 2010. kobayashi , m. & takeda , k. ( 2000 ) . `` information retrieval web '' . acm computing surveys . 32 ( 2 ) : 144–173 . citeseerx 10 \n",
      "Cleaned Token After Stem =  retriev 21 novemb 2010. kobayashi , m. & takeda , k. ( 2000 ) . `` inform retriev web `` . acm comput survey . 32 ( 2 ) : 144–173 . citeseerx 10 \n",
      "Cleaned Token Before =  of the system early on in the life-cycle. this can provide valuable information as to the feasibility of a design and can prevent the team from pursuing\n",
      "Cleaned Token After =  system early life-cycle . provide valuable information feasibility design prevent team pursuing \n",
      "Cleaned Token After Stem =  system earli life-cycl . provid valuabl inform feasibl design prevent team pursu \n",
      "Cleaned Token Before =  training students, nifft also provides consultancy, documentation and information retrieval services in manufacturing engineering, industrial metallurgy and\n",
      "Cleaned Token After =  training students , nifft also provides consultancy , documentation information retrieval services manufacturing engineering , industrial metallurgy \n",
      "Cleaned Token After Stem =  train student , nifft also provid consult , document inform retriev servic manufactur engin , industri metallurgi \n",
      "Cleaned Token Before =  language as part of document retrieval. smeaton, alan f; dublin, national institute for higher education (1989). information retrieval and natural language processing\n",
      "Cleaned Token After =  language part document retrieval . smeaton , alan f ; dublin , national institute higher education ( 1989 ) . information retrieval natural language processing \n",
      "Cleaned Token After Stem =  languag part document retriev . smeaton , alan f ; dublin , nation institut higher educ ( 1989 ) . inform retriev natur languag process \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, information retrieval. http://delta-intkey.com https://web.archive.org/web/20070609093942/http://www\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval . http : //delta-intkey.com https : //web.archive.org/web/20070609093942/http : //www \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev . http : //delta-intkey.com http : //web.archive.org/web/20070609093942/http : //www \n",
      "Cleaned Token Before =  per minute. http://midi.teragonaudio.com/tech/midifile/ppqn.htm information retrieval for music and motion, meinard müller, springer science & business\n",
      "Cleaned Token After =  per minute . http : //midi.teragonaudio.com/tech/midifile/ppqn.htm information retrieval music motion , meinard müller , springer science & business \n",
      "Cleaned Token After Stem =  per minut . http : //midi.teragonaudio.com/tech/midifile/ppqn.htm inform retriev music motion , meinard müller , springer scienc & busi \n",
      "Cleaned Token Before =  line tool (wmic): wmic is a command-line tool designed to ease wmi information retrieval about a system by using some simple keywords (aliases). wmic.exe\n",
      "Cleaned Token After =  line tool ( wmic ) : wmic command-line tool designed ease wmi information retrieval system using simple keywords ( aliases ) . wmic.exe \n",
      "Cleaned Token After Stem =  line tool ( wmic ) : wmic command-lin tool design eas wmi inform retriev system use simpl keyword ( alias ) . wmic.ex \n",
      "Cleaned Token Before =  filing information makes its retrieval and use nearly impossible. transferring information refers to the process of responding to requests, retrieval from\n",
      "Cleaned Token After =  filing information makes retrieval use nearly impossible . transferring information refers process responding requests , retrieval \n",
      "Cleaned Token After Stem =  file inform make retriev use nearli imposs . transfer inform refer process respond request , retriev \n",
      "Cleaned Token Before =  compound term processing data mining data warehouse fuzzy logic information retrieval list of datasets for machine learning research machine learning\n",
      "Cleaned Token After =  compound term processing data mining data warehouse fuzzy logic information retrieval list datasets machine learning research machine learning \n",
      "Cleaned Token After Stem =  compound term process data mine data warehous fuzzi logic inform retriev list dataset machin learn research machin learn \n",
      "Cleaned Token Before =  field of science, bioinformatics combines biology, computer science, information engineering, mathematics and statistics to analyze and interpret the\n",
      "Cleaned Token After =  field science , bioinformatics combines biology , computer science , information engineering , mathematics statistics analyze interpret \n",
      "Cleaned Token After Stem =  field scienc , bioinformat combin biolog , comput scienc , inform engin , mathemat statist analyz interpret \n",
      "Cleaned Token Before =  associations; defining the topic of a document; document clustering for information retrieval; data mining and named entities recognition; creating semantic maps\n",
      "Cleaned Token After =  associations ; defining topic document ; document clustering information retrieval ; data mining named entities recognition ; creating semantic maps \n",
      "Cleaned Token After Stem =  associ ; defin topic document ; document cluster inform retriev ; data mine name entiti recognit ; creat semant map \n",
      "Cleaned Token Before =  an example of a general procedure in analytic number theory: deriving information about the distribution of a sequence (here, prime ideals or prime numbers)\n",
      "Cleaned Token After =  example general procedure analytic number theory : deriving information distribution sequence ( , prime ideals prime numbers ) \n",
      "Cleaned Token After Stem =  exampl gener procedur analyt number theori : deriv inform distribut sequenc ( , prime ideal prime number ) \n",
      "Cleaned Token Before =  and information systems. broadly, query languages can be classified according to whether they are database query languages or information retrieval query\n",
      "Cleaned Token After =  information systems . broadly , query languages classified according whether database query languages information retrieval query \n",
      "Cleaned Token After Stem =  inform system . broadli , queri languag classifi accord whether databas queri languag inform retriev queri \n",
      "Cleaned Token Before =  of unrelated information, this constraint must be overcome. skilled memory theory involves three steps: meaningful encoding, retrieval structure, and\n",
      "Cleaned Token After =  unrelated information , constraint must overcome . skilled memory theory involves three steps : meaningful encoding , retrieval structure , \n",
      "Cleaned Token After Stem =  unrel inform , constraint must overcom . skill memori theori involv three step : meaning encod , retriev structur , \n",
      "Cleaned Token Before =  surgical sperm retrieval is an alternative means of semen collection, where other means are not possible, e.g. in posthumous sperm retrieval. albeit an increase\n",
      "Cleaned Token After =  surgical sperm retrieval alternative means semen collection , means possible , e.g . posthumous sperm retrieval . albeit increase \n",
      "Cleaned Token After Stem =  surgic sperm retriev altern mean semen collect , mean possibl , e.g . posthum sperm retriev . albeit increas \n",
      "Cleaned Token Before =  inequality, while many advanced dissimilarity functions used in information retrieval do not satisfy this. as in any tree-based data structure, the m-tree\n",
      "Cleaned Token After =  inequality , many advanced dissimilarity functions used information retrieval satisfy . tree-based data structure , m-tree \n",
      "Cleaned Token After Stem =  inequ , mani advanc dissimilar function use inform retriev satisfi . tree-bas data structur , m-tree \n",
      "Cleaned Token Before =  available to the public on the uspto's public pair (patent application information retrieval) web site. reexaminations are assigned serial numbers and cross\n",
      "Cleaned Token After =  available public uspto 's public pair ( patent application information retrieval ) web site . reexaminations assigned serial numbers cross \n",
      "Cleaned Token After Stem =  avail public uspto 's public pair ( patent applic inform retriev ) web site . reexamin assign serial number cross \n",
      "Cleaned Token Before =  of stock market activity, sports results, and the like. work on information retrieval has been influential in development of the lexis-nexis systems and\n",
      "Cleaned Token After =  stock market activity , sports results , like . work information retrieval influential development lexis-nexis systems \n",
      "Cleaned Token After Stem =  stock market activ , sport result , like . work inform retriev influenti develop lexis-nexi system \n",
      "Cleaned Token Before =  number crunching and for it to become a tool for communications and information-retrieval. he wanted to turn vannevar bush's idea for a memex machine into\n",
      "Cleaned Token After =  number crunching become tool communications information-retrieval . wanted turn vannevar bush 's idea memex machine \n",
      "Cleaned Token After Stem =  number crunch becom tool commun information-retriev . want turn vannevar bush 's idea memex machin \n",
      "Cleaned Token Before =  the library catalogues are being stored in the computer for easy information retrieval. it is also proposed to digitalise the manuscripts of this library\n",
      "Cleaned Token After =  library catalogues stored computer easy information retrieval . also proposed digitalise manuscripts library \n",
      "Cleaned Token After Stem =  librari catalogu store comput easi inform retriev . also propos digitalis manuscript librari \n",
      "Cleaned Token Before =  the context of the educational relevance of microcomputers and of information retrieval software operating on repositories of data that might potentially\n",
      "Cleaned Token After =  context educational relevance microcomputers information retrieval software operating repositories data might potentially \n",
      "Cleaned Token After Stem =  context educ relev microcomput inform retriev softwar oper repositori data might potenti \n",
      "Cleaned Token Before =  was originally \"the result of personal free tagging of information [...] for one's own retrieval\", but online sharing and interaction expanded it into\n",
      "Cleaned Token After =  originally `` result personal free tagging information [ ... ] one 's retrieval '' , online sharing interaction expanded \n",
      "Cleaned Token After Stem =  origin `` result person free tag inform [ ... ] one 's retriev `` , onlin share interact expand \n",
      "Cleaned Token Before =  intelligence, machine learning, psycholinguistics, eye tracking, information retrieval, and indian language wordnets - indowordnet. a significant contribution\n",
      "Cleaned Token After =  intelligence , machine learning , psycholinguistics , eye tracking , information retrieval , indian language wordnets - indowordnet . significant contribution \n",
      "Cleaned Token After Stem =  intellig , machin learn , psycholinguist , eye track , inform retriev , indian languag wordnet - indowordnet . signific contribut \n",
      "Cleaned Token Before =  annual international sigir conference on research and development in information retrieval. archived from the original (pdf) on 2010-12-14. blei, david m.;\n",
      "Cleaned Token After =  annual international sigir conference research development information retrieval . archived original ( pdf ) 2010-12-14. blei , david m. ; \n",
      "Cleaned Token After Stem =  annual intern sigir confer research develop inform retriev . archiv origin ( pdf ) 2010-12-14. blei , david m. ; \n",
      "Cleaned Token Before =  book chapter: naive bayes text classification, introduction to information retrieval naive bayes for text classification with unbalanced classes benchmark\n",
      "Cleaned Token After =  book chapter : naive bayes text classification , introduction information retrieval naive bayes text classification unbalanced classes benchmark \n",
      "Cleaned Token After Stem =  book chapter : naiv bay text classif , introduct inform retriev naiv bay text classif unbalanc class benchmark \n",
      "Cleaned Token Before =  quantification: investigating political bias in social media and web search\". information retrieval journal. 22 (1–2): 188–227. doi:10.1007/s10791-018-9341-2. stromberg\n",
      "Cleaned Token After =  quantification : investigating political bias social media web search '' . information retrieval journal . 22 ( 1–2 ) : 188–227 . doi:10.1007/s10791-018-9341-2 . stromberg \n",
      "Cleaned Token After Stem =  quantif : investig polit bia social media web search `` . inform retriev journal . 22 ( 1–2 ) : 188–227 . doi:10.1007/s10791-018-9341-2 . stromberg \n",
      "Cleaned Token Before =  model of information seeking behaviour was born out of a need to focus the field of information and library science on human use of information, rather\n",
      "Cleaned Token After =  model information seeking behaviour born need focus field information library science human use information , rather \n",
      "Cleaned Token After Stem =  model inform seek behaviour born need focu field inform librari scienc human use inform , rather \n",
      "Cleaned Token Before =  laboratory information management systems (lims) - software used to manage the collection, processing, storage, retrieval and analysis of information generated\n",
      "Cleaned Token After =  laboratory information management systems ( lims ) - software used manage collection , processing , storage , retrieval analysis information generated \n",
      "Cleaned Token After Stem =  laboratori inform manag system ( lim ) - softwar use manag collect , process , storag , retriev analysi inform gener \n",
      "Cleaned Token Before =  american scientist and business executive, and holds 10 patents in information retrieval. he has an interdisciplinary educational background: masters in\n",
      "Cleaned Token After =  american scientist business executive , holds 10 patents information retrieval . interdisciplinary educational background : masters \n",
      "Cleaned Token After Stem =  american scientist busi execut , hold 10 patent inform retriev . interdisciplinari educ background : master \n",
      "Cleaned Token Before =  information economics for management (iem) library and information science (lis) information analysis and retrieval (iar) preservation of information\n",
      "Cleaned Token After =  information economics management ( iem ) library information science ( lis ) information analysis retrieval ( iar ) preservation information \n",
      "Cleaned Token After Stem =  inform econom manag ( iem ) librari inform scienc ( li ) inform analysi retriev ( iar ) preserv inform \n",
      "Cleaned Token Before =  designed to provide teletext services in tvs. prestel was a british information-retrieval system based on teletext protocols. however, it was essentially\n",
      "Cleaned Token After =  designed provide teletext services tvs . prestel british information-retrieval system based teletext protocols . however , essentially \n",
      "Cleaned Token After Stem =  design provid teletext servic tv . prestel british information-retriev system base teletext protocol . howev , essenti \n",
      "Cleaned Token Before =  content extraction (ace) is a research program for developing advanced information extraction technologies convened by the nist from 1999 to 2008, succeeding\n",
      "Cleaned Token After =  content extraction ( ace ) research program developing advanced information extraction technologies convened nist 1999 2008 , succeeding \n",
      "Cleaned Token After Stem =  content extract ( ace ) research program develop advanc inform extract technolog conven nist 1999 2008 , succeed \n",
      "Cleaned Token Before =  translation, and other information retrieval services as a way of ensuring a constant flow of consistently high-quality information to those working in scientific\n",
      "Cleaned Token After =  translation , information retrieval services way ensuring constant flow consistently high-quality information working scientific \n",
      "Cleaned Token After Stem =  translat , inform retriev servic way ensur constant flow consist high-qual inform work scientif \n",
      "Cleaned Token Before =  bibliometric methods are frequently used in the field of library and information science. the sub-field of bibliometrics which concerns itself with the\n",
      "Cleaned Token After =  bibliometric methods frequently used field library information science . sub-field bibliometrics concerns \n",
      "Cleaned Token After Stem =  bibliometr method frequent use field librari inform scienc . sub-field bibliometr concern \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Token Before =  what would become westlaw. west's chief competitor in the legal information retrieval market is lexisnexis. (ironically, lawford and von briesen sold\n",
      "Cleaned Token After =  would become westlaw . west 's chief competitor legal information retrieval market lexisnexis . ( ironically , lawford von briesen sold \n",
      "Cleaned Token After Stem =  would becom westlaw . west 's chief competitor legal inform retriev market lexisnexi . ( iron , lawford von briesen sold \n",
      "Cleaned Token Before =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion\n",
      "Cleaned Token After =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion \n",
      "Cleaned Token After Stem =  digit librari comput platform digit market world wide web inform retriev secur cryptographi formal method secur servic intrus \n",
      "Cleaned Token Before =  (razmerita, kirchner & sudzina 2009). dorsey (2001) identified information retrieval, assessment and evaluation, organization, analysis, presentation\n",
      "Cleaned Token After =  ( razmerita , kirchner & sudzina 2009 ) . dorsey ( 2001 ) identified information retrieval , assessment evaluation , organization , analysis , presentation \n",
      "Cleaned Token After Stem =  ( razmerita , kirchner & sudzina 2009 ) . dorsey ( 2001 ) identifi inform retriev , assess evalu , organ , analysi , present \n",
      "Cleaned Token Before =  engineers don nelson and dick pick at trw developed the generalized information retrieval language and system, for use by the u.s. army to control the inventory\n",
      "Cleaned Token After =  engineers nelson dick pick trw developed generalized information retrieval language system , use u.s. army control inventory \n",
      "Cleaned Token After Stem =  engin nelson dick pick trw develop gener inform retriev languag system , use u.s. armi control inventori \n",
      "Cleaned Token Before =  cia who now works freelance and who specializes in computers and information retrieval sharon leal as jasmine gooden, an nypd lieutenant who leads the\n",
      "Cleaned Token After =  cia works freelance specializes computers information retrieval sharon leal jasmine gooden , nypd lieutenant leads \n",
      "Cleaned Token After Stem =  cia work freelanc special comput inform retriev sharon leal jasmin gooden , nypd lieuten lead \n",
      "Cleaned Token Before =  learned as a result of experience. memory allows us to store information for later retrieval. memory is often thought of as consisting of both a long-term\n",
      "Cleaned Token After =  learned result experience . memory allows us store information later retrieval . memory often thought consisting long-term \n",
      "Cleaned Token After Stem =  learn result experi . memori allow us store inform later retriev . memori often thought consist long-term \n",
      "Cleaned Token Before =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion\n",
      "Cleaned Token After =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion \n",
      "Cleaned Token After Stem =  digit librari comput platform digit market world wide web inform retriev secur cryptographi formal method secur servic intrus \n",
      "Cleaned Token Before =  single 8-bit character can be anywhere from 1 to 255 bits long. in information retrieval, bit arrays are a good representation for the posting lists of very\n",
      "Cleaned Token After =  single 8-bit character anywhere 1 255 bits long . information retrieval , bit arrays good representation posting lists \n",
      "Cleaned Token After Stem =  singl 8-bit charact anywher 1 255 bit long . inform retriev , bit array good represent post list \n",
      "Cleaned Token Before =  electronics engineers (ieee) in 2016 for his contributions to multimedia information retrieval. \"ko je ko u bh dijaspori: doktori nauka i naučno-istraživački radnici\"\n",
      "Cleaned Token After =  electronics engineers ( ieee ) 2016 contributions multimedia information retrieval . `` ko je ko u bh dijaspori : doktori nauka naučno-istraživački radnici '' \n",
      "Cleaned Token After Stem =  electron engin ( ieee ) 2016 contribut multimedia inform retriev . `` ko je ko u bh dijaspori : doktori nauka naučno-istraživački radnici `` \n",
      "Cleaned Token Before =  accessed 2019-10-01. jeff dean. \"challenges in building large-scale information retrieval systems\" (pdf). p. 58. retrieved 2020-05-30. olesen, jakob stoklund\n",
      "Cleaned Token After =  accessed 2019-10-01. jeff dean . `` challenges building large-scale information retrieval systems '' ( pdf ) . p. 58. retrieved 2020-05-30. olesen , jakob stoklund \n",
      "Cleaned Token After Stem =  access 2019-10-01. jeff dean . `` challeng build large-scal inform retriev system `` ( pdf ) . p. 58. retriev 2020-05-30. olesen , jakob stoklund \n",
      "Cleaned Token Before =  activities involving the life cycle of information, including creation, maintenance (use, storage, retrieval), and disposal, regardless of media\". the\n",
      "Cleaned Token After =  activities involving life cycle information , including creation , maintenance ( use , storage , retrieval ) , disposal , regardless media '' . \n",
      "Cleaned Token After Stem =  activ involv life cycl inform , includ creation , mainten ( use , storag , retriev ) , dispos , regardless media `` . \n",
      "Cleaned Token Before =  information retrieval systems. universiteit utrecht, dspace.library.uu.nl/bitstream/handle/1874/10643/typke_05_survey_of_music_information_retrieval_systems\n",
      "Cleaned Token After =  information retrieval systems . universiteit utrecht , dspace.library.uu.nl/bitstream/handle/1874/10643/typke_05_survey_of_music_information_retrieval_systems \n",
      "Cleaned Token After Stem =  inform retriev system . universiteit utrecht , dspace.library.uu.nl/bitstream/handle/1874/10643/typke_05_survey_of_music_information_retrieval_system \n",
      "Cleaned Token Before =  for information retrieval available at that time, the implementation of this concept was a tremendous step forwards for the science of information retrieval\n",
      "Cleaned Token After =  information retrieval available time , implementation concept tremendous step forwards science information retrieval \n",
      "Cleaned Token After Stem =  inform retriev avail time , implement concept tremend step forward scienc inform retriev \n",
      "Cleaned Token Before =  which pursues research in cloud robotics and automation, social information retrieval using geometric algorithms, and algorithmic automation for feeding\n",
      "Cleaned Token After =  pursues research cloud robotics automation , social information retrieval using geometric algorithms , algorithmic automation feeding \n",
      "Cleaned Token After Stem =  pursu research cloud robot autom , social inform retriev use geometr algorithm , algorithm autom feed \n",
      "Cleaned Token Before =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion\n",
      "Cleaned Token After =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion \n",
      "Cleaned Token After Stem =  digit librari comput platform digit market world wide web inform retriev secur cryptographi formal method secur servic intrus \n",
      "Cleaned Token Before =  international acm sigir conference on research and development in information retrieval (pp. 363-372). acm. \"garmin poi loader\". garmin. retrieved 2008-01-17\n",
      "Cleaned Token After =  international acm sigir conference research development information retrieval ( pp . 363-372 ) . acm . `` garmin poi loader '' . garmin . retrieved 2008-01-17 \n",
      "Cleaned Token After Stem =  intern acm sigir confer research develop inform retriev ( pp . 363-372 ) . acm . `` garmin poi loader `` . garmin . retriev 2008-01-17 \n",
      "Cleaned Token Before =  xerox parc map viewer was an experiment in providing interactive information retrieval, rather than access to just static files, on the world wide web\n",
      "Cleaned Token After =  xerox parc map viewer experiment providing interactive information retrieval , rather access static files , world wide web \n",
      "Cleaned Token After Stem =  xerox parc map viewer experi provid interact inform retriev , rather access static file , world wide web \n",
      "Cleaned Token Before =  might be useful in some natural processing tasks: it can improve information retrieval or speech recognition significantly (by indexing/recognizing documents\n",
      "Cleaned Token After =  might useful natural processing tasks : improve information retrieval speech recognition significantly ( indexing/recognizing documents \n",
      "Cleaned Token After Stem =  might use natur process task : improv inform retriev speech recognit significantli ( indexing/recogn document \n",
      "Cleaned Token Before =  multiple isomorphous replacement, a crystallographic technique music information retrieval mir, an independent media center content management system mir (software)\n",
      "Cleaned Token After =  multiple isomorphous replacement , crystallographic technique music information retrieval mir , independent media center content management system mir ( software ) \n",
      "Cleaned Token After Stem =  multipl isomorph replac , crystallograph techniqu music inform retriev mir , independ media center content manag system mir ( softwar ) \n",
      "Cleaned Token Before =  theoretical frameworks such as a unified utility-based theory bridging information retrieval, summarization, free-text question-answering and related tasks.\n",
      "Cleaned Token After =  theoretical frameworks unified utility-based theory bridging information retrieval , summarization , free-text question-answering related tasks . \n",
      "Cleaned Token After Stem =  theoret framework unifi utility-bas theori bridg inform retriev , summar , free-text question-answ relat task . \n",
      "Cleaned Token Before =  dynamic-sys ergodic theory and dynamical systems comp.theory.info-retrieval information retrieval comp.windows.x x window system comp.windows.x.kde kde desktop\n",
      "Cleaned Token After =  dynamic-sys ergodic theory dynamical systems comp.theory.info-retrieval information retrieval comp.windows.x x window system comp.windows.x.kde kde desktop \n",
      "Cleaned Token After Stem =  dynamic-si ergod theori dynam system comp.theory.info-retriev inform retriev comp.windows.x x window system comp.windows.x.kd kde desktop \n",
      "Cleaned Token Before =  diego. his research interests are in statistical machine learning, information retrieval, and natural language processing; focus on computational and statistical\n",
      "Cleaned Token After =  diego . research interests statistical machine learning , information retrieval , natural language processing ; focus computational statistical \n",
      "Cleaned Token After Stem =  diego . research interest statist machin learn , inform retriev , natur languag process ; focu comput statist \n",
      "Cleaned Token Before =  professional body and a learned society that represents those working in information technology (it) and computer science, both in the united kingdom and\n",
      "Cleaned Token After =  professional body learned society represents working information technology ( ) computer science , united kingdom \n",
      "Cleaned Token After Stem =  profession bodi learn societi repres work inform technolog ( ) comput scienc , unit kingdom \n",
      "Cleaned Token Before =  text and applies them to information management like information retrieval, question answering, and structuring information in wikis. the ubiquitous knowledge\n",
      "Cleaned Token After =  text applies information management like information retrieval , question answering , structuring information wikis . ubiquitous knowledge \n",
      "Cleaned Token After Stem =  text appli inform manag like inform retriev , question answer , structur inform wiki . ubiquit knowledg \n",
      "Cleaned Token Before =  bitonic tour) recursive least squares method beat tracking in music information retrieval adaptive-critic training strategy for artificial neural networks\n",
      "Cleaned Token After =  bitonic tour ) recursive least squares method beat tracking music information retrieval adaptive-critic training strategy artificial neural networks \n",
      "Cleaned Token After Stem =  biton tour ) recurs least squar method beat track music inform retriev adaptive-crit train strategi artifici neural network \n",
      "Cleaned Token Before =  2008. venna, j., peltonen, j., nybo, k., aidos, h., & kaski, s.: information retrieval perspective to nonlinear dimensionality reduction for data visualization\n",
      "Cleaned Token After =  2008. venna , j. , peltonen , j. , nybo , k. , aidos , h. , & kaski , s. : information retrieval perspective nonlinear dimensionality reduction data visualization \n",
      "Cleaned Token After Stem =  2008. venna , j. , peltonen , j. , nybo , k. , aido , h. , & kaski , s. : inform retriev perspect nonlinear dimension reduct data visual \n",
      "Cleaned Token Before =  studies in music theory. isbn 9780199714353. müller, meinard (2007). information retrieval for music and motion, p.60. isbn 9783540740483. \"a pitch class is\n",
      "Cleaned Token After =  studies music theory . isbn 9780199714353. müller , meinard ( 2007 ) . information retrieval music motion , p.60 . isbn 9783540740483 . `` pitch class \n",
      "Cleaned Token After Stem =  studi music theori . isbn 9780199714353. müller , meinard ( 2007 ) . inform retriev music motion , p.60 . isbn 9783540740483 . `` pitch class \n",
      "Cleaned Token Before =  1991). \"review: fractint brought to book\". newscientist. reed business information. retrieved 25 march 2013. tyler, bert and wegner, timothy, fractal creations\n",
      "Cleaned Token After =  1991 ) . `` review : fractint brought book '' . newscientist . reed business information . retrieved 25 march 2013. tyler , bert wegner , timothy , fractal creations \n",
      "Cleaned Token After Stem =  1991 ) . `` review : fractint brought book `` . newscientist . reed busi inform . retriev 25 march 2013. tyler , bert wegner , timothi , fractal creation \n",
      "Cleaned Token Before =  reengineering creative brief data modeling design brief functional requirements information technology model-driven engineering model transformation language non-functional\n",
      "Cleaned Token After =  reengineering creative brief data modeling design brief functional requirements information technology model-driven engineering model transformation language non-functional \n",
      "Cleaned Token After Stem =  reengin creativ brief data model design brief function requir inform technolog model-driven engin model transform languag non-funct \n",
      "Cleaned Token Before =  provide mechanisms for improved content discovery, information extraction, information retrieval, user collaboration, and extension of current search\n",
      "Cleaned Token After =  provide mechanisms improved content discovery , information extraction , information retrieval , user collaboration , extension current search \n",
      "Cleaned Token After Stem =  provid mechan improv content discoveri , inform extract , inform retriev , user collabor , extens current search \n",
      "Cleaned Token Before =  trying to google bomb every word in the dictionary. adversarial information retrieval captcha blog scraping link farm spam in blogs spamdexing \"wired\n",
      "Cleaned Token After =  trying google bomb every word dictionary . adversarial information retrieval captcha blog scraping link farm spam blogs spamdexing `` wired \n",
      "Cleaned Token After Stem =  tri googl bomb everi word dictionari . adversari inform retriev captcha blog scrape link farm spam blog spamdex `` wire \n",
      "Cleaned Token Before =  (potentially) by specialized information retrieval algorithms to extract the relevant primary biodiversity information that is reported therein, sometimes\n",
      "Cleaned Token After =  ( potentially ) specialized information retrieval algorithms extract relevant primary biodiversity information reported therein , sometimes \n",
      "Cleaned Token After Stem =  ( potenti ) special inform retriev algorithm extract relev primari biodivers inform report therein , sometim \n",
      "Cleaned Token Before =   prabhakar raghavan & hinrich schütze (2008). \"introduction to information retrieval\". cambridge university press. retrieved 2008-11-09.cs1 maint: uses\n",
      "Cleaned Token After =  prabhakar raghavan & hinrich schütze ( 2008 ) . `` introduction information retrieval '' . cambridge university press . retrieved 2008-11-09.cs1 maint : uses \n",
      "Cleaned Token After Stem =  prabhakar raghavan & hinrich schütze ( 2008 ) . `` introduct inform retriev `` . cambridg univers press . retriev 2008-11-09.cs1 maint : use \n",
      "Cleaned Token Before =  free documentation license: think data structures: algorithms and information retrieval in java , green tea press, july 7, 2017. think bayes: bayesian statistics\n",
      "Cleaned Token After =  free documentation license : think data structures : algorithms information retrieval java , green tea press , july 7 , 2017. think bayes : bayesian statistics \n",
      "Cleaned Token After Stem =  free document licens : think data structur : algorithm inform retriev java , green tea press , juli 7 , 2017. think bay : bayesian statist \n",
      "Cleaned Token Before =  environmental changes. as the retention interval between encoding and retrieval of the memory lengthens, there is an increase in both the amount that\n",
      "Cleaned Token After =  environmental changes . retention interval encoding retrieval memory lengthens , increase amount \n",
      "Cleaned Token After Stem =  environment chang . retent interv encod retriev memori lengthen , increas amount \n",
      "Cleaned Token Before =  (garbage-issue information retrieval unit) (voiced by rosearik \"rikki\" simons) is a malfunctioning and dimwitted robot sir (standard-issue information retrieval) unit\n",
      "Cleaned Token After =  ( garbage-issue information retrieval unit ) ( voiced rosearik `` rikki '' simons ) malfunctioning dimwitted robot sir ( standard-issue information retrieval ) unit \n",
      "Cleaned Token After Stem =  ( garbage-issu inform retriev unit ) ( voic rosearik `` rikki `` simon ) malfunct dimwit robot sir ( standard-issu inform retriev ) unit \n",
      "Cleaned Token Before =  human-computer interaction, user interface, information engineering, information indexing and retrieval, testing, modelling and simulation, project management\n",
      "Cleaned Token After =  human-computer interaction , user interface , information engineering , information indexing retrieval , testing , modelling simulation , project management \n",
      "Cleaned Token After Stem =  human-comput interact , user interfac , inform engin , inform index retriev , test , model simul , project manag \n",
      "Cleaned Token Before =  the advancement of indexing, abstracting and related methods of information retrieval. other similar societies include: association of southern african\n",
      "Cleaned Token After =  advancement indexing , abstracting related methods information retrieval . similar societies include : association southern african \n",
      "Cleaned Token After Stem =  advanc index , abstract relat method inform retriev . similar societi includ : associ southern african \n",
      "Cleaned Token Before =  metabolic pathway divergence-from-randomness model, a probabilistic information retrieval model. dounreay fast reactor, the second reactor to achieve criticality\n",
      "Cleaned Token After =  metabolic pathway divergence-from-randomness model , probabilistic information retrieval model . dounreay fast reactor , second reactor achieve criticality \n",
      "Cleaned Token After Stem =  metabol pathway divergence-from-random model , probabilist inform retriev model . dounreay fast reactor , second reactor achiev critic \n",
      "Cleaned Token Before =  techniques sighpc: high performance computing sigir: information retrieval sigite: information technology education sigkdd: knowledge discovery and data\n",
      "Cleaned Token After =  techniques sighpc : high performance computing sigir : information retrieval sigite : information technology education sigkdd : knowledge discovery data \n",
      "Cleaned Token After Stem =  techniqu sighpc : high perform comput sigir : inform retriev sigit : inform technolog educ sigkdd : knowledg discoveri data \n",
      "Cleaned Token Before =  united ireland. information retrieval specialist group, a specialist group of the british computer society promoting information retrieval international\n",
      "Cleaned Token After =  united ireland . information retrieval specialist group , specialist group british computer society promoting information retrieval international \n",
      "Cleaned Token After Stem =  unit ireland . inform retriev specialist group , specialist group british comput societi promot inform retriev intern \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, information retrieval. version: 3 may 2006. duckweed growth inhibition test list of standards\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval . version : 3 may 2006. duckweed growth inhibition test list standards \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev . version : 3 may 2006. duckwe growth inhibit test list standard \n",
      "Cleaned Token Before =  the two basic functions outlined. marcus p. zillman, an internet information retrieval consultant and speaker said \"this website is the start of a new\n",
      "Cleaned Token After =  two basic functions outlined . marcus p. zillman , internet information retrieval consultant speaker said `` website start new \n",
      "Cleaned Token After Stem =  two basic function outlin . marcu p. zillman , internet inform retriev consult speaker said `` websit start new \n",
      "Cleaned Token Before =  theory (simplicity, complexity, unexpectedness, cognition, probability, information) cognitive complexity classification of fcattest items cognitive complexity/depth\n",
      "Cleaned Token After =  theory ( simplicity , complexity , unexpectedness , cognition , probability , information ) cognitive complexity classification fcattest items cognitive complexity/depth \n",
      "Cleaned Token After Stem =  theori ( simplic , complex , unexpected , cognit , probabl , inform ) cognit complex classif fcattest item cognit complexity/depth \n",
      "Cleaned Token Before =  you choose. heck, andré; murtagh, fionn, eds. (1993). intelligent information retrieval: the case of astronomy and related space sciences. astrophysics\n",
      "Cleaned Token After =  choose . heck , andré ; murtagh , fionn , eds . ( 1993 ) . intelligent information retrieval : case astronomy related space sciences . astrophysics \n",
      "Cleaned Token After Stem =  choos . heck , andré ; murtagh , fionn , ed . ( 1993 ) . intellig inform retriev : case astronomi relat space scienc . astrophys \n",
      "Cleaned Token Before =  designed for the scientometric evaluation, but for the purpose of information retrieval\". also, normalizing at a higher aggregation level, rather than at\n",
      "Cleaned Token After =  designed scientometric evaluation , purpose information retrieval '' . also , normalizing higher aggregation level , rather \n",
      "Cleaned Token After Stem =  design scientometr evalu , purpos inform retriev `` . also , normal higher aggreg level , rather \n",
      "Cleaned Token Before =  international acm sigir conference on research and development in information retrieval, pp. 284, doi:10.1145/1148170.1148222, isbn 978-1595933690. charikar\n",
      "Cleaned Token After =  international acm sigir conference research development information retrieval , pp . 284 , doi:10.1145/1148170.1148222 , isbn 978-1595933690. charikar \n",
      "Cleaned Token After Stem =  intern acm sigir confer research develop inform retriev , pp . 284 , doi:10.1145/1148170.1148222 , isbn 978-1595933690. charikar \n",
      "Cleaned Token Before =  (branchiopoda)\". crustacea, the higher taxa: description, identification, and information retrieval. archived from the original on july 23, 2011. retrieved february\n",
      "Cleaned Token After =  ( branchiopoda ) '' . crustacea , higher taxa : description , identification , information retrieval . archived original july 23 , 2011. retrieved february \n",
      "Cleaned Token After Stem =  ( branchiopoda ) `` . crustacea , higher taxa : descript , identif , inform retriev . archiv origin juli 23 , 2011. retriev februari \n",
      "Cleaned Token Before =  a feasibility of doing interlanguage information retrieval by google machine translation system of information transmission from persian journals xml\n",
      "Cleaned Token After =  feasibility interlanguage information retrieval google machine translation system information transmission persian journals xml \n",
      "Cleaned Token After Stem =  feasibl interlanguag inform retriev googl machin translat system inform transmiss persian journal xml \n",
      "Cleaned Token Before =  propulsion information retrieval system, part of the chemical propulsion information analysis center police information retrieval system, an information system\n",
      "Cleaned Token After =  propulsion information retrieval system , part chemical propulsion information analysis center police information retrieval system , information system \n",
      "Cleaned Token After Stem =  propuls inform retriev system , part chemic propuls inform analysi center polic inform retriev system , inform system \n",
      "Cleaned Token Before =  ways to retrieve 3d information. thus, shape matching methods for 3d content retrieval have become popular. shape matching retrieval is based on techniques\n",
      "Cleaned Token After =  ways retrieve 3d information . thus , shape matching methods 3d content retrieval become popular . shape matching retrieval based techniques \n",
      "Cleaned Token After Stem =  way retriev 3d inform . thu , shape match method 3d content retriev becom popular . shape match retriev base techniqu \n",
      "Cleaned Token Before =  dallwitz (1992 onwards). the families of flowering plants: descriptions, illustrations, identification, information retrieval. http://delta-intkey.com\n",
      "Cleaned Token After =  dallwitz ( 1992 onwards ) . families flowering plants : descriptions , illustrations , identification , information retrieval . http : //delta-intkey.com \n",
      "Cleaned Token After Stem =  dallwitz ( 1992 onward ) . famili flower plant : descript , illustr , identif , inform retriev . http : //delta-intkey.com \n",
      "Cleaned Token Before =  over 20 years, and is recognized for her contributions in music information retrieval, including developing the constant-q transform. she is a fellow\n",
      "Cleaned Token After =  20 years , recognized contributions music information retrieval , including developing constant-q transform . fellow \n",
      "Cleaned Token After Stem =  20 year , recogn contribut music inform retriev , includ develop constant-q transform . fellow \n",
      "Cleaned Token Before =  known for his work on error detection and correction, and worked on information retrieval. he has also held exhibitions of his mathematically inspired sculptures\n",
      "Cleaned Token After =  known work error detection correction , worked information retrieval . also held exhibitions mathematically inspired sculptures \n",
      "Cleaned Token After Stem =  known work error detect correct , work inform retriev . also held exhibit mathemat inspir sculptur \n",
      "Cleaned Token Before =  advertising opportunity for brand advertisers, and drive search and information retrieval. although support and development of windows live agents has been\n",
      "Cleaned Token After =  advertising opportunity brand advertisers , drive search information retrieval . although support development windows live agents \n",
      "Cleaned Token After Stem =  advertis opportun brand advertis , drive search inform retriev . although support develop window live agent \n",
      "Cleaned Token Before =  for hearing aids or cochlear implants; echo cancellation; music information retrieval, and perceptual coding (e.g. mp3 or opus). architectural acoustics\n",
      "Cleaned Token After =  hearing aids cochlear implants ; echo cancellation ; music information retrieval , perceptual coding ( e.g . mp3 opus ) . architectural acoustics \n",
      "Cleaned Token After Stem =  hear aid cochlear implant ; echo cancel ; music inform retriev , perceptu code ( e.g . mp3 opu ) . architectur acoust \n",
      "Cleaned Token Before =  augmented reality, a related term, takes place in the physical world, with information or objects added virtually. there are many practical applications of\n",
      "Cleaned Token After =  augmented reality , related term , takes place physical world , information objects added virtually . many practical applications \n",
      "Cleaned Token After Stem =  augment realiti , relat term , take place physic world , inform object ad virtual . mani practic applic \n",
      "Cleaned Token Before =  productivity due to easy retrieval of information increased coordination of construction documents embedding and linking of vital information such as vendors for\n",
      "Cleaned Token After =  productivity due easy retrieval information increased coordination construction documents embedding linking vital information vendors \n",
      "Cleaned Token After Stem =  product due easi retriev inform increas coordin construct document embed link vital inform vendor \n",
      "Cleaned Token Before =  recognition but also image recognition, natural language processing, information retrieval, multimodal processing, and multitask learning. in terms of freely\n",
      "Cleaned Token After =  recognition also image recognition , natural language processing , information retrieval , multimodal processing , multitask learning . terms freely \n",
      "Cleaned Token After Stem =  recognit also imag recognit , natur languag process , inform retriev , multimod process , multitask learn . term freeli \n",
      "Cleaned Token Before =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion\n",
      "Cleaned Token After =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion \n",
      "Cleaned Token After Stem =  digit librari comput platform digit market world wide web inform retriev secur cryptographi formal method secur servic intrus \n",
      "Cleaned Token Before =  a social network by thushar a.k, and p. santhi thilagam traffic information retrieval based on fuzzy ontology and rdf on the semantic web by jun zhai\n",
      "Cleaned Token After =  social network thushar a.k , p. santhi thilagam traffic information retrieval based fuzzy ontology rdf semantic web jun zhai \n",
      "Cleaned Token After Stem =  social network thushar a.k , p. santhi thilagam traffic inform retriev base fuzzi ontolog rdf semant web jun zhai \n",
      "Cleaned Token Before =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion\n",
      "Cleaned Token After =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion \n",
      "Cleaned Token After Stem =  digit librari comput platform digit market world wide web inform retriev secur cryptographi formal method secur servic intrus \n",
      "Cleaned Token Before =  rosenfeld. \"networked information retrieval and organization: issues and questions.\" journal of the american society for information science 47.9 (1996):\n",
      "Cleaned Token After =  rosenfeld . `` networked information retrieval organization : issues questions . '' journal american society information science 47.9 ( 1996 ) : \n",
      "Cleaned Token After Stem =  rosenfeld . `` network inform retriev organ : issu question . `` journal american societi inform scienc 47.9 ( 1996 ) : \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, information retrieval. version: 27 april 2006. http://delta-intkey.com. monocot families\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval . version : 27 april 2006. http : //delta-intkey.com . monocot families \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev . version : 27 april 2006. http : //delta-intkey.com . monocot famili \n",
      "Cleaned Token Before =  natural language processing, argument mining, sentiment analysis, and information retrieval. she is a professor of computer science at ku leuven. moens earned\n",
      "Cleaned Token After =  natural language processing , argument mining , sentiment analysis , information retrieval . professor computer science ku leuven . moens earned \n",
      "Cleaned Token After Stem =  natur languag process , argument mine , sentiment analysi , inform retriev . professor comput scienc ku leuven . moen earn \n",
      "Cleaned Token Before =  (branchiopoda)\". crustacea, the higher taxa: description, identification, and information retrieval. archived from the original on july 23, 2011. retrieved february\n",
      "Cleaned Token After =  ( branchiopoda ) '' . crustacea , higher taxa : description , identification , information retrieval . archived original july 23 , 2011. retrieved february \n",
      "Cleaned Token After Stem =  ( branchiopoda ) `` . crustacea , higher taxa : descript , identif , inform retriev . archiv origin juli 23 , 2011. retriev februari \n",
      "Cleaned Token Before =  how wikipedia can be utilized to provide intelligent, intuitive information retrieval. koru is the māori word for the newborn, unfurling fern frond, symbolizing\n",
      "Cleaned Token After =  wikipedia utilized provide intelligent , intuitive information retrieval . koru māori word newborn , unfurling fern frond , symbolizing \n",
      "Cleaned Token After Stem =  wikipedia util provid intellig , intuit inform retriev . koru māori word newborn , unfurl fern frond , symbol \n",
      "Cleaned Token Before =  extremely high (e.g., in critical parts of microprocessor design). further information on this is expanded below. as with programming language semantics, styles\n",
      "Cleaned Token After =  extremely high ( e.g. , critical parts microprocessor design ) . information expanded . programming language semantics , styles \n",
      "Cleaned Token After Stem =  extrem high ( e.g . , critic part microprocessor design ) . inform expand . program languag semant , style \n",
      "Cleaned Token Before =   and information retrieval. piotr bojanowski, edouard grave, armand joulin, and tomas mikolov. \"enriching word vectors with subword information\" v t e\n",
      "Cleaned Token After =  information retrieval . piotr bojanowski , edouard grave , armand joulin , tomas mikolov . `` enriching word vectors subword information '' v e \n",
      "Cleaned Token After Stem =  inform retriev . piotr bojanowski , edouard grave , armand joulin , toma mikolov . `` enrich word vector subword inform `` v e \n",
      "Cleaned Token Before =  permitted much more consistent and flexible typography, as well as information retrieval. a chinese translation of the lexicon, based on the third english\n",
      "Cleaned Token After =  permitted much consistent flexible typography , well information retrieval . chinese translation lexicon , based third english \n",
      "Cleaned Token After Stem =  permit much consist flexibl typographi , well inform retriev . chines translat lexicon , base third english \n",
      "Cleaned Token Before =  turing award in 2004 allen kent – pioneer of information science, especially mechanized information retrieval gary a. klein 1964 – research psychologist\n",
      "Cleaned Token After =  turing award 2004 allen kent – pioneer information science , especially mechanized information retrieval gary a. klein 1964 – research psychologist \n",
      "Cleaned Token After Stem =  ture award 2004 allen kent – pioneer inform scienc , especi mechan inform retriev gari a. klein 1964 – research psychologist \n",
      "Cleaned Token Before =  infinitary logics, which allow for formulas to provide an infinite amount of information, and higher-order logics, which include a portion of set theory directly\n",
      "Cleaned Token After =  infinitary logics , allow formulas provide infinite amount information , higher-order logics , include portion set theory directly \n",
      "Cleaned Token After Stem =  infinitari logic , allow formula provid infinit amount inform , higher-ord logic , includ portion set theori directli \n",
      "Cleaned Token Before =  (2001). \"pir-tor: scalable anonymous communication using private information retrieval\" (pdf). usenix security symposium. retrieved 10 april 2015. \"security\n",
      "Cleaned Token After =  ( 2001 ) . `` pir-tor : scalable anonymous communication using private information retrieval '' ( pdf ) . usenix security symposium . retrieved 10 april 2015 . `` security \n",
      "Cleaned Token After Stem =  ( 2001 ) . `` pir-tor : scalabl anonym commun use privat inform retriev `` ( pdf ) . usenix secur symposium . retriev 10 april 2015 . `` secur \n",
      "Cleaned Token Before =  where ips could create, modify and delete their pages of information, and information retrieval centre (irc), which mirrored copy of the pages is provided\n",
      "Cleaned Token After =  ips could create , modify delete pages information , information retrieval centre ( irc ) , mirrored copy pages provided \n",
      "Cleaned Token After Stem =  ip could creat , modifi delet page inform , inform retriev centr ( irc ) , mirror copi page provid \n",
      "Cleaned Token Before =  machine. proceedings of the 13th international society for music information retrieval conference (ismir 2012). vijay iyar. microtiming studies archived\n",
      "Cleaned Token After =  machine . proceedings 13th international society music information retrieval conference ( ismir 2012 ) . vijay iyar . microtiming studies archived \n",
      "Cleaned Token After Stem =  machin . proceed 13th intern societi music inform retriev confer ( ismir 2012 ) . vijay iyar . microtim studi archiv \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, information retrieval. version: 3 may 2006. http://delta-intkey.com. links and more links\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval . version : 3 may 2006. http : //delta-intkey.com . links links \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev . version : 3 may 2006. http : //delta-intkey.com . link link \n",
      "Cleaned Token Before =  intelligence to distributed image retrieval\", information sciences, 2010 d. picard, m. cord, a. revel, \"image retrieval over networks : active learning\n",
      "Cleaned Token After =  intelligence distributed image retrieval '' , information sciences , 2010 d. picard , m. cord , a. revel , `` image retrieval networks : active learning \n",
      "Cleaned Token After Stem =  intellig distribut imag retriev `` , inform scienc , 2010 d. picard , m. cord , a. revel , `` imag retriev network : activ learn \n",
      "Cleaned Token Before =  include robotics (motion planning and visibility problems), geographic information systems (gis) (geometrical location and search, route planning), integrated\n",
      "Cleaned Token After =  include robotics ( motion planning visibility problems ) , geographic information systems ( gis ) ( geometrical location search , route planning ) , integrated \n",
      "Cleaned Token After Stem =  includ robot ( motion plan visibl problem ) , geograph inform system ( gi ) ( geometr locat search , rout plan ) , integr \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, information retrieval. https://web.archive.org/web/20070103200438/http://delta-intkey\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval . https : //web.archive.org/web/20070103200438/http : //delta-intkey \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev . http : //web.archive.org/web/20070103200438/http : //delta-intkey \n",
      "Cleaned Token Before =  \"bad writers\" and \"dumb and dumber\". internet portal adversarial information retrieval googlewhack link doping political google bombs in the 2004 u.s.\n",
      "Cleaned Token After =  `` bad writers '' `` dumb dumber '' . internet portal adversarial information retrieval googlewhack link doping political google bombs 2004 u.s . \n",
      "Cleaned Token After Stem =  `` bad writer `` `` dumb dumber `` . internet portal adversari inform retriev googlewhack link dope polit googl bomb 2004 u. . \n",
      "Cleaned Token Before =  transformer model for sequential music recommender system\". forum for information retrieval evaluation: 49–53. retrieved 13 february 2021. porter, alastair\n",
      "Cleaned Token After =  transformer model sequential music recommender system '' . forum information retrieval evaluation : 49–53 . retrieved 13 february 2021. porter , alastair \n",
      "Cleaned Token After Stem =  transform model sequenti music recommend system `` . forum inform retriev evalu : 49–53 . retriev 13 februari 2021. porter , alastair \n",
      "Cleaned Token Before =  interaction, information retrieval and cognitive psychology. jones, william (2008). \"personal information management\". annual review of information science\n",
      "Cleaned Token After =  interaction , information retrieval cognitive psychology . jones , william ( 2008 ) . `` personal information management '' . annual review information science \n",
      "Cleaned Token After Stem =  interact , inform retriev cognit psycholog . jone , william ( 2008 ) . `` person inform manag `` . annual review inform scienc \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, information retrieval. version: 3 may 2006. https://web.archive.org/web/2007010320043\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval . version : 3 may 2006. https : //web.archive.org/web/2007010320043 \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev . version : 3 may 2006. http : //web.archive.org/web/2007010320043 \n",
      "Cleaned Token Before =  environments in order to gain a deeper understanding of the complex information processing that define such systems. these topics are broad, but often\n",
      "Cleaned Token After =  environments order gain deeper understanding complex information processing define systems . topics broad , often \n",
      "Cleaned Token After Stem =  environ order gain deeper understand complex inform process defin system . topic broad , often \n",
      "Cleaned Token Before =  alfred nobel 1994) monika henzinger - algorithmic game theory and information retrieval naira hovakimyan - differential games and adaptive control peter\n",
      "Cleaned Token After =  alfred nobel 1994 ) monika henzinger - algorithmic game theory information retrieval naira hovakimyan - differential games adaptive control peter \n",
      "Cleaned Token After Stem =  alfr nobel 1994 ) monika henzing - algorithm game theori inform retriev naira hovakimyan - differenti game adapt control peter \n",
      "Cleaned Token Before =  software was implemented as an extension of the rogirs keyword information retrieval system written by bart berger and john m. cooney at resource one\n",
      "Cleaned Token After =  software implemented extension rogirs keyword information retrieval system written bart berger john m. cooney resource one \n",
      "Cleaned Token After Stem =  softwar implement extens rogir keyword inform retriev system written bart berger john m. cooney resourc one \n",
      "Cleaned Token Before =  taxonomist adjudges to be a unit taxonomy for search engines thesaurus (information retrieval) typology (disambiguation) https://en.wiktionary.org/wiki/taxonomy\n",
      "Cleaned Token After =  taxonomist adjudges unit taxonomy search engines thesaurus ( information retrieval ) typology ( disambiguation ) https : //en.wiktionary.org/wiki/taxonomy \n",
      "Cleaned Token After Stem =  taxonomist adjudg unit taxonomi search engin thesauru ( inform retriev ) typolog ( disambigu ) http : //en.wiktionary.org/wiki/taxonomi \n",
      "Cleaned Token Before =  hiding technologies. in 1997, he created hz.com, an electronic mail information retrieval system for two-way pagers and early cellular phones. when the hz\n",
      "Cleaned Token After =  hiding technologies . 1997 , created hz.com , electronic mail information retrieval system two-way pagers early cellular phones . hz \n",
      "Cleaned Token After Stem =  hide technolog . 1997 , creat hz.com , electron mail inform retriev system two-way pager earli cellular phone . hz \n",
      "Cleaned Token Before =  filtering bandits\", the 39th international acm sigir conference on information retrieval (sigir 2016), arxiv:1502.03473, bibcode:2015arxiv150203473l gentile\n",
      "Cleaned Token After =  filtering bandits '' , 39th international acm sigir conference information retrieval ( sigir 2016 ) , arxiv:1502.03473 , bibcode:2015arxiv150203473l gentile \n",
      "Cleaned Token After Stem =  filter bandit `` , 39th intern acm sigir confer inform retriev ( sigir 2016 ) , arxiv:1502.03473 , bibcode:2015arxiv150203473l gentil \n",
      "Cleaned Token Before =  information_retrieval_from_black_holes/links/0deec51644192e9586000000/better-late-than-never-information-retrieval-from-black-holes.pdf\n",
      "Cleaned Token After =  information_retrieval_from_black_holes/links/0deec51644192e9586000000/better-late-than-never-information-retrieval-from-black-holes.pdf \n",
      "Cleaned Token After Stem =  information_retrieval_from_black_holes/links/0deec51644192e9586000000/better-late-than-never-information-retrieval-from-black-holes.pdf \n",
      "Cleaned Token Before =  approximation. journal of the acm, pages 653-750. chor b. (1998). \"private information retrieval\". journal of the acm. 45 (6): 965–982. citeseerx 10.1.1.51.3663\n",
      "Cleaned Token After =  approximation . journal acm , pages 653-750. chor b . ( 1998 ) . `` private information retrieval '' . journal acm . 45 ( 6 ) : 965–982 . citeseerx 10.1.1.51.3663 \n",
      "Cleaned Token After Stem =  approxim . journal acm , page 653-750. chor b . ( 1998 ) . `` privat inform retriev `` . journal acm . 45 ( 6 ) : 965–982 . citeseerx 10.1.1.51.3663 \n",
      "Cleaned Token Before =  the remaining suffixes. incremental encoding is widely used in information retrieval to compress the lexicons used in search indexes; these list all\n",
      "Cleaned Token After =  remaining suffixes . incremental encoding widely used information retrieval compress lexicons used search indexes ; list \n",
      "Cleaned Token After Stem =  remain suffix . increment encod wide use inform retriev compress lexicon use search index ; list \n",
      "Cleaned Token Before =  network. topic modeling is a classic solution to the problem of information retrieval using linked data and semantic web technology. related models and\n",
      "Cleaned Token After =  network . topic modeling classic solution problem information retrieval using linked data semantic web technology . related models \n",
      "Cleaned Token After Stem =  network . topic model classic solut problem inform retriev use link data semant web technolog . relat model \n",
      "Cleaned Token Before =  databases and search engines differ substantially in terms of coverage and retrieval qualities. users need to account for qualities and limitations of databases\n",
      "Cleaned Token After =  databases search engines differ substantially terms coverage retrieval qualities . users need account qualities limitations databases \n",
      "Cleaned Token After Stem =  databas search engin differ substanti term coverag retriev qualiti . user need account qualiti limit databas \n",
      "Cleaned Token Before =  registration, texture synthesis, super-resolution, stereo matching and information retrieval. they can be used to solve various computer vision problems which\n",
      "Cleaned Token After =  registration , texture synthesis , super-resolution , stereo matching information retrieval . used solve various computer vision problems \n",
      "Cleaned Token After Stem =  registr , textur synthesi , super-resolut , stereo match inform retriev . use solv variou comput vision problem \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, information retrieval. dressler, s.; schmidt, m. & zizka, g. (2014). \"medusagyne\". african\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval . dressler , s. ; schmidt , m. & zizka , g. ( 2014 ) . `` medusagyne '' . african \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev . dressler , s. ; schmidt , m. & zizka , g. ( 2014 ) . `` medusagyn `` . african \n",
      "Cleaned Token Before =  machine translation, speech recognition, speech synthesis, information retrieval, parsing, information extraction, and multimodal machine learning. until 1996\n",
      "Cleaned Token After =  machine translation , speech recognition , speech synthesis , information retrieval , parsing , information extraction , multimodal machine learning . 1996 \n",
      "Cleaned Token After Stem =  machin translat , speech recognit , speech synthesi , inform retriev , pars , inform extract , multimod machin learn . 1996 \n",
      "Cleaned Token Before =  reference formats. extraction of metadata from pdfs. retrieval of articles and bibliographic information based on isbn, doi, pubmed-id and arxiv-id. support\n",
      "Cleaned Token After =  reference formats . extraction metadata pdfs . retrieval articles bibliographic information based isbn , doi , pubmed-id arxiv-id . support \n",
      "Cleaned Token After Stem =  refer format . extract metadata pdf . retriev articl bibliograph inform base isbn , doi , pubmed-id arxiv-id . support \n",
      "Cleaned Token Before =  darwin core guid applicability statements twdg access protocol for information retrieval (tapir) tdwg standards documentation (sds) natural collection descriptions\n",
      "Cleaned Token After =  darwin core guid applicability statements twdg access protocol information retrieval ( tapir ) tdwg standards documentation ( sds ) natural collection descriptions \n",
      "Cleaned Token After Stem =  darwin core guid applic statement twdg access protocol inform retriev ( tapir ) tdwg standard document ( sd ) natur collect descript \n",
      "Cleaned Token Before =  similarity measure for content-based image and video retrieval (pdf). multimedia information retrieval workshop, 28th annual acm sigir conference. archived\n",
      "Cleaned Token After =  similarity measure content-based image video retrieval ( pdf ) . multimedia information retrieval workshop , 28th annual acm sigir conference . archived \n",
      "Cleaned Token After Stem =  similar measur content-bas imag video retriev ( pdf ) . multimedia inform retriev workshop , 28th annual acm sigir confer . archiv \n",
      "Cleaned Token Before =  watson and m.j. dallwitz (1992 onwards). the families of flowering plants: descriptions, illustrations, identification, information retrieval. v t e\n",
      "Cleaned Token After =  watson m.j. dallwitz ( 1992 onwards ) . families flowering plants : descriptions , illustrations , identification , information retrieval . v e \n",
      "Cleaned Token After Stem =  watson m.j. dallwitz ( 1992 onward ) . famili flower plant : descript , illustr , identif , inform retriev . v e \n",
      "Cleaned Token Before =  the improved recall of specific episodes or information when the context present at encoding and retrieval are the same. in a simpler manner, \"when events\n",
      "Cleaned Token After =  improved recall specific episodes information context present encoding retrieval . simpler manner , `` events \n",
      "Cleaned Token After Stem =  improv recal specif episod inform context present encod retriev . simpler manner , `` event \n",
      "Cleaned Token Before =  also helped advance visualization. the use of visualization to present information is not a new phenomenon. it has been used in maps, scientific drawings\n",
      "Cleaned Token After =  also helped advance visualization . use visualization present information new phenomenon . used maps , scientific drawings \n",
      "Cleaned Token After Stem =  also help advanc visual . use visual present inform new phenomenon . use map , scientif draw \n",
      "Cleaned Token Before =  jpeg image). the scope of a forensic analysis can vary from simple information retrieval to reconstructing a series of events. in a 2002 book, computer forensics\n",
      "Cleaned Token After =  jpeg image ) . scope forensic analysis vary simple information retrieval reconstructing series events . 2002 book , computer forensics \n",
      "Cleaned Token After Stem =  jpeg imag ) . scope forens analysi vari simpl inform retriev reconstruct seri event . 2002 book , comput forens \n",
      "Cleaned Token Before =  processing market analysis market timing mathematical finance multimedia information retrieval multiple comparisons problem overfitting price action trading texas\n",
      "Cleaned Token After =  processing market analysis market timing mathematical finance multimedia information retrieval multiple comparisons problem overfitting price action trading texas \n",
      "Cleaned Token After Stem =  process market analysi market time mathemat financ multimedia inform retriev multipl comparison problem overfit price action trade texa \n",
      "Cleaned Token Before =  vision to include geospatial information at the core of the semantic web to facilitate information retrieval and information integration. this vision requires\n",
      "Cleaned Token After =  vision include geospatial information core semantic web facilitate information retrieval information integration . vision requires \n",
      "Cleaned Token After Stem =  vision includ geospati inform core semant web facilit inform retriev inform integr . vision requir \n",
      "Cleaned Token Before =  kathleen beller in 1988; they have three children. his brother is information retrieval researcher stephen robertson.[citation needed] in july 1998, dolby\n",
      "Cleaned Token After =  kathleen beller 1988 ; three children . brother information retrieval researcher stephen robertson . [ citation needed ] july 1998 , dolby \n",
      "Cleaned Token After Stem =  kathleen beller 1988 ; three children . brother inform retriev research stephen robertson . [ citat need ] juli 1998 , dolbi \n",
      "Cleaned Token Before =  international acm sigir conference on research and development in information retrieval (sigir), pp. 65-74, 2018. modeling co-evolution across multiple\n",
      "Cleaned Token After =  international acm sigir conference research development information retrieval ( sigir ) , pp . 65-74 , 2018. modeling co-evolution across multiple \n",
      "Cleaned Token After Stem =  intern acm sigir confer research develop inform retriev ( sigir ) , pp . 65-74 , 2018. model co-evolut across multipl \n",
      "Cleaned Token Before =  of the world: descriptions, illustrations, identification, and information retrieval; including synonyms, morphology, anatomy, physiology, phytochemistry\n",
      "Cleaned Token After =  world : descriptions , illustrations , identification , information retrieval ; including synonyms , morphology , anatomy , physiology , phytochemistry \n",
      "Cleaned Token After Stem =  world : descript , illustr , identif , inform retriev ; includ synonym , morpholog , anatomi , physiolog , phytochemistri \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, and information retrieval. loranthus balle, simone; dandy, j.e.; gilmour, j.s.l.; holttum\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval . loranthus balle , simone ; dandy , j.e . ; gilmour , j.s.l . ; holttum \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev . loranthu ball , simon ; dandi , j.e . ; gilmour , j.s.l . ; holttum \n",
      "Cleaned Token Before =  retrieved 7 may 2017. \"vol libre: the first fractal cgi movie\". history of information. jeremy norman & co. retrieved 5 march 2017. \"susan stepney professor\n",
      "Cleaned Token After =  retrieved 7 may 2017 . `` vol libre : first fractal cgi movie '' . history information . jeremy norman & co. retrieved 5 march 2017 . `` susan stepney professor \n",
      "Cleaned Token After Stem =  retriev 7 may 2017 . `` vol libr : first fractal cgi movi `` . histori inform . jeremi norman & co. retriev 5 march 2017 . `` susan stepney professor \n",
      "Cleaned Token Before =  bioinformatics, medical informatics, expert systems, databases, multimedia, information retrieval and more. especially significant contributions include co-authoring\n",
      "Cleaned Token After =  bioinformatics , medical informatics , expert systems , databases , multimedia , information retrieval . especially significant contributions include co-authoring \n",
      "Cleaned Token After Stem =  bioinformat , medic informat , expert system , databas , multimedia , inform retriev . especi signific contribut includ co-author \n",
      "Cleaned Token Before =  analysis. one approach to complexity theory of numerical analysis is information based complexity. continuous complexity theory can also refer to complexity\n",
      "Cleaned Token After =  analysis . one approach complexity theory numerical analysis information based complexity . continuous complexity theory also refer complexity \n",
      "Cleaned Token After Stem =  analysi . one approach complex theori numer analysi inform base complex . continu complex theori also refer complex \n",
      "Cleaned Token Before =  grouping and organizing content through social media mining, document retrieval and clustering. for instance, if a person searches \"red, large, four-wheeled\n",
      "Cleaned Token After =  grouping organizing content social media mining , document retrieval clustering . instance , person searches `` red , large , four-wheeled \n",
      "Cleaned Token After Stem =  group organ content social media mine , document retriev cluster . instanc , person search `` red , larg , four-wheel \n",
      "Cleaned Token Before =  people to save and bookmark information for retrieval. these practices marked both present and future acts of information processing. swiss scientist\n",
      "Cleaned Token After =  people save bookmark information retrieval . practices marked present future acts information processing . swiss scientist \n",
      "Cleaned Token After Stem =  peopl save bookmark inform retriev . practic mark present futur act inform process . swiss scientist \n",
      "Cleaned Token Before =  pages. web pages often describe or discuss a particular topic. in information retrieval and machine learning literature, classification algorithms have\n",
      "Cleaned Token After =  pages . web pages often describe discuss particular topic . information retrieval machine learning literature , classification algorithms \n",
      "Cleaned Token After Stem =  page . web page often describ discuss particular topic . inform retriev machin learn literatur , classif algorithm \n",
      "Cleaned Token Before =  to be aware of what information is available for retrieval, so does the transactive memory system provide teammates with information regarding the knowledge\n",
      "Cleaned Token After =  aware information available retrieval , transactive memory system provide teammates information regarding knowledge \n",
      "Cleaned Token After Stem =  awar inform avail retriev , transact memori system provid teammat inform regard knowledg \n",
      "Cleaned Token Before =  of the world: descriptions, illustrations, identification, and information retrieval; including synonyms, morphology, anatomy, physiology, phytochemistry\n",
      "Cleaned Token After =  world : descriptions , illustrations , identification , information retrieval ; including synonyms , morphology , anatomy , physiology , phytochemistry \n",
      "Cleaned Token After Stem =  world : descript , illustr , identif , inform retriev ; includ synonym , morpholog , anatomi , physiolog , phytochemistri \n",
      "Cleaned Token Before =  machine dic corporation. dicカラーガイド情報検索 (ver 1.4) [dic color guide information retrieval (version 1.4)] [retrieved 2009-09-15]. (in japanese).[permanent\n",
      "Cleaned Token After =  machine dic corporation . dicカラーガイド情報検索 ( ver 1.4 ) [ dic color guide information retrieval ( version 1.4 ) ] [ retrieved 2009-09-15 ] . ( japanese ) . [ permanent \n",
      "Cleaned Token After Stem =  machin dic corpor . dicカラーガイド情報検索 ( ver 1.4 ) [ dic color guid inform retriev ( version 1.4 ) ] [ retriev 2009-09-15 ] . ( japanes ) . [ perman \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, information retrieval. version: 9 march 2006. https://web.archive\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval . version : 9 march 2006. https : //web.archive \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev . version : 9 march 2006. http : //web.arch \n",
      "Cleaned Token Before =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion\n",
      "Cleaned Token After =  digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion \n",
      "Cleaned Token After Stem =  digit librari comput platform digit market world wide web inform retriev secur cryptographi formal method secur servic intrus \n",
      "Cleaned Token Before =  of information calls handled and provide consistent quality in information retrieval.[citation needed] ivr systems are used to service high call volumes\n",
      "Cleaned Token After =  information calls handled provide consistent quality information retrieval . [ citation needed ] ivr systems used service high call volumes \n",
      "Cleaned Token After Stem =  inform call handl provid consist qualiti inform retriev . [ citat need ] ivr system use servic high call volum \n",
      "Cleaned Token Before =  between information structure and posture and gesture). there were some attempts to apply the theory of topic/comment for information retrieval and automatic\n",
      "Cleaned Token After =  information structure posture gesture ) . attempts apply theory topic/comment information retrieval automatic \n",
      "Cleaned Token After Stem =  inform structur postur gestur ) . attempt appli theori topic/com inform retriev automat \n",
      "Cleaned Token Before =  what are the philosophical consequences of the p vs np problem? what is information? the church–turing thesis and its variations are central to the theory\n",
      "Cleaned Token After =  philosophical consequences p vs np problem ? information ? church–turing thesis variations central theory \n",
      "Cleaned Token After Stem =  philosoph consequ p vs np problem ? inform ? church–tur thesi variat central theori \n",
      "Cleaned Token Before =  and straightedge constructions, instance-based learning, music information retrieval, and computational music theory. he was a co-founder of the annual\n",
      "Cleaned Token After =  straightedge constructions , instance-based learning , music information retrieval , computational music theory . co-founder annual \n",
      "Cleaned Token After Stem =  straightedg construct , instance-bas learn , music inform retriev , comput music theori . co-found annual \n",
      "Cleaned Token Before =  the field of artificial intelligence (ai) dedicated to representing information about the world in a form that a computer system can utilize to solve\n",
      "Cleaned Token After =  field artificial intelligence ( ai ) dedicated representing information world form computer system utilize solve \n",
      "Cleaned Token After Stem =  field artifici intellig ( ai ) dedic repres inform world form comput system util solv \n",
      "Cleaned Token Before =  'infinity series' in much of his music. in the research field of music information retrieval, self-similarity commonly refers to the fact that music often consists\n",
      "Cleaned Token After =  'infinity series ' much music . research field music information retrieval , self-similarity commonly refers fact music often consists \n",
      "Cleaned Token After Stem =  'infin seri ' much music . research field music inform retriev , self-similar commonli refer fact music often consist \n",
      "Cleaned Token Before =  to informetrics, bibliometrics information retrieval, and most recently altmetrics, domains at the core of information science\". a special memorial issue\n",
      "Cleaned Token After =  informetrics , bibliometrics information retrieval , recently altmetrics , domains core information science '' . special memorial issue \n",
      "Cleaned Token After Stem =  informetr , bibliometr inform retriev , recent altmetr , domain core inform scienc `` . special memori issu \n",
      "Cleaned Token Before =  track inventory, developed a database system named generalized information retrieval language system (girls). as a public domain item, a developer named\n",
      "Cleaned Token After =  track inventory , developed database system named generalized information retrieval language system ( girls ) . public domain item , developer named \n",
      "Cleaned Token After Stem =  track inventori , develop databas system name gener inform retriev languag system ( girl ) . public domain item , develop name \n",
      "Cleaned Token Before =  grefenstette is especially known for his work on cross-language information retrieval and distributional semantics. grefenstette, gregory; wilber, laura\n",
      "Cleaned Token After =  grefenstette especially known work cross-language information retrieval distributional semantics . grefenstette , gregory ; wilber , laura \n",
      "Cleaned Token After Stem =  grefenstett especi known work cross-languag inform retriev distribut semant . grefenstett , gregori ; wilber , laura \n",
      "Cleaned Token Before =  lists the qualities of popular search engines evaluation measures (information retrieval), which is quantitative and which describes general methods by which\n",
      "Cleaned Token After =  lists qualities popular search engines evaluation measures ( information retrieval ) , quantitative describes general methods \n",
      "Cleaned Token After Stem =  list qualiti popular search engin evalu measur ( inform retriev ) , quantit describ gener method \n",
      "Cleaned Token Before =  classification. otlet was responsible for the development of an early information retrieval tool, the \"repertoire bibliographique universel\" (rbu) which utilized\n",
      "Cleaned Token After =  classification . otlet responsible development early information retrieval tool , `` repertoire bibliographique universel '' ( rbu ) utilized \n",
      "Cleaned Token After Stem =  classif . otlet respons develop earli inform retriev tool , `` repertoir bibliographiqu universel `` ( rbu ) util \n",
      "Cleaned Token Before =   a slang term meaning act with more courage patent application information retrieval, an online service providing access to the prosecution histories\n",
      "Cleaned Token After =  slang term meaning act courage patent application information retrieval , online service providing access prosecution histories \n",
      "Cleaned Token After Stem =  slang term mean act courag patent applic inform retriev , onlin servic provid access prosecut histori \n",
      "Cleaned Token Before =  (coleoptera): descriptions, illustrations, identification, and information retrieval for families and subfamilies\". retrieved january 26, 2017. beenen\n",
      "Cleaned Token After =  ( coleoptera ) : descriptions , illustrations , identification , information retrieval families subfamilies '' . retrieved january 26 , 2017. beenen \n",
      "Cleaned Token After Stem =  ( coleoptera ) : descript , illustr , identif , inform retriev famili subfamili `` . retriev januari 26 , 2017. beenen \n",
      "Cleaned Token Before =  representations. instead, colour vision is exploited to capture dimensional information using techniques such as domain coloring. stephen wolfram's book on cellular\n",
      "Cleaned Token After =  representations . instead , colour vision exploited capture dimensional information using techniques domain coloring . stephen wolfram 's book cellular \n",
      "Cleaned Token After Stem =  represent . instead , colour vision exploit captur dimension inform use techniqu domain color . stephen wolfram 's book cellular \n",
      "Cleaned Token Before =  translation, speech recognition, speech synthesis, information retrieval, parsing and information extraction. until 1996, the institute existed as the\n",
      "Cleaned Token After =  translation , speech recognition , speech synthesis , information retrieval , parsing information extraction . 1996 , institute existed \n",
      "Cleaned Token After Stem =  translat , speech recognit , speech synthesi , inform retriev , pars inform extract . 1996 , institut exist \n",
      "Cleaned Token Before =  internet information retrieval university of minnesota rfc freeware numerous companies no numerous gopher sites 1998 pagerank information retrieval world\n",
      "Cleaned Token After =  internet information retrieval university minnesota rfc freeware numerous companies numerous gopher sites 1998 pagerank information retrieval world \n",
      "Cleaned Token After Stem =  internet inform retriev univers minnesota rfc freewar numer compani numer gopher site 1998 pagerank inform retriev world \n",
      "Cleaned Token Before =  names in the united states are listed in the national pesticide information retrieval system. nitisinone (orfadin) pesticide properties database. \"mesotrione\"\n",
      "Cleaned Token After =  names united states listed national pesticide information retrieval system . nitisinone ( orfadin ) pesticide properties database . `` mesotrione '' \n",
      "Cleaned Token After Stem =  name unit state list nation pesticid inform retriev system . nitisinon ( orfadin ) pesticid properti databas . `` mesotrion `` \n",
      "Cleaned Token Before =  the influence of font type and line length on visual search and information retrieval in web pages. international journal of human-computer studies, 64(5)\n",
      "Cleaned Token After =  influence font type line length visual search information retrieval web pages . international journal human-computer studies , 64 ( 5 ) \n",
      "Cleaned Token After Stem =  influenc font type line length visual search inform retriev web page . intern journal human-comput studi , 64 ( 5 ) \n",
      "Cleaned Token Before =  bits/second is the maximum rate that information can be transferred throughput is the actual rate that information is transferred latency the delay between\n",
      "Cleaned Token After =  bits/second maximum rate information transferred throughput actual rate information transferred latency delay \n",
      "Cleaned Token After Stem =  bits/second maximum rate inform transfer throughput actual rate inform transfer latenc delay \n",
      "Cleaned Token Before =  collection use and internet access for an hourly fee. there is an information retrieval reference service for questions that cannot be answered by their\n",
      "Cleaned Token After =  collection use internet access hourly fee . information retrieval reference service questions answered \n",
      "Cleaned Token After Stem =  collect use internet access hourli fee . inform retriev refer servic question answer \n",
      "Cleaned Token Before =  distributed systems, game theory, general game playing, image processing, information retrieval, knowledge systems, logic, machine learning, multi-agent systems\n",
      "Cleaned Token After =  distributed systems , game theory , general game playing , image processing , information retrieval , knowledge systems , logic , machine learning , multi-agent systems \n",
      "Cleaned Token After Stem =  distribut system , game theori , gener game play , imag process , inform retriev , knowledg system , logic , machin learn , multi-ag system \n",
      "Cleaned Token Before =  sciences, verification technologies, multimedia, event processing, information retrieval, programming environments, business transformation, and optimization\n",
      "Cleaned Token After =  sciences , verification technologies , multimedia , event processing , information retrieval , programming environments , business transformation , optimization \n",
      "Cleaned Token After Stem =  scienc , verif technolog , multimedia , event process , inform retriev , program environ , busi transform , optim \n",
      "Cleaned Token Before =  malacostraca)\". crustacea, the higher taxa: description, identification, and information retrieval. retrieved june 4, 2010. schotte m, boyko cb, bruce nl, poore gc\n",
      "Cleaned Token After =  malacostraca ) '' . crustacea , higher taxa : description , identification , information retrieval . retrieved june 4 , 2010. schotte , boyko cb , bruce nl , poore gc \n",
      "Cleaned Token After Stem =  malacostraca ) `` . crustacea , higher taxa : descript , identif , inform retriev . retriev june 4 , 2010. schott , boyko cb , bruce nl , poor gc \n",
      "Cleaned Token Before =  development of resources and corpus analysis, internet addiction, information retrieval, and automatic summarization. her technologies have been applied\n",
      "Cleaned Token After =  development resources corpus analysis , internet addiction , information retrieval , automatic summarization . technologies applied \n",
      "Cleaned Token After Stem =  develop resourc corpu analysi , internet addict , inform retriev , automat summar . technolog appli \n",
      "Cleaned Token Before =  and recalling information that was previously acquired. memory occurs through three fundamental stages: encoding, storage, and retrieval. storing refers\n",
      "Cleaned Token After =  recalling information previously acquired . memory occurs three fundamental stages : encoding , storage , retrieval . storing refers \n",
      "Cleaned Token After Stem =  recal inform previous acquir . memori occur three fundament stage : encod , storag , retriev . store refer \n",
      "Cleaned Token Before =  work concerning two concepts pertaining to bibliographic control, information retrieval, and knowledge organization: a definition of the meaning of a “work”\n",
      "Cleaned Token After =  work concerning two concepts pertaining bibliographic control , information retrieval , knowledge organization : definition meaning “ work ” \n",
      "Cleaned Token After Stem =  work concern two concept pertain bibliograph control , inform retriev , knowledg organ : definit mean “ work ” \n",
      "Cleaned Token Before =   wordpress.com, wix. the core cms features are, indexing, search and retrieval, format management, revision control, and management. features may vary\n",
      "Cleaned Token After =  wordpress.com , wix . core cms features , indexing , search retrieval , format management , revision control , management . features may vary \n",
      "Cleaned Token After Stem =  wordpress.com , wix . core cm featur , index , search retriev , format manag , revis control , manag . featur may vari \n",
      "Cleaned Token Before =  applications. quest information and learning. isbn 0-5422-6663-6. wu, weili; hui xiong; shashi shekhar (2003). clustering and information retrieval. kluwer academic\n",
      "Cleaned Token After =  applications . quest information learning . isbn 0-5422-6663-6. wu , weili ; hui xiong ; shashi shekhar ( 2003 ) . clustering information retrieval . kluwer academic \n",
      "Cleaned Token After Stem =  applic . quest inform learn . isbn 0-5422-6663-6. wu , weili ; hui xiong ; shashi shekhar ( 2003 ) . cluster inform retriev . kluwer academ \n",
      "Cleaned Token Before =  stamped. alternate automated approaches for generating traces using information retrieval methods have been developed. in transaction processing software\n",
      "Cleaned Token After =  stamped . alternate automated approaches generating traces using information retrieval methods developed . transaction processing software \n",
      "Cleaned Token After Stem =  stamp . altern autom approach gener trace use inform retriev method develop . transact process softwar \n",
      "Cleaned Token Before =  spam with language model disagreement, pdf. from the first international workshop on adversarial information retrieval (airweb'05) chiba, japan, 2005.\n",
      "Cleaned Token After =  spam language model disagreement , pdf . first international workshop adversarial information retrieval ( airweb'05 ) chiba , japan , 2005 . \n",
      "Cleaned Token After Stem =  spam languag model disagr , pdf . first intern workshop adversari inform retriev ( airweb'05 ) chiba , japan , 2005 . \n",
      "Cleaned Token Before =  the magnitude and the phase components of the sar data, during information retrieval. one of the major advantages of tomo-sar is that it can separate\n",
      "Cleaned Token After =  magnitude phase components sar data , information retrieval . one major advantages tomo-sar separate \n",
      "Cleaned Token After Stem =  magnitud phase compon sar data , inform retriev . one major advantag tomo-sar separ \n",
      "Cleaned Token Before =  of parents and children and believe that since the days of quick information retrieval on the internet, schools for knowledge transfer purposes are no\n",
      "Cleaned Token After =  parents children believe since days quick information retrieval internet , schools knowledge transfer purposes \n",
      "Cleaned Token After Stem =  parent children believ sinc day quick inform retriev internet , school knowledg transfer purpos \n",
      "Cleaned Token Before =  topics, such as measuring spam mass. pagerank cheirank adversarial information retrieval hilltop algorithm hits algorithm spamdexing 7603350, guha, ramanathan\n",
      "Cleaned Token After =  topics , measuring spam mass . pagerank cheirank adversarial information retrieval hilltop algorithm hits algorithm spamdexing 7603350 , guha , ramanathan \n",
      "Cleaned Token After Stem =  topic , measur spam mass . pagerank cheirank adversari inform retriev hilltop algorithm hit algorithm spamdex 7603350 , guha , ramanathan \n",
      "Cleaned Token Before =  (2005-08-04). \"lam dna\". hangingtogether.org. retrieved 2012-04-05. information retrieval & library automation. lomond systems. 1997. \"glam peak — digital\n",
      "Cleaned Token After =  ( 2005-08-04 ) . `` lam dna '' . hangingtogether.org . retrieved 2012-04-05. information retrieval & library automation . lomond systems . 1997 . `` glam peak — digital \n",
      "Cleaned Token After Stem =  ( 2005-08-04 ) . `` lam dna `` . hangingtogether.org . retriev 2012-04-05. inform retriev & librari autom . lomond system . 1997 . `` glam peak — digit \n",
      "Cleaned Token Before =  approaches. here we can include computational musicology, music information retrieval, and the more computational approaches of music cognition. interfaces\n",
      "Cleaned Token After =  approaches . include computational musicology , music information retrieval , computational approaches music cognition . interfaces \n",
      "Cleaned Token After Stem =  approach . includ comput musicolog , music inform retriev , comput approach music cognit . interfac \n",
      "Cleaned Token Before =  g. formulas that, given the contents of a database, extract certain information from it. in the predominant relational database paradigm, the contents\n",
      "Cleaned Token After =  g. formulas , given contents database , extract certain information . predominant relational database paradigm , contents \n",
      "Cleaned Token After Stem =  g. formula , given content databas , extract certain inform . predomin relat databas paradigm , content \n",
      "Cleaned Token Before =  and opus, and to understand the content of the signal, e.g. music information retrieval to allow the identification of music tracks via shazam (service)\n",
      "Cleaned Token After =  opus , understand content signal , e.g . music information retrieval allow identification music tracks via shazam ( service ) \n",
      "Cleaned Token After Stem =  opu , understand content signal , e.g . music inform retriev allow identif music track via shazam ( servic ) \n",
      "Cleaned Token Before =  bernardo, eds. (2007). evaluation of multilingual and multi-modal information retrieval: 7th workshop of the cross-language evaluation forum, clef 2006\n",
      "Cleaned Token After =  bernardo , eds . ( 2007 ) . evaluation multilingual multi-modal information retrieval : 7th workshop cross-language evaluation forum , clef 2006 \n",
      "Cleaned Token After Stem =  bernardo , ed . ( 2007 ) . evalu multilingu multi-mod inform retriev : 7th workshop cross-languag evalu forum , clef 2006 \n",
      "Cleaned Token Before =  analyzer, proceedings of the 10th international conference on music information retrieval conference (ismir2009), pp. 291–296, october 2009. keiji hirata\n",
      "Cleaned Token After =  analyzer , proceedings 10th international conference music information retrieval conference ( ismir2009 ) , pp . 291–296 , october 2009. keiji hirata \n",
      "Cleaned Token After Stem =  analyz , proceed 10th intern confer music inform retriev confer ( ismir2009 ) , pp . 291–296 , octob 2009. keiji hirata \n",
      "Cleaned Token Before =  three languages, providing a consistent and unique environment for information retrieval regardless of the language. in addition to the original mesh terms\n",
      "Cleaned Token After =  three languages , providing consistent unique environment information retrieval regardless language . addition original mesh terms \n",
      "Cleaned Token After Stem =  three languag , provid consist uniqu environ inform retriev regardless languag . addit origin mesh term \n",
      "Cleaned Token Before =  analysis, bayesian reasoning, product configuration, and private information retrieval.[citation needed] every arbitrary bdd (even if it is not reduced\n",
      "Cleaned Token After =  analysis , bayesian reasoning , product configuration , private information retrieval . [ citation needed ] every arbitrary bdd ( even reduced \n",
      "Cleaned Token After Stem =  analysi , bayesian reason , product configur , privat inform retriev . [ citat need ] everi arbitrari bdd ( even reduc \n",
      "Cleaned Token Before =  at retrieval of verbatim traces than younger children, although even very young children (4-year-olds) are able to retrieve verbatim information at above\n",
      "Cleaned Token After =  retrieval verbatim traces younger children , although even young children ( 4-year-olds ) able retrieve verbatim information \n",
      "Cleaned Token After Stem =  retriev verbatim trace younger children , although even young children ( 4-year-old ) abl retriev verbatim inform \n",
      "Cleaned Token Before =  edgar, the electronic data gathering, analysis, and retrieval system, performs automated collection, validation, indexing, acceptance, and forwarding\n",
      "Cleaned Token After =  edgar , electronic data gathering , analysis , retrieval system , performs automated collection , validation , indexing , acceptance , forwarding \n",
      "Cleaned Token After Stem =  edgar , electron data gather , analysi , retriev system , perform autom collect , valid , index , accept , forward \n",
      "Cleaned Token Before =  relies on the direct retrieval of information. priming can influence reconstructive memory because it can interfere with retrieval cues. psychologist elizabeth\n",
      "Cleaned Token After =  relies direct retrieval information . priming influence reconstructive memory interfere retrieval cues . psychologist elizabeth \n",
      "Cleaned Token After Stem =  reli direct retriev inform . prime influenc reconstruct memori interfer retriev cue . psychologist elizabeth \n",
      "Cleaned Token Before =  deep-rooted passion for information and knowledge, which has fueled her unparalleled talents in the areas of information retrieval by any means necessary\n",
      "Cleaned Token After =  deep-rooted passion information knowledge , fueled unparalleled talents areas information retrieval means necessary \n",
      "Cleaned Token After Stem =  deep-root passion inform knowledg , fuel unparallel talent area inform retriev mean necessari \n",
      "Cleaned Token Before =  the award recognizes achievement in furthering the progress in information retrieval and natural language processing; the award commemorates the life\n",
      "Cleaned Token After =  award recognizes achievement furthering progress information retrieval natural language processing ; award commemorates life \n",
      "Cleaned Token After Stem =  award recogn achiev further progress inform retriev natur languag process ; award commemor life \n",
      "Cleaned Token Before =  establishment is listed in the espirs database (electronic seveso plant information retrieval system. article 20 (inspections) of the seveso directive states\n",
      "Cleaned Token After =  establishment listed espirs database ( electronic seveso plant information retrieval system . article 20 ( inspections ) seveso directive states \n",
      "Cleaned Token After Stem =  establish list espir databas ( electron seveso plant inform retriev system . articl 20 ( inspect ) seveso direct state \n",
      "Cleaned Token Before =  (all or parts of) programs from specification given in form of type information. type theory is closely linked to many fields of active research. most\n",
      "Cleaned Token After =  ( parts ) programs specification given form type information . type theory closely linked many fields active research . \n",
      "Cleaned Token After Stem =  ( part ) program specif given form type inform . type theori close link mani field activ research . \n",
      "Cleaned Token Before =  granted a patent for one of the earliest systems for cross-language information retrieval. littman received his ph.d. in computer science from brown university\n",
      "Cleaned Token After =  granted patent one earliest systems cross-language information retrieval . littman received ph.d. computer science brown university \n",
      "Cleaned Token After Stem =  grant patent one earliest system cross-languag inform retriev . littman receiv ph.d. comput scienc brown univers \n",
      "Cleaned Token Before =  complexity — includes table of orders of growth for common algorithms information-based complexity \"knuth: recent news\". 28 august 2016. archived from\n",
      "Cleaned Token After =  complexity — includes table orders growth common algorithms information-based complexity `` knuth : recent news '' . 28 august 2016. archived \n",
      "Cleaned Token After Stem =  complex — includ tabl order growth common algorithm information-bas complex `` knuth : recent news `` . 28 august 2016. archiv \n",
      "Cleaned Token Before =  information systems to be opened to 'outside' correspondents not just for transaction processing but also for e-messaging and information retrieval and\n",
      "Cleaned Token After =  information systems opened 'outside ' correspondents transaction processing also e-messaging information retrieval \n",
      "Cleaned Token After Stem =  inform system open 'outsid ' correspond transact process also e-messag inform retriev \n",
      "Cleaned Token Before =  1967–2011), american performance poet david blair (information technologist) (1947–2011), information retrieval scientist david blair (rugby union) (born 1985)\n",
      "Cleaned Token After =  1967–2011 ) , american performance poet david blair ( information technologist ) ( 1947–2011 ) , information retrieval scientist david blair ( rugby union ) ( born 1985 ) \n",
      "Cleaned Token After Stem =  1967–2011 ) , american perform poet david blair ( inform technologist ) ( 1947–2011 ) , inform retriev scientist david blair ( rugbi union ) ( born 1985 ) \n",
      "Cleaned Token Before =  human information interaction and exploratory search and his work sits at the intersection of human-computer interaction and information retrieval, a subdomain\n",
      "Cleaned Token After =  human information interaction exploratory search work sits intersection human-computer interaction information retrieval , subdomain \n",
      "Cleaned Token After Stem =  human inform interact exploratori search work sit intersect human-comput interact inform retriev , subdomain \n",
      "Cleaned Token Before =  card artificial intelligence for video surveillance multimedia information retrieval multilinear subspace learning pattern recognition, analogy and case-based\n",
      "Cleaned Token After =  card artificial intelligence video surveillance multimedia information retrieval multilinear subspace learning pattern recognition , analogy case-based \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Token After Stem =  card artifici intellig video surveil multimedia inform retriev multilinear subspac learn pattern recognit , analog case-bas \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, and information retrieval. version: 29th july 2006\". retrieved 27 december 2006. willemstein\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval . version : 29th july 2006 '' . retrieved 27 december 2006. willemstein \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev . version : 29th juli 2006 `` . retriev 27 decemb 2006. willemstein \n",
      "Cleaned Token Before =  effective retrieval structure that makes it easier to access information that has been stored in long-term memory is facilitated by using repeated retrieval practice\n",
      "Cleaned Token After =  effective retrieval structure makes easier access information stored long-term memory facilitated using repeated retrieval practice \n",
      "Cleaned Token After Stem =  effect retriev structur make easier access inform store long-term memori facilit use repeat retriev practic \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, information retrieval. version: 9 march 2006. https://web.archive\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval . version : 9 march 2006. https : //web.archive \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev . version : 9 march 2006. http : //web.arch \n",
      "Cleaned Token Before =  dishes squid as food aquatic sciences and fisheries abstracts. information retrieval ltd. october 1974. retrieved 20 april 2013. cs1 maint: discouraged\n",
      "Cleaned Token After =  dishes squid food aquatic sciences fisheries abstracts . information retrieval ltd. october 1974. retrieved 20 april 2013. cs1 maint : discouraged \n",
      "Cleaned Token After Stem =  dish squid food aquat scienc fisheri abstract . inform retriev ltd. octob 1974. retriev 20 april 2013. cs1 maint : discourag \n",
      "Cleaned Token Before =  dallwitz (1992 onwards). the families of flowering plants: descriptions, illustrations, identification, information retrieval. http://delta-intkey.com\n",
      "Cleaned Token After =  dallwitz ( 1992 onwards ) . families flowering plants : descriptions , illustrations , identification , information retrieval . http : //delta-intkey.com \n",
      "Cleaned Token After Stem =  dallwitz ( 1992 onward ) . famili flower plant : descript , illustr , identif , inform retriev . http : //delta-intkey.com \n",
      "Cleaned Token Before =  scientific experience in the field of text mining and multilingual information retrieval. averbis works in the field of terminology management, natural language\n",
      "Cleaned Token After =  scientific experience field text mining multilingual information retrieval . averbis works field terminology management , natural language \n",
      "Cleaned Token After Stem =  scientif experi field text mine multilingu inform retriev . averbi work field terminolog manag , natur languag \n",
      "Cleaned Token Before =  and informal discussion aimed at improving the retrieval, analysis, and dissemination of patent information. piug maintains a membership of over 700 patent\n",
      "Cleaned Token After =  informal discussion aimed improving retrieval , analysis , dissemination patent information . piug maintains membership 700 patent \n",
      "Cleaned Token After Stem =  inform discuss aim improv retriev , analysi , dissemin patent inform . piug maintain membership 700 patent \n",
      "Cleaned Token Before =  maxillipoda)\". crustacea, the higher taxa: description, identification, and information retrieval. australian museum. archived from the original on april 15, 2012\n",
      "Cleaned Token After =  maxillipoda ) '' . crustacea , higher taxa : description , identification , information retrieval . australian museum . archived original april 15 , 2012 \n",
      "Cleaned Token After Stem =  maxillipoda ) `` . crustacea , higher taxa : descript , identif , inform retriev . australian museum . archiv origin april 15 , 2012 \n",
      "Cleaned Token Before =  or term from memory, combined with partial recall and the feeling that retrieval is imminent. the phenomenon's name comes from the saying, \"it's on the\n",
      "Cleaned Token After =  term memory , combined partial recall feeling retrieval imminent . phenomenon 's name comes saying , `` 's \n",
      "Cleaned Token After Stem =  term memori , combin partial recal feel retriev immin . phenomenon 's name come say , `` 's \n",
      "Cleaned Token Before =  disaster risk reduction the mutual joint visit programme for seveso inspections seveso plants information retrieval system major accident reporting system\n",
      "Cleaned Token After =  disaster risk reduction mutual joint visit programme seveso inspections seveso plants information retrieval system major accident reporting system \n",
      "Cleaned Token After Stem =  disast risk reduct mutual joint visit programm seveso inspect seveso plant inform retriev system major accid report system \n",
      "Cleaned Token Before =  family and show his magnificence, and a newer library which was an information retrieval system for research and discussion by contemporary scholars. the\n",
      "Cleaned Token After =  family show magnificence , newer library information retrieval system research discussion contemporary scholars . \n",
      "Cleaned Token After Stem =  famili show magnific , newer librari inform retriev system research discuss contemporari scholar . \n",
      "Cleaned Token Before =  names in the united states are listed in the national pesticide information retrieval system. pesticide properties database. \"azoxystrobin\". university\n",
      "Cleaned Token After =  names united states listed national pesticide information retrieval system . pesticide properties database . `` azoxystrobin '' . university \n",
      "Cleaned Token After Stem =  name unit state list nation pesticid inform retriev system . pesticid properti databas . `` azoxystrobin `` . univers \n",
      "Cleaned Token Before =  (apocynaceae): descriptions, illustrations, identification, and information retrieval archived 2007-07-08 at the wayback machine version: 21 september\n",
      "Cleaned Token After =  ( apocynaceae ) : descriptions , illustrations , identification , information retrieval archived 2007-07-08 wayback machine version : 21 september \n",
      "Cleaned Token After Stem =  ( apocynacea ) : descript , illustr , identif , inform retriev archiv 2007-07-08 wayback machin version : 21 septemb \n",
      "Cleaned Token Before =  was being served from hard disk drives, as is done in traditional information retrieval (ir) systems. google dealt with the increasing query volume by increasing\n",
      "Cleaned Token After =  served hard disk drives , done traditional information retrieval ( ir ) systems . google dealt increasing query volume increasing \n",
      "Cleaned Token After Stem =  serv hard disk drive , done tradit inform retriev ( ir ) system . googl dealt increas queri volum increas \n",
      "Cleaned Token Before =  security phrases dice's coefficient, a similarity measure used in information retrieval dice.com, a career website dual interlocked storage cell, an implementation\n",
      "Cleaned Token After =  security phrases dice 's coefficient , similarity measure used information retrieval dice.com , career website dual interlocked storage cell , implementation \n",
      "Cleaned Token After Stem =  secur phrase dice 's coeffici , similar measur use inform retriev dice.com , career websit dual interlock storag cell , implement \n",
      "Cleaned Token Before =  multidimensional information space, text retrieval conference, 4 november 1996 mit artificial intelligence laboratory, the jair information space, mit artificial\n",
      "Cleaned Token After =  multidimensional information space , text retrieval conference , 4 november 1996 mit artificial intelligence laboratory , jair information space , mit artificial \n",
      "Cleaned Token After Stem =  multidimension inform space , text retriev confer , 4 novemb 1996 mit artifici intellig laboratori , jair inform space , mit artifici \n",
      "Cleaned Token Before =  informedia digital library which has made seminal strides in multimedia information retrieval and won best paper awards at major conferences. he was also a founder\n",
      "Cleaned Token After =  informedia digital library made seminal strides multimedia information retrieval best paper awards major conferences . also founder \n",
      "Cleaned Token After Stem =  informedia digit librari made semin stride multimedia inform retriev best paper award major confer . also founder \n",
      "Cleaned Token Before =  encyclopedias as information retrieval becomes simpler. some online encyclopedias are medical wikis, which use wiki software to write the information collaboratively\n",
      "Cleaned Token After =  encyclopedias information retrieval becomes simpler . online encyclopedias medical wikis , use wiki software write information collaboratively \n",
      "Cleaned Token After Stem =  encyclopedia inform retriev becom simpler . onlin encyclopedia medic wiki , use wiki softwar write inform collabor \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, information retrieval. version: 3 may 2006. http://delta-intkey.com. e-flora ncbi taxonomy\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval . version : 3 may 2006. http : //delta-intkey.com . e-flora ncbi taxonomy \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev . version : 3 may 2006. http : //delta-intkey.com . e-flora ncbi taxonomi \n",
      "Cleaned Token Before =  (2007-11-27). \"cognitive shifts related to interactive information retrieval\". online information review. 31 (6): 845–860. doi:10.1108/14684520710841801\n",
      "Cleaned Token After =  ( 2007-11-27 ) . `` cognitive shifts related interactive information retrieval '' . online information review . 31 ( 6 ) : 845–860 . doi:10.1108/14684520710841801 \n",
      "Cleaned Token After Stem =  ( 2007-11-27 ) . `` cognit shift relat interact inform retriev `` . onlin inform review . 31 ( 6 ) : 845–860 . doi:10.1108/14684520710841801 \n",
      "Cleaned Token Before =  (rosearik rikki simons), an ineffective and erratic standard issue information retrieval (sir) unit which was hastily made out of spare parts found in a\n",
      "Cleaned Token After =  ( rosearik rikki simons ) , ineffective erratic standard issue information retrieval ( sir ) unit hastily made spare parts found \n",
      "Cleaned Token After Stem =  ( rosearik rikki simon ) , ineffect errat standard issu inform retriev ( sir ) unit hastili made spare part found \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, information retrieval. https://web.archive.org/web/20070103200438/http://delta-intkey\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval . https : //web.archive.org/web/20070103200438/http : //delta-intkey \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev . http : //web.archive.org/web/20070103200438/http : //delta-intkey \n",
      "Cleaned Token Before =  provides courses on information retrieval for the students and the researchers of the universities.<ref>education in information literacy the universities\n",
      "Cleaned Token After =  provides courses information retrieval students researchers universities. < ref > education information literacy universities \n",
      "Cleaned Token After Stem =  provid cours inform retriev student research univers . < ref > educ inform literaci univers \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, and information retrieval\". retrieved 4 september 2019. manchester, steven r.; dilcher, david\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval '' . retrieved 4 september 2019. manchester , steven r. ; dilcher , david \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev `` . retriev 4 septemb 2019. manchest , steven r. ; dilcher , david \n",
      "Cleaned Token Before =   her thesis focused on knowledge-rich documents, in particular information retrieval for scientific articles. the hypothesis of this work was that embedding\n",
      "Cleaned Token After =  thesis focused knowledge-rich documents , particular information retrieval scientific articles . hypothesis work embedding \n",
      "Cleaned Token After Stem =  thesi focus knowledge-rich document , particular inform retriev scientif articl . hypothesi work embed \n",
      "Cleaned Token Before =  applications in information technology seek to mine end user data to support and improve machine-based processes, such as information retrieval and recommendation\n",
      "Cleaned Token After =  applications information technology seek mine end user data support improve machine-based processes , information retrieval recommendation \n",
      "Cleaned Token After Stem =  applic inform technolog seek mine end user data support improv machine-bas process , inform retriev recommend \n",
      "Cleaned Token Before =  adoption of word-based classification systems has had little impact on information retrieval quality within library catalogs to date. critics of the new systems\n",
      "Cleaned Token After =  adoption word-based classification systems little impact information retrieval quality within library catalogs date . critics new systems \n",
      "Cleaned Token After Stem =  adopt word-bas classif system littl impact inform retriev qualiti within librari catalog date . critic new system \n",
      "Cleaned Token Before =  a mechanical system using superimposed codes of descriptors for information retrieval called zatocoding, 1948. atomic bomb – edward p. ney discovered\n",
      "Cleaned Token After =  mechanical system using superimposed codes descriptors information retrieval called zatocoding , 1948. atomic bomb – edward p. ney discovered \n",
      "Cleaned Token After Stem =  mechan system use superimpos code descriptor inform retriev call zatocod , 1948. atom bomb – edward p. ney discov \n",
      "Cleaned Token Before =  frohmann, b. (1990). \"rules of indexing: a critique of mentalism in information retrieval theory.\" journal of documentation, 81-101. beghtol, c. (1986). \"bibliographic\n",
      "Cleaned Token After =  frohmann , b . ( 1990 ) . `` rules indexing : critique mentalism information retrieval theory . '' journal documentation , 81-101. beghtol , c. ( 1986 ) . `` bibliographic \n",
      "Cleaned Token After Stem =  frohmann , b . ( 1990 ) . `` rule index : critiqu mental inform retriev theori . `` journal document , 81-101. beghtol , c. ( 1986 ) . `` bibliograph \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, information retrieval. version: 3 may 2006. http://delta-intkey.com liliaceae in flora\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval . version : 3 may 2006. http : //delta-intkey.com liliaceae flora \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev . version : 3 may 2006. http : //delta-intkey.com liliacea flora \n",
      "Cleaned Token Before =  international acm sigir conference on research and development in information retrieval (1998), pp. 46–54 carrot search s.c. \"carrot search: document clustering\n",
      "Cleaned Token After =  international acm sigir conference research development information retrieval ( 1998 ) , pp . 46–54 carrot search s.c. `` carrot search : document clustering \n",
      "Cleaned Token After Stem =  intern acm sigir confer research develop inform retriev ( 1998 ) , pp . 46–54 carrot search s.c. `` carrot search : document cluster \n",
      "Cleaned Token Before =  resolution for string hash tables, in ‘proc. spire string processing and information retrieval symp.’, springer-verlag, pp. 92–104 askitis, n. and zobel, j. 2011\n",
      "Cleaned Token After =  resolution string hash tables , ‘ proc . spire string processing information retrieval symp. ’ , springer-verlag , pp . 92–104 askitis , n. zobel , j . 2011 \n",
      "Cleaned Token After Stem =  resolut string hash tabl , ‘ proc . spire string process inform retriev symp . ’ , springer-verlag , pp . 92–104 askiti , n. zobel , j . 2011 \n",
      "Cleaned Token Before =  point function is known, then it is possible to perform private information retrieval. as a simplified example of this, it is possible to test whether\n",
      "Cleaned Token After =  point function known , possible perform private information retrieval . simplified example , possible test whether \n",
      "Cleaned Token After Stem =  point function known , possibl perform privat inform retriev . simplifi exampl , possibl test whether \n",
      "Cleaned Token Before =  in l. watson and m.j. dallwitz (1992 onwards). the families of flowering plants: descriptions, illustrations, identification, information retrieval.\n",
      "Cleaned Token After =  l. watson m.j. dallwitz ( 1992 onwards ) . families flowering plants : descriptions , illustrations , identification , information retrieval . \n",
      "Cleaned Token After Stem =  l. watson m.j. dallwitz ( 1992 onward ) . famili flower plant : descript , illustr , identif , inform retriev . \n",
      "Cleaned Token Before =  applicable something is. relevance may also refer to: relevance (information retrieval), a measure of a document's applicability to a given subject or\n",
      "Cleaned Token After =  applicable something . relevance may also refer : relevance ( information retrieval ) , measure document 's applicability given subject \n",
      "Cleaned Token After Stem =  applic someth . relev may also refer : relev ( inform retriev ) , measur document 's applic given subject \n",
      "Cleaned Token Before =  action litigation information on classactionlitigation.com eric skelly, \"surtitles at the opera,\" public radio news and information in houston, texas\n",
      "Cleaned Token After =  action litigation information classactionlitigation.com eric skelly , `` surtitles opera , '' public radio news information houston , texas \n",
      "Cleaned Token After Stem =  action litig inform classactionlitigation.com eric skelli , `` surtitl opera , `` public radio news inform houston , texa \n",
      "Cleaned Token Before =  computerised documentation centre for linguistics and did research on information retrieval. having come to the conclusion that \"the problem with research on\n",
      "Cleaned Token After =  computerised documentation centre linguistics research information retrieval . come conclusion `` problem research \n",
      "Cleaned Token After Stem =  computeris document centr linguist research inform retriev . come conclus `` problem research \n",
      "Cleaned Token Before =  arctic archipelago: descriptions, illustrations, identification, and information retrieval[cd]. ottawa: nrc research press; ottawa: canadian museum of nature\n",
      "Cleaned Token After =  arctic archipelago : descriptions , illustrations , identification , information retrieval [ cd ] . ottawa : nrc research press ; ottawa : canadian museum nature \n",
      "Cleaned Token After Stem =  arctic archipelago : descript , illustr , identif , inform retriev [ cd ] . ottawa : nrc research press ; ottawa : canadian museum natur \n",
      "Cleaned Token Before =  titled the embassy, where the player can either engage in psychic information retrieval or can jeopardise the mission by forcing one of the guards to commit\n",
      "Cleaned Token After =  titled embassy , player either engage psychic information retrieval jeopardise mission forcing one guards commit \n",
      "Cleaned Token After Stem =  titl embassi , player either engag psychic inform retriev jeopardis mission forc one guard commit \n",
      "Cleaned Token Before =  \"the application of information processing involving both computer hardware and software that deals with the storage, retrieval, sharing, and use of\n",
      "Cleaned Token After =  `` application information processing involving computer hardware software deals storage , retrieval , sharing , use \n",
      "Cleaned Token After Stem =  `` applic inform process involv comput hardwar softwar deal storag , retriev , share , use \n",
      "Cleaned Token Before =  and printed on the document as a method of identification or for detail or information retrieval. global document type identifier at gs1 website v t e\n",
      "Cleaned Token After =  printed document method identification detail information retrieval . global document type identifier gs1 website v e \n",
      "Cleaned Token After Stem =  print document method identif detail inform retriev . global document type identifi gs1 websit v e \n",
      "Cleaned Token Before =  amherst. her dissertation, in computer science, is titled retrieval of passages for information reduction. she also graduated from the united states army\n",
      "Cleaned Token After =  amherst . dissertation , computer science , titled retrieval passages information reduction . also graduated united states army \n",
      "Cleaned Token After Stem =  amherst . dissert , comput scienc , titl retriev passag inform reduct . also graduat unit state armi \n",
      "Cleaned Token Before =  \"fluency heuristic: a model of how the mind exploits a by-product of information retrieval\". journal of experimental psychology: learning, memory, and cognition\n",
      "Cleaned Token After =  `` fluency heuristic : model mind exploits by-product information retrieval '' . journal experimental psychology : learning , memory , cognition \n",
      "Cleaned Token After Stem =  `` fluenci heurist : model mind exploit by-product inform retriev `` . journal experiment psycholog : learn , memori , cognit \n",
      "Cleaned Token Before =  \"lifelogging: personal big data\" (pdf). foundations and trends in information retrieval. 8 (1): 1–125. doi:10.1561/1500000033. issn 1554-0669. an introduction\n",
      "Cleaned Token After =  `` lifelogging : personal big data '' ( pdf ) . foundations trends information retrieval . 8 ( 1 ) : 1–125 . doi:10.1561/1500000033 . issn 1554-0669. introduction \n",
      "Cleaned Token After Stem =  `` lifelog : person big data `` ( pdf ) . foundat trend inform retriev . 8 ( 1 ) : 1–125 . doi:10.1561/1500000033 . issn 1554-0669. introduct \n",
      "Cleaned Token Before =  animated series games in relief, a baseball statistic geographic information retrieval great indian rock, a music festival in india independent grouping\n",
      "Cleaned Token After =  animated series games relief , baseball statistic geographic information retrieval great indian rock , music festival india independent grouping \n",
      "Cleaned Token After Stem =  anim seri game relief , basebal statist geograph inform retriev great indian rock , music festiv india independ group \n",
      "Cleaned Token Before =  computational models of musical creativity list of music software music information retrieval informs computing society conference: annapolis: music, computation\n",
      "Cleaned Token After =  computational models musical creativity list music software music information retrieval informs computing society conference : annapolis : music , computation \n",
      "Cleaned Token After Stem =  comput model music creativ list music softwar music inform retriev inform comput societi confer : annapoli : music , comput \n",
      "Cleaned Token Before =  mood to stock market prices. he has taught courses on data mining, information retrieval, and digital libraries. his research has been funded by the andrew\n",
      "Cleaned Token After =  mood stock market prices . taught courses data mining , information retrieval , digital libraries . research funded andrew \n",
      "Cleaned Token After Stem =  mood stock market price . taught cours data mine , inform retriev , digit librari . research fund andrew \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, information retrieval. https://web.archive.org/web/20070103200438/http://delta-intkey\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval . https : //web.archive.org/web/20070103200438/http : //delta-intkey \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev . http : //web.archive.org/web/20070103200438/http : //delta-intkey \n",
      "Cleaned Token Before =  areas including natural language processing, machine learning, information retrieval, data mining, computational linguistics, distributed computing,\n",
      "Cleaned Token After =  areas including natural language processing , machine learning , information retrieval , data mining , computational linguistics , distributed computing , \n",
      "Cleaned Token After Stem =  area includ natur languag process , machin learn , inform retriev , data mine , comput linguist , distribut comput , \n",
      "Cleaned Token Before =  large information systems). nyberg has made significant research contributions to the fields of automatic text translation, information retrieval, and\n",
      "Cleaned Token After =  large information systems ) . nyberg made significant research contributions fields automatic text translation , information retrieval , \n",
      "Cleaned Token After Stem =  larg inform system ) . nyberg made signific research contribut field automat text translat , inform retriev , \n",
      "Cleaned Token Before =  \" united states patent and trademark office patent application information retrieval (pair), the uspto search engine for patent and patent application\n",
      "Cleaned Token After =  `` united states patent trademark office patent application information retrieval ( pair ) , uspto search engine patent patent application \n",
      "Cleaned Token After Stem =  `` unit state patent trademark offic patent applic inform retriev ( pair ) , uspto search engin patent patent applic \n",
      "Cleaned Token Before =  learning and data mining are showing that is not the case for many information retrieval and extraction-based problems.[citation needed] more recent methods\n",
      "Cleaned Token After =  learning data mining showing case many information retrieval extraction-based problems . [ citation needed ] recent methods \n",
      "Cleaned Token After Stem =  learn data mine show case mani inform retriev extraction-bas problem . [ citat need ] recent method \n",
      "Cleaned Token Before =  fields of imaging and signal processing. various approaches of phase retrieval have been developed over the years. light detectors, such as photographic\n",
      "Cleaned Token After =  fields imaging signal processing . various approaches phase retrieval developed years . light detectors , photographic \n",
      "Cleaned Token After Stem =  field imag signal process . variou approach phase retriev develop year . light detector , photograph \n",
      "Cleaned Token Before =  in health and medicine are: hoff, wilbur (may 1967). \"a health information retrieval system for personal use\". journal of school health. 37 (5): 251–254\n",
      "Cleaned Token After =  health medicine : hoff , wilbur ( may 1967 ) . `` health information retrieval system personal use '' . journal school health . 37 ( 5 ) : 251–254 \n",
      "Cleaned Token After Stem =  health medicin : hoff , wilbur ( may 1967 ) . `` health inform retriev system person use `` . journal school health . 37 ( 5 ) : 251–254 \n",
      "Cleaned Token Before =  login; and electronic transcript by budsir: buddhist scriptures information retrieval, cd-rom and online, both requiring payment. sixth council tipiṭaka\n",
      "Cleaned Token After =  login ; electronic transcript budsir : buddhist scriptures information retrieval , cd-rom online , requiring payment . sixth council tipiṭaka \n",
      "Cleaned Token After Stem =  login ; electron transcript budsir : buddhist scriptur inform retriev , cd-rom onlin , requir payment . sixth council tipiṭaka \n",
      "Cleaned Token Before =  to the change in context as the learner switches from encoding information to retrieval during testing. this account draws from the considerable evidence\n",
      "Cleaned Token After =  change context learner switches encoding information retrieval testing . account draws considerable evidence \n",
      "Cleaned Token After Stem =  chang context learner switch encod inform retriev test . account draw consider evid \n",
      "Cleaned Token Before =  instrument\" (pdf). proceedings of sixth international conference on music information retrieval, london, uk. 11. pp. 524–527. kilmer, anne draffkorn (1971). the\n",
      "Cleaned Token After =  instrument '' ( pdf ) . proceedings sixth international conference music information retrieval , london , uk . 11. pp . 524–527 . kilmer , anne draffkorn ( 1971 ) . \n",
      "Cleaned Token After Stem =  instrument `` ( pdf ) . proceed sixth intern confer music inform retriev , london , uk . 11. pp . 524–527 . kilmer , ann draffkorn ( 1971 ) . \n",
      "Cleaned Token Before =  leverage digital information resources. cirss members have expertise in digital preservation, interview methods, information retrieval, data and text mining\n",
      "Cleaned Token After =  leverage digital information resources . cirss members expertise digital preservation , interview methods , information retrieval , data text mining \n",
      "Cleaned Token After Stem =  leverag digit inform resourc . cirss member expertis digit preserv , interview method , inform retriev , data text mine \n",
      "Cleaned Token Before =  original thinker in information retrieval, quantum mechanics and computational linguistics.\" he wrote a sequential logic for information structuring in \"mathematics\n",
      "Cleaned Token After =  original thinker information retrieval , quantum mechanics computational linguistics . '' wrote sequential logic information structuring `` mathematics \n",
      "Cleaned Token After Stem =  origin thinker inform retriev , quantum mechan comput linguist . `` wrote sequenti logic inform structur `` mathemat \n",
      "Cleaned Token Before =  for years or even decades, it may be forgotten when the retrieval processes for that information fail. concerning unwanted memories, modern terminology\n",
      "Cleaned Token After =  years even decades , may forgotten retrieval processes information fail . concerning unwanted memories , modern terminology \n",
      "Cleaned Token After Stem =  year even decad , may forgotten retriev process inform fail . concern unwant memori , modern terminolog \n",
      "Cleaned Token Before =  retrieved october 30, 2008. \"microsoft corp acquires netcarta corp(cmg information) from cmgi inc\". thomson financial. february 3, 1997. archived from the\n",
      "Cleaned Token After =  retrieved october 30 , 2008 . `` microsoft corp acquires netcarta corp ( cmg information ) cmgi inc '' . thomson financial . february 3 , 1997. archived \n",
      "Cleaned Token After Stem =  retriev octob 30 , 2008 . `` microsoft corp acquir netcarta corp ( cmg inform ) cmgi inc `` . thomson financi . februari 3 , 1997. archiv \n",
      "Cleaned Token Before =  network of representations than mood incongruent information. retrieval - mood-congruent information is more likely to be retrieved from memory than other\n",
      "Cleaned Token After =  network representations mood incongruent information . retrieval - mood-congruent information likely retrieved memory \n",
      "Cleaned Token After Stem =  network represent mood incongru inform . retriev - mood-congru inform like retriev memori \n",
      "Cleaned Token Before =  input device, a musical multitouch controller lemur project, an information retrieval toolkit lemur may refer to: limbed excursion mechanical utility\n",
      "Cleaned Token After =  input device , musical multitouch controller lemur project , information retrieval toolkit lemur may refer : limbed excursion mechanical utility \n",
      "Cleaned Token After Stem =  input devic , music multitouch control lemur project , inform retriev toolkit lemur may refer : limb excurs mechan util \n",
      "Cleaned Token Before =  arctic archipelago: descriptions, illustrations, identification, and information retrieval. version: 15 november 2000. hedysarum boreale. usda nrcs plant guide\n",
      "Cleaned Token After =  arctic archipelago : descriptions , illustrations , identification , information retrieval . version : 15 november 2000. hedysarum boreale . usda nrcs plant guide \n",
      "Cleaned Token After Stem =  arctic archipelago : descript , illustr , identif , inform retriev . version : 15 novemb 2000. hedysarum boreal . usda nrc plant guid \n",
      "Cleaned Token Before =  identification, and information retrieval. in english, french, german, portuguese, and spanish. international legume database & information service: erythrina\n",
      "Cleaned Token After =  identification , information retrieval . english , french , german , portuguese , spanish . international legume database & information service : erythrina \n",
      "Cleaned Token After Stem =  identif , inform retriev . english , french , german , portugues , spanish . intern legum databas & inform servic : erythrina \n",
      "Cleaned Token Before =  principles and the records and information (rim) program; records and information creation and use; record storage, retrieval, conversion, and facilities;\n",
      "Cleaned Token After =  principles records information ( rim ) program ; records information creation use ; record storage , retrieval , conversion , facilities ; \n",
      "Cleaned Token After Stem =  principl record inform ( rim ) program ; record inform creation use ; record storag , retriev , convers , facil ; \n",
      "Cleaned Token Before =  flowering plants: descriptions, illustrations, identification, information retrieval. https://web.archive.org/web/20070103200438/http://delta-intkey\n",
      "Cleaned Token After =  flowering plants : descriptions , illustrations , identification , information retrieval . https : //web.archive.org/web/20070103200438/http : //delta-intkey \n",
      "Cleaned Token After Stem =  flower plant : descript , illustr , identif , inform retriev . http : //web.archive.org/web/20070103200438/http : //delta-intkey \n",
      "Cleaned Token Before =  similarity function. it is used for improving the performance of information retrieval and document clustering. in a similar line of research, random manhattan\n",
      "Cleaned Token After =  similarity function . used improving performance information retrieval document clustering . similar line research , random manhattan \n",
      "Cleaned Token After Stem =  similar function . use improv perform inform retriev document cluster . similar line research , random manhattan \n",
      "Cleaned Token Before =  for search (and similarity) results based on the principles of information retrieval (tf/idf) and presents results in a ux-driven search product. matthew\n",
      "Cleaned Token After =  search ( similarity ) results based principles information retrieval ( tf/idf ) presents results ux-driven search product . matthew \n",
      "Cleaned Token After Stem =  search ( similar ) result base principl inform retriev ( tf/idf ) present result ux-driven search product . matthew \n",
      "Cleaned Token Before =  results randomization/permutation tests to evaluate outcomes in information retrieval experiments (with and without adjustments for multiple comparisons)\n",
      "Cleaned Token After =  results randomization/permutation tests evaluate outcomes information retrieval experiments ( without adjustments multiple comparisons ) \n",
      "Cleaned Token After Stem =  result randomization/permut test evalu outcom inform retriev experi ( without adjust multipl comparison ) \n",
      "Cleaned Token Before =  of intelligent multimedia interfaces and intelligent multimedia information retrieval used the term personalcasting at an international conference on\n",
      "Cleaned Token After =  intelligent multimedia interfaces intelligent multimedia information retrieval used term personalcasting international conference \n",
      "Cleaned Token After Stem =  intellig multimedia interfac intellig multimedia inform retriev use term personalcast intern confer \n"
     ]
    }
   ],
   "source": [
    "# read data from csv\n",
    "df = pd.read_csv('data_wiki_articles.csv', sep=\",\")\n",
    "data = list(df[\"description\"].astype(str).str.lower())\n",
    "words_cleaned = []\n",
    "words_stemmed = []\n",
    "\n",
    "for i in data:\n",
    "    token = word_tokenize(i)\n",
    "    cleaned_token = \"\"\n",
    "    \n",
    "    for word in token:\n",
    "        if word not in stop_words:\n",
    "            cleaned_token += word +\" \"\n",
    "            \n",
    "    print('Cleaned Token Before = ',i)\n",
    "    print('Cleaned Token After = ', cleaned_token)\n",
    "    words_cleaned.append(cleaned_token)\n",
    "    token_stemming = word_tokenize(cleaned_token)\n",
    "    word_stemmed = \"\"\n",
    "    \n",
    "    for wstem in token_stemming:\n",
    "        word_stemmed += stemmer.stem(wstem) + \" \"\n",
    "    \n",
    "    print('Cleaned Token After Stem = ', word_stemmed)\n",
    "    words_stemmed.append(word_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>artificial intelligence ( ai ) intelligence de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a.i . artificial intelligence ( also known a.i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>artificial general intelligence ( agi ) hypoth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>artificial intelligence , defined intelligence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>artificial intelligence healthcare , known als...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>flowering plants : descriptions , illustration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>similarity function . used improving performan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>search ( similarity ) results based principles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>results randomization/permutation tests evalua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>intelligent multimedia interfaces intelligent ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   word\n",
       "0     artificial intelligence ( ai ) intelligence de...\n",
       "1     a.i . artificial intelligence ( also known a.i...\n",
       "2     artificial general intelligence ( agi ) hypoth...\n",
       "3     artificial intelligence , defined intelligence...\n",
       "4     artificial intelligence healthcare , known als...\n",
       "...                                                 ...\n",
       "3995  flowering plants : descriptions , illustration...\n",
       "3996  similarity function . used improving performan...\n",
       "3997  search ( similarity ) results based principles...\n",
       "3998  results randomization/permutation tests evalua...\n",
       "3999  intelligent multimedia interfaces intelligent ...\n",
       "\n",
       "[4000 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving to csv\n",
    "data_cleaned = {'word':words_cleaned}\n",
    "df = pd.DataFrame(data_cleaned)\n",
    "\n",
    "df.to_csv('data_wiki_articles_cleaned.csv',index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
